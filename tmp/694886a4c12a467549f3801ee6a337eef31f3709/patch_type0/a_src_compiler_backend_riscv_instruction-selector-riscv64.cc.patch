diff --git a/src/compiler/backend/riscv/instruction-selector-riscv64.cc b/src/compiler/backend/riscv/instruction-selector-riscv64.cc
index 3369833d47c..c564e6d40cc 100644
--- a/src/compiler/backend/riscv/instruction-selector-riscv64.cc
+++ b/src/compiler/backend/riscv/instruction-selector-riscv64.cc
@@ -14,7 +14,8 @@ namespace v8 {
 namespace internal {
 namespace compiler {
 
-bool RiscvOperandGenerator::IsIntegerConstant(Node* node) {
+template <typename Adapter>
+bool RiscvOperandGeneratorT<Adapter>::IsIntegerConstant(Node* node) {
   if (node->opcode() == IrOpcode::kNumberConstant) {
     const double value = OpParameter<double>(node->op());
     return base::bit_cast<int64_t>(value) == 0;
@@ -23,7 +24,8 @@ bool RiscvOperandGenerator::IsIntegerConstant(Node* node) {
          (node->opcode() == IrOpcode::kInt64Constant);
 }
 
-int64_t RiscvOperandGenerator::GetIntegerConstantValue(Node* node) {
+template <typename Adapter>
+int64_t RiscvOperandGeneratorT<Adapter>::GetIntegerConstantValue(Node* node) {
   if (node->opcode() == IrOpcode::kInt32Constant) {
     return OpParameter<int32_t>(node->op());
   } else if (node->opcode() == IrOpcode::kInt64Constant) {
@@ -35,8 +37,9 @@ int64_t RiscvOperandGenerator::GetIntegerConstantValue(Node* node) {
   return base::bit_cast<int64_t>(value);
 }
 
-bool RiscvOperandGenerator::CanBeImmediate(int64_t value,
-                                           InstructionCode opcode) {
+template <typename Adapter>
+bool RiscvOperandGeneratorT<Adapter>::CanBeImmediate(int64_t value,
+                                                     InstructionCode opcode) {
   switch (ArchOpcodeField::decode(opcode)) {
     case kRiscvShl32:
     case kRiscvSar32:
@@ -76,8 +79,9 @@ bool RiscvOperandGenerator::CanBeImmediate(int64_t value,
   }
 }
 
+template <typename Adapter>
 struct ExtendingLoadMatcher {
-  ExtendingLoadMatcher(Node* node, InstructionSelector* selector)
+  ExtendingLoadMatcher(Node* node, InstructionSelectorT<Adapter>* selector)
       : matches_(false), selector_(selector), base_(nullptr), immediate_(0) {
     Initialize(node);
   }
@@ -99,7 +103,7 @@ struct ExtendingLoadMatcher {
 
  private:
   bool matches_;
-  InstructionSelector* selector_;
+  InstructionSelectorT<Adapter>* selector_;
   Node* base_;
   int64_t immediate_;
   ArchOpcode opcode_;
@@ -124,7 +128,7 @@ struct ExtendingLoadMatcher {
         return;
       }
 
-      RiscvOperandGenerator g(selector_);
+      RiscvOperandGeneratorT<Adapter> g(selector_);
       Node* load = m.left().node();
       Node* offset = load->InputAt(1);
       base_ = load->InputAt(0);
@@ -141,10 +145,11 @@ struct ExtendingLoadMatcher {
   }
 };
 
-bool TryEmitExtendingLoad(InstructionSelector* selector, Node* node,
+template <typename Adapter>
+bool TryEmitExtendingLoad(InstructionSelectorT<Adapter>* selector, Node* node,
                           Node* output_node) {
-  ExtendingLoadMatcher m(node, selector);
-  RiscvOperandGenerator g(selector);
+  ExtendingLoadMatcher<Adapter> m(node, selector);
+  RiscvOperandGeneratorT<Adapter> g(selector);
   if (m.Matches()) {
     InstructionOperand inputs[2];
     inputs[0] = g.UseRegister(m.base());
@@ -160,9 +165,10 @@ bool TryEmitExtendingLoad(InstructionSelector* selector, Node* node,
   return false;
 }
 
-void EmitLoad(InstructionSelector* selector, Node* node, InstructionCode opcode,
-              Node* output = nullptr) {
-  RiscvOperandGenerator g(selector);
+template <typename Adapter>
+void EmitLoad(InstructionSelectorT<Adapter>* selector, Node* node,
+              InstructionCode opcode, Node* output = nullptr) {
+  RiscvOperandGeneratorT<Adapter> g(selector);
   Node* base = node->InputAt(0);
   Node* index = node->InputAt(1);
 
@@ -206,9 +212,10 @@ void EmitLoad(InstructionSelector* selector, Node* node, InstructionCode opcode,
   }
 }
 
-void EmitS128Load(InstructionSelector* selector, Node* node,
+template <typename Adapter>
+void EmitS128Load(InstructionSelectorT<Adapter>* selector, Node* node,
                   InstructionCode opcode, VSew sew, Vlmul lmul) {
-  RiscvOperandGenerator g(selector);
+  RiscvOperandGeneratorT<Adapter> g(selector);
   Node* base = node->InputAt(0);
   Node* index = node->InputAt(1);
 
@@ -228,13 +235,14 @@ void EmitS128Load(InstructionSelector* selector, Node* node,
   }
 }
 
-void InstructionSelector::VisitStoreLane(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitStoreLane(Node* node) {
   StoreLaneParameters params = StoreLaneParametersOf(node->op());
   LoadStoreLaneParams f(params.rep, params.laneidx);
   InstructionCode opcode = kRiscvS128StoreLane;
   opcode |= MiscField::encode(f.sz);
 
-  RiscvOperandGenerator g(this);
+  RiscvOperandGeneratorT<Adapter> g(this);
   Node* base = node->InputAt(0);
   Node* index = node->InputAt(1);
   InstructionOperand addr_reg = g.TempRegister();
@@ -248,13 +256,15 @@ void InstructionSelector::VisitStoreLane(Node* node) {
   opcode |= AddressingModeField::encode(kMode_MRI);
   Emit(opcode, 0, nullptr, 4, inputs);
 }
-void InstructionSelector::VisitLoadLane(Node* node) {
+
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitLoadLane(Node* node) {
   LoadLaneParameters params = LoadLaneParametersOf(node->op());
   LoadStoreLaneParams f(params.rep.representation(), params.laneidx);
   InstructionCode opcode = kRiscvS128LoadLane;
   opcode |= MiscField::encode(f.sz);
 
-  RiscvOperandGenerator g(this);
+  RiscvOperandGeneratorT<Adapter> g(this);
   Node* base = node->InputAt(0);
   Node* index = node->InputAt(1);
   InstructionOperand addr_reg = g.TempRegister();
@@ -264,7 +274,8 @@ void InstructionSelector::VisitLoadLane(Node* node) {
        g.UseImmediate(params.laneidx), addr_reg, g.TempImmediate(0));
 }
 
-void InstructionSelector::VisitLoad(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitLoad(Node* node) {
   LoadRepresentation load_rep = LoadRepresentationOf(node->op());
 
   InstructionCode opcode = kArchNop;
@@ -324,10 +335,14 @@ void InstructionSelector::VisitLoad(Node* node) {
   EmitLoad(this, node, opcode);
 }
 
-void InstructionSelector::VisitStorePair(Node* node) { UNREACHABLE(); }
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitStorePair(Node* node) {
+  UNREACHABLE();
+}
 
-void InstructionSelector::VisitStore(Node* node) {
-  RiscvOperandGenerator g(this);
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitStore(Node* node) {
+  RiscvOperandGeneratorT<Adapter> g(this);
   Node* base = node->InputAt(0);
   Node* index = node->InputAt(1);
   Node* value = node->InputAt(2);
@@ -420,12 +435,15 @@ void InstructionSelector::VisitStore(Node* node) {
   }
 }
 
-void InstructionSelector::VisitWord32And(Node* node) {
-  VisitBinop(this, node, kRiscvAnd32, true, kRiscvAnd32);
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitWord32And(Node* node) {
+  VisitBinop<Adapter, Int32BinopMatcher>(this, node, kRiscvAnd32, true,
+                                         kRiscvAnd32);
 }
 
-void InstructionSelector::VisitWord64And(Node* node) {
-  RiscvOperandGenerator g(this);
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitWord64And(Node* node) {
+  RiscvOperandGeneratorT<Adapter> g(this);
   Int64BinopMatcher m(node);
   if (m.left().IsWord64Shr() && CanCover(node, m.left().node()) &&
       m.right().HasResolvedValue()) {
@@ -458,24 +476,29 @@ void InstructionSelector::VisitWord64And(Node* node) {
       // Other cases fall through to the normal And operation.
     }
   }
-  VisitBinop(this, node, kRiscvAnd, true, kRiscvAnd);
+  VisitBinop<Adapter, Int64BinopMatcher>(this, node, kRiscvAnd, true,
+                                         kRiscvAnd);
 }
 
-void InstructionSelector::VisitWord32Or(Node* node) {
-  VisitBinop(this, node, kRiscvOr32, true, kRiscvOr32);
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitWord32Or(Node* node) {
+  VisitBinop<Adapter, Int32BinopMatcher>(this, node, kRiscvOr32, true,
+                                         kRiscvOr32);
 }
 
-void InstructionSelector::VisitWord64Or(Node* node) {
-  VisitBinop(this, node, kRiscvOr, true, kRiscvOr);
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitWord64Or(Node* node) {
+  VisitBinop<Adapter, Int64BinopMatcher>(this, node, kRiscvOr, true, kRiscvOr);
 }
 
-void InstructionSelector::VisitWord32Xor(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitWord32Xor(Node* node) {
   Int32BinopMatcher m(node);
   if (m.left().IsWord32Or() && CanCover(node, m.left().node()) &&
       m.right().Is(-1)) {
     Int32BinopMatcher mleft(m.left().node());
     if (!mleft.right().HasResolvedValue()) {
-      RiscvOperandGenerator g(this);
+      RiscvOperandGeneratorT<Adapter> g(this);
       Emit(kRiscvNor32, g.DefineAsRegister(node),
            g.UseRegister(mleft.left().node()),
            g.UseRegister(mleft.right().node()));
@@ -484,21 +507,23 @@ void InstructionSelector::VisitWord32Xor(Node* node) {
   }
   if (m.right().Is(-1)) {
     // Use Nor for bit negation and eliminate constant loading for xori.
-    RiscvOperandGenerator g(this);
+    RiscvOperandGeneratorT<Adapter> g(this);
     Emit(kRiscvNor32, g.DefineAsRegister(node), g.UseRegister(m.left().node()),
          g.TempImmediate(0));
     return;
   }
-  VisitBinop(this, node, kRiscvXor32, true, kRiscvXor32);
+  VisitBinop<Adapter, Int32BinopMatcher>(this, node, kRiscvXor32, true,
+                                         kRiscvXor32);
 }
 
-void InstructionSelector::VisitWord64Xor(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitWord64Xor(Node* node) {
   Int64BinopMatcher m(node);
   if (m.left().IsWord64Or() && CanCover(node, m.left().node()) &&
       m.right().Is(-1)) {
     Int64BinopMatcher mleft(m.left().node());
     if (!mleft.right().HasResolvedValue()) {
-      RiscvOperandGenerator g(this);
+      RiscvOperandGeneratorT<Adapter> g(this);
       Emit(kRiscvNor, g.DefineAsRegister(node),
            g.UseRegister(mleft.left().node()),
            g.UseRegister(mleft.right().node()));
@@ -507,16 +532,18 @@ void InstructionSelector::VisitWord64Xor(Node* node) {
   }
   if (m.right().Is(-1)) {
     // Use Nor for bit negation and eliminate constant loading for xori.
-    RiscvOperandGenerator g(this);
+    RiscvOperandGeneratorT<Adapter> g(this);
     Emit(kRiscvNor, g.DefineAsRegister(node), g.UseRegister(m.left().node()),
          g.TempImmediate(0));
     return;
   }
-  VisitBinop(this, node, kRiscvXor, true, kRiscvXor);
+  VisitBinop<Adapter, Int64BinopMatcher>(this, node, kRiscvXor, true,
+                                         kRiscvXor);
 }
 
-void InstructionSelector::VisitWord64Shl(Node* node) {
-  RiscvOperandGenerator g(this);
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitWord64Shl(Node* node) {
+  RiscvOperandGeneratorT<Adapter> g(this);
   Int64BinopMatcher m(node);
   if ((m.left().IsChangeInt32ToInt64() || m.left().IsChangeUint32ToUint64()) &&
       m.right().IsInRange(32, 63) && CanCover(node, m.left().node())) {
@@ -555,11 +582,13 @@ void InstructionSelector::VisitWord64Shl(Node* node) {
   VisitRRO(this, kRiscvShl64, node);
 }
 
-void InstructionSelector::VisitWord64Shr(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitWord64Shr(Node* node) {
   VisitRRO(this, kRiscvShr64, node);
 }
 
-void InstructionSelector::VisitWord64Sar(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitWord64Sar(Node* node) {
   if (TryEmitExtendingLoad(this, node, node)) return;
   Int64BinopMatcher m(node);
   if (m.left().IsChangeInt32ToInt64() && m.right().HasResolvedValue() &&
@@ -567,7 +596,7 @@ void InstructionSelector::VisitWord64Sar(Node* node) {
     if ((m.left().InputAt(0)->opcode() != IrOpcode::kLoad &&
          m.left().InputAt(0)->opcode() != IrOpcode::kLoadImmutable) ||
         !CanCover(m.left().node(), m.left().InputAt(0))) {
-      RiscvOperandGenerator g(this);
+      RiscvOperandGeneratorT<Adapter> g(this);
       Emit(kRiscvSar32, g.DefineAsRegister(node),
            g.UseRegister(m.left().node()->InputAt(0)),
            g.UseImmediate(m.right().node()));
@@ -577,86 +606,116 @@ void InstructionSelector::VisitWord64Sar(Node* node) {
   VisitRRO(this, kRiscvSar64, node);
 }
 
-void InstructionSelector::VisitWord32Rol(Node* node) { UNREACHABLE(); }
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitWord32Rol(Node* node) {
+  UNREACHABLE();
+}
 
-void InstructionSelector::VisitWord64Rol(Node* node) { UNREACHABLE(); }
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitWord64Rol(Node* node) {
+  UNREACHABLE();
+}
 
-void InstructionSelector::VisitWord32Ror(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitWord32Ror(Node* node) {
   VisitRRO(this, kRiscvRor32, node);
 }
 
-void InstructionSelector::VisitWord32Clz(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitWord32Clz(Node* node) {
   VisitRR(this, kRiscvClz32, node);
 }
 
-void InstructionSelector::VisitWord32ReverseBits(Node* node) { UNREACHABLE(); }
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitWord32ReverseBits(Node* node) {
+  UNREACHABLE();
+}
 
-void InstructionSelector::VisitWord64ReverseBits(Node* node) { UNREACHABLE(); }
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitWord64ReverseBits(Node* node) {
+  UNREACHABLE();
+}
 
-void InstructionSelector::VisitWord64ReverseBytes(Node* node) {
-  RiscvOperandGenerator g(this);
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitWord64ReverseBytes(Node* node) {
+  RiscvOperandGeneratorT<Adapter> g(this);
   Emit(kRiscvByteSwap64, g.DefineAsRegister(node),
        g.UseRegister(node->InputAt(0)));
 }
 
-void InstructionSelector::VisitWord32ReverseBytes(Node* node) {
-  RiscvOperandGenerator g(this);
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitWord32ReverseBytes(Node* node) {
+  RiscvOperandGeneratorT<Adapter> g(this);
   Emit(kRiscvByteSwap32, g.DefineAsRegister(node),
        g.UseRegister(node->InputAt(0)));
 }
 
-void InstructionSelector::VisitSimd128ReverseBytes(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitSimd128ReverseBytes(Node* node) {
   UNREACHABLE();
 }
 
-void InstructionSelector::VisitWord32Ctz(Node* node) {
-  RiscvOperandGenerator g(this);
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitWord32Ctz(Node* node) {
+  RiscvOperandGeneratorT<Adapter> g(this);
   Emit(kRiscvCtz32, g.DefineAsRegister(node), g.UseRegister(node->InputAt(0)));
 }
 
-void InstructionSelector::VisitWord64Ctz(Node* node) {
-  RiscvOperandGenerator g(this);
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitWord64Ctz(Node* node) {
+  RiscvOperandGeneratorT<Adapter> g(this);
   Emit(kRiscvCtz64, g.DefineAsRegister(node), g.UseRegister(node->InputAt(0)));
 }
 
-void InstructionSelector::VisitWord32Popcnt(Node* node) {
-  RiscvOperandGenerator g(this);
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitWord32Popcnt(Node* node) {
+  RiscvOperandGeneratorT<Adapter> g(this);
   Emit(kRiscvPopcnt32, g.DefineAsRegister(node),
        g.UseRegister(node->InputAt(0)));
 }
 
-void InstructionSelector::VisitWord64Popcnt(Node* node) {
-  RiscvOperandGenerator g(this);
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitWord64Popcnt(Node* node) {
+  RiscvOperandGeneratorT<Adapter> g(this);
   Emit(kRiscvPopcnt64, g.DefineAsRegister(node),
        g.UseRegister(node->InputAt(0)));
 }
 
-void InstructionSelector::VisitWord64Ror(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitWord64Ror(Node* node) {
   VisitRRO(this, kRiscvRor64, node);
 }
 
-void InstructionSelector::VisitWord64Clz(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitWord64Clz(Node* node) {
   VisitRR(this, kRiscvClz64, node);
 }
 
-void InstructionSelector::VisitInt32Add(Node* node) {
-  VisitBinop(this, node, kRiscvAdd32, true, kRiscvAdd32);
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitInt32Add(Node* node) {
+  VisitBinop<Adapter, Int32BinopMatcher>(this, node, kRiscvAdd32, true,
+                                         kRiscvAdd32);
 }
 
-void InstructionSelector::VisitInt64Add(Node* node) {
-  VisitBinop(this, node, kRiscvAdd64, true, kRiscvAdd64);
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitInt64Add(Node* node) {
+  VisitBinop<Adapter, Int64BinopMatcher>(this, node, kRiscvAdd64, true,
+                                         kRiscvAdd64);
 }
 
-void InstructionSelector::VisitInt32Sub(Node* node) {
-  VisitBinop(this, node, kRiscvSub32);
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitInt32Sub(Node* node) {
+  VisitBinop<Adapter, Int32BinopMatcher>(this, node, kRiscvSub32);
 }
 
-void InstructionSelector::VisitInt64Sub(Node* node) {
-  VisitBinop(this, node, kRiscvSub64);
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitInt64Sub(Node* node) {
+  VisitBinop<Adapter, Int64BinopMatcher>(this, node, kRiscvSub64);
 }
 
-void InstructionSelector::VisitInt32Mul(Node* node) {
-  RiscvOperandGenerator g(this);
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitInt32Mul(Node* node) {
+  RiscvOperandGeneratorT<Adapter> g(this);
   Int32BinopMatcher m(node);
   if (m.right().HasResolvedValue() && m.right().ResolvedValue() > 0) {
     uint32_t value = static_cast<uint32_t>(m.right().ResolvedValue());
@@ -694,24 +753,29 @@ void InstructionSelector::VisitInt32Mul(Node* node) {
   VisitRRR(this, kRiscvMul32, node);
 }
 
-void InstructionSelector::VisitInt32MulHigh(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitInt32MulHigh(Node* node) {
   VisitRRR(this, kRiscvMulHigh32, node);
 }
 
-void InstructionSelector::VisitInt64MulHigh(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitInt64MulHigh(Node* node) {
   VisitRRR(this, kRiscvMulHigh64, node);
 }
 
-void InstructionSelector::VisitUint32MulHigh(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitUint32MulHigh(Node* node) {
   VisitRRR(this, kRiscvMulHighU32, node);
 }
 
-void InstructionSelector::VisitUint64MulHigh(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitUint64MulHigh(Node* node) {
   VisitRRR(this, kRiscvMulHighU64, node);
 }
 
-void InstructionSelector::VisitInt64Mul(Node* node) {
-  RiscvOperandGenerator g(this);
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitInt64Mul(Node* node) {
+  RiscvOperandGeneratorT<Adapter> g(this);
   Int64BinopMatcher m(node);
   // TODO(dusmil): Add optimization for shifts larger than 32.
   if (m.right().HasResolvedValue() && m.right().ResolvedValue() > 0) {
@@ -736,8 +800,9 @@ void InstructionSelector::VisitInt64Mul(Node* node) {
        g.UseRegister(m.right().node()));
 }
 
-void InstructionSelector::VisitInt32Div(Node* node) {
-  RiscvOperandGenerator g(this);
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitInt32Div(Node* node) {
+  RiscvOperandGeneratorT<Adapter> g(this);
   Int32BinopMatcher m(node);
   Node* left = node->InputAt(0);
   Node* right = node->InputAt(1);
@@ -758,15 +823,17 @@ void InstructionSelector::VisitInt32Div(Node* node) {
        g.UseRegister(m.right().node()));
 }
 
-void InstructionSelector::VisitUint32Div(Node* node) {
-  RiscvOperandGenerator g(this);
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitUint32Div(Node* node) {
+  RiscvOperandGeneratorT<Adapter> g(this);
   Int32BinopMatcher m(node);
   Emit(kRiscvDivU32, g.DefineSameAsFirst(node), g.UseRegister(m.left().node()),
        g.UseRegister(m.right().node()));
 }
 
-void InstructionSelector::VisitInt32Mod(Node* node) {
-  RiscvOperandGenerator g(this);
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitInt32Mod(Node* node) {
+  RiscvOperandGeneratorT<Adapter> g(this);
   Int32BinopMatcher m(node);
   Node* left = node->InputAt(0);
   Node* right = node->InputAt(1);
@@ -787,67 +854,79 @@ void InstructionSelector::VisitInt32Mod(Node* node) {
        g.UseRegister(m.right().node()));
 }
 
-void InstructionSelector::VisitUint32Mod(Node* node) {
-  RiscvOperandGenerator g(this);
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitUint32Mod(Node* node) {
+  RiscvOperandGeneratorT<Adapter> g(this);
   Int32BinopMatcher m(node);
   Emit(kRiscvModU32, g.DefineAsRegister(node), g.UseRegister(m.left().node()),
        g.UseRegister(m.right().node()));
 }
 
-void InstructionSelector::VisitInt64Div(Node* node) {
-  RiscvOperandGenerator g(this);
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitInt64Div(Node* node) {
+  RiscvOperandGeneratorT<Adapter> g(this);
   Int64BinopMatcher m(node);
   Emit(kRiscvDiv64, g.DefineSameAsFirst(node), g.UseRegister(m.left().node()),
        g.UseRegister(m.right().node()));
 }
 
-void InstructionSelector::VisitUint64Div(Node* node) {
-  RiscvOperandGenerator g(this);
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitUint64Div(Node* node) {
+  RiscvOperandGeneratorT<Adapter> g(this);
   Int64BinopMatcher m(node);
   Emit(kRiscvDivU64, g.DefineSameAsFirst(node), g.UseRegister(m.left().node()),
        g.UseRegister(m.right().node()));
 }
 
-void InstructionSelector::VisitInt64Mod(Node* node) {
-  RiscvOperandGenerator g(this);
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitInt64Mod(Node* node) {
+  RiscvOperandGeneratorT<Adapter> g(this);
   Int64BinopMatcher m(node);
   Emit(kRiscvMod64, g.DefineAsRegister(node), g.UseRegister(m.left().node()),
        g.UseRegister(m.right().node()));
 }
 
-void InstructionSelector::VisitUint64Mod(Node* node) {
-  RiscvOperandGenerator g(this);
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitUint64Mod(Node* node) {
+  RiscvOperandGeneratorT<Adapter> g(this);
   Int64BinopMatcher m(node);
   Emit(kRiscvModU64, g.DefineAsRegister(node), g.UseRegister(m.left().node()),
        g.UseRegister(m.right().node()));
 }
 
-void InstructionSelector::VisitChangeFloat32ToFloat64(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitChangeFloat32ToFloat64(Node* node) {
   VisitRR(this, kRiscvCvtDS, node);
 }
 
-void InstructionSelector::VisitRoundInt32ToFloat32(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitRoundInt32ToFloat32(Node* node) {
   VisitRR(this, kRiscvCvtSW, node);
 }
 
-void InstructionSelector::VisitRoundUint32ToFloat32(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitRoundUint32ToFloat32(Node* node) {
   VisitRR(this, kRiscvCvtSUw, node);
 }
 
-void InstructionSelector::VisitChangeInt32ToFloat64(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitChangeInt32ToFloat64(Node* node) {
   VisitRR(this, kRiscvCvtDW, node);
 }
 
-void InstructionSelector::VisitChangeInt64ToFloat64(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitChangeInt64ToFloat64(Node* node) {
   VisitRR(this, kRiscvCvtDL, node);
 }
 
-void InstructionSelector::VisitChangeUint32ToFloat64(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitChangeUint32ToFloat64(Node* node) {
   VisitRR(this, kRiscvCvtDUw, node);
 }
 
-void InstructionSelector::VisitTruncateFloat32ToInt32(Node* node) {
-  RiscvOperandGenerator g(this);
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitTruncateFloat32ToInt32(Node* node) {
+  RiscvOperandGeneratorT<Adapter> g(this);
   InstructionCode opcode = kRiscvTruncWS;
   TruncateKind kind = OpParameter<TruncateKind>(node->op());
   if (kind == TruncateKind::kSetOverflowToMin) {
@@ -856,8 +935,9 @@ void InstructionSelector::VisitTruncateFloat32ToInt32(Node* node) {
   Emit(opcode, g.DefineAsRegister(node), g.UseRegister(node->InputAt(0)));
 }
 
-void InstructionSelector::VisitTruncateFloat32ToUint32(Node* node) {
-  RiscvOperandGenerator g(this);
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitTruncateFloat32ToUint32(Node* node) {
+  RiscvOperandGeneratorT<Adapter> g(this);
   InstructionCode opcode = kRiscvTruncUwS;
   TruncateKind kind = OpParameter<TruncateKind>(node->op());
   if (kind == TruncateKind::kSetOverflowToMin) {
@@ -866,8 +946,9 @@ void InstructionSelector::VisitTruncateFloat32ToUint32(Node* node) {
   Emit(opcode, g.DefineAsRegister(node), g.UseRegister(node->InputAt(0)));
 }
 
-void InstructionSelector::VisitChangeFloat64ToInt32(Node* node) {
-  RiscvOperandGenerator g(this);
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitChangeFloat64ToInt32(Node* node) {
+  RiscvOperandGeneratorT<Adapter> g(this);
   Node* value = node->InputAt(0);
   // Match ChangeFloat64ToInt32(Float64Round##OP) to corresponding instruction
   // which does rounding and conversion to integer format.
@@ -929,8 +1010,9 @@ void InstructionSelector::VisitChangeFloat64ToInt32(Node* node) {
   VisitRR(this, kRiscvTruncWD, node);
 }
 
-void InstructionSelector::VisitTryTruncateFloat64ToInt32(Node* node) {
-  RiscvOperandGenerator g(this);
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitTryTruncateFloat64ToInt32(Node* node) {
+  RiscvOperandGeneratorT<Adapter> g(this);
   InstructionOperand inputs[] = {g.UseRegister(node->InputAt(0))};
   InstructionOperand outputs[2];
   size_t output_count = 0;
@@ -944,8 +1026,10 @@ void InstructionSelector::VisitTryTruncateFloat64ToInt32(Node* node) {
   this->Emit(kRiscvTruncWD, output_count, outputs, 1, inputs);
 }
 
-void InstructionSelector::VisitTryTruncateFloat64ToUint32(Node* node) {
-  RiscvOperandGenerator g(this);
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitTryTruncateFloat64ToUint32(
+    Node* node) {
+  RiscvOperandGeneratorT<Adapter> g(this);
   InstructionOperand inputs[] = {g.UseRegister(node->InputAt(0))};
   InstructionOperand outputs[2];
   size_t output_count = 0;
@@ -959,24 +1043,29 @@ void InstructionSelector::VisitTryTruncateFloat64ToUint32(Node* node) {
   Emit(kRiscvTruncUwD, output_count, outputs, 1, inputs);
 }
 
-void InstructionSelector::VisitChangeFloat64ToInt64(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitChangeFloat64ToInt64(Node* node) {
   VisitRR(this, kRiscvTruncLD, node);
 }
 
-void InstructionSelector::VisitChangeFloat64ToUint32(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitChangeFloat64ToUint32(Node* node) {
   VisitRR(this, kRiscvTruncUwD, node);
 }
 
-void InstructionSelector::VisitChangeFloat64ToUint64(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitChangeFloat64ToUint64(Node* node) {
   VisitRR(this, kRiscvTruncUlD, node);
 }
 
-void InstructionSelector::VisitTruncateFloat64ToUint32(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitTruncateFloat64ToUint32(Node* node) {
   VisitRR(this, kRiscvTruncUwD, node);
 }
 
-void InstructionSelector::VisitTruncateFloat64ToInt64(Node* node) {
-  RiscvOperandGenerator g(this);
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitTruncateFloat64ToInt64(Node* node) {
+  RiscvOperandGeneratorT<Adapter> g(this);
   InstructionCode opcode = kRiscvTruncLD;
   TruncateKind kind = OpParameter<TruncateKind>(node->op());
   if (kind == TruncateKind::kSetOverflowToMin) {
@@ -985,8 +1074,9 @@ void InstructionSelector::VisitTruncateFloat64ToInt64(Node* node) {
   Emit(opcode, g.DefineAsRegister(node), g.UseRegister(node->InputAt(0)));
 }
 
-void InstructionSelector::VisitTryTruncateFloat32ToInt64(Node* node) {
-  RiscvOperandGenerator g(this);
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitTryTruncateFloat32ToInt64(Node* node) {
+  RiscvOperandGeneratorT<Adapter> g(this);
   InstructionOperand inputs[] = {g.UseRegister(node->InputAt(0))};
   InstructionOperand outputs[2];
   size_t output_count = 0;
@@ -1000,8 +1090,9 @@ void InstructionSelector::VisitTryTruncateFloat32ToInt64(Node* node) {
   this->Emit(kRiscvTruncLS, output_count, outputs, 1, inputs);
 }
 
-void InstructionSelector::VisitTryTruncateFloat64ToInt64(Node* node) {
-  RiscvOperandGenerator g(this);
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitTryTruncateFloat64ToInt64(Node* node) {
+  RiscvOperandGeneratorT<Adapter> g(this);
   InstructionOperand inputs[] = {g.UseRegister(node->InputAt(0))};
   InstructionOperand outputs[2];
   size_t output_count = 0;
@@ -1015,8 +1106,10 @@ void InstructionSelector::VisitTryTruncateFloat64ToInt64(Node* node) {
   Emit(kRiscvTruncLD, output_count, outputs, 1, inputs);
 }
 
-void InstructionSelector::VisitTryTruncateFloat32ToUint64(Node* node) {
-  RiscvOperandGenerator g(this);
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitTryTruncateFloat32ToUint64(
+    Node* node) {
+  RiscvOperandGeneratorT<Adapter> g(this);
   InstructionOperand inputs[] = {g.UseRegister(node->InputAt(0))};
   InstructionOperand outputs[2];
   size_t output_count = 0;
@@ -1030,8 +1123,10 @@ void InstructionSelector::VisitTryTruncateFloat32ToUint64(Node* node) {
   Emit(kRiscvTruncUlS, output_count, outputs, 1, inputs);
 }
 
-void InstructionSelector::VisitTryTruncateFloat64ToUint64(Node* node) {
-  RiscvOperandGenerator g(this);
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitTryTruncateFloat64ToUint64(
+    Node* node) {
+  RiscvOperandGeneratorT<Adapter> g(this);
 
   InstructionOperand inputs[] = {g.UseRegister(node->InputAt(0))};
   InstructionOperand outputs[2];
@@ -1046,22 +1141,25 @@ void InstructionSelector::VisitTryTruncateFloat64ToUint64(Node* node) {
   Emit(kRiscvTruncUlD, output_count, outputs, 1, inputs);
 }
 
-void InstructionSelector::VisitBitcastWord32ToWord64(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitBitcastWord32ToWord64(Node* node) {
   DCHECK(SmiValuesAre31Bits());
   DCHECK(COMPRESS_POINTERS_BOOL);
-  RiscvOperandGenerator g(this);
+  RiscvOperandGeneratorT<Adapter> g(this);
   Emit(kRiscvZeroExtendWord, g.DefineAsRegister(node),
        g.UseRegister(node->InputAt(0)));
 }
 
-void EmitSignExtendWord(InstructionSelector* selector, Node* node) {
-  RiscvOperandGenerator g(selector);
+template <typename Adapter>
+void EmitSignExtendWord(InstructionSelectorT<Adapter>* selector, Node* node) {
+  RiscvOperandGeneratorT<Adapter> g(selector);
   Node* value = node->InputAt(0);
   selector->Emit(kRiscvSignExtendWord, g.DefineAsRegister(node),
                  g.UseRegister(value));
 }
 
-void InstructionSelector::VisitChangeInt32ToInt64(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitChangeInt32ToInt64(Node* node) {
   Node* value = node->InputAt(0);
   if ((value->opcode() == IrOpcode::kLoad ||
        value->opcode() == IrOpcode::kLoadImmutable) &&
@@ -1098,7 +1196,9 @@ void InstructionSelector::VisitChangeInt32ToInt64(Node* node) {
   }
 }
 
-bool InstructionSelector::ZeroExtendsWord32ToWord64NoPhis(Node* node) {
+template <typename Adapter>
+bool InstructionSelectorT<Adapter>::ZeroExtendsWord32ToWord64NoPhis(
+    Node* node) {
   DCHECK_NE(node->opcode(), IrOpcode::kPhi);
   if (node->opcode() == IrOpcode::kLoad ||
       node->opcode() == IrOpcode::kLoadImmutable) {
@@ -1118,8 +1218,9 @@ bool InstructionSelector::ZeroExtendsWord32ToWord64NoPhis(Node* node) {
   return false;
 }
 
-void InstructionSelector::VisitChangeUint32ToUint64(Node* node) {
-  RiscvOperandGenerator g(this);
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitChangeUint32ToUint64(Node* node) {
+  RiscvOperandGeneratorT<Adapter> g(this);
   Node* value = node->InputAt(0);
   if (ZeroExtendsWord32ToWord64(value)) {
     Emit(kArchNop, g.DefineSameAsFirst(node), g.Use(value));
@@ -1129,8 +1230,9 @@ void InstructionSelector::VisitChangeUint32ToUint64(Node* node) {
        g.UseRegister(node->InputAt(0)));
 }
 
-void InstructionSelector::VisitTruncateInt64ToInt32(Node* node) {
-  RiscvOperandGenerator g(this);
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitTruncateInt64ToInt32(Node* node) {
+  RiscvOperandGeneratorT<Adapter> g(this);
   Node* value = node->InputAt(0);
   if (CanCover(node, value)) {
     switch (value->opcode()) {
@@ -1162,97 +1264,118 @@ void InstructionSelector::VisitTruncateInt64ToInt32(Node* node) {
        g.UseRegister(node->InputAt(0)), g.TempImmediate(0));
 }
 
-void InstructionSelector::VisitRoundInt64ToFloat32(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitRoundInt64ToFloat32(Node* node) {
   VisitRR(this, kRiscvCvtSL, node);
 }
 
-void InstructionSelector::VisitRoundInt64ToFloat64(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitRoundInt64ToFloat64(Node* node) {
   VisitRR(this, kRiscvCvtDL, node);
 }
 
-void InstructionSelector::VisitRoundUint64ToFloat32(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitRoundUint64ToFloat32(Node* node) {
   VisitRR(this, kRiscvCvtSUl, node);
 }
 
-void InstructionSelector::VisitRoundUint64ToFloat64(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitRoundUint64ToFloat64(Node* node) {
   VisitRR(this, kRiscvCvtDUl, node);
 }
 
-void InstructionSelector::VisitBitcastFloat32ToInt32(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitBitcastFloat32ToInt32(Node* node) {
   VisitRR(this, kRiscvBitcastFloat32ToInt32, node);
 }
 
-void InstructionSelector::VisitBitcastFloat64ToInt64(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitBitcastFloat64ToInt64(Node* node) {
   VisitRR(this, kRiscvBitcastDL, node);
 }
 
-void InstructionSelector::VisitBitcastInt32ToFloat32(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitBitcastInt32ToFloat32(Node* node) {
   VisitRR(this, kRiscvBitcastInt32ToFloat32, node);
 }
 
-void InstructionSelector::VisitBitcastInt64ToFloat64(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitBitcastInt64ToFloat64(Node* node) {
   VisitRR(this, kRiscvBitcastLD, node);
 }
 
-void InstructionSelector::VisitFloat64RoundDown(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitFloat64RoundDown(Node* node) {
   VisitRR(this, kRiscvFloat64RoundDown, node);
 }
 
-void InstructionSelector::VisitFloat32RoundUp(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitFloat32RoundUp(Node* node) {
   VisitRR(this, kRiscvFloat32RoundUp, node);
 }
 
-void InstructionSelector::VisitFloat64RoundUp(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitFloat64RoundUp(Node* node) {
   VisitRR(this, kRiscvFloat64RoundUp, node);
 }
 
-void InstructionSelector::VisitFloat32RoundTruncate(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitFloat32RoundTruncate(Node* node) {
   VisitRR(this, kRiscvFloat32RoundTruncate, node);
 }
 
-void InstructionSelector::VisitFloat64RoundTruncate(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitFloat64RoundTruncate(Node* node) {
   VisitRR(this, kRiscvFloat64RoundTruncate, node);
 }
 
-void InstructionSelector::VisitFloat64RoundTiesAway(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitFloat64RoundTiesAway(Node* node) {
   UNREACHABLE();
 }
 
-void InstructionSelector::VisitFloat32RoundTiesEven(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitFloat32RoundTiesEven(Node* node) {
   VisitRR(this, kRiscvFloat32RoundTiesEven, node);
 }
 
-void InstructionSelector::VisitFloat64RoundTiesEven(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitFloat64RoundTiesEven(Node* node) {
   VisitRR(this, kRiscvFloat64RoundTiesEven, node);
 }
 
-void InstructionSelector::VisitFloat32Neg(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitFloat32Neg(Node* node) {
   VisitRR(this, kRiscvNegS, node);
 }
 
-void InstructionSelector::VisitFloat64Neg(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitFloat64Neg(Node* node) {
   VisitRR(this, kRiscvNegD, node);
 }
 
-void InstructionSelector::VisitFloat64Ieee754Binop(Node* node,
-                                                   InstructionCode opcode) {
-  RiscvOperandGenerator g(this);
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitFloat64Ieee754Binop(
+    Node* node, InstructionCode opcode) {
+  RiscvOperandGeneratorT<Adapter> g(this);
   Emit(opcode, g.DefineAsFixed(node, fa0), g.UseFixed(node->InputAt(0), fa0),
        g.UseFixed(node->InputAt(1), fa1))
       ->MarkAsCall();
 }
 
-void InstructionSelector::VisitFloat64Ieee754Unop(Node* node,
-                                                  InstructionCode opcode) {
-  RiscvOperandGenerator g(this);
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitFloat64Ieee754Unop(
+    Node* node, InstructionCode opcode) {
+  RiscvOperandGeneratorT<Adapter> g(this);
   Emit(opcode, g.DefineAsFixed(node, fa0), g.UseFixed(node->InputAt(0), fa1))
       ->MarkAsCall();
 }
 
-void InstructionSelector::EmitPrepareArguments(
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::EmitPrepareArguments(
     ZoneVector<PushParameter>* arguments, const CallDescriptor* call_descriptor,
     Node* node) {
-  RiscvOperandGenerator g(this);
+  RiscvOperandGeneratorT<Adapter> g(this);
 
   // Prepare for C function call.
   if (call_descriptor->IsCFunctionCall()) {
@@ -1290,9 +1413,10 @@ void InstructionSelector::EmitPrepareArguments(
   }
 }
 
-void InstructionSelector::VisitUnalignedLoad(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitUnalignedLoad(Node* node) {
   LoadRepresentation load_rep = LoadRepresentationOf(node->op());
-  RiscvOperandGenerator g(this);
+  RiscvOperandGeneratorT<Adapter> g(this);
   Node* base = node->InputAt(0);
   Node* index = node->InputAt(1);
 
@@ -1345,8 +1469,9 @@ void InstructionSelector::VisitUnalignedLoad(Node* node) {
   }
 }
 
-void InstructionSelector::VisitUnalignedStore(Node* node) {
-  RiscvOperandGenerator g(this);
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitUnalignedStore(Node* node) {
+  RiscvOperandGeneratorT<Adapter> g(this);
   Node* base = node->InputAt(0);
   Node* index = node->InputAt(1);
   Node* value = node->InputAt(2);
@@ -1425,9 +1550,10 @@ bool IsNodeUnsigned(Node* n) {
 #endif
 
 // Shared routine for multiple word compare operations.
-void VisitFullWord32Compare(InstructionSelector* selector, Node* node,
+template <typename Adapter>
+void VisitFullWord32Compare(InstructionSelectorT<Adapter>* selector, Node* node,
                             InstructionCode opcode, FlagsContinuation* cont) {
-  RiscvOperandGenerator g(selector);
+  RiscvOperandGeneratorT<Adapter> g(selector);
   InstructionOperand leftOp = g.TempRegister();
   InstructionOperand rightOp = g.TempRegister();
 
@@ -1440,11 +1566,12 @@ void VisitFullWord32Compare(InstructionSelector* selector, Node* node,
 }
 
 #ifndef V8_COMPRESS_POINTERS
-void VisitOptimizedWord32Compare(InstructionSelector* selector, Node* node,
-                                 InstructionCode opcode,
+template <typename Adapter>
+void VisitOptimizedWord32Compare(InstructionSelectorT<Adapter>* selector,
+                                 Node* node, InstructionCode opcode,
                                  FlagsContinuation* cont) {
   if (v8_flags.debug_code) {
-    RiscvOperandGenerator g(selector);
+    RiscvOperandGeneratorT<Adapter> g(selector);
     InstructionOperand leftOp = g.TempRegister();
     InstructionOperand rightOp = g.TempRegister();
     InstructionOperand optimizedResult = g.TempRegister();
@@ -1471,7 +1598,8 @@ void VisitOptimizedWord32Compare(InstructionSelector* selector, Node* node,
   VisitWordCompare(selector, node, opcode, cont, false);
 }
 #endif
-void VisitWord32Compare(InstructionSelector* selector, Node* node,
+template <typename Adapter>
+void VisitWord32Compare(InstructionSelectorT<Adapter>* selector, Node* node,
                         FlagsContinuation* cont) {
   // RISC-V doesn't support Word32 compare instructions. Instead it relies
   // that the values in registers are correctly sign-extended and uses
@@ -1506,14 +1634,16 @@ void VisitWord32Compare(InstructionSelector* selector, Node* node,
 #endif
 }
 
-void VisitWord64Compare(InstructionSelector* selector, Node* node,
+template <typename Adapter>
+void VisitWord64Compare(InstructionSelectorT<Adapter>* selector, Node* node,
                         FlagsContinuation* cont) {
   VisitWordCompare(selector, node, kRiscvCmp, cont, false);
 }
 
-void VisitAtomicLoad(InstructionSelector* selector, Node* node,
+template <typename Adapter>
+void VisitAtomicLoad(InstructionSelectorT<Adapter>* selector, Node* node,
                      AtomicWidth width) {
-  RiscvOperandGenerator g(selector);
+  RiscvOperandGeneratorT<Adapter> g(selector);
   Node* base = node->InputAt(0);
   Node* index = node->InputAt(1);
 
@@ -1572,9 +1702,10 @@ void VisitAtomicLoad(InstructionSelector* selector, Node* node,
   }
 }
 
-void VisitAtomicStore(InstructionSelector* selector, Node* node,
+template <typename Adapter>
+void VisitAtomicStore(InstructionSelectorT<Adapter>* selector, Node* node,
                       AtomicWidth width) {
-  RiscvOperandGenerator g(selector);
+  RiscvOperandGeneratorT<Adapter> g(selector);
   Node* base = node->InputAt(0);
   Node* index = node->InputAt(1);
   Node* value = node->InputAt(2);
@@ -1652,9 +1783,10 @@ void VisitAtomicStore(InstructionSelector* selector, Node* node,
   }
 }
 
-void VisitAtomicBinop(InstructionSelector* selector, Node* node,
+template <typename Adapter>
+void VisitAtomicBinop(InstructionSelectorT<Adapter>* selector, Node* node,
                       ArchOpcode opcode, AtomicWidth width) {
-  RiscvOperandGenerator g(selector);
+  RiscvOperandGeneratorT<Adapter> g(selector);
   Node* base = node->InputAt(0);
   Node* index = node->InputAt(1);
   Node* value = node->InputAt(2);
@@ -1679,13 +1811,14 @@ void VisitAtomicBinop(InstructionSelector* selector, Node* node,
 
 }  // namespace
 
-void InstructionSelector::VisitStackPointerGreaterThan(
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitStackPointerGreaterThan(
     Node* node, FlagsContinuation* cont) {
   StackCheckKind kind = StackCheckKindOf(node->op());
   InstructionCode opcode =
       kArchStackPointerGreaterThan | MiscField::encode(static_cast<int>(kind));
 
-  RiscvOperandGenerator g(this);
+  RiscvOperandGeneratorT<Adapter> g(this);
 
   // No outputs.
   InstructionOperand* const outputs = nullptr;
@@ -1721,8 +1854,9 @@ bool CanCoverTrap(Node* user, Node* value) {
   return true;
 }
 // Shared routine for word comparisons against zero.
-void InstructionSelector::VisitWordCompareZero(Node* user, Node* value,
-                                               FlagsContinuation* cont) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitWordCompareZero(
+    Node* user, Node* value, FlagsContinuation* cont) {
   // Try to combine with comparisons against 0 by simply inverting the branch.
   while (CanCover(user, value)) {
     if (value->opcode() == IrOpcode::kWord32Equal) {
@@ -1806,19 +1940,24 @@ void InstructionSelector::VisitWordCompareZero(Node* user, Node* value,
             switch (node->opcode()) {
               case IrOpcode::kInt32AddWithOverflow:
                 cont->OverwriteAndNegateIfEqual(kOverflow);
-                return VisitBinop(this, node, kRiscvAdd64, cont);
+                return VisitBinop<Adapter, Int32BinopMatcher>(
+                    this, node, kRiscvAdd64, cont);
               case IrOpcode::kInt32SubWithOverflow:
                 cont->OverwriteAndNegateIfEqual(kOverflow);
-                return VisitBinop(this, node, kRiscvSub64, cont);
+                return VisitBinop<Adapter, Int32BinopMatcher>(
+                    this, node, kRiscvSub64, cont);
               case IrOpcode::kInt32MulWithOverflow:
                 cont->OverwriteAndNegateIfEqual(kOverflow);
-                return VisitBinop(this, node, kRiscvMulOvf32, cont);
+                return VisitBinop<Adapter, Int32BinopMatcher>(
+                    this, node, kRiscvMulOvf32, cont);
               case IrOpcode::kInt64AddWithOverflow:
                 cont->OverwriteAndNegateIfEqual(kOverflow);
-                return VisitBinop(this, node, kRiscvAddOvf64, cont);
+                return VisitBinop<Adapter, Int32BinopMatcher>(
+                    this, node, kRiscvAddOvf64, cont);
               case IrOpcode::kInt64SubWithOverflow:
                 cont->OverwriteAndNegateIfEqual(kOverflow);
-                return VisitBinop(this, node, kRiscvSubOvf64, cont);
+                return VisitBinop<Adapter, Int32BinopMatcher>(
+                    this, node, kRiscvSubOvf64, cont);
               default:
                 break;
             }
@@ -1843,7 +1982,8 @@ void InstructionSelector::VisitWordCompareZero(Node* user, Node* value,
   EmitWordCompareZero(this, value, cont);
 }
 
-void InstructionSelector::VisitWord32Equal(Node* const node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitWord32Equal(Node* const node) {
   FlagsContinuation cont = FlagsContinuation::ForSet(kEqual, node);
   Int32BinopMatcher m(node);
   if (m.right().Is(0)) {
@@ -1851,7 +1991,7 @@ void InstructionSelector::VisitWord32Equal(Node* const node) {
   }
   if (isolate() && (V8_STATIC_ROOTS_BOOL ||
                     (COMPRESS_POINTERS_BOOL && !isolate()->bootstrapper()))) {
-    RiscvOperandGenerator g(this);
+    RiscvOperandGeneratorT<Adapter> g(this);
     const RootsTable& roots_table = isolate()->roots_table();
     RootIndex root_index;
     Node* left = nullptr;
@@ -1887,74 +2027,89 @@ void InstructionSelector::VisitWord32Equal(Node* const node) {
   VisitWord32Compare(this, node, &cont);
 }
 
-void InstructionSelector::VisitInt32LessThan(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitInt32LessThan(Node* node) {
   FlagsContinuation cont = FlagsContinuation::ForSet(kSignedLessThan, node);
   VisitWord32Compare(this, node, &cont);
 }
 
-void InstructionSelector::VisitInt32LessThanOrEqual(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitInt32LessThanOrEqual(Node* node) {
   FlagsContinuation cont =
       FlagsContinuation::ForSet(kSignedLessThanOrEqual, node);
   VisitWord32Compare(this, node, &cont);
 }
 
-void InstructionSelector::VisitUint32LessThan(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitUint32LessThan(Node* node) {
   FlagsContinuation cont = FlagsContinuation::ForSet(kUnsignedLessThan, node);
   VisitWord32Compare(this, node, &cont);
 }
 
-void InstructionSelector::VisitUint32LessThanOrEqual(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitUint32LessThanOrEqual(Node* node) {
   FlagsContinuation cont =
       FlagsContinuation::ForSet(kUnsignedLessThanOrEqual, node);
   VisitWord32Compare(this, node, &cont);
 }
 
-void InstructionSelector::VisitInt32AddWithOverflow(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitInt32AddWithOverflow(Node* node) {
   if (Node* ovf = NodeProperties::FindProjection(node, 1)) {
     FlagsContinuation cont = FlagsContinuation::ForSet(kOverflow, ovf);
-    return VisitBinop(this, node, kRiscvAdd64, &cont);
+    return VisitBinop<Adapter, Int32BinopMatcher>(this, node, kRiscvAdd64,
+                                                  &cont);
   }
   FlagsContinuation cont;
-  VisitBinop(this, node, kRiscvAdd64, &cont);
+  VisitBinop<Adapter, Int32BinopMatcher>(this, node, kRiscvAdd64, &cont);
 }
 
-void InstructionSelector::VisitInt32SubWithOverflow(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitInt32SubWithOverflow(Node* node) {
   if (Node* ovf = NodeProperties::FindProjection(node, 1)) {
     FlagsContinuation cont = FlagsContinuation::ForSet(kOverflow, ovf);
-    return VisitBinop(this, node, kRiscvSub64, &cont);
+    return VisitBinop<Adapter, Int32BinopMatcher>(this, node, kRiscvSub64,
+                                                  &cont);
   }
   FlagsContinuation cont;
-  VisitBinop(this, node, kRiscvSub64, &cont);
+  VisitBinop<Adapter, Int32BinopMatcher>(this, node, kRiscvSub64, &cont);
 }
 
-void InstructionSelector::VisitInt32MulWithOverflow(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitInt32MulWithOverflow(Node* node) {
   if (Node* ovf = NodeProperties::FindProjection(node, 1)) {
     FlagsContinuation cont = FlagsContinuation::ForSet(kOverflow, ovf);
-    return VisitBinop(this, node, kRiscvMulOvf32, &cont);
+    return VisitBinop<Adapter, Int32BinopMatcher>(this, node, kRiscvMulOvf32,
+                                                  &cont);
   }
   FlagsContinuation cont;
-  VisitBinop(this, node, kRiscvMulOvf32, &cont);
+  VisitBinop<Adapter, Int32BinopMatcher>(this, node, kRiscvMulOvf32, &cont);
 }
 
-void InstructionSelector::VisitInt64AddWithOverflow(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitInt64AddWithOverflow(Node* node) {
   if (Node* ovf = NodeProperties::FindProjection(node, 1)) {
     FlagsContinuation cont = FlagsContinuation::ForSet(kOverflow, ovf);
-    return VisitBinop(this, node, kRiscvAddOvf64, &cont);
+    return VisitBinop<Adapter, Int64BinopMatcher>(this, node, kRiscvAddOvf64,
+                                                  &cont);
   }
   FlagsContinuation cont;
-  VisitBinop(this, node, kRiscvAddOvf64, &cont);
+  VisitBinop<Adapter, Int64BinopMatcher>(this, node, kRiscvAddOvf64, &cont);
 }
 
-void InstructionSelector::VisitInt64SubWithOverflow(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitInt64SubWithOverflow(Node* node) {
   if (Node* ovf = NodeProperties::FindProjection(node, 1)) {
     FlagsContinuation cont = FlagsContinuation::ForSet(kOverflow, ovf);
-    return VisitBinop(this, node, kRiscvSubOvf64, &cont);
+    return VisitBinop<Adapter, Int64BinopMatcher>(this, node, kRiscvSubOvf64,
+                                                  &cont);
   }
   FlagsContinuation cont;
-  VisitBinop(this, node, kRiscvSubOvf64, &cont);
+  VisitBinop<Adapter, Int64BinopMatcher>(this, node, kRiscvSubOvf64, &cont);
 }
 
-void InstructionSelector::VisitInt64MulWithOverflow(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitInt64MulWithOverflow(Node* node) {
   if (Node* ovf = NodeProperties::FindProjection(node, 1)) {
     // RISCV64 doesn't set the overflow flag for multiplication, so we need to
     // test on kNotEqual. Here is the code sequence used:
@@ -1963,13 +2118,15 @@ void InstructionSelector::VisitInt64MulWithOverflow(Node* node) {
     //   srai temp, rdl, 63
     //   xor overflow, rdl, temp
     FlagsContinuation cont = FlagsContinuation::ForSet(kNotEqual, ovf);
-    return VisitBinop(this, node, kRiscvMulOvf64, &cont);
+    return VisitBinop<Adapter, Int64BinopMatcher>(this, node, kRiscvMulOvf64,
+                                                  &cont);
   }
   FlagsContinuation cont;
-  VisitBinop(this, node, kRiscvMulOvf64, &cont);
+  VisitBinop<Adapter, Int64BinopMatcher>(this, node, kRiscvMulOvf64, &cont);
 }
 
-void InstructionSelector::VisitWord64Equal(Node* const node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitWord64Equal(Node* const node) {
   FlagsContinuation cont = FlagsContinuation::ForSet(kEqual, node);
   Int64BinopMatcher m(node);
   if (m.right().Is(0)) {
@@ -1979,45 +2136,54 @@ void InstructionSelector::VisitWord64Equal(Node* const node) {
   VisitWord64Compare(this, node, &cont);
 }
 
-void InstructionSelector::VisitInt64LessThan(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitInt64LessThan(Node* node) {
   FlagsContinuation cont = FlagsContinuation::ForSet(kSignedLessThan, node);
   VisitWord64Compare(this, node, &cont);
 }
 
-void InstructionSelector::VisitInt64LessThanOrEqual(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitInt64LessThanOrEqual(Node* node) {
   FlagsContinuation cont =
       FlagsContinuation::ForSet(kSignedLessThanOrEqual, node);
   VisitWord64Compare(this, node, &cont);
 }
 
-void InstructionSelector::VisitUint64LessThan(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitUint64LessThan(Node* node) {
   FlagsContinuation cont = FlagsContinuation::ForSet(kUnsignedLessThan, node);
   VisitWord64Compare(this, node, &cont);
 }
 
-void InstructionSelector::VisitUint64LessThanOrEqual(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitUint64LessThanOrEqual(Node* node) {
   FlagsContinuation cont =
       FlagsContinuation::ForSet(kUnsignedLessThanOrEqual, node);
   VisitWord64Compare(this, node, &cont);
 }
 
-void InstructionSelector::VisitWord32AtomicLoad(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitWord32AtomicLoad(Node* node) {
   VisitAtomicLoad(this, node, AtomicWidth::kWord32);
 }
 
-void InstructionSelector::VisitWord32AtomicStore(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitWord32AtomicStore(Node* node) {
   VisitAtomicStore(this, node, AtomicWidth::kWord32);
 }
 
-void InstructionSelector::VisitWord64AtomicLoad(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitWord64AtomicLoad(Node* node) {
   VisitAtomicLoad(this, node, AtomicWidth::kWord64);
 }
 
-void InstructionSelector::VisitWord64AtomicStore(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitWord64AtomicStore(Node* node) {
   VisitAtomicStore(this, node, AtomicWidth::kWord64);
 }
 
-void InstructionSelector::VisitWord32AtomicExchange(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitWord32AtomicExchange(Node* node) {
   ArchOpcode opcode;
   MachineType type = AtomicOpType(node->op());
   if (type == MachineType::Int8()) {
@@ -2037,7 +2203,8 @@ void InstructionSelector::VisitWord32AtomicExchange(Node* node) {
   VisitAtomicExchange(this, node, opcode, AtomicWidth::kWord32);
 }
 
-void InstructionSelector::VisitWord64AtomicExchange(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitWord64AtomicExchange(Node* node) {
   ArchOpcode opcode;
   MachineType type = AtomicOpType(node->op());
   if (type == MachineType::Uint8()) {
@@ -2054,7 +2221,9 @@ void InstructionSelector::VisitWord64AtomicExchange(Node* node) {
   VisitAtomicExchange(this, node, opcode, AtomicWidth::kWord64);
 }
 
-void InstructionSelector::VisitWord32AtomicCompareExchange(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitWord32AtomicCompareExchange(
+    Node* node) {
   ArchOpcode opcode;
   MachineType type = AtomicOpType(node->op());
   if (type == MachineType::Int8()) {
@@ -2074,7 +2243,9 @@ void InstructionSelector::VisitWord32AtomicCompareExchange(Node* node) {
   VisitAtomicCompareExchange(this, node, opcode, AtomicWidth::kWord32);
 }
 
-void InstructionSelector::VisitWord64AtomicCompareExchange(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitWord64AtomicCompareExchange(
+    Node* node) {
   ArchOpcode opcode;
   MachineType type = AtomicOpType(node->op());
   if (type == MachineType::Uint8()) {
@@ -2090,7 +2261,8 @@ void InstructionSelector::VisitWord64AtomicCompareExchange(Node* node) {
   }
   VisitAtomicCompareExchange(this, node, opcode, AtomicWidth::kWord64);
 }
-void InstructionSelector::VisitWord32AtomicBinaryOperation(
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitWord32AtomicBinaryOperation(
     Node* node, ArchOpcode int8_op, ArchOpcode uint8_op, ArchOpcode int16_op,
     ArchOpcode uint16_op, ArchOpcode word32_op) {
   ArchOpcode opcode;
@@ -2112,11 +2284,12 @@ void InstructionSelector::VisitWord32AtomicBinaryOperation(
   VisitAtomicBinop(this, node, opcode, AtomicWidth::kWord32);
 }
 
-#define VISIT_ATOMIC_BINOP(op)                                           \
-  void InstructionSelector::VisitWord32Atomic##op(Node* node) {          \
-    VisitWord32AtomicBinaryOperation(                                    \
-        node, kAtomic##op##Int8, kAtomic##op##Uint8, kAtomic##op##Int16, \
-        kAtomic##op##Uint16, kAtomic##op##Word32);                       \
+#define VISIT_ATOMIC_BINOP(op)                                            \
+  template <typename Adapter>                                             \
+  void InstructionSelectorT<Adapter>::VisitWord32Atomic##op(Node* node) { \
+    VisitWord32AtomicBinaryOperation(                                     \
+        node, kAtomic##op##Int8, kAtomic##op##Uint8, kAtomic##op##Int16,  \
+        kAtomic##op##Uint16, kAtomic##op##Word32);                        \
   }
 VISIT_ATOMIC_BINOP(Add)
 VISIT_ATOMIC_BINOP(Sub)
@@ -2125,7 +2298,8 @@ VISIT_ATOMIC_BINOP(Or)
 VISIT_ATOMIC_BINOP(Xor)
 #undef VISIT_ATOMIC_BINOP
 
-void InstructionSelector::VisitWord64AtomicBinaryOperation(
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitWord64AtomicBinaryOperation(
     Node* node, ArchOpcode uint8_op, ArchOpcode uint16_op, ArchOpcode uint32_op,
     ArchOpcode uint64_op) {
   ArchOpcode opcode;
@@ -2145,7 +2319,8 @@ void InstructionSelector::VisitWord64AtomicBinaryOperation(
 }
 
 #define VISIT_ATOMIC_BINOP(op)                                                 \
-  void InstructionSelector::VisitWord64Atomic##op(Node* node) {                \
+  template <typename Adapter>                                                  \
+  void InstructionSelectorT<Adapter>::VisitWord64Atomic##op(Node* node) {      \
     VisitWord64AtomicBinaryOperation(node, kAtomic##op##Uint8,                 \
                                      kAtomic##op##Uint16, kAtomic##op##Word32, \
                                      kRiscvWord64Atomic##op##Uint64);          \
@@ -2157,33 +2332,39 @@ VISIT_ATOMIC_BINOP(Or)
 VISIT_ATOMIC_BINOP(Xor)
 #undef VISIT_ATOMIC_BINOP
 
-void InstructionSelector::VisitInt32AbsWithOverflow(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitInt32AbsWithOverflow(Node* node) {
   UNREACHABLE();
 }
 
-void InstructionSelector::VisitInt64AbsWithOverflow(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitInt64AbsWithOverflow(Node* node) {
   UNREACHABLE();
 }
 
-void InstructionSelector::VisitSignExtendWord8ToInt64(Node* node) {
-  RiscvOperandGenerator g(this);
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitSignExtendWord8ToInt64(Node* node) {
+  RiscvOperandGeneratorT<Adapter> g(this);
   Emit(kRiscvSignExtendByte, g.DefineAsRegister(node),
        g.UseRegister(node->InputAt(0)));
 }
 
-void InstructionSelector::VisitSignExtendWord16ToInt64(Node* node) {
-  RiscvOperandGenerator g(this);
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitSignExtendWord16ToInt64(Node* node) {
+  RiscvOperandGeneratorT<Adapter> g(this);
   Emit(kRiscvSignExtendShort, g.DefineAsRegister(node),
        g.UseRegister(node->InputAt(0)));
 }
 
-void InstructionSelector::VisitSignExtendWord32ToInt64(Node* node) {
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitSignExtendWord32ToInt64(Node* node) {
   EmitSignExtendWord(this, node);
 }
 
 // static
+template <typename Adapter>
 MachineOperatorBuilder::Flags
-InstructionSelector::SupportedMachineOperatorFlags() {
+InstructionSelectorT<Adapter>::SupportedMachineOperatorFlags() {
   MachineOperatorBuilder::Flags flags = MachineOperatorBuilder::kNoFlags;
   return flags | MachineOperatorBuilder::kWord32Ctz |
          MachineOperatorBuilder::kWord64Ctz |
@@ -2204,6 +2385,11 @@ InstructionSelector::SupportedMachineOperatorFlags() {
 #undef TRACE_UNIMPL
 #undef TRACE
 
+template class EXPORT_TEMPLATE_DEFINE(V8_EXPORT_PRIVATE)
+    InstructionSelectorT<TurbofanAdapter>;
+template class EXPORT_TEMPLATE_DEFINE(V8_EXPORT_PRIVATE)
+    InstructionSelectorT<TurboshaftAdapter>;
+
 }  // namespace compiler
 }  // namespace internal
 }  // namespace v8
-- 
2.35.1

