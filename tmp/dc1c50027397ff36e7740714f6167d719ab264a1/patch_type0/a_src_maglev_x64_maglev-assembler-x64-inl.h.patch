diff --git a/src/maglev/x64/maglev-assembler-x64-inl.h b/src/maglev/x64/maglev-assembler-x64-inl.h
index 3973d7ca6c7..23dc13d03aa 100644
--- a/src/maglev/x64/maglev-assembler-x64-inl.h
+++ b/src/maglev/x64/maglev-assembler-x64-inl.h
@@ -232,31 +232,10 @@ inline void MaglevAssembler::BindBlock(BasicBlock* block) {
   bind(block->label());
 }
 
-inline void MaglevAssembler::DoubleToInt64Repr(Register dst,
-                                               DoubleRegister src) {
-  Movq(dst, src);
-}
-
-inline void MaglevAssembler::SmiTagInt32(Register obj, Label* fail) {
-  addl(obj, obj);
-  if (fail != nullptr) {
-    JumpIf(kOverflow, fail);
-  } else if (v8_flags.debug_code) {
-    Check(kNoOverflow, AbortReason::kInputDoesNotFitSmi);
-  }
-}
-
-inline void MaglevAssembler::SmiTagUint32(Register obj, Label* fail) {
-  // Perform an unsigned comparison against Smi::kMaxValue.
-  if (fail != nullptr) {
-    cmpl(obj, Immediate(Smi::kMaxValue));
-    JumpIf(kUnsignedGreaterThan, fail);
-  } else if (v8_flags.debug_code) {
-    cmpl(obj, Immediate(Smi::kMaxValue));
-    Check(kUnsignedLessThanEqual, AbortReason::kInputDoesNotFitSmi);
-  }
-  addl(obj, obj);
-  Assert(kNoOverflow, AbortReason::kInputDoesNotFitSmi);
+inline void MaglevAssembler::SmiTagInt32AndSetFlags(Register dst,
+                                                    Register src) {
+  Move(dst, src);
+  addl(dst, dst);
 }
 
 inline void MaglevAssembler::CheckInt32IsSmi(Register obj, Label* fail,
@@ -269,11 +248,8 @@ inline void MaglevAssembler::CheckInt32IsSmi(Register obj, Label* fail,
   JumpIf(kOverflow, fail);
 }
 
-inline Condition MaglevAssembler::IsInt64Constant(Register reg,
-                                                  int64_t constant) {
-  movq(kScratchRegister, constant);
-  cmpq(reg, kScratchRegister);
-  return equal;
+inline void MaglevAssembler::MoveHeapNumber(Register dst, double value) {
+  movq_heap_number(dst, value);
 }
 
 inline Condition MaglevAssembler::IsRootConstant(Input input,
@@ -699,6 +675,24 @@ void MaglevAssembler::JumpIfByte(Condition cc, Register value, int32_t byte,
   j(cc, target, distance);
 }
 
+void MaglevAssembler::JumpIfHoleNan(DoubleRegister value, Register scratch,
+                                    Label* target, Label::Distance distance) {
+  Movq(scratch, value);
+  movq(kScratchRegister, kHoleNanInt64);
+  cmpq(scratch, kScratchRegister);
+  JumpIf(kEqual, target, distance);
+}
+
+void MaglevAssembler::JumpIfNotHoleNan(MemOperand operand, Label* target,
+                                       Label::Distance distance) {
+  MaglevAssembler::ScratchRegisterScope temps(this);
+  Register repr = temps.Acquire();
+  movq(repr, operand);
+  movq(kScratchRegister, kHoleNanInt64);
+  cmpq(repr, kScratchRegister);
+  JumpIf(kNotEqual, target, distance);
+}
+
 void MaglevAssembler::CompareInt32AndJumpIf(Register r1, Register r2,
                                             Condition cond, Label* target,
                                             Label::Distance distance) {
@@ -798,94 +792,6 @@ inline void MaglevAssembler::EmitEagerDeoptIfNotEqual(DeoptimizeReason reason,
   EmitEagerDeoptIf(not_equal, reason, node);
 }
 
-inline void MaglevAssembler::MaterialiseValueNode(Register dst,
-                                                  ValueNode* value) {
-  switch (value->opcode()) {
-    case Opcode::kInt32Constant: {
-      int32_t int_value = value->Cast<Int32Constant>()->value();
-      if (Smi::IsValid(int_value)) {
-        Move(dst, Smi::FromInt(int_value));
-      } else {
-        movq_heap_number(dst, int_value);
-      }
-      return;
-    }
-    case Opcode::kFloat64Constant: {
-      double double_value =
-          value->Cast<Float64Constant>()->value().get_scalar();
-      movq_heap_number(dst, double_value);
-      return;
-    }
-    default:
-      break;
-  }
-
-  DCHECK(!value->allocation().IsConstant());
-  DCHECK(value->allocation().IsAnyStackSlot());
-  using D = NewHeapNumberDescriptor;
-  DoubleRegister builtin_input_value = D::GetDoubleRegisterParameter(D::kValue);
-  MemOperand src = ToMemOperand(value->allocation());
-  switch (value->properties().value_representation()) {
-    case ValueRepresentation::kInt32: {
-      Label done;
-      movl(dst, src);
-      addl(dst, dst);
-      j(no_overflow, &done, Label::kNear);
-      // If we overflow, instead of bailing out (deopting), we change
-      // representation to a HeapNumber.
-      Cvtlsi2sd(builtin_input_value, src);
-      CallBuiltin<Builtin::kNewHeapNumber>(builtin_input_value);
-      Move(dst, kReturnRegister0);
-      bind(&done);
-      break;
-    }
-    case ValueRepresentation::kUint32: {
-      Label done, tag_smi;
-      movl(dst, src);
-      // Unsigned comparison against Smi::kMaxValue.
-      cmpl(dst, Immediate(Smi::kMaxValue));
-      // If we don't fit in a Smi, instead of bailing out (deopting), we
-      // change representation to a HeapNumber.
-      j(below_equal, &tag_smi, Label::kNear);
-      // The value was loaded with movl, so is zero extended in 64-bit.
-      // Therefore, we can do an unsigned 32-bit converstion to double with a
-      // 64-bit signed conversion (Cvt_q_si2sd instead of Cvt_l_si2sd).
-      Cvtqsi2sd(builtin_input_value, dst);
-      CallBuiltin<Builtin::kNewHeapNumber>(builtin_input_value);
-      Move(dst, kReturnRegister0);
-      jmp(&done, Label::kNear);
-      bind(&tag_smi);
-      SmiTag(dst);
-      bind(&done);
-      break;
-    }
-    case ValueRepresentation::kFloat64:
-      Movsd(builtin_input_value, src);
-      CallBuiltin<Builtin::kNewHeapNumber>(builtin_input_value);
-      Move(dst, kReturnRegister0);
-      break;
-    case ValueRepresentation::kHoleyFloat64: {
-      Label done, box;
-      movq(dst, src);
-      JumpIf(NegateCondition(IsInt64Constant(dst, kHoleNanInt64)), &box,
-             Label::kNear);
-      LoadRoot(dst, RootIndex::kUndefinedValue);
-      jmp(&done, Label::kNear);
-
-      bind(&box);
-      Movq(builtin_input_value, dst);
-      CallBuiltin<Builtin::kNewHeapNumber>(builtin_input_value);
-      Move(dst, kReturnRegister0);
-
-      bind(&done);
-      break;
-    }
-    case ValueRepresentation::kWord64:
-    case ValueRepresentation::kTagged:
-      UNREACHABLE();
-  }
-}
-
 inline void MaglevAssembler::AssertStackSizeCorrect() {
   if (v8_flags.debug_code) {
     movq(kScratchRegister, rbp);
-- 
2.35.1

