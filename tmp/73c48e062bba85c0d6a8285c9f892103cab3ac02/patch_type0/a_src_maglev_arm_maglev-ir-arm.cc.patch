diff --git a/src/maglev/arm/maglev-ir-arm.cc b/src/maglev/arm/maglev-ir-arm.cc
index dea4fab32b6..dd6444b83d6 100644
--- a/src/maglev/arm/maglev-ir-arm.cc
+++ b/src/maglev/arm/maglev-ir-arm.cc
@@ -741,7 +741,7 @@ enum class ReduceInterruptBudgetType { kLoop, kReturn };
 
 void HandleInterruptsAndTiering(MaglevAssembler* masm, ZoneLabelRef done,
                                 Node* node, ReduceInterruptBudgetType type,
-                                Register scratch0) {
+                                Input function) {
   // For loops, first check for interrupts. Don't do this for returns, as we
   // can't lazy deopt to the end of a return.
   if (type == ReduceInterruptBudgetType::kLoop) {
@@ -749,7 +749,8 @@ void HandleInterruptsAndTiering(MaglevAssembler* masm, ZoneLabelRef done,
     // Here, we only care about interrupts since we've already guarded against
     // real stack overflows on function entry.
     {
-      Register stack_limit = scratch0;
+      MaglevAssembler::ScratchRegisterScope temps(masm);
+      Register stack_limit = temps.Acquire();
       __ LoadStackLimit(stack_limit, StackLimitKind::kInterruptStackLimit);
       __ cmp(sp, stack_limit);
       __ b(hi, &next);
@@ -761,11 +762,9 @@ void HandleInterruptsAndTiering(MaglevAssembler* masm, ZoneLabelRef done,
     {
       SaveRegisterStateForCall save_register_state(masm,
                                                    node->register_snapshot());
-      Register function = scratch0;
-      __ ldr(function, MemOperand(fp, StandardFrameConstants::kFunctionOffset));
       __ Push(function);
-      // Move into kContextRegister after the load into scratch0, just in case
-      // scratch0 happens to be kContextRegister.
+      // Move into kContextRegister after the push, in case that one clobbers
+      // kContextRegister.
       __ Move(kContextRegister, masm->native_context().object());
       __ CallRuntime(Runtime::kBytecodeBudgetInterruptWithStackCheck_Maglev, 1);
       save_register_state.DefineSafepointWithLazyDeopt(node->lazy_deopt_info());
@@ -778,11 +777,9 @@ void HandleInterruptsAndTiering(MaglevAssembler* masm, ZoneLabelRef done,
   {
     SaveRegisterStateForCall save_register_state(masm,
                                                  node->register_snapshot());
-    Register function = scratch0;
-    __ ldr(function, MemOperand(fp, StandardFrameConstants::kFunctionOffset));
     __ Push(function);
-    // Move into kContextRegister after the load into scratch0, just in case
-    // scratch0 happens to be kContextRegister.
+    // Move into kContextRegister after the push, in case that one clobbers
+    // kContextRegister.
     __ Move(kContextRegister, masm->native_context().object());
     // Note: must not cause a lazy deopt!
     __ CallRuntime(Runtime::kBytecodeBudgetInterrupt_Maglev, 1);
@@ -792,24 +789,27 @@ void HandleInterruptsAndTiering(MaglevAssembler* masm, ZoneLabelRef done,
 }
 
 void GenerateReduceInterruptBudget(MaglevAssembler* masm, Node* node,
-                                   ReduceInterruptBudgetType type, int amount) {
-  MaglevAssembler::ScratchRegisterScope temps(masm);
-  Register scratch = temps.Acquire();
-  Register feedback_cell = scratch;
-  Register budget = temps.Acquire();
-  __ ldr(feedback_cell,
-         MemOperand(fp, StandardFrameConstants::kFunctionOffset));
-  __ LoadTaggedField(
-      feedback_cell,
-      FieldMemOperand(feedback_cell, JSFunction::kFeedbackCellOffset));
-  __ ldr(budget,
-         FieldMemOperand(feedback_cell, FeedbackCell::kInterruptBudgetOffset));
-  __ sub(budget, budget, Operand(amount));
-  __ str(budget,
-         FieldMemOperand(feedback_cell, FeedbackCell::kInterruptBudgetOffset));
+                                   ReduceInterruptBudgetType type, int amount,
+                                   Input& function) {
+  {
+    MaglevAssembler::ScratchRegisterScope temps(masm);
+    Register scratch = temps.Acquire();
+    Register feedback_cell = scratch;
+    Register budget = temps.Acquire();
+    __ ldr(feedback_cell,
+           MemOperand(fp, StandardFrameConstants::kFunctionOffset));
+    __ LoadTaggedField(
+        feedback_cell,
+        FieldMemOperand(feedback_cell, JSFunction::kFeedbackCellOffset));
+    __ ldr(budget, FieldMemOperand(feedback_cell,
+                                   FeedbackCell::kInterruptBudgetOffset));
+    __ sub(budget, budget, Operand(amount));
+    __ str(budget, FieldMemOperand(feedback_cell,
+                                   FeedbackCell::kInterruptBudgetOffset));
+  }
   ZoneLabelRef done(masm);
   __ JumpToDeferredIf(lt, HandleInterruptsAndTiering, done, node, type,
-                      scratch);
+                      function);
   __ bind(*done);
 }
 
@@ -817,22 +817,24 @@ void GenerateReduceInterruptBudget(MaglevAssembler* masm, Node* node,
 
 int ReduceInterruptBudgetForLoop::MaxCallStackArgs() const { return 1; }
 void ReduceInterruptBudgetForLoop::SetValueLocationConstraints() {
+  UseAny(function());
   set_temporaries_needed(2);
 }
 void ReduceInterruptBudgetForLoop::GenerateCode(MaglevAssembler* masm,
                                                 const ProcessingState& state) {
   GenerateReduceInterruptBudget(masm, this, ReduceInterruptBudgetType::kLoop,
-                                amount());
+                                amount(), function());
 }
 
 int ReduceInterruptBudgetForReturn::MaxCallStackArgs() const { return 1; }
 void ReduceInterruptBudgetForReturn::SetValueLocationConstraints() {
+  UseAny(function());
   set_temporaries_needed(2);
 }
 void ReduceInterruptBudgetForReturn::GenerateCode(
     MaglevAssembler* masm, const ProcessingState& state) {
   GenerateReduceInterruptBudget(masm, this, ReduceInterruptBudgetType::kReturn,
-                                amount());
+                                amount(), function());
 }
 
 int FunctionEntryStackCheck::MaxCallStackArgs() const { return 1; }
