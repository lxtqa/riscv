diff --git a/src/codegen/ppc/macro-assembler-ppc.cc b/src/codegen/ppc/macro-assembler-ppc.cc
index c45a843aed..c4fa474f73 100644
--- a/src/codegen/ppc/macro-assembler-ppc.cc
+++ b/src/codegen/ppc/macro-assembler-ppc.cc
@@ -55,7 +55,7 @@ constexpr int kStackSavedSavedFPSizeInBytes =
 
 }  // namespace
 
-int TurboAssembler::RequiredStackSizeForCallerSaved(SaveFPRegsMode fp_mode,
+int MacroAssembler::RequiredStackSizeForCallerSaved(SaveFPRegsMode fp_mode,
                                                     Register exclusion1,
                                                     Register exclusion2,
                                                     Register exclusion3) const {
@@ -72,7 +72,7 @@ int TurboAssembler::RequiredStackSizeForCallerSaved(SaveFPRegsMode fp_mode,
   return bytes;
 }
 
-int TurboAssembler::PushCallerSaved(SaveFPRegsMode fp_mode, Register scratch1,
+int MacroAssembler::PushCallerSaved(SaveFPRegsMode fp_mode, Register scratch1,
                                     Register scratch2, Register exclusion1,
                                     Register exclusion2, Register exclusion3) {
   int bytes = 0;
@@ -91,7 +91,7 @@ int TurboAssembler::PushCallerSaved(SaveFPRegsMode fp_mode, Register scratch1,
   return bytes;
 }
 
-int TurboAssembler::PopCallerSaved(SaveFPRegsMode fp_mode, Register scratch1,
+int MacroAssembler::PopCallerSaved(SaveFPRegsMode fp_mode, Register scratch1,
                                    Register scratch2, Register exclusion1,
                                    Register exclusion2, Register exclusion3) {
   int bytes = 0;
@@ -109,12 +109,12 @@ int TurboAssembler::PopCallerSaved(SaveFPRegsMode fp_mode, Register scratch1,
   return bytes;
 }
 
-void TurboAssembler::Jump(Register target) {
+void MacroAssembler::Jump(Register target) {
   mtctr(target);
   bctr();
 }
 
-void TurboAssembler::LoadFromConstantsTable(Register destination,
+void MacroAssembler::LoadFromConstantsTable(Register destination,
                                             int constant_index) {
   DCHECK(RootsTable::IsImmortalImmovable(RootIndex::kBuiltinsConstantsTable));
 
@@ -127,11 +127,11 @@ void TurboAssembler::LoadFromConstantsTable(Register destination,
       r0);
 }
 
-void TurboAssembler::LoadRootRelative(Register destination, int32_t offset) {
+void MacroAssembler::LoadRootRelative(Register destination, int32_t offset) {
   LoadU64(destination, MemOperand(kRootRegister, offset), r0);
 }
 
-void TurboAssembler::LoadRootRegisterOffset(Register destination,
+void MacroAssembler::LoadRootRegisterOffset(Register destination,
                                             intptr_t offset) {
   if (offset == 0) {
     mr(destination, kRootRegister);
@@ -140,7 +140,7 @@ void TurboAssembler::LoadRootRegisterOffset(Register destination,
   }
 }
 
-MemOperand TurboAssembler::ExternalReferenceAsOperand(
+MemOperand MacroAssembler::ExternalReferenceAsOperand(
     ExternalReference reference, Register scratch) {
   if (root_array_available_ && options().enable_root_relative_access) {
     int64_t offset =
@@ -170,7 +170,7 @@ MemOperand TurboAssembler::ExternalReferenceAsOperand(
   return MemOperand(scratch, 0);
 }
 
-void TurboAssembler::Jump(intptr_t target, RelocInfo::Mode rmode,
+void MacroAssembler::Jump(intptr_t target, RelocInfo::Mode rmode,
                           Condition cond, CRegister cr) {
   Label skip;
 
@@ -183,13 +183,13 @@ void TurboAssembler::Jump(intptr_t target, RelocInfo::Mode rmode,
   bind(&skip);
 }
 
-void TurboAssembler::Jump(Address target, RelocInfo::Mode rmode, Condition cond,
+void MacroAssembler::Jump(Address target, RelocInfo::Mode rmode, Condition cond,
                           CRegister cr) {
   DCHECK(!RelocInfo::IsCodeTarget(rmode));
   Jump(static_cast<intptr_t>(target), rmode, cond, cr);
 }
 
-void TurboAssembler::Jump(Handle<Code> code, RelocInfo::Mode rmode,
+void MacroAssembler::Jump(Handle<Code> code, RelocInfo::Mode rmode,
                           Condition cond, CRegister cr) {
   DCHECK(RelocInfo::IsCodeTarget(rmode));
   DCHECK_IMPLIES(options().isolate_independent_code,
@@ -204,7 +204,7 @@ void TurboAssembler::Jump(Handle<Code> code, RelocInfo::Mode rmode,
   Jump(static_cast<intptr_t>(target_index), rmode, cond, cr);
 }
 
-void TurboAssembler::Jump(const ExternalReference& reference) {
+void MacroAssembler::Jump(const ExternalReference& reference) {
   UseScratchRegisterScope temps(this);
   Register scratch = temps.Acquire();
   Move(scratch, reference);
@@ -218,7 +218,7 @@ void TurboAssembler::Jump(const ExternalReference& reference) {
   Jump(scratch);
 }
 
-void TurboAssembler::Call(Register target) {
+void MacroAssembler::Call(Register target) {
   BlockTrampolinePoolScope block_trampoline_pool(this);
   // branch via link register and set LK bit for return point
   mtctr(target);
@@ -236,7 +236,7 @@ int MacroAssembler::CallSizeNotPredictableCodeSize(Address target,
   return (2 + kMovInstructionsNoConstantPool) * kInstrSize;
 }
 
-void TurboAssembler::Call(Address target, RelocInfo::Mode rmode,
+void MacroAssembler::Call(Address target, RelocInfo::Mode rmode,
                           Condition cond) {
   BlockTrampolinePoolScope block_trampoline_pool(this);
   DCHECK(cond == al);
@@ -252,7 +252,7 @@ void TurboAssembler::Call(Address target, RelocInfo::Mode rmode,
   bctrl();
 }
 
-void TurboAssembler::Call(Handle<Code> code, RelocInfo::Mode rmode,
+void MacroAssembler::Call(Handle<Code> code, RelocInfo::Mode rmode,
                           Condition cond) {
   BlockTrampolinePoolScope block_trampoline_pool(this);
   DCHECK(RelocInfo::IsCodeTarget(rmode));
@@ -268,7 +268,7 @@ void TurboAssembler::Call(Handle<Code> code, RelocInfo::Mode rmode,
   Call(static_cast<Address>(target_index), rmode, cond);
 }
 
-void TurboAssembler::CallBuiltin(Builtin builtin, Condition cond) {
+void MacroAssembler::CallBuiltin(Builtin builtin, Condition cond) {
   ASM_CODE_COMMENT_STRING(this, CommentForOffHeapTrampoline("call", builtin));
   // Use ip directly instead of using UseScratchRegisterScope, as we do not
   // preserve scratch registers across calls.
@@ -309,7 +309,7 @@ void TurboAssembler::CallBuiltin(Builtin builtin, Condition cond) {
   }
 }
 
-void TurboAssembler::TailCallBuiltin(Builtin builtin, Condition cond,
+void MacroAssembler::TailCallBuiltin(Builtin builtin, Condition cond,
                                      CRegister cr) {
   ASM_CODE_COMMENT_STRING(this,
                           CommentForOffHeapTrampoline("tail call", builtin));
@@ -352,13 +352,13 @@ void TurboAssembler::TailCallBuiltin(Builtin builtin, Condition cond,
   }
 }
 
-void TurboAssembler::Drop(int count) {
+void MacroAssembler::Drop(int count) {
   if (count > 0) {
     AddS64(sp, sp, Operand(count * kSystemPointerSize), r0);
   }
 }
 
-void TurboAssembler::Drop(Register count, Register scratch) {
+void MacroAssembler::Drop(Register count, Register scratch) {
   ShiftLeftU64(scratch, count, Operand(kSystemPointerSizeLog2));
   add(sp, sp, scratch);
 }
@@ -376,19 +376,19 @@ Operand MacroAssembler::ClearedValue() const {
       static_cast<int32_t>(HeapObjectReference::ClearedValue(isolate()).ptr()));
 }
 
-void TurboAssembler::Call(Label* target) { b(target, SetLK); }
+void MacroAssembler::Call(Label* target) { b(target, SetLK); }
 
-void TurboAssembler::Push(Handle<HeapObject> handle) {
+void MacroAssembler::Push(Handle<HeapObject> handle) {
   mov(r0, Operand(handle));
   push(r0);
 }
 
-void TurboAssembler::Push(Smi smi) {
+void MacroAssembler::Push(Smi smi) {
   mov(r0, Operand(smi));
   push(r0);
 }
 
-void TurboAssembler::PushArray(Register array, Register size, Register scratch,
+void MacroAssembler::PushArray(Register array, Register size, Register scratch,
                                Register scratch2, PushArrayOrder order) {
   Label loop, done;
 
@@ -420,7 +420,7 @@ void TurboAssembler::PushArray(Register array, Register size, Register scratch,
   }
 }
 
-void TurboAssembler::Move(Register dst, Handle<HeapObject> value,
+void MacroAssembler::Move(Register dst, Handle<HeapObject> value,
                           RelocInfo::Mode rmode) {
   // TODO(jgruber,v8:8887): Also consider a root-relative load when generating
   // non-isolate-independent code. In many cases it might be cheaper than
@@ -438,7 +438,7 @@ void TurboAssembler::Move(Register dst, Handle<HeapObject> value,
   }
 }
 
-void TurboAssembler::Move(Register dst, ExternalReference reference) {
+void MacroAssembler::Move(Register dst, ExternalReference reference) {
   // TODO(jgruber,v8:8887): Also consider a root-relative load when generating
   // non-isolate-independent code. In many cases it might be cheaper than
   // embedding the relocatable value.
@@ -449,20 +449,20 @@ void TurboAssembler::Move(Register dst, ExternalReference reference) {
   mov(dst, Operand(reference));
 }
 
-void TurboAssembler::Move(Register dst, Register src, Condition cond) {
+void MacroAssembler::Move(Register dst, Register src, Condition cond) {
   DCHECK(cond == al);
   if (dst != src) {
     mr(dst, src);
   }
 }
 
-void TurboAssembler::Move(DoubleRegister dst, DoubleRegister src) {
+void MacroAssembler::Move(DoubleRegister dst, DoubleRegister src) {
   if (dst != src) {
     fmr(dst, src);
   }
 }
 
-void TurboAssembler::MultiPush(RegList regs, Register location) {
+void MacroAssembler::MultiPush(RegList regs, Register location) {
   int16_t num_to_push = regs.Count();
   int16_t stack_offset = num_to_push * kSystemPointerSize;
 
@@ -475,7 +475,7 @@ void TurboAssembler::MultiPush(RegList regs, Register location) {
   }
 }
 
-void TurboAssembler::MultiPop(RegList regs, Register location) {
+void MacroAssembler::MultiPop(RegList regs, Register location) {
   int16_t stack_offset = 0;
 
   for (int16_t i = 0; i < Register::kNumRegisters; i++) {
@@ -487,7 +487,7 @@ void TurboAssembler::MultiPop(RegList regs, Register location) {
   addi(location, location, Operand(stack_offset));
 }
 
-void TurboAssembler::MultiPushDoubles(DoubleRegList dregs, Register location) {
+void MacroAssembler::MultiPushDoubles(DoubleRegList dregs, Register location) {
   int16_t num_to_push = dregs.Count();
   int16_t stack_offset = num_to_push * kDoubleSize;
 
@@ -501,7 +501,7 @@ void TurboAssembler::MultiPushDoubles(DoubleRegList dregs, Register location) {
   }
 }
 
-void TurboAssembler::MultiPushV128(Simd128RegList simd_regs, Register scratch,
+void MacroAssembler::MultiPushV128(Simd128RegList simd_regs, Register scratch,
                                    Register location) {
   int16_t num_to_push = simd_regs.Count();
   int16_t stack_offset = num_to_push * kSimd128Size;
@@ -516,7 +516,7 @@ void TurboAssembler::MultiPushV128(Simd128RegList simd_regs, Register scratch,
   }
 }
 
-void TurboAssembler::MultiPopDoubles(DoubleRegList dregs, Register location) {
+void MacroAssembler::MultiPopDoubles(DoubleRegList dregs, Register location) {
   int16_t stack_offset = 0;
 
   for (int16_t i = 0; i < DoubleRegister::kNumRegisters; i++) {
@@ -529,7 +529,7 @@ void TurboAssembler::MultiPopDoubles(DoubleRegList dregs, Register location) {
   addi(location, location, Operand(stack_offset));
 }
 
-void TurboAssembler::MultiPopV128(Simd128RegList simd_regs, Register scratch,
+void MacroAssembler::MultiPopV128(Simd128RegList simd_regs, Register scratch,
                                   Register location) {
   int16_t stack_offset = 0;
 
@@ -543,7 +543,7 @@ void TurboAssembler::MultiPopV128(Simd128RegList simd_regs, Register scratch,
   addi(location, location, Operand(stack_offset));
 }
 
-void TurboAssembler::MultiPushF64AndV128(DoubleRegList dregs,
+void MacroAssembler::MultiPushF64AndV128(DoubleRegList dregs,
                                          Simd128RegList simd_regs,
                                          Register scratch1, Register scratch2,
                                          Register location) {
@@ -580,7 +580,7 @@ void TurboAssembler::MultiPushF64AndV128(DoubleRegList dregs,
 #endif
 }
 
-void TurboAssembler::MultiPopF64AndV128(DoubleRegList dregs,
+void MacroAssembler::MultiPopF64AndV128(DoubleRegList dregs,
                                         Simd128RegList simd_regs,
                                         Register scratch1, Register scratch2,
                                         Register location) {
@@ -611,7 +611,7 @@ void TurboAssembler::MultiPopF64AndV128(DoubleRegList dregs,
   MultiPopDoubles(dregs);
 }
 
-void TurboAssembler::LoadTaggedRoot(Register destination, RootIndex index) {
+void MacroAssembler::LoadTaggedRoot(Register destination, RootIndex index) {
   ASM_CODE_COMMENT(this);
   if (V8_STATIC_ROOTS_BOOL && RootsTable::IsReadOnly(index)) {
     mov(destination, Operand(ReadOnlyRootPtr(index), RelocInfo::Mode::NO_INFO));
@@ -620,7 +620,7 @@ void TurboAssembler::LoadTaggedRoot(Register destination, RootIndex index) {
   LoadRoot(destination, index);
 }
 
-void TurboAssembler::LoadRoot(Register destination, RootIndex index,
+void MacroAssembler::LoadRoot(Register destination, RootIndex index,
                               Condition cond) {
   DCHECK(cond == al);
   if (V8_STATIC_ROOTS_BOOL && RootsTable::IsReadOnly(index)) {
@@ -631,7 +631,7 @@ void TurboAssembler::LoadRoot(Register destination, RootIndex index,
           MemOperand(kRootRegister, RootRegisterOffsetForRootIndex(index)), r0);
 }
 
-void TurboAssembler::LoadTaggedPointerField(const Register& destination,
+void MacroAssembler::LoadTaggedPointerField(const Register& destination,
                                             const MemOperand& field_operand,
                                             const Register& scratch) {
   if (COMPRESS_POINTERS_BOOL) {
@@ -641,7 +641,7 @@ void TurboAssembler::LoadTaggedPointerField(const Register& destination,
   }
 }
 
-void TurboAssembler::LoadAnyTaggedField(const Register& destination,
+void MacroAssembler::LoadAnyTaggedField(const Register& destination,
                                         const MemOperand& field_operand,
                                         const Register& scratch) {
   if (COMPRESS_POINTERS_BOOL) {
@@ -651,7 +651,7 @@ void TurboAssembler::LoadAnyTaggedField(const Register& destination,
   }
 }
 
-void TurboAssembler::SmiUntag(Register dst, const MemOperand& src, RCBit rc,
+void MacroAssembler::SmiUntag(Register dst, const MemOperand& src, RCBit rc,
                               Register scratch) {
   if (SmiValuesAre31Bits()) {
     LoadU32(dst, src, scratch);
@@ -662,7 +662,7 @@ void TurboAssembler::SmiUntag(Register dst, const MemOperand& src, RCBit rc,
   SmiUntag(dst, rc);
 }
 
-void TurboAssembler::StoreTaggedField(const Register& value,
+void MacroAssembler::StoreTaggedField(const Register& value,
                                       const MemOperand& dst_field_operand,
                                       const Register& scratch) {
   if (COMPRESS_POINTERS_BOOL) {
@@ -674,21 +674,21 @@ void TurboAssembler::StoreTaggedField(const Register& value,
   }
 }
 
-void TurboAssembler::DecompressTaggedSigned(Register destination,
+void MacroAssembler::DecompressTaggedSigned(Register destination,
                                             Register src) {
   RecordComment("[ DecompressTaggedSigned");
   ZeroExtWord32(destination, src);
   RecordComment("]");
 }
 
-void TurboAssembler::DecompressTaggedSigned(Register destination,
+void MacroAssembler::DecompressTaggedSigned(Register destination,
                                             MemOperand field_operand) {
   RecordComment("[ DecompressTaggedSigned");
   LoadU32(destination, field_operand, r0);
   RecordComment("]");
 }
 
-void TurboAssembler::DecompressTaggedPointer(Register destination,
+void MacroAssembler::DecompressTaggedPointer(Register destination,
                                              Register source) {
   RecordComment("[ DecompressTaggedPointer");
   ZeroExtWord32(destination, source);
@@ -696,7 +696,7 @@ void TurboAssembler::DecompressTaggedPointer(Register destination,
   RecordComment("]");
 }
 
-void TurboAssembler::DecompressTaggedPointer(Register destination,
+void MacroAssembler::DecompressTaggedPointer(Register destination,
                                              MemOperand field_operand) {
   RecordComment("[ DecompressTaggedPointer");
   LoadU32(destination, field_operand, r0);
@@ -704,14 +704,14 @@ void TurboAssembler::DecompressTaggedPointer(Register destination,
   RecordComment("]");
 }
 
-void TurboAssembler::DecompressTaggedPointer(const Register& destination,
+void MacroAssembler::DecompressTaggedPointer(const Register& destination,
                                              Tagged_t immediate) {
   ASM_CODE_COMMENT(this);
   AddS64(destination, kPtrComprCageBaseRegister,
          Operand(immediate, RelocInfo::Mode::NO_INFO));
 }
 
-void TurboAssembler::DecompressAnyTagged(Register destination,
+void MacroAssembler::DecompressAnyTagged(Register destination,
                                          MemOperand field_operand) {
   RecordComment("[ DecompressAnyTagged");
   LoadU32(destination, field_operand, r0);
@@ -719,7 +719,7 @@ void TurboAssembler::DecompressAnyTagged(Register destination,
   RecordComment("]");
 }
 
-void TurboAssembler::DecompressAnyTagged(Register destination,
+void MacroAssembler::DecompressAnyTagged(Register destination,
                                          Register source) {
   RecordComment("[ DecompressAnyTagged");
   ZeroExtWord32(destination, source);
@@ -727,7 +727,7 @@ void TurboAssembler::DecompressAnyTagged(Register destination,
   RecordComment("]");
 }
 
-void TurboAssembler::LoadTaggedSignedField(Register destination,
+void MacroAssembler::LoadTaggedSignedField(Register destination,
                                            MemOperand field_operand,
                                            Register scratch) {
   if (COMPRESS_POINTERS_BOOL) {
@@ -776,17 +776,17 @@ void MacroAssembler::RecordWriteField(Register object, int offset,
   }
 }
 
-void TurboAssembler::MaybeSaveRegisters(RegList registers) {
+void MacroAssembler::MaybeSaveRegisters(RegList registers) {
   if (registers.is_empty()) return;
   MultiPush(registers);
 }
 
-void TurboAssembler::MaybeRestoreRegisters(RegList registers) {
+void MacroAssembler::MaybeRestoreRegisters(RegList registers) {
   if (registers.is_empty()) return;
   MultiPop(registers);
 }
 
-void TurboAssembler::CallEphemeronKeyBarrier(Register object,
+void MacroAssembler::CallEphemeronKeyBarrier(Register object,
                                              Register slot_address,
                                              SaveFPRegsMode fp_mode) {
   DCHECK(!AreAliased(object, slot_address));
@@ -809,7 +809,7 @@ void TurboAssembler::CallEphemeronKeyBarrier(Register object,
   MaybeRestoreRegisters(registers);
 }
 
-void TurboAssembler::CallRecordWriteStubSaveRegisters(Register object,
+void MacroAssembler::CallRecordWriteStubSaveRegisters(Register object,
                                                       Register slot_address,
                                                       SaveFPRegsMode fp_mode,
                                                       StubCallMode mode) {
@@ -832,7 +832,7 @@ void TurboAssembler::CallRecordWriteStubSaveRegisters(Register object,
   MaybeRestoreRegisters(registers);
 }
 
-void TurboAssembler::CallRecordWriteStub(Register object, Register slot_address,
+void MacroAssembler::CallRecordWriteStub(Register object, Register slot_address,
                                          SaveFPRegsMode fp_mode,
                                          StubCallMode mode) {
   // Use CallRecordWriteStubSaveRegisters if the object and slot registers
@@ -909,7 +909,7 @@ void MacroAssembler::RecordWrite(Register object, Register slot_address,
   }
 }
 
-void TurboAssembler::PushCommonFrame(Register marker_reg) {
+void MacroAssembler::PushCommonFrame(Register marker_reg) {
   int fp_delta = 0;
   mflr(r0);
   if (V8_EMBEDDED_CONSTANT_POOL_BOOL) {
@@ -932,7 +932,7 @@ void TurboAssembler::PushCommonFrame(Register marker_reg) {
   addi(fp, sp, Operand(fp_delta * kSystemPointerSize));
 }
 
-void TurboAssembler::PushStandardFrame(Register function_reg) {
+void MacroAssembler::PushStandardFrame(Register function_reg) {
   int fp_delta = 0;
   mflr(r0);
   if (V8_EMBEDDED_CONSTANT_POOL_BOOL) {
@@ -956,7 +956,7 @@ void TurboAssembler::PushStandardFrame(Register function_reg) {
   Push(kJavaScriptCallArgCountRegister);
 }
 
-void TurboAssembler::RestoreFrameStateForTailCall() {
+void MacroAssembler::RestoreFrameStateForTailCall() {
   if (V8_EMBEDDED_CONSTANT_POOL_BOOL) {
     LoadU64(kConstantPoolRegister,
             MemOperand(fp, StandardFrameConstants::kConstantPoolOffset));
@@ -967,61 +967,61 @@ void TurboAssembler::RestoreFrameStateForTailCall() {
   mtlr(r0);
 }
 
-void TurboAssembler::CanonicalizeNaN(const DoubleRegister dst,
+void MacroAssembler::CanonicalizeNaN(const DoubleRegister dst,
                                      const DoubleRegister src) {
   // Turn potential sNaN into qNaN.
   fsub(dst, src, kDoubleRegZero);
 }
 
-void TurboAssembler::ConvertIntToDouble(Register src, DoubleRegister dst) {
+void MacroAssembler::ConvertIntToDouble(Register src, DoubleRegister dst) {
   MovIntToDouble(dst, src, r0);
   fcfid(dst, dst);
 }
 
-void TurboAssembler::ConvertUnsignedIntToDouble(Register src,
+void MacroAssembler::ConvertUnsignedIntToDouble(Register src,
                                                 DoubleRegister dst) {
   MovUnsignedIntToDouble(dst, src, r0);
   fcfid(dst, dst);
 }
 
-void TurboAssembler::ConvertIntToFloat(Register src, DoubleRegister dst) {
+void MacroAssembler::ConvertIntToFloat(Register src, DoubleRegister dst) {
   MovIntToDouble(dst, src, r0);
   fcfids(dst, dst);
 }
 
-void TurboAssembler::ConvertUnsignedIntToFloat(Register src,
+void MacroAssembler::ConvertUnsignedIntToFloat(Register src,
                                                DoubleRegister dst) {
   MovUnsignedIntToDouble(dst, src, r0);
   fcfids(dst, dst);
 }
 
 #if V8_TARGET_ARCH_PPC64
-void TurboAssembler::ConvertInt64ToDouble(Register src,
+void MacroAssembler::ConvertInt64ToDouble(Register src,
                                           DoubleRegister double_dst) {
   MovInt64ToDouble(double_dst, src);
   fcfid(double_dst, double_dst);
 }
 
-void TurboAssembler::ConvertUnsignedInt64ToFloat(Register src,
+void MacroAssembler::ConvertUnsignedInt64ToFloat(Register src,
                                                  DoubleRegister double_dst) {
   MovInt64ToDouble(double_dst, src);
   fcfidus(double_dst, double_dst);
 }
 
-void TurboAssembler::ConvertUnsignedInt64ToDouble(Register src,
+void MacroAssembler::ConvertUnsignedInt64ToDouble(Register src,
                                                   DoubleRegister double_dst) {
   MovInt64ToDouble(double_dst, src);
   fcfidu(double_dst, double_dst);
 }
 
-void TurboAssembler::ConvertInt64ToFloat(Register src,
+void MacroAssembler::ConvertInt64ToFloat(Register src,
                                          DoubleRegister double_dst) {
   MovInt64ToDouble(double_dst, src);
   fcfids(double_dst, double_dst);
 }
 #endif
 
-void TurboAssembler::ConvertDoubleToInt64(const DoubleRegister double_input,
+void MacroAssembler::ConvertDoubleToInt64(const DoubleRegister double_input,
 #if !V8_TARGET_ARCH_PPC64
                                           const Register dst_hi,
 #endif
@@ -1044,7 +1044,7 @@ void TurboAssembler::ConvertDoubleToInt64(const DoubleRegister double_input,
 }
 
 #if V8_TARGET_ARCH_PPC64
-void TurboAssembler::ConvertDoubleToUnsignedInt64(
+void MacroAssembler::ConvertDoubleToUnsignedInt64(
     const DoubleRegister double_input, const Register dst,
     const DoubleRegister double_dst, FPRoundingMode rounding_mode) {
   if (rounding_mode == kRoundToZero) {
@@ -1060,7 +1060,7 @@ void TurboAssembler::ConvertDoubleToUnsignedInt64(
 #endif
 
 #if !V8_TARGET_ARCH_PPC64
-void TurboAssembler::ShiftLeftPair(Register dst_low, Register dst_high,
+void MacroAssembler::ShiftLeftPair(Register dst_low, Register dst_high,
                                    Register src_low, Register src_high,
                                    Register scratch, Register shift) {
   DCHECK(!AreAliased(dst_low, src_high));
@@ -1085,7 +1085,7 @@ void TurboAssembler::ShiftLeftPair(Register dst_low, Register dst_high,
   bind(&done);
 }
 
-void TurboAssembler::ShiftLeftPair(Register dst_low, Register dst_high,
+void MacroAssembler::ShiftLeftPair(Register dst_low, Register dst_high,
                                    Register src_low, Register src_high,
                                    uint32_t shift) {
   DCHECK(!AreAliased(dst_low, src_high));
@@ -1107,7 +1107,7 @@ void TurboAssembler::ShiftLeftPair(Register dst_low, Register dst_high,
   }
 }
 
-void TurboAssembler::ShiftRightPair(Register dst_low, Register dst_high,
+void MacroAssembler::ShiftRightPair(Register dst_low, Register dst_high,
                                     Register src_low, Register src_high,
                                     Register scratch, Register shift) {
   DCHECK(!AreAliased(dst_low, src_high));
@@ -1132,7 +1132,7 @@ void TurboAssembler::ShiftRightPair(Register dst_low, Register dst_high,
   bind(&done);
 }
 
-void TurboAssembler::ShiftRightPair(Register dst_low, Register dst_high,
+void MacroAssembler::ShiftRightPair(Register dst_low, Register dst_high,
                                     Register src_low, Register src_high,
                                     uint32_t shift) {
   DCHECK(!AreAliased(dst_low, src_high));
@@ -1154,7 +1154,7 @@ void TurboAssembler::ShiftRightPair(Register dst_low, Register dst_high,
   }
 }
 
-void TurboAssembler::ShiftRightAlgPair(Register dst_low, Register dst_high,
+void MacroAssembler::ShiftRightAlgPair(Register dst_low, Register dst_high,
                                        Register src_low, Register src_high,
                                        Register scratch, Register shift) {
   DCHECK(!AreAliased(dst_low, src_high, shift));
@@ -1178,7 +1178,7 @@ void TurboAssembler::ShiftRightAlgPair(Register dst_low, Register dst_high,
   bind(&done);
 }
 
-void TurboAssembler::ShiftRightAlgPair(Register dst_low, Register dst_high,
+void MacroAssembler::ShiftRightAlgPair(Register dst_low, Register dst_high,
                                        Register src_low, Register src_high,
                                        uint32_t shift) {
   DCHECK(!AreAliased(dst_low, src_high));
@@ -1201,7 +1201,7 @@ void TurboAssembler::ShiftRightAlgPair(Register dst_low, Register dst_high,
 }
 #endif
 
-void TurboAssembler::LoadConstantPoolPointerRegisterFromCodeTargetAddress(
+void MacroAssembler::LoadConstantPoolPointerRegisterFromCodeTargetAddress(
     Register code_target_address) {
   // Builtins do not use the constant pool (see is_constant_pool_available).
   static_assert(InstructionStream::kOnHeapBodyIsContiguous);
@@ -1217,19 +1217,19 @@ void TurboAssembler::LoadConstantPoolPointerRegisterFromCodeTargetAddress(
   add(kConstantPoolRegister, kConstantPoolRegister, r0);
 }
 
-void TurboAssembler::LoadPC(Register dst) {
+void MacroAssembler::LoadPC(Register dst) {
   b(4, SetLK);
   mflr(dst);
 }
 
-void TurboAssembler::ComputeCodeStartAddress(Register dst) {
+void MacroAssembler::ComputeCodeStartAddress(Register dst) {
   mflr(r0);
   LoadPC(dst);
   subi(dst, dst, Operand(pc_offset() - kInstrSize));
   mtlr(r0);
 }
 
-void TurboAssembler::LoadConstantPoolPointerRegister() {
+void MacroAssembler::LoadConstantPoolPointerRegister() {
   //
   // Builtins do not use the constant pool (see is_constant_pool_available).
   static_assert(InstructionStream::kOnHeapBodyIsContiguous);
@@ -1240,7 +1240,7 @@ void TurboAssembler::LoadConstantPoolPointerRegister() {
                    ConstantPoolPosition(), delta);
 }
 
-void TurboAssembler::StubPrologue(StackFrame::Type type) {
+void MacroAssembler::StubPrologue(StackFrame::Type type) {
   {
     ConstantPoolUnavailableScope constant_pool_unavailable(this);
     mov(r11, Operand(StackFrame::TypeToMarker(type)));
@@ -1252,7 +1252,7 @@ void TurboAssembler::StubPrologue(StackFrame::Type type) {
   }
 }
 
-void TurboAssembler::Prologue() {
+void MacroAssembler::Prologue() {
   PushStandardFrame(r4);
   if (V8_EMBEDDED_CONSTANT_POOL_BOOL) {
     // base contains prologue address
@@ -1261,7 +1261,7 @@ void TurboAssembler::Prologue() {
   }
 }
 
-void TurboAssembler::DropArguments(Register count, ArgumentsCountType type,
+void MacroAssembler::DropArguments(Register count, ArgumentsCountType type,
                                    ArgumentsCountMode mode) {
   int receiver_bytes =
       (mode == kCountExcludesReceiver) ? kSystemPointerSize : 0;
@@ -1287,7 +1287,7 @@ void TurboAssembler::DropArguments(Register count, ArgumentsCountType type,
   }
 }
 
-void TurboAssembler::DropArgumentsAndPushNewReceiver(Register argc,
+void MacroAssembler::DropArgumentsAndPushNewReceiver(Register argc,
                                                      Register receiver,
                                                      ArgumentsCountType type,
                                                      ArgumentsCountMode mode) {
@@ -1302,7 +1302,7 @@ void TurboAssembler::DropArgumentsAndPushNewReceiver(Register argc,
   }
 }
 
-void TurboAssembler::EnterFrame(StackFrame::Type type,
+void MacroAssembler::EnterFrame(StackFrame::Type type,
                                 bool load_constant_pool_pointer_reg) {
   if (V8_EMBEDDED_CONSTANT_POOL_BOOL && load_constant_pool_pointer_reg) {
     // Push type explicitly so we can leverage the constant pool.
@@ -1326,7 +1326,7 @@ void TurboAssembler::EnterFrame(StackFrame::Type type,
 #endif  // V8_ENABLE_WEBASSEMBLY
 }
 
-int TurboAssembler::LeaveFrame(StackFrame::Type type, int stack_adjustment) {
+int MacroAssembler::LeaveFrame(StackFrame::Type type, int stack_adjustment) {
   ConstantPoolUnavailableScope constant_pool_unavailable(this);
   // r3: preserved
   // r4: preserved
@@ -1422,7 +1422,7 @@ void MacroAssembler::EnterExitFrame(int stack_space,
   StoreU64(r8, MemOperand(fp, ExitFrameConstants::kSPOffset));
 }
 
-int TurboAssembler::ActivationFrameAlignment() {
+int MacroAssembler::ActivationFrameAlignment() {
 #if !defined(USE_SIMULATOR)
   // Running on the real platform. Use the alignment as mandated by the local
   // environment.
@@ -1472,11 +1472,11 @@ void MacroAssembler::LeaveExitFrame(Register argument_count,
   }
 }
 
-void TurboAssembler::MovFromFloatResult(const DoubleRegister dst) {
+void MacroAssembler::MovFromFloatResult(const DoubleRegister dst) {
   Move(dst, d1);
 }
 
-void TurboAssembler::MovFromFloatParameter(const DoubleRegister dst) {
+void MacroAssembler::MovFromFloatParameter(const DoubleRegister dst) {
   Move(dst, d1);
 }
 
@@ -1487,10 +1487,10 @@ void MacroAssembler::LoadStackLimit(Register destination, StackLimitKind kind) {
       kind == StackLimitKind::kRealStackLimit
           ? ExternalReference::address_of_real_jslimit(isolate)
           : ExternalReference::address_of_jslimit(isolate);
-  DCHECK(TurboAssembler::IsAddressableThroughRootRegister(isolate, limit));
+  DCHECK(MacroAssembler::IsAddressableThroughRootRegister(isolate, limit));
 
   intptr_t offset =
-      TurboAssembler::RootRegisterOffsetForExternalReference(isolate, limit);
+      MacroAssembler::RootRegisterOffsetForExternalReference(isolate, limit);
   CHECK(is_int32(offset));
   LoadU64(destination, MemOperand(kRootRegister, offset), r0);
 }
@@ -1783,7 +1783,7 @@ void MacroAssembler::CompareRoot(Register obj, RootIndex index) {
   CmpS64(obj, r0);
 }
 
-void TurboAssembler::AddAndCheckForOverflow(Register dst, Register left,
+void MacroAssembler::AddAndCheckForOverflow(Register dst, Register left,
                                             Register right,
                                             Register overflow_dst,
                                             Register scratch) {
@@ -1815,7 +1815,7 @@ void TurboAssembler::AddAndCheckForOverflow(Register dst, Register left,
   if (!left_is_right) and_(overflow_dst, scratch, overflow_dst, SetRC);
 }
 
-void TurboAssembler::AddAndCheckForOverflow(Register dst, Register left,
+void MacroAssembler::AddAndCheckForOverflow(Register dst, Register left,
                                             intptr_t right,
                                             Register overflow_dst,
                                             Register scratch) {
@@ -1840,7 +1840,7 @@ void TurboAssembler::AddAndCheckForOverflow(Register dst, Register left,
   }
 }
 
-void TurboAssembler::SubAndCheckForOverflow(Register dst, Register left,
+void MacroAssembler::SubAndCheckForOverflow(Register dst, Register left,
                                             Register right,
                                             Register overflow_dst,
                                             Register scratch) {
@@ -1871,7 +1871,7 @@ void TurboAssembler::SubAndCheckForOverflow(Register dst, Register left,
   }
 }
 
-void TurboAssembler::MinF64(DoubleRegister dst, DoubleRegister lhs,
+void MacroAssembler::MinF64(DoubleRegister dst, DoubleRegister lhs,
                             DoubleRegister rhs, DoubleRegister scratch) {
   Label check_zero, return_left, return_right, return_nan, done;
   fcmpu(lhs, rhs);
@@ -1919,7 +1919,7 @@ void TurboAssembler::MinF64(DoubleRegister dst, DoubleRegister lhs,
   bind(&done);
 }
 
-void TurboAssembler::MaxF64(DoubleRegister dst, DoubleRegister lhs,
+void MacroAssembler::MaxF64(DoubleRegister dst, DoubleRegister lhs,
                             DoubleRegister rhs, DoubleRegister scratch) {
   Label check_zero, return_left, return_right, return_nan, done;
   fcmpu(lhs, rhs);
@@ -1965,7 +1965,7 @@ void MacroAssembler::JumpIfIsInRange(Register value, unsigned lower_limit,
   ble(on_in_range);
 }
 
-void TurboAssembler::TruncateDoubleToI(Isolate* isolate, Zone* zone,
+void MacroAssembler::TruncateDoubleToI(Isolate* isolate, Zone* zone,
                                        Register result,
                                        DoubleRegister double_input,
                                        StubCallMode stub_mode) {
@@ -1998,7 +1998,7 @@ void TurboAssembler::TruncateDoubleToI(Isolate* isolate, Zone* zone,
   bind(&done);
 }
 
-void TurboAssembler::TryInlineTruncateDoubleToI(Register result,
+void MacroAssembler::TryInlineTruncateDoubleToI(Register result,
                                                 DoubleRegister double_input,
                                                 Label* done) {
   DoubleRegister double_scratch = kScratchDoubleReg;
@@ -2254,7 +2254,7 @@ void MacroAssembler::EmitDecrementCounter(StatsCounter* counter, int value,
   }
 }
 
-void TurboAssembler::Check(Condition cond, AbortReason reason, CRegister cr) {
+void MacroAssembler::Check(Condition cond, AbortReason reason, CRegister cr) {
   Label L;
   b(cond, &L, cr);
   Abort(reason);
@@ -2262,7 +2262,7 @@ void TurboAssembler::Check(Condition cond, AbortReason reason, CRegister cr) {
   bind(&L);
 }
 
-void TurboAssembler::Abort(AbortReason reason) {
+void MacroAssembler::Abort(AbortReason reason) {
   Label abort_start;
   bind(&abort_start);
   if (v8_flags.code_comments) {
@@ -2306,7 +2306,7 @@ void TurboAssembler::Abort(AbortReason reason) {
   // will not return here
 }
 
-void TurboAssembler::LoadMap(Register destination, Register object) {
+void MacroAssembler::LoadMap(Register destination, Register object) {
   LoadTaggedPointerField(destination,
                          FieldMemOperand(object, HeapObject::kMapOffset), r0);
 }
@@ -2321,11 +2321,11 @@ void MacroAssembler::LoadNativeContextSlot(Register dst, int index) {
 }
 
 #ifdef V8_ENABLE_DEBUG_CODE
-void TurboAssembler::Assert(Condition cond, AbortReason reason, CRegister cr) {
+void MacroAssembler::Assert(Condition cond, AbortReason reason, CRegister cr) {
   if (v8_flags.debug_code) Check(cond, reason, cr);
 }
 
-void TurboAssembler::AssertNotSmi(Register object) {
+void MacroAssembler::AssertNotSmi(Register object) {
   if (v8_flags.debug_code) {
     static_assert(kSmiTag == 0);
     TestIfSmi(object, r0);
@@ -2333,7 +2333,7 @@ void TurboAssembler::AssertNotSmi(Register object) {
   }
 }
 
-void TurboAssembler::AssertSmi(Register object) {
+void MacroAssembler::AssertSmi(Register object) {
   if (v8_flags.debug_code) {
     static_assert(kSmiTag == 0);
     TestIfSmi(object, r0);
@@ -2431,7 +2431,7 @@ void MacroAssembler::AssertUndefinedOrAllocationSite(Register object,
 
 static const int kRegisterPassedArguments = 8;
 
-int TurboAssembler::CalculateStackPassedWords(int num_reg_arguments,
+int MacroAssembler::CalculateStackPassedWords(int num_reg_arguments,
                                               int num_double_arguments) {
   int stack_passed_words = 0;
   if (num_double_arguments > DoubleRegister::kNumRegisters) {
@@ -2445,7 +2445,7 @@ int TurboAssembler::CalculateStackPassedWords(int num_reg_arguments,
   return stack_passed_words;
 }
 
-void TurboAssembler::PrepareCallCFunction(int num_reg_arguments,
+void MacroAssembler::PrepareCallCFunction(int num_reg_arguments,
                                           int num_double_arguments,
                                           Register scratch) {
   int frame_alignment = ActivationFrameAlignment();
@@ -2474,16 +2474,16 @@ void TurboAssembler::PrepareCallCFunction(int num_reg_arguments,
   StoreU64WithUpdate(r0, MemOperand(sp, -stack_space * kSystemPointerSize));
 }
 
-void TurboAssembler::PrepareCallCFunction(int num_reg_arguments,
+void MacroAssembler::PrepareCallCFunction(int num_reg_arguments,
                                           Register scratch) {
   PrepareCallCFunction(num_reg_arguments, 0, scratch);
 }
 
-void TurboAssembler::MovToFloatParameter(DoubleRegister src) { Move(d1, src); }
+void MacroAssembler::MovToFloatParameter(DoubleRegister src) { Move(d1, src); }
 
-void TurboAssembler::MovToFloatResult(DoubleRegister src) { Move(d1, src); }
+void MacroAssembler::MovToFloatResult(DoubleRegister src) { Move(d1, src); }
 
-void TurboAssembler::MovToFloatParameters(DoubleRegister src1,
+void MacroAssembler::MovToFloatParameters(DoubleRegister src1,
                                           DoubleRegister src2) {
   if (src2 == d1) {
     DCHECK(src1 != d2);
@@ -2495,7 +2495,7 @@ void TurboAssembler::MovToFloatParameters(DoubleRegister src1,
   }
 }
 
-void TurboAssembler::CallCFunction(ExternalReference function,
+void MacroAssembler::CallCFunction(ExternalReference function,
                                    int num_reg_arguments,
                                    int num_double_arguments,
                                    bool has_function_descriptor) {
@@ -2504,25 +2504,25 @@ void TurboAssembler::CallCFunction(ExternalReference function,
                       has_function_descriptor);
 }
 
-void TurboAssembler::CallCFunction(Register function, int num_reg_arguments,
+void MacroAssembler::CallCFunction(Register function, int num_reg_arguments,
                                    int num_double_arguments,
                                    bool has_function_descriptor) {
   CallCFunctionHelper(function, num_reg_arguments, num_double_arguments,
                       has_function_descriptor);
 }
 
-void TurboAssembler::CallCFunction(ExternalReference function,
+void MacroAssembler::CallCFunction(ExternalReference function,
                                    int num_arguments,
                                    bool has_function_descriptor) {
   CallCFunction(function, num_arguments, 0, has_function_descriptor);
 }
 
-void TurboAssembler::CallCFunction(Register function, int num_arguments,
+void MacroAssembler::CallCFunction(Register function, int num_arguments,
                                    bool has_function_descriptor) {
   CallCFunction(function, num_arguments, 0, has_function_descriptor);
 }
 
-void TurboAssembler::CallCFunctionHelper(Register function,
+void MacroAssembler::CallCFunctionHelper(Register function,
                                          int num_reg_arguments,
                                          int num_double_arguments,
                                          bool has_function_descriptor) {
@@ -2605,7 +2605,7 @@ void TurboAssembler::CallCFunctionHelper(Register function,
   }
 }
 
-void TurboAssembler::CheckPageFlag(
+void MacroAssembler::CheckPageFlag(
     Register object,
     Register scratch,  // scratch may be same register as object
     int mask, Condition cc, Label* condition_met) {
@@ -2625,9 +2625,9 @@ void TurboAssembler::CheckPageFlag(
   }
 }
 
-void TurboAssembler::SetRoundingMode(FPRoundingMode RN) { mtfsfi(7, RN); }
+void MacroAssembler::SetRoundingMode(FPRoundingMode RN) { mtfsfi(7, RN); }
 
-void TurboAssembler::ResetRoundingMode() {
+void MacroAssembler::ResetRoundingMode() {
   mtfsfi(7, kRoundToNearest);  // reset (default is kRoundToNearest)
 }
 
@@ -2636,15 +2636,15 @@ void TurboAssembler::ResetRoundingMode() {
 // New MacroAssembler Interfaces added for PPC
 //
 ////////////////////////////////////////////////////////////////////////////////
-void TurboAssembler::LoadIntLiteral(Register dst, int value) {
+void MacroAssembler::LoadIntLiteral(Register dst, int value) {
   mov(dst, Operand(value));
 }
 
-void TurboAssembler::LoadSmiLiteral(Register dst, Smi smi) {
+void MacroAssembler::LoadSmiLiteral(Register dst, Smi smi) {
   mov(dst, Operand(smi));
 }
 
-void TurboAssembler::LoadDoubleLiteral(DoubleRegister result,
+void MacroAssembler::LoadDoubleLiteral(DoubleRegister result,
                                        base::Double value, Register scratch) {
   if (V8_EMBEDDED_CONSTANT_POOL_BOOL && is_constant_pool_available() &&
       !(scratch == r0 && ConstantPoolAccessIsInOverflow())) {
@@ -2693,7 +2693,7 @@ void TurboAssembler::LoadDoubleLiteral(DoubleRegister result,
   addi(sp, sp, Operand(kDoubleSize));
 }
 
-void TurboAssembler::MovIntToDouble(DoubleRegister dst, Register src,
+void MacroAssembler::MovIntToDouble(DoubleRegister dst, Register src,
                                     Register scratch) {
 // sign-extend src to 64-bit
 #if V8_TARGET_ARCH_PPC64
@@ -2718,7 +2718,7 @@ void TurboAssembler::MovIntToDouble(DoubleRegister dst, Register src,
   addi(sp, sp, Operand(kDoubleSize));
 }
 
-void TurboAssembler::MovUnsignedIntToDouble(DoubleRegister dst, Register src,
+void MacroAssembler::MovUnsignedIntToDouble(DoubleRegister dst, Register src,
                                             Register scratch) {
 // zero-extend src to 64-bit
 #if V8_TARGET_ARCH_PPC64
@@ -2743,7 +2743,7 @@ void TurboAssembler::MovUnsignedIntToDouble(DoubleRegister dst, Register src,
   addi(sp, sp, Operand(kDoubleSize));
 }
 
-void TurboAssembler::MovInt64ToDouble(DoubleRegister dst,
+void MacroAssembler::MovInt64ToDouble(DoubleRegister dst,
 #if !V8_TARGET_ARCH_PPC64
                                       Register src_hi,
 #endif
@@ -2768,7 +2768,7 @@ void TurboAssembler::MovInt64ToDouble(DoubleRegister dst,
 }
 
 #if V8_TARGET_ARCH_PPC64
-void TurboAssembler::MovInt64ComponentsToDouble(DoubleRegister dst,
+void MacroAssembler::MovInt64ComponentsToDouble(DoubleRegister dst,
                                                 Register src_hi,
                                                 Register src_lo,
                                                 Register scratch) {
@@ -2788,7 +2788,7 @@ void TurboAssembler::MovInt64ComponentsToDouble(DoubleRegister dst,
 }
 #endif
 
-void TurboAssembler::InsertDoubleLow(DoubleRegister dst, Register src,
+void MacroAssembler::InsertDoubleLow(DoubleRegister dst, Register src,
                                      Register scratch) {
 #if V8_TARGET_ARCH_PPC64
   if (CpuFeatures::IsSupported(PPC_8_PLUS)) {
@@ -2807,7 +2807,7 @@ void TurboAssembler::InsertDoubleLow(DoubleRegister dst, Register src,
   addi(sp, sp, Operand(kDoubleSize));
 }
 
-void TurboAssembler::InsertDoubleHigh(DoubleRegister dst, Register src,
+void MacroAssembler::InsertDoubleHigh(DoubleRegister dst, Register src,
                                       Register scratch) {
 #if V8_TARGET_ARCH_PPC64
   if (CpuFeatures::IsSupported(PPC_8_PLUS)) {
@@ -2826,7 +2826,7 @@ void TurboAssembler::InsertDoubleHigh(DoubleRegister dst, Register src,
   addi(sp, sp, Operand(kDoubleSize));
 }
 
-void TurboAssembler::MovDoubleLowToInt(Register dst, DoubleRegister src) {
+void MacroAssembler::MovDoubleLowToInt(Register dst, DoubleRegister src) {
 #if V8_TARGET_ARCH_PPC64
   if (CpuFeatures::IsSupported(PPC_8_PLUS)) {
     mffprwz(dst, src);
@@ -2841,7 +2841,7 @@ void TurboAssembler::MovDoubleLowToInt(Register dst, DoubleRegister src) {
   addi(sp, sp, Operand(kDoubleSize));
 }
 
-void TurboAssembler::MovDoubleHighToInt(Register dst, DoubleRegister src) {
+void MacroAssembler::MovDoubleHighToInt(Register dst, DoubleRegister src) {
 #if V8_TARGET_ARCH_PPC64
   if (CpuFeatures::IsSupported(PPC_8_PLUS)) {
     mffprd(dst, src);
@@ -2857,7 +2857,7 @@ void TurboAssembler::MovDoubleHighToInt(Register dst, DoubleRegister src) {
   addi(sp, sp, Operand(kDoubleSize));
 }
 
-void TurboAssembler::MovDoubleToInt64(
+void MacroAssembler::MovDoubleToInt64(
 #if !V8_TARGET_ARCH_PPC64
     Register dst_hi,
 #endif
@@ -2881,7 +2881,7 @@ void TurboAssembler::MovDoubleToInt64(
   addi(sp, sp, Operand(kDoubleSize));
 }
 
-void TurboAssembler::MovIntToFloat(DoubleRegister dst, Register src,
+void MacroAssembler::MovIntToFloat(DoubleRegister dst, Register src,
                                    Register scratch) {
   if (CpuFeatures::IsSupported(PPC_8_PLUS)) {
     ShiftLeftU64(scratch, src, Operand(32));
@@ -2896,7 +2896,7 @@ void TurboAssembler::MovIntToFloat(DoubleRegister dst, Register src,
   addi(sp, sp, Operand(kFloatSize));
 }
 
-void TurboAssembler::MovFloatToInt(Register dst, DoubleRegister src,
+void MacroAssembler::MovFloatToInt(Register dst, DoubleRegister src,
                                    DoubleRegister scratch) {
   if (CpuFeatures::IsSupported(PPC_8_PLUS)) {
     xscvdpspn(scratch, src);
@@ -2910,12 +2910,12 @@ void TurboAssembler::MovFloatToInt(Register dst, DoubleRegister src,
   addi(sp, sp, Operand(kFloatSize));
 }
 
-void TurboAssembler::AddS64(Register dst, Register src, Register value, OEBit s,
+void MacroAssembler::AddS64(Register dst, Register src, Register value, OEBit s,
                             RCBit r) {
   add(dst, src, value, s, r);
 }
 
-void TurboAssembler::AddS64(Register dst, Register src, const Operand& value,
+void MacroAssembler::AddS64(Register dst, Register src, const Operand& value,
                             Register scratch, OEBit s, RCBit r) {
   if (is_int16(value.immediate()) && s == LeaveOE && r == LeaveRC) {
     addi(dst, src, value);
@@ -2925,12 +2925,12 @@ void TurboAssembler::AddS64(Register dst, Register src, const Operand& value,
   }
 }
 
-void TurboAssembler::SubS64(Register dst, Register src, Register value, OEBit s,
+void MacroAssembler::SubS64(Register dst, Register src, Register value, OEBit s,
                             RCBit r) {
   sub(dst, src, value, s, r);
 }
 
-void TurboAssembler::SubS64(Register dst, Register src, const Operand& value,
+void MacroAssembler::SubS64(Register dst, Register src, const Operand& value,
                             Register scratch, OEBit s, RCBit r) {
   if (is_int16(value.immediate()) && s == LeaveOE && r == LeaveRC) {
     subi(dst, src, value);
@@ -2940,31 +2940,31 @@ void TurboAssembler::SubS64(Register dst, Register src, const Operand& value,
   }
 }
 
-void TurboAssembler::AddS32(Register dst, Register src, Register value,
+void MacroAssembler::AddS32(Register dst, Register src, Register value,
                             RCBit r) {
   AddS64(dst, src, value, LeaveOE, r);
   extsw(dst, dst, r);
 }
 
-void TurboAssembler::AddS32(Register dst, Register src, const Operand& value,
+void MacroAssembler::AddS32(Register dst, Register src, const Operand& value,
                             Register scratch, RCBit r) {
   AddS64(dst, src, value, scratch, LeaveOE, r);
   extsw(dst, dst, r);
 }
 
-void TurboAssembler::SubS32(Register dst, Register src, Register value,
+void MacroAssembler::SubS32(Register dst, Register src, Register value,
                             RCBit r) {
   SubS64(dst, src, value, LeaveOE, r);
   extsw(dst, dst, r);
 }
 
-void TurboAssembler::SubS32(Register dst, Register src, const Operand& value,
+void MacroAssembler::SubS32(Register dst, Register src, const Operand& value,
                             Register scratch, RCBit r) {
   SubS64(dst, src, value, scratch, LeaveOE, r);
   extsw(dst, dst, r);
 }
 
-void TurboAssembler::MulS64(Register dst, Register src, const Operand& value,
+void MacroAssembler::MulS64(Register dst, Register src, const Operand& value,
                             Register scratch, OEBit s, RCBit r) {
   if (is_int16(value.immediate()) && s == LeaveOE && r == LeaveRC) {
     mulli(dst, src, value);
@@ -2974,45 +2974,45 @@ void TurboAssembler::MulS64(Register dst, Register src, const Operand& value,
   }
 }
 
-void TurboAssembler::MulS64(Register dst, Register src, Register value, OEBit s,
+void MacroAssembler::MulS64(Register dst, Register src, Register value, OEBit s,
                             RCBit r) {
   mulld(dst, src, value, s, r);
 }
 
-void TurboAssembler::MulS32(Register dst, Register src, const Operand& value,
+void MacroAssembler::MulS32(Register dst, Register src, const Operand& value,
                             Register scratch, OEBit s, RCBit r) {
   MulS64(dst, src, value, scratch, s, r);
   extsw(dst, dst, r);
 }
 
-void TurboAssembler::MulS32(Register dst, Register src, Register value, OEBit s,
+void MacroAssembler::MulS32(Register dst, Register src, Register value, OEBit s,
                             RCBit r) {
   MulS64(dst, src, value, s, r);
   extsw(dst, dst, r);
 }
 
-void TurboAssembler::DivS64(Register dst, Register src, Register value, OEBit s,
+void MacroAssembler::DivS64(Register dst, Register src, Register value, OEBit s,
                             RCBit r) {
   divd(dst, src, value, s, r);
 }
 
-void TurboAssembler::DivU64(Register dst, Register src, Register value, OEBit s,
+void MacroAssembler::DivU64(Register dst, Register src, Register value, OEBit s,
                             RCBit r) {
   divdu(dst, src, value, s, r);
 }
 
-void TurboAssembler::DivS32(Register dst, Register src, Register value, OEBit s,
+void MacroAssembler::DivS32(Register dst, Register src, Register value, OEBit s,
                             RCBit r) {
   divw(dst, src, value, s, r);
   extsw(dst, dst);
 }
-void TurboAssembler::DivU32(Register dst, Register src, Register value, OEBit s,
+void MacroAssembler::DivU32(Register dst, Register src, Register value, OEBit s,
                             RCBit r) {
   divwu(dst, src, value, s, r);
   ZeroExtWord32(dst, dst);
 }
 
-void TurboAssembler::ModS64(Register dst, Register src, Register value) {
+void MacroAssembler::ModS64(Register dst, Register src, Register value) {
   if (CpuFeatures::IsSupported(PPC_9_PLUS)) {
     modsd(dst, src, value);
   } else {
@@ -3025,7 +3025,7 @@ void TurboAssembler::ModS64(Register dst, Register src, Register value) {
   }
 }
 
-void TurboAssembler::ModU64(Register dst, Register src, Register value) {
+void MacroAssembler::ModU64(Register dst, Register src, Register value) {
   if (CpuFeatures::IsSupported(PPC_9_PLUS)) {
     modud(dst, src, value);
   } else {
@@ -3038,7 +3038,7 @@ void TurboAssembler::ModU64(Register dst, Register src, Register value) {
   }
 }
 
-void TurboAssembler::ModS32(Register dst, Register src, Register value) {
+void MacroAssembler::ModS32(Register dst, Register src, Register value) {
   if (CpuFeatures::IsSupported(PPC_9_PLUS)) {
     modsw(dst, src, value);
   } else {
@@ -3051,7 +3051,7 @@ void TurboAssembler::ModS32(Register dst, Register src, Register value) {
   }
   extsw(dst, dst);
 }
-void TurboAssembler::ModU32(Register dst, Register src, Register value) {
+void MacroAssembler::ModU32(Register dst, Register src, Register value) {
   if (CpuFeatures::IsSupported(PPC_9_PLUS)) {
     moduw(dst, src, value);
   } else {
@@ -3065,7 +3065,7 @@ void TurboAssembler::ModU32(Register dst, Register src, Register value) {
   ZeroExtWord32(dst, dst);
 }
 
-void TurboAssembler::AndU64(Register dst, Register src, const Operand& value,
+void MacroAssembler::AndU64(Register dst, Register src, const Operand& value,
                             Register scratch, RCBit r) {
   if (is_uint16(value.immediate()) && r == SetRC) {
     andi(dst, src, value);
@@ -3075,12 +3075,12 @@ void TurboAssembler::AndU64(Register dst, Register src, const Operand& value,
   }
 }
 
-void TurboAssembler::AndU64(Register dst, Register src, Register value,
+void MacroAssembler::AndU64(Register dst, Register src, Register value,
                             RCBit r) {
   and_(dst, src, value, r);
 }
 
-void TurboAssembler::OrU64(Register dst, Register src, const Operand& value,
+void MacroAssembler::OrU64(Register dst, Register src, const Operand& value,
                            Register scratch, RCBit r) {
   if (is_int16(value.immediate()) && r == LeaveRC) {
     ori(dst, src, value);
@@ -3090,12 +3090,12 @@ void TurboAssembler::OrU64(Register dst, Register src, const Operand& value,
   }
 }
 
-void TurboAssembler::OrU64(Register dst, Register src, Register value,
+void MacroAssembler::OrU64(Register dst, Register src, Register value,
                            RCBit r) {
   orx(dst, src, value, r);
 }
 
-void TurboAssembler::XorU64(Register dst, Register src, const Operand& value,
+void MacroAssembler::XorU64(Register dst, Register src, const Operand& value,
                             Register scratch, RCBit r) {
   if (is_int16(value.immediate()) && r == LeaveRC) {
     xori(dst, src, value);
@@ -3105,112 +3105,112 @@ void TurboAssembler::XorU64(Register dst, Register src, const Operand& value,
   }
 }
 
-void TurboAssembler::XorU64(Register dst, Register src, Register value,
+void MacroAssembler::XorU64(Register dst, Register src, Register value,
                             RCBit r) {
   xor_(dst, src, value, r);
 }
 
-void TurboAssembler::AndU32(Register dst, Register src, const Operand& value,
+void MacroAssembler::AndU32(Register dst, Register src, const Operand& value,
                             Register scratch, RCBit r) {
   AndU64(dst, src, value, scratch, r);
   extsw(dst, dst, r);
 }
 
-void TurboAssembler::AndU32(Register dst, Register src, Register value,
+void MacroAssembler::AndU32(Register dst, Register src, Register value,
                             RCBit r) {
   AndU64(dst, src, value, r);
   extsw(dst, dst, r);
 }
 
-void TurboAssembler::OrU32(Register dst, Register src, const Operand& value,
+void MacroAssembler::OrU32(Register dst, Register src, const Operand& value,
                            Register scratch, RCBit r) {
   OrU64(dst, src, value, scratch, r);
   extsw(dst, dst, r);
 }
 
-void TurboAssembler::OrU32(Register dst, Register src, Register value,
+void MacroAssembler::OrU32(Register dst, Register src, Register value,
                            RCBit r) {
   OrU64(dst, src, value, r);
   extsw(dst, dst, r);
 }
 
-void TurboAssembler::XorU32(Register dst, Register src, const Operand& value,
+void MacroAssembler::XorU32(Register dst, Register src, const Operand& value,
                             Register scratch, RCBit r) {
   XorU64(dst, src, value, scratch, r);
   extsw(dst, dst, r);
 }
 
-void TurboAssembler::XorU32(Register dst, Register src, Register value,
+void MacroAssembler::XorU32(Register dst, Register src, Register value,
                             RCBit r) {
   XorU64(dst, src, value, r);
   extsw(dst, dst, r);
 }
 
-void TurboAssembler::ShiftLeftU64(Register dst, Register src,
+void MacroAssembler::ShiftLeftU64(Register dst, Register src,
                                   const Operand& value, RCBit r) {
   sldi(dst, src, value, r);
 }
 
-void TurboAssembler::ShiftRightU64(Register dst, Register src,
+void MacroAssembler::ShiftRightU64(Register dst, Register src,
                                    const Operand& value, RCBit r) {
   srdi(dst, src, value, r);
 }
 
-void TurboAssembler::ShiftRightS64(Register dst, Register src,
+void MacroAssembler::ShiftRightS64(Register dst, Register src,
                                    const Operand& value, RCBit r) {
   sradi(dst, src, value.immediate(), r);
 }
 
-void TurboAssembler::ShiftLeftU32(Register dst, Register src,
+void MacroAssembler::ShiftLeftU32(Register dst, Register src,
                                   const Operand& value, RCBit r) {
   slwi(dst, src, value, r);
 }
 
-void TurboAssembler::ShiftRightU32(Register dst, Register src,
+void MacroAssembler::ShiftRightU32(Register dst, Register src,
                                    const Operand& value, RCBit r) {
   srwi(dst, src, value, r);
 }
 
-void TurboAssembler::ShiftRightS32(Register dst, Register src,
+void MacroAssembler::ShiftRightS32(Register dst, Register src,
                                    const Operand& value, RCBit r) {
   srawi(dst, src, value.immediate(), r);
 }
 
-void TurboAssembler::ShiftLeftU64(Register dst, Register src, Register value,
+void MacroAssembler::ShiftLeftU64(Register dst, Register src, Register value,
                                   RCBit r) {
   sld(dst, src, value, r);
 }
 
-void TurboAssembler::ShiftRightU64(Register dst, Register src, Register value,
+void MacroAssembler::ShiftRightU64(Register dst, Register src, Register value,
                                    RCBit r) {
   srd(dst, src, value, r);
 }
 
-void TurboAssembler::ShiftRightS64(Register dst, Register src, Register value,
+void MacroAssembler::ShiftRightS64(Register dst, Register src, Register value,
                                    RCBit r) {
   srad(dst, src, value, r);
 }
 
-void TurboAssembler::ShiftLeftU32(Register dst, Register src, Register value,
+void MacroAssembler::ShiftLeftU32(Register dst, Register src, Register value,
                                   RCBit r) {
   slw(dst, src, value, r);
 }
 
-void TurboAssembler::ShiftRightU32(Register dst, Register src, Register value,
+void MacroAssembler::ShiftRightU32(Register dst, Register src, Register value,
                                    RCBit r) {
   srw(dst, src, value, r);
 }
 
-void TurboAssembler::ShiftRightS32(Register dst, Register src, Register value,
+void MacroAssembler::ShiftRightS32(Register dst, Register src, Register value,
                                    RCBit r) {
   sraw(dst, src, value, r);
 }
 
-void TurboAssembler::CmpS64(Register src1, Register src2, CRegister cr) {
+void MacroAssembler::CmpS64(Register src1, Register src2, CRegister cr) {
   cmp(src1, src2, cr);
 }
 
-void TurboAssembler::CmpS64(Register src1, const Operand& src2,
+void MacroAssembler::CmpS64(Register src1, const Operand& src2,
                             Register scratch, CRegister cr) {
   intptr_t value = src2.immediate();
   if (is_int16(value)) {
@@ -3221,7 +3221,7 @@ void TurboAssembler::CmpS64(Register src1, const Operand& src2,
   }
 }
 
-void TurboAssembler::CmpU64(Register src1, const Operand& src2,
+void MacroAssembler::CmpU64(Register src1, const Operand& src2,
                             Register scratch, CRegister cr) {
   intptr_t value = src2.immediate();
   if (is_uint16(value)) {
@@ -3232,11 +3232,11 @@ void TurboAssembler::CmpU64(Register src1, const Operand& src2,
   }
 }
 
-void TurboAssembler::CmpU64(Register src1, Register src2, CRegister cr) {
+void MacroAssembler::CmpU64(Register src1, Register src2, CRegister cr) {
   cmpl(src1, src2, cr);
 }
 
-void TurboAssembler::CmpS32(Register src1, const Operand& src2,
+void MacroAssembler::CmpS32(Register src1, const Operand& src2,
                             Register scratch, CRegister cr) {
   intptr_t value = src2.immediate();
   if (is_int16(value)) {
@@ -3247,11 +3247,11 @@ void TurboAssembler::CmpS32(Register src1, const Operand& src2,
   }
 }
 
-void TurboAssembler::CmpS32(Register src1, Register src2, CRegister cr) {
+void MacroAssembler::CmpS32(Register src1, Register src2, CRegister cr) {
   cmpw(src1, src2, cr);
 }
 
-void TurboAssembler::CmpU32(Register src1, const Operand& src2,
+void MacroAssembler::CmpU32(Register src1, const Operand& src2,
                             Register scratch, CRegister cr) {
   intptr_t value = src2.immediate();
   if (is_uint16(value)) {
@@ -3262,55 +3262,55 @@ void TurboAssembler::CmpU32(Register src1, const Operand& src2,
   }
 }
 
-void TurboAssembler::CmpU32(Register src1, Register src2, CRegister cr) {
+void MacroAssembler::CmpU32(Register src1, Register src2, CRegister cr) {
   cmplw(src1, src2, cr);
 }
 
-void TurboAssembler::AddF64(DoubleRegister dst, DoubleRegister lhs,
+void MacroAssembler::AddF64(DoubleRegister dst, DoubleRegister lhs,
                             DoubleRegister rhs, RCBit r) {
   fadd(dst, lhs, rhs, r);
 }
 
-void TurboAssembler::SubF64(DoubleRegister dst, DoubleRegister lhs,
+void MacroAssembler::SubF64(DoubleRegister dst, DoubleRegister lhs,
                             DoubleRegister rhs, RCBit r) {
   fsub(dst, lhs, rhs, r);
 }
 
-void TurboAssembler::MulF64(DoubleRegister dst, DoubleRegister lhs,
+void MacroAssembler::MulF64(DoubleRegister dst, DoubleRegister lhs,
                             DoubleRegister rhs, RCBit r) {
   fmul(dst, lhs, rhs, r);
 }
 
-void TurboAssembler::DivF64(DoubleRegister dst, DoubleRegister lhs,
+void MacroAssembler::DivF64(DoubleRegister dst, DoubleRegister lhs,
                             DoubleRegister rhs, RCBit r) {
   fdiv(dst, lhs, rhs, r);
 }
 
-void TurboAssembler::AddF32(DoubleRegister dst, DoubleRegister lhs,
+void MacroAssembler::AddF32(DoubleRegister dst, DoubleRegister lhs,
                             DoubleRegister rhs, RCBit r) {
   fadd(dst, lhs, rhs, r);
   frsp(dst, dst, r);
 }
 
-void TurboAssembler::SubF32(DoubleRegister dst, DoubleRegister lhs,
+void MacroAssembler::SubF32(DoubleRegister dst, DoubleRegister lhs,
                             DoubleRegister rhs, RCBit r) {
   fsub(dst, lhs, rhs, r);
   frsp(dst, dst, r);
 }
 
-void TurboAssembler::MulF32(DoubleRegister dst, DoubleRegister lhs,
+void MacroAssembler::MulF32(DoubleRegister dst, DoubleRegister lhs,
                             DoubleRegister rhs, RCBit r) {
   fmul(dst, lhs, rhs, r);
   frsp(dst, dst, r);
 }
 
-void TurboAssembler::DivF32(DoubleRegister dst, DoubleRegister lhs,
+void MacroAssembler::DivF32(DoubleRegister dst, DoubleRegister lhs,
                             DoubleRegister rhs, RCBit r) {
   fdiv(dst, lhs, rhs, r);
   frsp(dst, dst, r);
 }
 
-void TurboAssembler::CopySignF64(DoubleRegister dst, DoubleRegister lhs,
+void MacroAssembler::CopySignF64(DoubleRegister dst, DoubleRegister lhs,
                                  DoubleRegister rhs, RCBit r) {
   fcpsgn(dst, rhs, lhs, r);
 }
@@ -3513,7 +3513,7 @@ void MacroAssembler::AndSmiLiteral(Register dst, Register src, Smi smi,
   V(StoreU64WithUpdate, stdu, stdux)
 
 #define MEM_OP_WITH_ALIGN_FUNCTION(name, ri_op, rr_op)           \
-  void TurboAssembler::name(Register reg, const MemOperand& mem, \
+  void MacroAssembler::name(Register reg, const MemOperand& mem, \
                             Register scratch) {                  \
     GenerateMemoryOperationWithAlign(reg, mem, ri_op, rr_op);    \
   }
@@ -3527,7 +3527,7 @@ MEM_OP_WITH_ALIGN_LIST(MEM_OP_WITH_ALIGN_FUNCTION)
   V(StoreU64, std, pstd, stdx)
 
 #define MEM_OP_WITH_ALIGN_PREFIXED_FUNCTION(name, ri_op, rip_op, rr_op)       \
-  void TurboAssembler::name(Register reg, const MemOperand& mem,              \
+  void MacroAssembler::name(Register reg, const MemOperand& mem,              \
                             Register scratch) {                               \
     GenerateMemoryOperationWithAlignPrefixed(reg, mem, ri_op, rip_op, rr_op); \
   }
@@ -3542,7 +3542,7 @@ MEM_OP_WITH_ALIGN_PREFIXED_LIST(MEM_OP_WITH_ALIGN_PREFIXED_FUNCTION)
   V(StoreF32WithUpdate, DoubleRegister, stfsu, stfsux)
 
 #define MEM_OP_FUNCTION(name, result_t, ri_op, rr_op)            \
-  void TurboAssembler::name(result_t reg, const MemOperand& mem, \
+  void MacroAssembler::name(result_t reg, const MemOperand& mem, \
                             Register scratch) {                  \
     GenerateMemoryOperation(reg, mem, ri_op, rr_op);             \
   }
@@ -3564,7 +3564,7 @@ MEM_OP_LIST(MEM_OP_FUNCTION)
   V(StoreF32, DoubleRegister, stfs, pstfs, stfsx)
 
 #define MEM_OP_PREFIXED_FUNCTION(name, result_t, ri_op, rip_op, rr_op) \
-  void TurboAssembler::name(result_t reg, const MemOperand& mem,       \
+  void MacroAssembler::name(result_t reg, const MemOperand& mem,       \
                             Register scratch) {                        \
     GenerateMemoryOperationPrefixed(reg, mem, ri_op, rip_op, rr_op);   \
   }
@@ -3581,7 +3581,7 @@ MEM_OP_PREFIXED_LIST(MEM_OP_PREFIXED_FUNCTION)
   V(LoadSimd128Uint8, lxsibzx)
 
 #define MEM_OP_SIMD_FUNCTION(name, rr_op)                               \
-  void TurboAssembler::name(Simd128Register reg, const MemOperand& mem, \
+  void MacroAssembler::name(Simd128Register reg, const MemOperand& mem, \
                             Register scratch) {                         \
     GenerateMemoryOperationRR(reg, mem, rr_op);                         \
   }
@@ -3589,7 +3589,7 @@ MEM_OP_SIMD_LIST(MEM_OP_SIMD_FUNCTION)
 #undef MEM_OP_SIMD_LIST
 #undef MEM_OP_SIMD_FUNCTION
 
-void TurboAssembler::LoadS8(Register dst, const MemOperand& mem,
+void MacroAssembler::LoadS8(Register dst, const MemOperand& mem,
                             Register scratch) {
   LoadU8(dst, mem, scratch);
   extsb(dst, dst);
@@ -3605,13 +3605,13 @@ void TurboAssembler::LoadS8(Register dst, const MemOperand& mem,
 
 #ifdef V8_TARGET_BIG_ENDIAN
 #define MEM_LE_OP_FUNCTION(name, op)                                 \
-  void TurboAssembler::name##LE(Register reg, const MemOperand& mem, \
+  void MacroAssembler::name##LE(Register reg, const MemOperand& mem, \
                                 Register scratch) {                  \
     GenerateMemoryOperationRR(reg, mem, op);                         \
   }
 #else
 #define MEM_LE_OP_FUNCTION(name, op)                                 \
-  void TurboAssembler::name##LE(Register reg, const MemOperand& mem, \
+  void MacroAssembler::name##LE(Register reg, const MemOperand& mem, \
                                 Register scratch) {                  \
     name(reg, mem, scratch);                                         \
   }
@@ -3621,7 +3621,7 @@ MEM_LE_OP_LIST(MEM_LE_OP_FUNCTION)
 #undef MEM_LE_OP_FUNCTION
 #undef MEM_LE_OP_LIST
 
-void TurboAssembler::LoadS32LE(Register dst, const MemOperand& mem,
+void MacroAssembler::LoadS32LE(Register dst, const MemOperand& mem,
                                Register scratch) {
 #ifdef V8_TARGET_BIG_ENDIAN
   LoadU32LE(dst, mem, scratch);
@@ -3631,7 +3631,7 @@ void TurboAssembler::LoadS32LE(Register dst, const MemOperand& mem,
 #endif
 }
 
-void TurboAssembler::LoadS16LE(Register dst, const MemOperand& mem,
+void MacroAssembler::LoadS16LE(Register dst, const MemOperand& mem,
                                Register scratch) {
 #ifdef V8_TARGET_BIG_ENDIAN
   LoadU16LE(dst, mem, scratch);
@@ -3641,7 +3641,7 @@ void TurboAssembler::LoadS16LE(Register dst, const MemOperand& mem,
 #endif
 }
 
-void TurboAssembler::LoadF64LE(DoubleRegister dst, const MemOperand& mem,
+void MacroAssembler::LoadF64LE(DoubleRegister dst, const MemOperand& mem,
                                Register scratch, Register scratch2) {
 #ifdef V8_TARGET_BIG_ENDIAN
   LoadU64LE(scratch, mem, scratch2);
@@ -3653,7 +3653,7 @@ void TurboAssembler::LoadF64LE(DoubleRegister dst, const MemOperand& mem,
 #endif
 }
 
-void TurboAssembler::LoadF32LE(DoubleRegister dst, const MemOperand& mem,
+void MacroAssembler::LoadF32LE(DoubleRegister dst, const MemOperand& mem,
                                Register scratch, Register scratch2) {
 #ifdef V8_TARGET_BIG_ENDIAN
   LoadU32LE(scratch, mem, scratch2);
@@ -3665,7 +3665,7 @@ void TurboAssembler::LoadF32LE(DoubleRegister dst, const MemOperand& mem,
 #endif
 }
 
-void TurboAssembler::StoreF64LE(DoubleRegister dst, const MemOperand& mem,
+void MacroAssembler::StoreF64LE(DoubleRegister dst, const MemOperand& mem,
                                 Register scratch, Register scratch2) {
 #ifdef V8_TARGET_BIG_ENDIAN
   StoreF64(dst, mem, scratch2);
@@ -3676,7 +3676,7 @@ void TurboAssembler::StoreF64LE(DoubleRegister dst, const MemOperand& mem,
 #endif
 }
 
-void TurboAssembler::StoreF32LE(DoubleRegister dst, const MemOperand& mem,
+void MacroAssembler::StoreF32LE(DoubleRegister dst, const MemOperand& mem,
                                 Register scratch, Register scratch2) {
 #ifdef V8_TARGET_BIG_ENDIAN
   StoreF32(dst, mem, scratch2);
@@ -3749,7 +3749,7 @@ void TurboAssembler::StoreF32LE(DoubleRegister dst, const MemOperand& mem,
   V(S128AndNot, vandc)
 
 #define EMIT_SIMD_BINOP(name, op)                                      \
-  void TurboAssembler::name(Simd128Register dst, Simd128Register src1, \
+  void MacroAssembler::name(Simd128Register dst, Simd128Register src1, \
                             Simd128Register src2) {                    \
     op(dst, src1, src2);                                               \
   }
@@ -3772,13 +3772,13 @@ SIMD_BINOP_LIST(EMIT_SIMD_BINOP)
   V(I8x16ShrU, vsrb)
 
 #define EMIT_SIMD_SHIFT(name, op)                                      \
-  void TurboAssembler::name(Simd128Register dst, Simd128Register src1, \
+  void MacroAssembler::name(Simd128Register dst, Simd128Register src1, \
                             Register src2, Simd128Register scratch) {  \
     mtvsrd(scratch, src2);                                             \
     vspltb(scratch, scratch, Operand(7));                              \
     op(dst, src1, scratch);                                            \
   }                                                                    \
-  void TurboAssembler::name(Simd128Register dst, Simd128Register src1, \
+  void MacroAssembler::name(Simd128Register dst, Simd128Register src1, \
                             const Operand& src2, Register scratch1,    \
                             Simd128Register scratch2) {                \
     mov(scratch1, src2);                                               \
@@ -3815,7 +3815,7 @@ SIMD_SHIFT_LIST(EMIT_SIMD_SHIFT)
   V(I8x16Popcnt, vpopcntb)
 
 #define EMIT_SIMD_UNOP(name, op)                                        \
-  void TurboAssembler::name(Simd128Register dst, Simd128Register src) { \
+  void MacroAssembler::name(Simd128Register dst, Simd128Register src) { \
     op(dst, src);                                                       \
   }
 SIMD_UNOP_LIST(EMIT_SIMD_UNOP)
@@ -3836,7 +3836,7 @@ SIMD_UNOP_LIST(EMIT_SIMD_UNOP)
   V(I16x8ExtMulHighI8x16U, vmuleub, vmuloub, vmrghh)
 
 #define EMIT_SIMD_EXT_MUL(name, mul_even, mul_odd, merge)                    \
-  void TurboAssembler::name(Simd128Register dst, Simd128Register src1,       \
+  void MacroAssembler::name(Simd128Register dst, Simd128Register src1,       \
                             Simd128Register src2, Simd128Register scratch) { \
     EXT_MUL(scratch, dst, mul_even, mul_odd)                                 \
     merge(dst, scratch, dst);                                                \
@@ -3852,7 +3852,7 @@ SIMD_EXT_MUL_LIST(EMIT_SIMD_EXT_MUL)
   V(I8x16AllTrue, vcmpgtub)
 
 #define EMIT_SIMD_ALL_TRUE(name, op)                              \
-  void TurboAssembler::name(Register dst, Simd128Register src,    \
+  void MacroAssembler::name(Register dst, Simd128Register src,    \
                             Register scratch1, Register scratch2, \
                             Simd128Register scratch3) {           \
     constexpr uint8_t fxm = 0x2; /* field mask. */                \
@@ -3875,7 +3875,7 @@ SIMD_ALL_TRUE_LIST(EMIT_SIMD_ALL_TRUE)
   V(I16x8BitMask, vextracthm, 0x10203040506070)
 
 #define EMIT_SIMD_BITMASK(name, op, indicies)                              \
-  void TurboAssembler::name(Register dst, Simd128Register src,             \
+  void MacroAssembler::name(Register dst, Simd128Register src,             \
                             Register scratch1, Simd128Register scratch2) { \
     if (CpuFeatures::IsSupported(PPC_10_PLUS)) {                           \
       op(dst, src);                                                        \
@@ -3898,7 +3898,7 @@ SIMD_BITMASK_LIST(EMIT_SIMD_BITMASK)
   V(F32x4Qfms, xvnmsubmsp)
 
 #define EMIT_SIMD_QFM(name, op)                                         \
-  void TurboAssembler::name(Simd128Register dst, Simd128Register src1,  \
+  void MacroAssembler::name(Simd128Register dst, Simd128Register src1,  \
                             Simd128Register src2, Simd128Register src3, \
                             Simd128Register scratch) {                  \
     Simd128Register dest = dst;                                         \
@@ -3915,7 +3915,7 @@ SIMD_QFM_LIST(EMIT_SIMD_QFM)
 #undef EMIT_SIMD_QFM
 #undef SIMD_QFM_LIST
 
-void TurboAssembler::I64x2ExtMulLowI32x4S(Simd128Register dst,
+void MacroAssembler::I64x2ExtMulLowI32x4S(Simd128Register dst,
                                           Simd128Register src1,
                                           Simd128Register src2,
                                           Simd128Register scratch) {
@@ -3925,7 +3925,7 @@ void TurboAssembler::I64x2ExtMulLowI32x4S(Simd128Register dst,
   vinsertd(dst, scratch, Operand(0));
 }
 
-void TurboAssembler::I64x2ExtMulHighI32x4S(Simd128Register dst,
+void MacroAssembler::I64x2ExtMulHighI32x4S(Simd128Register dst,
                                            Simd128Register src1,
                                            Simd128Register src2,
                                            Simd128Register scratch) {
@@ -3935,7 +3935,7 @@ void TurboAssembler::I64x2ExtMulHighI32x4S(Simd128Register dst,
   vor(dst, scratch, scratch);
 }
 
-void TurboAssembler::I64x2ExtMulLowI32x4U(Simd128Register dst,
+void MacroAssembler::I64x2ExtMulLowI32x4U(Simd128Register dst,
                                           Simd128Register src1,
                                           Simd128Register src2,
                                           Simd128Register scratch) {
@@ -3945,7 +3945,7 @@ void TurboAssembler::I64x2ExtMulLowI32x4U(Simd128Register dst,
   vinsertd(dst, scratch, Operand(0));
 }
 
-void TurboAssembler::I64x2ExtMulHighI32x4U(Simd128Register dst,
+void MacroAssembler::I64x2ExtMulHighI32x4U(Simd128Register dst,
                                            Simd128Register src1,
                                            Simd128Register src2,
                                            Simd128Register scratch) {
@@ -3956,7 +3956,7 @@ void TurboAssembler::I64x2ExtMulHighI32x4U(Simd128Register dst,
 }
 #undef EXT_MUL
 
-void TurboAssembler::LoadSimd128LE(Simd128Register dst, const MemOperand& mem,
+void MacroAssembler::LoadSimd128LE(Simd128Register dst, const MemOperand& mem,
                                    Register scratch) {
 #ifdef V8_TARGET_BIG_ENDIAN
   LoadSimd128(dst, mem, scratch);
@@ -3966,7 +3966,7 @@ void TurboAssembler::LoadSimd128LE(Simd128Register dst, const MemOperand& mem,
 #endif
 }
 
-void TurboAssembler::StoreSimd128LE(Simd128Register src, const MemOperand& mem,
+void MacroAssembler::StoreSimd128LE(Simd128Register src, const MemOperand& mem,
                                     Register scratch1,
                                     Simd128Register scratch2) {
 #ifdef V8_TARGET_BIG_ENDIAN
@@ -3977,7 +3977,7 @@ void TurboAssembler::StoreSimd128LE(Simd128Register src, const MemOperand& mem,
 #endif
 }
 
-void TurboAssembler::F64x2Splat(Simd128Register dst, DoubleRegister src,
+void MacroAssembler::F64x2Splat(Simd128Register dst, DoubleRegister src,
                                 Register scratch) {
   constexpr int lane_width_in_bytes = 8;
   MovDoubleToInt64(scratch, src);
@@ -3985,35 +3985,35 @@ void TurboAssembler::F64x2Splat(Simd128Register dst, DoubleRegister src,
   vinsertd(dst, dst, Operand(1 * lane_width_in_bytes));
 }
 
-void TurboAssembler::F32x4Splat(Simd128Register dst, DoubleRegister src,
+void MacroAssembler::F32x4Splat(Simd128Register dst, DoubleRegister src,
                                 DoubleRegister scratch1, Register scratch2) {
   MovFloatToInt(scratch2, src, scratch1);
   mtvsrd(dst, scratch2);
   vspltw(dst, dst, Operand(1));
 }
 
-void TurboAssembler::I64x2Splat(Simd128Register dst, Register src) {
+void MacroAssembler::I64x2Splat(Simd128Register dst, Register src) {
   constexpr int lane_width_in_bytes = 8;
   mtvsrd(dst, src);
   vinsertd(dst, dst, Operand(1 * lane_width_in_bytes));
 }
 
-void TurboAssembler::I32x4Splat(Simd128Register dst, Register src) {
+void MacroAssembler::I32x4Splat(Simd128Register dst, Register src) {
   mtvsrd(dst, src);
   vspltw(dst, dst, Operand(1));
 }
 
-void TurboAssembler::I16x8Splat(Simd128Register dst, Register src) {
+void MacroAssembler::I16x8Splat(Simd128Register dst, Register src) {
   mtvsrd(dst, src);
   vsplth(dst, dst, Operand(3));
 }
 
-void TurboAssembler::I8x16Splat(Simd128Register dst, Register src) {
+void MacroAssembler::I8x16Splat(Simd128Register dst, Register src) {
   mtvsrd(dst, src);
   vspltb(dst, dst, Operand(7));
 }
 
-void TurboAssembler::F64x2ExtractLane(DoubleRegister dst, Simd128Register src,
+void MacroAssembler::F64x2ExtractLane(DoubleRegister dst, Simd128Register src,
                                       uint8_t imm_lane_idx,
                                       Simd128Register scratch1,
                                       Register scratch2) {
@@ -4023,7 +4023,7 @@ void TurboAssembler::F64x2ExtractLane(DoubleRegister dst, Simd128Register src,
   MovInt64ToDouble(dst, scratch2);
 }
 
-void TurboAssembler::F32x4ExtractLane(DoubleRegister dst, Simd128Register src,
+void MacroAssembler::F32x4ExtractLane(DoubleRegister dst, Simd128Register src,
                                       uint8_t imm_lane_idx,
                                       Simd128Register scratch1,
                                       Register scratch2, Register scratch3) {
@@ -4033,7 +4033,7 @@ void TurboAssembler::F32x4ExtractLane(DoubleRegister dst, Simd128Register src,
   MovIntToFloat(dst, scratch2, scratch3);
 }
 
-void TurboAssembler::I64x2ExtractLane(Register dst, Simd128Register src,
+void MacroAssembler::I64x2ExtractLane(Register dst, Simd128Register src,
                                       uint8_t imm_lane_idx,
                                       Simd128Register scratch) {
   constexpr int lane_width_in_bytes = 8;
@@ -4041,7 +4041,7 @@ void TurboAssembler::I64x2ExtractLane(Register dst, Simd128Register src,
   mfvsrd(dst, scratch);
 }
 
-void TurboAssembler::I32x4ExtractLane(Register dst, Simd128Register src,
+void MacroAssembler::I32x4ExtractLane(Register dst, Simd128Register src,
                                       uint8_t imm_lane_idx,
                                       Simd128Register scratch) {
   constexpr int lane_width_in_bytes = 4;
@@ -4049,7 +4049,7 @@ void TurboAssembler::I32x4ExtractLane(Register dst, Simd128Register src,
   mfvsrd(dst, scratch);
 }
 
-void TurboAssembler::I16x8ExtractLaneU(Register dst, Simd128Register src,
+void MacroAssembler::I16x8ExtractLaneU(Register dst, Simd128Register src,
                                        uint8_t imm_lane_idx,
                                        Simd128Register scratch) {
   constexpr int lane_width_in_bytes = 2;
@@ -4057,28 +4057,28 @@ void TurboAssembler::I16x8ExtractLaneU(Register dst, Simd128Register src,
   mfvsrd(dst, scratch);
 }
 
-void TurboAssembler::I16x8ExtractLaneS(Register dst, Simd128Register src,
+void MacroAssembler::I16x8ExtractLaneS(Register dst, Simd128Register src,
                                        uint8_t imm_lane_idx,
                                        Simd128Register scratch) {
   I16x8ExtractLaneU(dst, src, imm_lane_idx, scratch);
   extsh(dst, dst);
 }
 
-void TurboAssembler::I8x16ExtractLaneU(Register dst, Simd128Register src,
+void MacroAssembler::I8x16ExtractLaneU(Register dst, Simd128Register src,
                                        uint8_t imm_lane_idx,
                                        Simd128Register scratch) {
   vextractub(scratch, src, Operand(15 - imm_lane_idx));
   mfvsrd(dst, scratch);
 }
 
-void TurboAssembler::I8x16ExtractLaneS(Register dst, Simd128Register src,
+void MacroAssembler::I8x16ExtractLaneS(Register dst, Simd128Register src,
                                        uint8_t imm_lane_idx,
                                        Simd128Register scratch) {
   I8x16ExtractLaneU(dst, src, imm_lane_idx, scratch);
   extsb(dst, dst);
 }
 
-void TurboAssembler::F64x2ReplaceLane(Simd128Register dst, Simd128Register src1,
+void MacroAssembler::F64x2ReplaceLane(Simd128Register dst, Simd128Register src1,
                                       DoubleRegister src2, uint8_t imm_lane_idx,
                                       Register scratch1,
                                       Simd128Register scratch2) {
@@ -4095,7 +4095,7 @@ void TurboAssembler::F64x2ReplaceLane(Simd128Register dst, Simd128Register src1,
   }
 }
 
-void TurboAssembler::F32x4ReplaceLane(Simd128Register dst, Simd128Register src1,
+void MacroAssembler::F32x4ReplaceLane(Simd128Register dst, Simd128Register src1,
                                       DoubleRegister src2, uint8_t imm_lane_idx,
                                       Register scratch1,
                                       DoubleRegister scratch2,
@@ -4113,7 +4113,7 @@ void TurboAssembler::F32x4ReplaceLane(Simd128Register dst, Simd128Register src1,
   }
 }
 
-void TurboAssembler::I64x2ReplaceLane(Simd128Register dst, Simd128Register src1,
+void MacroAssembler::I64x2ReplaceLane(Simd128Register dst, Simd128Register src1,
                                       Register src2, uint8_t imm_lane_idx,
                                       Simd128Register scratch) {
   constexpr int lane_width_in_bytes = 8;
@@ -4128,7 +4128,7 @@ void TurboAssembler::I64x2ReplaceLane(Simd128Register dst, Simd128Register src1,
   }
 }
 
-void TurboAssembler::I32x4ReplaceLane(Simd128Register dst, Simd128Register src1,
+void MacroAssembler::I32x4ReplaceLane(Simd128Register dst, Simd128Register src1,
                                       Register src2, uint8_t imm_lane_idx,
                                       Simd128Register scratch) {
   constexpr int lane_width_in_bytes = 4;
@@ -4143,7 +4143,7 @@ void TurboAssembler::I32x4ReplaceLane(Simd128Register dst, Simd128Register src1,
   }
 }
 
-void TurboAssembler::I16x8ReplaceLane(Simd128Register dst, Simd128Register src1,
+void MacroAssembler::I16x8ReplaceLane(Simd128Register dst, Simd128Register src1,
                                       Register src2, uint8_t imm_lane_idx,
                                       Simd128Register scratch) {
   constexpr int lane_width_in_bytes = 2;
@@ -4154,7 +4154,7 @@ void TurboAssembler::I16x8ReplaceLane(Simd128Register dst, Simd128Register src1,
   vinserth(dst, scratch, Operand((7 - imm_lane_idx) * lane_width_in_bytes));
 }
 
-void TurboAssembler::I8x16ReplaceLane(Simd128Register dst, Simd128Register src1,
+void MacroAssembler::I8x16ReplaceLane(Simd128Register dst, Simd128Register src1,
                                       Register src2, uint8_t imm_lane_idx,
                                       Simd128Register scratch) {
   if (src1 != dst) {
@@ -4164,7 +4164,7 @@ void TurboAssembler::I8x16ReplaceLane(Simd128Register dst, Simd128Register src1,
   vinsertb(dst, scratch, Operand(15 - imm_lane_idx));
 }
 
-void TurboAssembler::I64x2Mul(Simd128Register dst, Simd128Register src1,
+void MacroAssembler::I64x2Mul(Simd128Register dst, Simd128Register src1,
                               Simd128Register src2, Register scratch1,
                               Register scratch2, Register scratch3,
                               Simd128Register scratch4) {
@@ -4191,7 +4191,7 @@ void TurboAssembler::I64x2Mul(Simd128Register dst, Simd128Register src1,
   }
 }
 
-void TurboAssembler::I16x8Mul(Simd128Register dst, Simd128Register src1,
+void MacroAssembler::I16x8Mul(Simd128Register dst, Simd128Register src1,
                               Simd128Register src2) {
   vxor(kSimd128RegZero, kSimd128RegZero, kSimd128RegZero);
   vmladduhm(dst, src1, src2, kSimd128RegZero);
@@ -4204,7 +4204,7 @@ void TurboAssembler::I16x8Mul(Simd128Register dst, Simd128Register src1,
   vsel(dst, src2, result, scratch2);                     \
   /* Use xvmindp to turn any selected SNANs to QNANs. */ \
   xvmindp(dst, dst, dst);
-void TurboAssembler::F64x2Min(Simd128Register dst, Simd128Register src1,
+void MacroAssembler::F64x2Min(Simd128Register dst, Simd128Register src1,
                               Simd128Register src2, Simd128Register scratch1,
                               Simd128Register scratch2) {
   xvmindp(scratch1, src1, src2);
@@ -4212,7 +4212,7 @@ void TurboAssembler::F64x2Min(Simd128Register dst, Simd128Register src1,
   F64X2_MIN_MAX_NAN(scratch1)
 }
 
-void TurboAssembler::F64x2Max(Simd128Register dst, Simd128Register src1,
+void MacroAssembler::F64x2Max(Simd128Register dst, Simd128Register src1,
                               Simd128Register src2, Simd128Register scratch1,
                               Simd128Register scratch2) {
   xvmaxdp(scratch1, src1, src2);
@@ -4221,108 +4221,108 @@ void TurboAssembler::F64x2Max(Simd128Register dst, Simd128Register src1,
 }
 #undef F64X2_MIN_MAX_NAN
 
-void TurboAssembler::F64x2Lt(Simd128Register dst, Simd128Register src1,
+void MacroAssembler::F64x2Lt(Simd128Register dst, Simd128Register src1,
                              Simd128Register src2) {
   xvcmpgtdp(dst, src2, src1);
 }
 
-void TurboAssembler::F64x2Le(Simd128Register dst, Simd128Register src1,
+void MacroAssembler::F64x2Le(Simd128Register dst, Simd128Register src1,
                              Simd128Register src2) {
   xvcmpgedp(dst, src2, src1);
 }
 
-void TurboAssembler::F64x2Ne(Simd128Register dst, Simd128Register src1,
+void MacroAssembler::F64x2Ne(Simd128Register dst, Simd128Register src1,
                              Simd128Register src2, Simd128Register scratch) {
   xvcmpeqdp(scratch, src1, src2);
   vnor(dst, scratch, scratch);
 }
 
-void TurboAssembler::F32x4Lt(Simd128Register dst, Simd128Register src1,
+void MacroAssembler::F32x4Lt(Simd128Register dst, Simd128Register src1,
                              Simd128Register src2) {
   xvcmpgtsp(dst, src2, src1);
 }
 
-void TurboAssembler::F32x4Le(Simd128Register dst, Simd128Register src1,
+void MacroAssembler::F32x4Le(Simd128Register dst, Simd128Register src1,
                              Simd128Register src2) {
   xvcmpgesp(dst, src2, src1);
 }
 
-void TurboAssembler::F32x4Ne(Simd128Register dst, Simd128Register src1,
+void MacroAssembler::F32x4Ne(Simd128Register dst, Simd128Register src1,
                              Simd128Register src2, Simd128Register scratch) {
   xvcmpeqsp(scratch, src1, src2);
   vnor(dst, scratch, scratch);
 }
 
-void TurboAssembler::I64x2Ne(Simd128Register dst, Simd128Register src1,
+void MacroAssembler::I64x2Ne(Simd128Register dst, Simd128Register src1,
                              Simd128Register src2, Simd128Register scratch) {
   vcmpequd(scratch, src1, src2);
   vnor(dst, scratch, scratch);
 }
 
-void TurboAssembler::I64x2GeS(Simd128Register dst, Simd128Register src1,
+void MacroAssembler::I64x2GeS(Simd128Register dst, Simd128Register src1,
                               Simd128Register src2, Simd128Register scratch) {
   vcmpgtsd(scratch, src2, src1);
   vnor(dst, scratch, scratch);
 }
 
-void TurboAssembler::I32x4Ne(Simd128Register dst, Simd128Register src1,
+void MacroAssembler::I32x4Ne(Simd128Register dst, Simd128Register src1,
                              Simd128Register src2, Simd128Register scratch) {
   vcmpequw(scratch, src1, src2);
   vnor(dst, scratch, scratch);
 }
 
-void TurboAssembler::I32x4GeS(Simd128Register dst, Simd128Register src1,
+void MacroAssembler::I32x4GeS(Simd128Register dst, Simd128Register src1,
                               Simd128Register src2, Simd128Register scratch) {
   vcmpgtsw(scratch, src2, src1);
   vnor(dst, scratch, scratch);
 }
 
-void TurboAssembler::I32x4GeU(Simd128Register dst, Simd128Register src1,
+void MacroAssembler::I32x4GeU(Simd128Register dst, Simd128Register src1,
                               Simd128Register src2, Simd128Register scratch) {
   vcmpequw(scratch, src1, src2);
   vcmpgtuw(dst, src1, src2);
   vor(dst, dst, scratch);
 }
 
-void TurboAssembler::I16x8Ne(Simd128Register dst, Simd128Register src1,
+void MacroAssembler::I16x8Ne(Simd128Register dst, Simd128Register src1,
                              Simd128Register src2, Simd128Register scratch) {
   vcmpequh(scratch, src1, src2);
   vnor(dst, scratch, scratch);
 }
 
-void TurboAssembler::I16x8GeS(Simd128Register dst, Simd128Register src1,
+void MacroAssembler::I16x8GeS(Simd128Register dst, Simd128Register src1,
                               Simd128Register src2, Simd128Register scratch) {
   vcmpgtsh(scratch, src2, src1);
   vnor(dst, scratch, scratch);
 }
 
-void TurboAssembler::I16x8GeU(Simd128Register dst, Simd128Register src1,
+void MacroAssembler::I16x8GeU(Simd128Register dst, Simd128Register src1,
                               Simd128Register src2, Simd128Register scratch) {
   vcmpequh(scratch, src1, src2);
   vcmpgtuh(dst, src1, src2);
   vor(dst, dst, scratch);
 }
 
-void TurboAssembler::I8x16Ne(Simd128Register dst, Simd128Register src1,
+void MacroAssembler::I8x16Ne(Simd128Register dst, Simd128Register src1,
                              Simd128Register src2, Simd128Register scratch) {
   vcmpequb(scratch, src1, src2);
   vnor(dst, scratch, scratch);
 }
 
-void TurboAssembler::I8x16GeS(Simd128Register dst, Simd128Register src1,
+void MacroAssembler::I8x16GeS(Simd128Register dst, Simd128Register src1,
                               Simd128Register src2, Simd128Register scratch) {
   vcmpgtsb(scratch, src2, src1);
   vnor(dst, scratch, scratch);
 }
 
-void TurboAssembler::I8x16GeU(Simd128Register dst, Simd128Register src1,
+void MacroAssembler::I8x16GeU(Simd128Register dst, Simd128Register src1,
                               Simd128Register src2, Simd128Register scratch) {
   vcmpequb(scratch, src1, src2);
   vcmpgtub(dst, src1, src2);
   vor(dst, dst, scratch);
 }
 
-void TurboAssembler::I64x2Abs(Simd128Register dst, Simd128Register src,
+void MacroAssembler::I64x2Abs(Simd128Register dst, Simd128Register src,
                               Simd128Register scratch) {
   constexpr int shift_bits = 63;
   xxspltib(scratch, Operand(shift_bits));
@@ -4330,7 +4330,7 @@ void TurboAssembler::I64x2Abs(Simd128Register dst, Simd128Register src,
   vxor(dst, src, scratch);
   vsubudm(dst, dst, scratch);
 }
-void TurboAssembler::I32x4Abs(Simd128Register dst, Simd128Register src,
+void MacroAssembler::I32x4Abs(Simd128Register dst, Simd128Register src,
                               Simd128Register scratch) {
   constexpr int shift_bits = 31;
   xxspltib(scratch, Operand(shift_bits));
@@ -4338,7 +4338,7 @@ void TurboAssembler::I32x4Abs(Simd128Register dst, Simd128Register src,
   vxor(dst, src, scratch);
   vsubuwm(dst, dst, scratch);
 }
-void TurboAssembler::I16x8Abs(Simd128Register dst, Simd128Register src,
+void MacroAssembler::I16x8Abs(Simd128Register dst, Simd128Register src,
                               Simd128Register scratch) {
   constexpr int shift_bits = 15;
   xxspltib(scratch, Operand(shift_bits));
@@ -4346,13 +4346,13 @@ void TurboAssembler::I16x8Abs(Simd128Register dst, Simd128Register src,
   vxor(dst, src, scratch);
   vsubuhm(dst, dst, scratch);
 }
-void TurboAssembler::I16x8Neg(Simd128Register dst, Simd128Register src,
+void MacroAssembler::I16x8Neg(Simd128Register dst, Simd128Register src,
                               Simd128Register scratch) {
   vspltish(scratch, Operand(1));
   vnor(dst, src, src);
   vadduhm(dst, scratch, dst);
 }
-void TurboAssembler::I8x16Abs(Simd128Register dst, Simd128Register src,
+void MacroAssembler::I8x16Abs(Simd128Register dst, Simd128Register src,
                               Simd128Register scratch) {
   constexpr int shift_bits = 7;
   xxspltib(scratch, Operand(shift_bits));
@@ -4360,38 +4360,38 @@ void TurboAssembler::I8x16Abs(Simd128Register dst, Simd128Register src,
   vxor(dst, src, scratch);
   vsububm(dst, dst, scratch);
 }
-void TurboAssembler::I8x16Neg(Simd128Register dst, Simd128Register src,
+void MacroAssembler::I8x16Neg(Simd128Register dst, Simd128Register src,
                               Simd128Register scratch) {
   xxspltib(scratch, Operand(1));
   vnor(dst, src, src);
   vaddubm(dst, scratch, dst);
 }
 
-void TurboAssembler::F64x2Pmin(Simd128Register dst, Simd128Register src1,
+void MacroAssembler::F64x2Pmin(Simd128Register dst, Simd128Register src1,
                                Simd128Register src2, Simd128Register scratch) {
   xvcmpgtdp(kScratchSimd128Reg, src1, src2);
   vsel(dst, src1, src2, kScratchSimd128Reg);
 }
 
-void TurboAssembler::F64x2Pmax(Simd128Register dst, Simd128Register src1,
+void MacroAssembler::F64x2Pmax(Simd128Register dst, Simd128Register src1,
                                Simd128Register src2, Simd128Register scratch) {
   xvcmpgtdp(kScratchSimd128Reg, src2, src1);
   vsel(dst, src1, src2, kScratchSimd128Reg);
 }
 
-void TurboAssembler::F32x4Pmin(Simd128Register dst, Simd128Register src1,
+void MacroAssembler::F32x4Pmin(Simd128Register dst, Simd128Register src1,
                                Simd128Register src2, Simd128Register scratch) {
   xvcmpgtsp(kScratchSimd128Reg, src1, src2);
   vsel(dst, src1, src2, kScratchSimd128Reg);
 }
 
-void TurboAssembler::F32x4Pmax(Simd128Register dst, Simd128Register src1,
+void MacroAssembler::F32x4Pmax(Simd128Register dst, Simd128Register src1,
                                Simd128Register src2, Simd128Register scratch) {
   xvcmpgtsp(kScratchSimd128Reg, src2, src1);
   vsel(dst, src1, src2, kScratchSimd128Reg);
 }
 
-void TurboAssembler::I32x4SConvertF32x4(Simd128Register dst,
+void MacroAssembler::I32x4SConvertF32x4(Simd128Register dst,
                                         Simd128Register src,
                                         Simd128Register scratch) {
   // NaN to 0
@@ -4400,37 +4400,37 @@ void TurboAssembler::I32x4SConvertF32x4(Simd128Register dst,
   xvcvspsxws(dst, scratch);
 }
 
-void TurboAssembler::I16x8SConvertI32x4(Simd128Register dst,
+void MacroAssembler::I16x8SConvertI32x4(Simd128Register dst,
                                         Simd128Register src1,
                                         Simd128Register src2) {
   vpkswss(dst, src2, src1);
 }
 
-void TurboAssembler::I16x8UConvertI32x4(Simd128Register dst,
+void MacroAssembler::I16x8UConvertI32x4(Simd128Register dst,
                                         Simd128Register src1,
                                         Simd128Register src2) {
   vpkswus(dst, src2, src1);
 }
 
-void TurboAssembler::I8x16SConvertI16x8(Simd128Register dst,
+void MacroAssembler::I8x16SConvertI16x8(Simd128Register dst,
                                         Simd128Register src1,
                                         Simd128Register src2) {
   vpkshss(dst, src2, src1);
 }
 
-void TurboAssembler::I8x16UConvertI16x8(Simd128Register dst,
+void MacroAssembler::I8x16UConvertI16x8(Simd128Register dst,
                                         Simd128Register src1,
                                         Simd128Register src2) {
   vpkshus(dst, src2, src1);
 }
 
-void TurboAssembler::F64x2ConvertLowI32x4S(Simd128Register dst,
+void MacroAssembler::F64x2ConvertLowI32x4S(Simd128Register dst,
                                            Simd128Register src) {
   vupklsw(dst, src);
   xvcvsxddp(dst, dst);
 }
 
-void TurboAssembler::F64x2ConvertLowI32x4U(Simd128Register dst,
+void MacroAssembler::F64x2ConvertLowI32x4U(Simd128Register dst,
                                            Simd128Register src,
                                            Register scratch1,
                                            Simd128Register scratch2) {
@@ -4444,7 +4444,7 @@ void TurboAssembler::F64x2ConvertLowI32x4U(Simd128Register dst,
   xvcvuxddp(dst, dst);
 }
 
-void TurboAssembler::I64x2UConvertI32x4Low(Simd128Register dst,
+void MacroAssembler::I64x2UConvertI32x4Low(Simd128Register dst,
                                            Simd128Register src,
                                            Register scratch1,
                                            Simd128Register scratch2) {
@@ -4457,7 +4457,7 @@ void TurboAssembler::I64x2UConvertI32x4Low(Simd128Register dst,
   vand(dst, scratch2, dst);
 }
 
-void TurboAssembler::I64x2UConvertI32x4High(Simd128Register dst,
+void MacroAssembler::I64x2UConvertI32x4High(Simd128Register dst,
                                             Simd128Register src,
                                             Register scratch1,
                                             Simd128Register scratch2) {
@@ -4470,7 +4470,7 @@ void TurboAssembler::I64x2UConvertI32x4High(Simd128Register dst,
   vand(dst, scratch2, dst);
 }
 
-void TurboAssembler::I32x4UConvertI16x8Low(Simd128Register dst,
+void MacroAssembler::I32x4UConvertI16x8Low(Simd128Register dst,
                                            Simd128Register src,
                                            Register scratch1,
                                            Simd128Register scratch2) {
@@ -4482,7 +4482,7 @@ void TurboAssembler::I32x4UConvertI16x8Low(Simd128Register dst,
   vand(dst, scratch2, dst);
 }
 
-void TurboAssembler::I32x4UConvertI16x8High(Simd128Register dst,
+void MacroAssembler::I32x4UConvertI16x8High(Simd128Register dst,
                                             Simd128Register src,
                                             Register scratch1,
                                             Simd128Register scratch2) {
@@ -4494,7 +4494,7 @@ void TurboAssembler::I32x4UConvertI16x8High(Simd128Register dst,
   vand(dst, scratch2, dst);
 }
 
-void TurboAssembler::I16x8UConvertI8x16Low(Simd128Register dst,
+void MacroAssembler::I16x8UConvertI8x16Low(Simd128Register dst,
                                            Simd128Register src,
                                            Register scratch1,
                                            Simd128Register scratch2) {
@@ -4506,7 +4506,7 @@ void TurboAssembler::I16x8UConvertI8x16Low(Simd128Register dst,
   vand(dst, scratch2, dst);
 }
 
-void TurboAssembler::I16x8UConvertI8x16High(Simd128Register dst,
+void MacroAssembler::I16x8UConvertI8x16High(Simd128Register dst,
                                             Simd128Register src,
                                             Register scratch1,
                                             Simd128Register scratch2) {
@@ -4518,7 +4518,7 @@ void TurboAssembler::I16x8UConvertI8x16High(Simd128Register dst,
   vand(dst, scratch2, dst);
 }
 
-void TurboAssembler::I8x16BitMask(Register dst, Simd128Register src,
+void MacroAssembler::I8x16BitMask(Register dst, Simd128Register src,
                                   Register scratch1, Register scratch2,
                                   Simd128Register scratch3) {
   if (CpuFeatures::IsSupported(PPC_10_PLUS)) {
@@ -4532,21 +4532,21 @@ void TurboAssembler::I8x16BitMask(Register dst, Simd128Register src,
   }
 }
 
-void TurboAssembler::I32x4DotI16x8S(Simd128Register dst, Simd128Register src1,
+void MacroAssembler::I32x4DotI16x8S(Simd128Register dst, Simd128Register src1,
                                     Simd128Register src2,
                                     Simd128Register scratch) {
   vxor(scratch, scratch, scratch);
   vmsumshm(dst, src1, src2, scratch);
 }
 
-void TurboAssembler::I16x8Q15MulRSatS(Simd128Register dst, Simd128Register src1,
+void MacroAssembler::I16x8Q15MulRSatS(Simd128Register dst, Simd128Register src1,
                                       Simd128Register src2,
                                       Simd128Register scratch) {
   vxor(scratch, scratch, scratch);
   vmhraddshs(dst, src1, src2, scratch);
 }
 
-void TurboAssembler::I8x16Swizzle(Simd128Register dst, Simd128Register src1,
+void MacroAssembler::I8x16Swizzle(Simd128Register dst, Simd128Register src1,
                                   Simd128Register src2,
                                   Simd128Register scratch) {
   // Saturate the indices to 5 bits. Input indices more than 31 should
@@ -4559,7 +4559,7 @@ void TurboAssembler::I8x16Swizzle(Simd128Register dst, Simd128Register src1,
   vperm(dst, dst, kSimd128RegZero, scratch);
 }
 
-void TurboAssembler::I8x16Shuffle(Simd128Register dst, Simd128Register src1,
+void MacroAssembler::I8x16Shuffle(Simd128Register dst, Simd128Register src1,
                                   Simd128Register src2, uint64_t high,
                                   uint64_t low, Register scratch1,
                                   Register scratch2, Simd128Register scratch3) {
@@ -4574,25 +4574,25 @@ void TurboAssembler::I8x16Shuffle(Simd128Register dst, Simd128Register src1,
   mul_even(scratch2, src, scratch1);                    \
   mul_odd(scratch1, src, scratch1);                     \
   add(dst, scratch2, scratch1);
-void TurboAssembler::I32x4ExtAddPairwiseI16x8S(Simd128Register dst,
+void MacroAssembler::I32x4ExtAddPairwiseI16x8S(Simd128Register dst,
                                                Simd128Register src,
                                                Simd128Register scratch1,
                                                Simd128Register scratch2) {
   EXT_ADD_PAIRWISE(vspltish, vmulesh, vmulosh, vadduwm)
 }
-void TurboAssembler::I32x4ExtAddPairwiseI16x8U(Simd128Register dst,
+void MacroAssembler::I32x4ExtAddPairwiseI16x8U(Simd128Register dst,
                                                Simd128Register src,
                                                Simd128Register scratch1,
                                                Simd128Register scratch2) {
   EXT_ADD_PAIRWISE(vspltish, vmuleuh, vmulouh, vadduwm)
 }
-void TurboAssembler::I16x8ExtAddPairwiseI8x16S(Simd128Register dst,
+void MacroAssembler::I16x8ExtAddPairwiseI8x16S(Simd128Register dst,
                                                Simd128Register src,
                                                Simd128Register scratch1,
                                                Simd128Register scratch2) {
   EXT_ADD_PAIRWISE(xxspltib, vmulesb, vmulosb, vadduhm)
 }
-void TurboAssembler::I16x8ExtAddPairwiseI8x16U(Simd128Register dst,
+void MacroAssembler::I16x8ExtAddPairwiseI8x16U(Simd128Register dst,
                                                Simd128Register src,
                                                Simd128Register scratch1,
                                                Simd128Register scratch2) {
@@ -4600,7 +4600,7 @@ void TurboAssembler::I16x8ExtAddPairwiseI8x16U(Simd128Register dst,
 }
 #undef EXT_ADD_PAIRWISE
 
-void TurboAssembler::F64x2PromoteLowF32x4(Simd128Register dst,
+void MacroAssembler::F64x2PromoteLowF32x4(Simd128Register dst,
                                           Simd128Register src) {
   constexpr int lane_number = 8;
   vextractd(dst, src, Operand(lane_number));
@@ -4608,7 +4608,7 @@ void TurboAssembler::F64x2PromoteLowF32x4(Simd128Register dst,
   xvcvspdp(dst, dst);
 }
 
-void TurboAssembler::F32x4DemoteF64x2Zero(Simd128Register dst,
+void MacroAssembler::F32x4DemoteF64x2Zero(Simd128Register dst,
                                           Simd128Register src,
                                           Simd128Register scratch) {
   constexpr int lane_number = 8;
@@ -4619,7 +4619,7 @@ void TurboAssembler::F32x4DemoteF64x2Zero(Simd128Register dst,
   vinsertd(dst, scratch, Operand(lane_number));
 }
 
-void TurboAssembler::I32x4TruncSatF64x2SZero(Simd128Register dst,
+void MacroAssembler::I32x4TruncSatF64x2SZero(Simd128Register dst,
                                              Simd128Register src,
                                              Simd128Register scratch) {
   constexpr int lane_number = 8;
@@ -4633,7 +4633,7 @@ void TurboAssembler::I32x4TruncSatF64x2SZero(Simd128Register dst,
   vinsertd(dst, scratch, Operand(lane_number));
 }
 
-void TurboAssembler::I32x4TruncSatF64x2UZero(Simd128Register dst,
+void MacroAssembler::I32x4TruncSatF64x2UZero(Simd128Register dst,
                                              Simd128Register src,
                                              Simd128Register scratch) {
   constexpr int lane_number = 8;
@@ -4649,7 +4649,7 @@ void TurboAssembler::I32x4TruncSatF64x2UZero(Simd128Register dst,
 #else
 #define MAYBE_REVERSE_BYTES(reg, instr)
 #endif
-void TurboAssembler::LoadLane64LE(Simd128Register dst, const MemOperand& mem,
+void MacroAssembler::LoadLane64LE(Simd128Register dst, const MemOperand& mem,
                                   int lane, Register scratch1,
                                   Simd128Register scratch2) {
   constexpr int lane_width_in_bytes = 8;
@@ -4657,7 +4657,7 @@ void TurboAssembler::LoadLane64LE(Simd128Register dst, const MemOperand& mem,
   MAYBE_REVERSE_BYTES(scratch2, xxbrd)
   vinsertd(dst, scratch2, Operand((1 - lane) * lane_width_in_bytes));
 }
-void TurboAssembler::LoadLane32LE(Simd128Register dst, const MemOperand& mem,
+void MacroAssembler::LoadLane32LE(Simd128Register dst, const MemOperand& mem,
                                   int lane, Register scratch1,
                                   Simd128Register scratch2) {
   constexpr int lane_width_in_bytes = 4;
@@ -4665,7 +4665,7 @@ void TurboAssembler::LoadLane32LE(Simd128Register dst, const MemOperand& mem,
   MAYBE_REVERSE_BYTES(scratch2, xxbrw)
   vinsertw(dst, scratch2, Operand((3 - lane) * lane_width_in_bytes));
 }
-void TurboAssembler::LoadLane16LE(Simd128Register dst, const MemOperand& mem,
+void MacroAssembler::LoadLane16LE(Simd128Register dst, const MemOperand& mem,
                                   int lane, Register scratch1,
                                   Simd128Register scratch2) {
   constexpr int lane_width_in_bytes = 2;
@@ -4673,7 +4673,7 @@ void TurboAssembler::LoadLane16LE(Simd128Register dst, const MemOperand& mem,
   MAYBE_REVERSE_BYTES(scratch2, xxbrh)
   vinserth(dst, scratch2, Operand((7 - lane) * lane_width_in_bytes));
 }
-void TurboAssembler::LoadLane8LE(Simd128Register dst, const MemOperand& mem,
+void MacroAssembler::LoadLane8LE(Simd128Register dst, const MemOperand& mem,
                                  int lane, Register scratch1,
                                  Simd128Register scratch2) {
   LoadSimd128Uint8(scratch2, mem, scratch1);
@@ -4681,7 +4681,7 @@ void TurboAssembler::LoadLane8LE(Simd128Register dst, const MemOperand& mem,
 }
 #undef MAYBE_REVERSE_BYTES
 
-void TurboAssembler::V128AnyTrue(Register dst, Simd128Register src,
+void MacroAssembler::V128AnyTrue(Register dst, Simd128Register src,
                                  Register scratch1, Register scratch2,
                                  Simd128Register scratch3) {
   constexpr uint8_t fxm = 0x2;  // field mask.
@@ -4695,18 +4695,18 @@ void TurboAssembler::V128AnyTrue(Register dst, Simd128Register src,
   isel(dst, scratch1, scratch2, bit_number);
 }
 
-void TurboAssembler::S128Not(Simd128Register dst, Simd128Register src) {
+void MacroAssembler::S128Not(Simd128Register dst, Simd128Register src) {
   vnor(dst, src, src);
 }
 
-void TurboAssembler::S128Const(Simd128Register dst, uint64_t high, uint64_t low,
+void MacroAssembler::S128Const(Simd128Register dst, uint64_t high, uint64_t low,
                                Register scratch1, Register scratch2) {
   mov(scratch1, Operand(low));
   mov(scratch2, Operand(high));
   mtvsrdd(dst, scratch2, scratch1);
 }
 
-void TurboAssembler::S128Select(Simd128Register dst, Simd128Register src1,
+void MacroAssembler::S128Select(Simd128Register dst, Simd128Register src1,
                                 Simd128Register src2, Simd128Register mask) {
   vsel(dst, src2, src1, mask);
 }
@@ -4726,7 +4726,7 @@ Register GetRegisterThatIsNotOneOf(Register reg1, Register reg2, Register reg3,
   UNREACHABLE();
 }
 
-void TurboAssembler::SwapP(Register src, Register dst, Register scratch) {
+void MacroAssembler::SwapP(Register src, Register dst, Register scratch) {
   if (src == dst) return;
   DCHECK(!AreAliased(src, dst, scratch));
   mr(scratch, src);
@@ -4734,7 +4734,7 @@ void TurboAssembler::SwapP(Register src, Register dst, Register scratch) {
   mr(dst, scratch);
 }
 
-void TurboAssembler::SwapP(Register src, MemOperand dst, Register scratch) {
+void MacroAssembler::SwapP(Register src, MemOperand dst, Register scratch) {
   if (dst.ra() != r0 && dst.ra().is_valid())
     DCHECK(!AreAliased(src, dst.ra(), scratch));
   if (dst.rb() != r0 && dst.rb().is_valid())
@@ -4745,7 +4745,7 @@ void TurboAssembler::SwapP(Register src, MemOperand dst, Register scratch) {
   StoreU64(scratch, dst, r0);
 }
 
-void TurboAssembler::SwapP(MemOperand src, MemOperand dst, Register scratch_0,
+void MacroAssembler::SwapP(MemOperand src, MemOperand dst, Register scratch_0,
                            Register scratch_1) {
   if (src.ra() != r0 && src.ra().is_valid())
     DCHECK(!AreAliased(src.ra(), scratch_0, scratch_1));
@@ -4777,7 +4777,7 @@ void TurboAssembler::SwapP(MemOperand src, MemOperand dst, Register scratch_0,
   }
 }
 
-void TurboAssembler::SwapFloat32(DoubleRegister src, DoubleRegister dst,
+void MacroAssembler::SwapFloat32(DoubleRegister src, DoubleRegister dst,
                                  DoubleRegister scratch) {
   if (src == dst) return;
   DCHECK(!AreAliased(src, dst, scratch));
@@ -4786,7 +4786,7 @@ void TurboAssembler::SwapFloat32(DoubleRegister src, DoubleRegister dst,
   fmr(dst, scratch);
 }
 
-void TurboAssembler::SwapFloat32(DoubleRegister src, MemOperand dst,
+void MacroAssembler::SwapFloat32(DoubleRegister src, MemOperand dst,
                                  DoubleRegister scratch) {
   DCHECK(!AreAliased(src, scratch));
   fmr(scratch, src);
@@ -4794,7 +4794,7 @@ void TurboAssembler::SwapFloat32(DoubleRegister src, MemOperand dst,
   StoreF32(scratch, dst, r0);
 }
 
-void TurboAssembler::SwapFloat32(MemOperand src, MemOperand dst,
+void MacroAssembler::SwapFloat32(MemOperand src, MemOperand dst,
                                  DoubleRegister scratch_0,
                                  DoubleRegister scratch_1) {
   DCHECK(!AreAliased(scratch_0, scratch_1));
@@ -4804,7 +4804,7 @@ void TurboAssembler::SwapFloat32(MemOperand src, MemOperand dst,
   StoreF32(scratch_1, src, r0);
 }
 
-void TurboAssembler::SwapDouble(DoubleRegister src, DoubleRegister dst,
+void MacroAssembler::SwapDouble(DoubleRegister src, DoubleRegister dst,
                                 DoubleRegister scratch) {
   if (src == dst) return;
   DCHECK(!AreAliased(src, dst, scratch));
@@ -4813,7 +4813,7 @@ void TurboAssembler::SwapDouble(DoubleRegister src, DoubleRegister dst,
   fmr(dst, scratch);
 }
 
-void TurboAssembler::SwapDouble(DoubleRegister src, MemOperand dst,
+void MacroAssembler::SwapDouble(DoubleRegister src, MemOperand dst,
                                 DoubleRegister scratch) {
   DCHECK(!AreAliased(src, scratch));
   fmr(scratch, src);
@@ -4821,7 +4821,7 @@ void TurboAssembler::SwapDouble(DoubleRegister src, MemOperand dst,
   StoreF64(scratch, dst, r0);
 }
 
-void TurboAssembler::SwapDouble(MemOperand src, MemOperand dst,
+void MacroAssembler::SwapDouble(MemOperand src, MemOperand dst,
                                 DoubleRegister scratch_0,
                                 DoubleRegister scratch_1) {
   DCHECK(!AreAliased(scratch_0, scratch_1));
@@ -4831,7 +4831,7 @@ void TurboAssembler::SwapDouble(MemOperand src, MemOperand dst,
   StoreF64(scratch_1, src, r0);
 }
 
-void TurboAssembler::SwapSimd128(Simd128Register src, Simd128Register dst,
+void MacroAssembler::SwapSimd128(Simd128Register src, Simd128Register dst,
                                  Simd128Register scratch) {
   if (src == dst) return;
   vor(scratch, src, src);
@@ -4839,7 +4839,7 @@ void TurboAssembler::SwapSimd128(Simd128Register src, Simd128Register dst,
   vor(dst, scratch, scratch);
 }
 
-void TurboAssembler::SwapSimd128(Simd128Register src, MemOperand dst,
+void MacroAssembler::SwapSimd128(Simd128Register src, MemOperand dst,
                                  Simd128Register scratch1, Register scratch2) {
   DCHECK(src != scratch1);
   LoadSimd128(scratch1, dst, scratch2);
@@ -4847,7 +4847,7 @@ void TurboAssembler::SwapSimd128(Simd128Register src, MemOperand dst,
   vor(src, scratch1, scratch1);
 }
 
-void TurboAssembler::SwapSimd128(MemOperand src, MemOperand dst,
+void MacroAssembler::SwapSimd128(MemOperand src, MemOperand dst,
                                  Simd128Register scratch1,
                                  Simd128Register scratch2, Register scratch3) {
   LoadSimd128(scratch1, src, scratch3);
@@ -4857,7 +4857,7 @@ void TurboAssembler::SwapSimd128(MemOperand src, MemOperand dst,
   StoreSimd128(scratch2, src, scratch3);
 }
 
-void TurboAssembler::ByteReverseU16(Register dst, Register val,
+void MacroAssembler::ByteReverseU16(Register dst, Register val,
                                     Register scratch) {
   if (CpuFeatures::IsSupported(PPC_10_PLUS)) {
     brh(dst, val);
@@ -4870,7 +4870,7 @@ void TurboAssembler::ByteReverseU16(Register dst, Register val,
   ZeroExtHalfWord(dst, dst);
 }
 
-void TurboAssembler::ByteReverseU32(Register dst, Register val,
+void MacroAssembler::ByteReverseU32(Register dst, Register val,
                                     Register scratch) {
   if (CpuFeatures::IsSupported(PPC_10_PLUS)) {
     brw(dst, val);
@@ -4883,7 +4883,7 @@ void TurboAssembler::ByteReverseU32(Register dst, Register val,
   ZeroExtWord32(dst, scratch);
 }
 
-void TurboAssembler::ByteReverseU64(Register dst, Register val, Register) {
+void MacroAssembler::ByteReverseU64(Register dst, Register val, Register) {
   if (CpuFeatures::IsSupported(PPC_10_PLUS)) {
     brd(dst, val);
     return;
@@ -4894,17 +4894,17 @@ void TurboAssembler::ByteReverseU64(Register dst, Register val, Register) {
   addi(sp, sp, Operand(kSystemPointerSize));
 }
 
-void TurboAssembler::JumpIfEqual(Register x, int32_t y, Label* dest) {
+void MacroAssembler::JumpIfEqual(Register x, int32_t y, Label* dest) {
   CmpS64(x, Operand(y), r0);
   beq(dest);
 }
 
-void TurboAssembler::JumpIfLessThan(Register x, int32_t y, Label* dest) {
+void MacroAssembler::JumpIfLessThan(Register x, int32_t y, Label* dest) {
   CmpS64(x, Operand(y), r0);
   blt(dest);
 }
 
-void TurboAssembler::LoadEntryFromBuiltinIndex(Register builtin_index) {
+void MacroAssembler::LoadEntryFromBuiltinIndex(Register builtin_index) {
   static_assert(kSystemPointerSize == 8);
   static_assert(kSmiTagSize == 1);
   static_assert(kSmiTag == 0);
@@ -4923,31 +4923,31 @@ void TurboAssembler::LoadEntryFromBuiltinIndex(Register builtin_index) {
   LoadU64(builtin_index, MemOperand(kRootRegister, builtin_index));
 }
 
-void TurboAssembler::CallBuiltinByIndex(Register builtin_index) {
+void MacroAssembler::CallBuiltinByIndex(Register builtin_index) {
   LoadEntryFromBuiltinIndex(builtin_index);
   Call(builtin_index);
 }
 
-void TurboAssembler::LoadEntryFromBuiltin(Builtin builtin,
+void MacroAssembler::LoadEntryFromBuiltin(Builtin builtin,
                                           Register destination) {
   ASM_CODE_COMMENT(this);
   LoadU64(destination, EntryFromBuiltinAsOperand(builtin));
 }
 
-MemOperand TurboAssembler::EntryFromBuiltinAsOperand(Builtin builtin) {
+MemOperand MacroAssembler::EntryFromBuiltinAsOperand(Builtin builtin) {
   ASM_CODE_COMMENT(this);
   DCHECK(root_array_available());
   return MemOperand(kRootRegister,
                     IsolateData::BuiltinEntrySlotOffset(builtin));
 }
 
-void TurboAssembler::LoadCodeEntry(Register destination, Register code_object) {
+void MacroAssembler::LoadCodeEntry(Register destination, Register code_object) {
   ASM_CODE_COMMENT(this);
   LoadU64(destination,
           FieldMemOperand(code_object, Code::kCodeEntryPointOffset), r0);
 }
 
-void TurboAssembler::LoadCodeInstructionStreamNonBuiltin(Register destination,
+void MacroAssembler::LoadCodeInstructionStreamNonBuiltin(Register destination,
                                                          Register code_object) {
   ASM_CODE_COMMENT(this);
   // Compute the InstructionStream object pointer from the code entry point.
@@ -4957,20 +4957,20 @@ void TurboAssembler::LoadCodeInstructionStreamNonBuiltin(Register destination,
          Operand(InstructionStream::kHeaderSize - kHeapObjectTag));
 }
 
-void TurboAssembler::CallCodeObject(Register code_object) {
+void MacroAssembler::CallCodeObject(Register code_object) {
   ASM_CODE_COMMENT(this);
   LoadCodeEntry(code_object, code_object);
   Call(code_object);
 }
 
-void TurboAssembler::JumpCodeObject(Register code_object, JumpMode jump_mode) {
+void MacroAssembler::JumpCodeObject(Register code_object, JumpMode jump_mode) {
   ASM_CODE_COMMENT(this);
   DCHECK_EQ(JumpMode::kJump, jump_mode);
   LoadCodeEntry(code_object, code_object);
   Jump(code_object);
 }
 
-void TurboAssembler::StoreReturnAddressAndCall(Register target) {
+void MacroAssembler::StoreReturnAddressAndCall(Register target) {
   // This generates the final instruction sequence for calls to C functions
   // once an exit frame has been constructed.
   //
@@ -5004,7 +5004,7 @@ void TurboAssembler::StoreReturnAddressAndCall(Register target) {
             SizeOfCodeGeneratedSince(&start_call));
 }
 
-void TurboAssembler::CallForDeoptimization(Builtin target, int, Label* exit,
+void MacroAssembler::CallForDeoptimization(Builtin target, int, Label* exit,
                                            DeoptimizeKind kind, Label* ret,
                                            Label*) {
   BlockTrampolinePoolScope block_trampoline_pool(this);
@@ -5017,30 +5017,30 @@ void TurboAssembler::CallForDeoptimization(Builtin target, int, Label* exit,
                                             : Deoptimizer::kEagerDeoptExitSize);
 }
 
-void TurboAssembler::ZeroExtByte(Register dst, Register src) {
+void MacroAssembler::ZeroExtByte(Register dst, Register src) {
   clrldi(dst, src, Operand(56));
 }
 
-void TurboAssembler::ZeroExtHalfWord(Register dst, Register src) {
+void MacroAssembler::ZeroExtHalfWord(Register dst, Register src) {
   clrldi(dst, src, Operand(48));
 }
 
-void TurboAssembler::ZeroExtWord32(Register dst, Register src) {
+void MacroAssembler::ZeroExtWord32(Register dst, Register src) {
   clrldi(dst, src, Operand(32));
 }
 
-void TurboAssembler::Trap() { stop(); }
-void TurboAssembler::DebugBreak() { stop(); }
+void MacroAssembler::Trap() { stop(); }
+void MacroAssembler::DebugBreak() { stop(); }
 
-void TurboAssembler::Popcnt32(Register dst, Register src) { popcntw(dst, src); }
+void MacroAssembler::Popcnt32(Register dst, Register src) { popcntw(dst, src); }
 
-void TurboAssembler::Popcnt64(Register dst, Register src) { popcntd(dst, src); }
+void MacroAssembler::Popcnt64(Register dst, Register src) { popcntd(dst, src); }
 
-void TurboAssembler::CountLeadingZerosU32(Register dst, Register src, RCBit r) {
+void MacroAssembler::CountLeadingZerosU32(Register dst, Register src, RCBit r) {
   cntlzw(dst, src, r);
 }
 
-void TurboAssembler::CountLeadingZerosU64(Register dst, Register src, RCBit r) {
+void MacroAssembler::CountLeadingZerosU64(Register dst, Register src, RCBit r) {
   cntlzd(dst, src, r);
 }
 
@@ -5057,7 +5057,7 @@ void TurboAssembler::CountLeadingZerosU64(Register dst, Register src, RCBit r) {
   addi(dst, dst, Operand(1));           /* dst++ */               \
   bdnz(&loop);                                                    \
   bind(&done);
-void TurboAssembler::CountTrailingZerosU32(Register dst, Register src,
+void MacroAssembler::CountTrailingZerosU32(Register dst, Register src,
                                            Register scratch1, Register scratch2,
                                            RCBit r) {
   if (CpuFeatures::IsSupported(PPC_9_PLUS)) {
@@ -5067,7 +5067,7 @@ void TurboAssembler::CountTrailingZerosU32(Register dst, Register src,
   }
 }
 
-void TurboAssembler::CountTrailingZerosU64(Register dst, Register src,
+void MacroAssembler::CountTrailingZerosU64(Register dst, Register src,
                                            Register scratch1, Register scratch2,
                                            RCBit r) {
   if (CpuFeatures::IsSupported(PPC_9_PLUS)) {
@@ -5078,14 +5078,14 @@ void TurboAssembler::CountTrailingZerosU64(Register dst, Register src,
 }
 #undef COUNT_TRAILING_ZEROES_SLOW
 
-void TurboAssembler::ClearByteU64(Register dst, int byte_idx) {
+void MacroAssembler::ClearByteU64(Register dst, int byte_idx) {
   CHECK(0 <= byte_idx && byte_idx <= 7);
   int shift = byte_idx*8;
   rldicl(dst, dst, shift, 8);
   rldicl(dst, dst, 64-shift, 0);
 }
 
-void TurboAssembler::ReverseBitsU64(Register dst, Register src,
+void MacroAssembler::ReverseBitsU64(Register dst, Register src,
                                     Register scratch1, Register scratch2) {
   ByteReverseU64(dst, src);
   for (int i = 0; i < 8; i++) {
@@ -5093,7 +5093,7 @@ void TurboAssembler::ReverseBitsU64(Register dst, Register src,
   }
 }
 
-void TurboAssembler::ReverseBitsU32(Register dst, Register src,
+void MacroAssembler::ReverseBitsU32(Register dst, Register src,
                                     Register scratch1, Register scratch2) {
   ByteReverseU32(dst, src, scratch1);
   for (int i = 4; i < 8; i++) {
@@ -5102,7 +5102,7 @@ void TurboAssembler::ReverseBitsU32(Register dst, Register src,
 }
 
 // byte_idx=7 refers to least significant byte
-void TurboAssembler::ReverseBitsInSingleByteU64(Register dst, Register src,
+void MacroAssembler::ReverseBitsInSingleByteU64(Register dst, Register src,
                                                 Register scratch1,
                                                 Register scratch2,
                                                 int byte_idx) {
