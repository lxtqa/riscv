diff --git a/src/wasm/baseline/riscv/liftoff-assembler-riscv64.h b/src/wasm/baseline/riscv/liftoff-assembler-riscv64.h
index c5cdebcbee2..afdc3e6a1cb 100644
--- a/src/wasm/baseline/riscv/liftoff-assembler-riscv64.h
+++ b/src/wasm/baseline/riscv/liftoff-assembler-riscv64.h
@@ -153,17 +153,17 @@ void LiftoffAssembler::LoadConstant(LiftoffRegister reg, WasmValue value,
                                     RelocInfo::Mode rmode) {
   switch (value.type().kind()) {
     case kI32:
-      TurboAssembler::li(reg.gp(), Operand(value.to_i32(), rmode));
+      MacroAssembler::li(reg.gp(), Operand(value.to_i32(), rmode));
       break;
     case kI64:
-      TurboAssembler::li(reg.gp(), Operand(value.to_i64(), rmode));
+      MacroAssembler::li(reg.gp(), Operand(value.to_i64(), rmode));
       break;
     case kF32:
-      TurboAssembler::LoadFPRImmediate(reg.fp(),
+      MacroAssembler::LoadFPRImmediate(reg.fp(),
                                        value.to_f32_boxed().get_bits());
       break;
     case kF64:
-      TurboAssembler::LoadFPRImmediate(reg.fp(),
+      MacroAssembler::LoadFPRImmediate(reg.fp(),
                                        value.to_f64_boxed().get_bits());
       break;
     default:
@@ -237,33 +237,33 @@ void LiftoffAssembler::Load(LiftoffRegister dst, Register src_addr,
       break;
     case LoadType::kI32Load16U:
     case LoadType::kI64Load16U:
-      TurboAssembler::Lhu(dst.gp(), src_op);
+      MacroAssembler::Lhu(dst.gp(), src_op);
       break;
     case LoadType::kI32Load16S:
     case LoadType::kI64Load16S:
-      TurboAssembler::Lh(dst.gp(), src_op);
+      MacroAssembler::Lh(dst.gp(), src_op);
       break;
     case LoadType::kI64Load32U:
-      TurboAssembler::Lwu(dst.gp(), src_op);
+      MacroAssembler::Lwu(dst.gp(), src_op);
       break;
     case LoadType::kI32Load:
     case LoadType::kI64Load32S:
-      TurboAssembler::Lw(dst.gp(), src_op);
+      MacroAssembler::Lw(dst.gp(), src_op);
       break;
     case LoadType::kI64Load:
-      TurboAssembler::Ld(dst.gp(), src_op);
+      MacroAssembler::Ld(dst.gp(), src_op);
       break;
     case LoadType::kF32Load:
-      TurboAssembler::LoadFloat(dst.fp(), src_op);
+      MacroAssembler::LoadFloat(dst.fp(), src_op);
       break;
     case LoadType::kF64Load:
-      TurboAssembler::LoadDouble(dst.fp(), src_op);
+      MacroAssembler::LoadDouble(dst.fp(), src_op);
       break;
     case LoadType::kS128Load: {
       VU.set(kScratchReg, E8, m1);
       Register src_reg = src_op.offset() == 0 ? src_op.rm() : kScratchReg;
       if (src_op.offset() != 0) {
-        TurboAssembler::AddWord(src_reg, src_op.rm(), src_op.offset());
+        MacroAssembler::AddWord(src_reg, src_op.rm(), src_op.offset());
       }
       vl(dst.fp().toV(), src_reg, 0, E8);
       break;
@@ -310,20 +310,20 @@ void LiftoffAssembler::Store(Register dst_addr, Register offset_reg,
       break;
     case StoreType::kI32Store16:
     case StoreType::kI64Store16:
-      TurboAssembler::Sh(src.gp(), dst_op);
+      MacroAssembler::Sh(src.gp(), dst_op);
       break;
     case StoreType::kI32Store:
     case StoreType::kI64Store32:
-      TurboAssembler::Sw(src.gp(), dst_op);
+      MacroAssembler::Sw(src.gp(), dst_op);
       break;
     case StoreType::kI64Store:
-      TurboAssembler::Sd(src.gp(), dst_op);
+      MacroAssembler::Sd(src.gp(), dst_op);
       break;
     case StoreType::kF32Store:
-      TurboAssembler::StoreFloat(src.fp(), dst_op);
+      MacroAssembler::StoreFloat(src.fp(), dst_op);
       break;
     case StoreType::kF64Store:
-      TurboAssembler::StoreDouble(src.fp(), dst_op);
+      MacroAssembler::StoreDouble(src.fp(), dst_op);
       break;
     case StoreType::kS128Store: {
       VU.set(kScratchReg, E8, m1);
@@ -692,14 +692,14 @@ void LiftoffAssembler::MoveStackValue(uint32_t dst_offset, uint32_t src_offset,
       StoreFloat(kScratchDoubleReg, dst);
       break;
     case kF64:
-      TurboAssembler::LoadDouble(kScratchDoubleReg, src);
-      TurboAssembler::StoreDouble(kScratchDoubleReg, dst);
+      MacroAssembler::LoadDouble(kScratchDoubleReg, src);
+      MacroAssembler::StoreDouble(kScratchDoubleReg, dst);
       break;
     case kS128: {
       VU.set(kScratchReg, E8, m1);
       Register src_reg = src.offset() == 0 ? src.rm() : kScratchReg;
       if (src.offset() != 0) {
-        TurboAssembler::Add64(src_reg, src.rm(), src.offset());
+        MacroAssembler::Add64(src_reg, src.rm(), src.offset());
       }
       vl(kSimd128ScratchReg, src_reg, 0, E8);
       Register dst_reg = dst.offset() == 0 ? dst.rm() : kScratchReg;
@@ -720,16 +720,16 @@ void LiftoffAssembler::MoveStackValue(uint32_t dst_offset, uint32_t src_offset,
 void LiftoffAssembler::Move(Register dst, Register src, ValueKind kind) {
   DCHECK_NE(dst, src);
   // TODO(ksreten): Handle different sizes here.
-  TurboAssembler::Move(dst, src);
+  MacroAssembler::Move(dst, src);
 }
 
 void LiftoffAssembler::Move(DoubleRegister dst, DoubleRegister src,
                             ValueKind kind) {
   DCHECK_NE(dst, src);
   if (kind != kS128) {
-    TurboAssembler::Move(dst, src);
+    MacroAssembler::Move(dst, src);
   } else {
-    TurboAssembler::vmv_vv(dst.toV(), src.toV());
+    MacroAssembler::vmv_vv(dst.toV(), src.toV());
   }
 }
 
@@ -750,7 +750,7 @@ void LiftoffAssembler::Spill(int offset, LiftoffRegister reg, ValueKind kind) {
       StoreFloat(reg.fp(), dst);
       break;
     case kF64:
-      TurboAssembler::StoreDouble(reg.fp(), dst);
+      MacroAssembler::StoreDouble(reg.fp(), dst);
       break;
     case kS128: {
       VU.set(kScratchReg, E8, m1);
@@ -773,7 +773,7 @@ void LiftoffAssembler::Spill(int offset, WasmValue value) {
     case kI32: {
       UseScratchRegisterScope temps(this);
       Register tmp = temps.Acquire();
-      TurboAssembler::li(tmp, Operand(value.to_i32()));
+      MacroAssembler::li(tmp, Operand(value.to_i32()));
       Sw(tmp, dst);
       break;
     }
@@ -782,7 +782,7 @@ void LiftoffAssembler::Spill(int offset, WasmValue value) {
     case kRefNull: {
       UseScratchRegisterScope temps(this);
       Register tmp = temps.Acquire();
-      TurboAssembler::li(tmp, value.to_i64());
+      MacroAssembler::li(tmp, value.to_i64());
       Sd(tmp, dst);
       break;
     }
@@ -808,13 +808,13 @@ void LiftoffAssembler::Fill(LiftoffRegister reg, int offset, ValueKind kind) {
       LoadFloat(reg.fp(), src);
       break;
     case kF64:
-      TurboAssembler::LoadDouble(reg.fp(), src);
+      MacroAssembler::LoadDouble(reg.fp(), src);
       break;
     case kS128: {
       VU.set(kScratchReg, E8, m1);
       Register src_reg = src.offset() == 0 ? src.rm() : kScratchReg;
       if (src.offset() != 0) {
-        TurboAssembler::Add64(src_reg, src.rm(), src.offset());
+        MacroAssembler::Add64(src_reg, src.rm(), src.offset());
       }
       vl(reg.fp().toV(), src_reg, 0, E8);
       break;
@@ -861,54 +861,54 @@ void LiftoffAssembler::FillStackSlotsWithZero(int start, int size) {
 }
 
 void LiftoffAssembler::emit_i64_clz(LiftoffRegister dst, LiftoffRegister src) {
-  TurboAssembler::Clz64(dst.gp(), src.gp());
+  MacroAssembler::Clz64(dst.gp(), src.gp());
 }
 
 void LiftoffAssembler::emit_i64_ctz(LiftoffRegister dst, LiftoffRegister src) {
-  TurboAssembler::Ctz64(dst.gp(), src.gp());
+  MacroAssembler::Ctz64(dst.gp(), src.gp());
 }
 
 bool LiftoffAssembler::emit_i64_popcnt(LiftoffRegister dst,
                                        LiftoffRegister src) {
-  TurboAssembler::Popcnt64(dst.gp(), src.gp(), kScratchReg);
+  MacroAssembler::Popcnt64(dst.gp(), src.gp(), kScratchReg);
   return true;
 }
 
 void LiftoffAssembler::emit_i32_mul(Register dst, Register lhs, Register rhs) {
-  TurboAssembler::Mul32(dst, lhs, rhs);
+  MacroAssembler::Mul32(dst, lhs, rhs);
 }
 
 void LiftoffAssembler::emit_i32_divs(Register dst, Register lhs, Register rhs,
                                      Label* trap_div_by_zero,
                                      Label* trap_div_unrepresentable) {
-  TurboAssembler::Branch(trap_div_by_zero, eq, rhs, Operand(zero_reg));
+  MacroAssembler::Branch(trap_div_by_zero, eq, rhs, Operand(zero_reg));
 
   // Check if lhs == kMinInt and rhs == -1, since this case is unrepresentable.
-  TurboAssembler::CompareI(kScratchReg, lhs, Operand(kMinInt), ne);
-  TurboAssembler::CompareI(kScratchReg2, rhs, Operand(-1), ne);
+  MacroAssembler::CompareI(kScratchReg, lhs, Operand(kMinInt), ne);
+  MacroAssembler::CompareI(kScratchReg2, rhs, Operand(-1), ne);
   add(kScratchReg, kScratchReg, kScratchReg2);
-  TurboAssembler::Branch(trap_div_unrepresentable, eq, kScratchReg,
+  MacroAssembler::Branch(trap_div_unrepresentable, eq, kScratchReg,
                          Operand(zero_reg));
 
-  TurboAssembler::Div32(dst, lhs, rhs);
+  MacroAssembler::Div32(dst, lhs, rhs);
 }
 
 void LiftoffAssembler::emit_i32_divu(Register dst, Register lhs, Register rhs,
                                      Label* trap_div_by_zero) {
-  TurboAssembler::Branch(trap_div_by_zero, eq, rhs, Operand(zero_reg));
-  TurboAssembler::Divu32(dst, lhs, rhs);
+  MacroAssembler::Branch(trap_div_by_zero, eq, rhs, Operand(zero_reg));
+  MacroAssembler::Divu32(dst, lhs, rhs);
 }
 
 void LiftoffAssembler::emit_i32_rems(Register dst, Register lhs, Register rhs,
                                      Label* trap_div_by_zero) {
-  TurboAssembler::Branch(trap_div_by_zero, eq, rhs, Operand(zero_reg));
-  TurboAssembler::Mod32(dst, lhs, rhs);
+  MacroAssembler::Branch(trap_div_by_zero, eq, rhs, Operand(zero_reg));
+  MacroAssembler::Mod32(dst, lhs, rhs);
 }
 
 void LiftoffAssembler::emit_i32_remu(Register dst, Register lhs, Register rhs,
                                      Label* trap_div_by_zero) {
-  TurboAssembler::Branch(trap_div_by_zero, eq, rhs, Operand(zero_reg));
-  TurboAssembler::Modu32(dst, lhs, rhs);
+  MacroAssembler::Branch(trap_div_by_zero, eq, rhs, Operand(zero_reg));
+  MacroAssembler::Modu32(dst, lhs, rhs);
 }
 
 #define I32_BINOP(name, instruction)                                 \
@@ -944,15 +944,15 @@ I32_BINOP_I(xor, Xor)
 #undef I32_BINOP_I
 
 void LiftoffAssembler::emit_i32_clz(Register dst, Register src) {
-  TurboAssembler::Clz32(dst, src);
+  MacroAssembler::Clz32(dst, src);
 }
 
 void LiftoffAssembler::emit_i32_ctz(Register dst, Register src) {
-  TurboAssembler::Ctz32(dst, src);
+  MacroAssembler::Ctz32(dst, src);
 }
 
 bool LiftoffAssembler::emit_i32_popcnt(Register dst, Register src) {
-  TurboAssembler::Popcnt32(dst, src, kScratchReg);
+  MacroAssembler::Popcnt32(dst, src, kScratchReg);
   return true;
 }
 
@@ -980,48 +980,48 @@ I32_SHIFTOP_I(shr, srliw)
 
 void LiftoffAssembler::emit_i64_mul(LiftoffRegister dst, LiftoffRegister lhs,
                                     LiftoffRegister rhs) {
-  TurboAssembler::Mul64(dst.gp(), lhs.gp(), rhs.gp());
+  MacroAssembler::Mul64(dst.gp(), lhs.gp(), rhs.gp());
 }
 
 bool LiftoffAssembler::emit_i64_divs(LiftoffRegister dst, LiftoffRegister lhs,
                                      LiftoffRegister rhs,
                                      Label* trap_div_by_zero,
                                      Label* trap_div_unrepresentable) {
-  TurboAssembler::Branch(trap_div_by_zero, eq, rhs.gp(), Operand(zero_reg));
+  MacroAssembler::Branch(trap_div_by_zero, eq, rhs.gp(), Operand(zero_reg));
 
   // Check if lhs == MinInt64 and rhs == -1, since this case is unrepresentable.
-  TurboAssembler::CompareI(kScratchReg, lhs.gp(),
+  MacroAssembler::CompareI(kScratchReg, lhs.gp(),
                            Operand(std::numeric_limits<int64_t>::min()), ne);
-  TurboAssembler::CompareI(kScratchReg2, rhs.gp(), Operand(-1), ne);
+  MacroAssembler::CompareI(kScratchReg2, rhs.gp(), Operand(-1), ne);
   add(kScratchReg, kScratchReg, kScratchReg2);
-  TurboAssembler::Branch(trap_div_unrepresentable, eq, kScratchReg,
+  MacroAssembler::Branch(trap_div_unrepresentable, eq, kScratchReg,
                          Operand(zero_reg));
 
-  TurboAssembler::Div64(dst.gp(), lhs.gp(), rhs.gp());
+  MacroAssembler::Div64(dst.gp(), lhs.gp(), rhs.gp());
   return true;
 }
 
 bool LiftoffAssembler::emit_i64_divu(LiftoffRegister dst, LiftoffRegister lhs,
                                      LiftoffRegister rhs,
                                      Label* trap_div_by_zero) {
-  TurboAssembler::Branch(trap_div_by_zero, eq, rhs.gp(), Operand(zero_reg));
-  TurboAssembler::Divu64(dst.gp(), lhs.gp(), rhs.gp());
+  MacroAssembler::Branch(trap_div_by_zero, eq, rhs.gp(), Operand(zero_reg));
+  MacroAssembler::Divu64(dst.gp(), lhs.gp(), rhs.gp());
   return true;
 }
 
 bool LiftoffAssembler::emit_i64_rems(LiftoffRegister dst, LiftoffRegister lhs,
                                      LiftoffRegister rhs,
                                      Label* trap_div_by_zero) {
-  TurboAssembler::Branch(trap_div_by_zero, eq, rhs.gp(), Operand(zero_reg));
-  TurboAssembler::Mod64(dst.gp(), lhs.gp(), rhs.gp());
+  MacroAssembler::Branch(trap_div_by_zero, eq, rhs.gp(), Operand(zero_reg));
+  MacroAssembler::Mod64(dst.gp(), lhs.gp(), rhs.gp());
   return true;
 }
 
 bool LiftoffAssembler::emit_i64_remu(LiftoffRegister dst, LiftoffRegister lhs,
                                      LiftoffRegister rhs,
                                      Label* trap_div_by_zero) {
-  TurboAssembler::Branch(trap_div_by_zero, eq, rhs.gp(), Operand(zero_reg));
-  TurboAssembler::Modu64(dst.gp(), lhs.gp(), rhs.gp());
+  MacroAssembler::Branch(trap_div_by_zero, eq, rhs.gp(), Operand(zero_reg));
+  MacroAssembler::Modu64(dst.gp(), lhs.gp(), rhs.gp());
   return true;
 }
 
@@ -1098,7 +1098,7 @@ void LiftoffAssembler::emit_i64_shri(LiftoffRegister dst, LiftoffRegister src,
 
 void LiftoffAssembler::emit_i64_addi(LiftoffRegister dst, LiftoffRegister lhs,
                                      int64_t imm) {
-  TurboAssembler::Add64(dst.gp(), lhs.gp(), Operand(imm));
+  MacroAssembler::Add64(dst.gp(), lhs.gp(), Operand(imm));
 }
 void LiftoffAssembler::emit_u32_to_uintptr(Register dst, Register src) {
   ZeroExtendWord(dst, src);
@@ -1125,7 +1125,7 @@ bool LiftoffAssembler::emit_type_conversion(WasmOpcode opcode,
       // According to WebAssembly spec, if I64 value does not fit the range of
       // I32, the value is undefined. Therefore, We use sign extension to
       // implement I64 to I32 truncation
-      TurboAssembler::SignExtendWord(dst.gp(), src.gp());
+      MacroAssembler::SignExtendWord(dst.gp(), src.gp());
       return true;
     case kExprI32SConvertF32:
     case kExprI32UConvertF32:
@@ -1172,39 +1172,39 @@ bool LiftoffAssembler::emit_type_conversion(WasmOpcode opcode,
 
       // Checking if trap.
       if (trap != nullptr) {
-        TurboAssembler::Branch(trap, eq, kScratchReg, Operand(zero_reg));
+        MacroAssembler::Branch(trap, eq, kScratchReg, Operand(zero_reg));
       }
 
       return true;
     }
     case kExprI32ReinterpretF32:
-      TurboAssembler::ExtractLowWordFromF64(dst.gp(), src.fp());
+      MacroAssembler::ExtractLowWordFromF64(dst.gp(), src.fp());
       return true;
     case kExprI64SConvertI32:
-      TurboAssembler::SignExtendWord(dst.gp(), src.gp());
+      MacroAssembler::SignExtendWord(dst.gp(), src.gp());
       return true;
     case kExprI64UConvertI32:
-      TurboAssembler::ZeroExtendWord(dst.gp(), src.gp());
+      MacroAssembler::ZeroExtendWord(dst.gp(), src.gp());
       return true;
     case kExprI64ReinterpretF64:
       fmv_x_d(dst.gp(), src.fp());
       return true;
     case kExprF32SConvertI32: {
-      TurboAssembler::Cvt_s_w(dst.fp(), src.gp());
+      MacroAssembler::Cvt_s_w(dst.fp(), src.gp());
       return true;
     }
     case kExprF32UConvertI32:
-      TurboAssembler::Cvt_s_uw(dst.fp(), src.gp());
+      MacroAssembler::Cvt_s_uw(dst.fp(), src.gp());
       return true;
     case kExprF32ReinterpretI32:
       fmv_w_x(dst.fp(), src.gp());
       return true;
     case kExprF64SConvertI32: {
-      TurboAssembler::Cvt_d_w(dst.fp(), src.gp());
+      MacroAssembler::Cvt_d_w(dst.fp(), src.gp());
       return true;
     }
     case kExprF64UConvertI32:
-      TurboAssembler::Cvt_d_uw(dst.fp(), src.gp());
+      MacroAssembler::Cvt_d_uw(dst.fp(), src.gp());
       return true;
     case kExprF64ConvertF32:
       fcvt_d_s(dst.fp(), src.fp());
@@ -1286,11 +1286,11 @@ void LiftoffAssembler::emit_i64_signextend_i32(LiftoffRegister dst,
 }
 
 void LiftoffAssembler::emit_jump(Label* label) {
-  TurboAssembler::Branch(label);
+  MacroAssembler::Branch(label);
 }
 
 void LiftoffAssembler::emit_jump(Register target) {
-  TurboAssembler::Jump(target);
+  MacroAssembler::Jump(target);
 }
 
 void LiftoffAssembler::emit_cond_jump(Condition cond, Label* label,
@@ -1299,44 +1299,44 @@ void LiftoffAssembler::emit_cond_jump(Condition cond, Label* label,
                                       const FreezeCacheState& frozen) {
   if (rhs == no_reg) {
     DCHECK(kind == kI32 || kind == kI64);
-    TurboAssembler::Branch(label, cond, lhs, Operand(zero_reg));
+    MacroAssembler::Branch(label, cond, lhs, Operand(zero_reg));
   } else {
     DCHECK((kind == kI32 || kind == kI64) ||
            (is_reference(kind) && (cond == kEqual || cond == kNotEqual)));
-    TurboAssembler::Branch(label, cond, lhs, Operand(rhs));
+    MacroAssembler::Branch(label, cond, lhs, Operand(rhs));
   }
 }
 
 void LiftoffAssembler::emit_i32_cond_jumpi(Condition cond, Label* label,
                                            Register lhs, int32_t imm,
                                            const FreezeCacheState& frozen) {
-  TurboAssembler::Branch(label, cond, lhs, Operand(imm));
+  MacroAssembler::Branch(label, cond, lhs, Operand(imm));
 }
 
 void LiftoffAssembler::emit_i32_subi_jump_negative(
     Register value, int subtrahend, Label* result_negative,
     const FreezeCacheState& frozen) {
   Sub64(value, value, Operand(subtrahend));
-  TurboAssembler::Branch(result_negative, lt, value, Operand(zero_reg));
+  MacroAssembler::Branch(result_negative, lt, value, Operand(zero_reg));
 }
 
 void LiftoffAssembler::emit_i32_eqz(Register dst, Register src) {
-  TurboAssembler::Sltu(dst, src, 1);
+  MacroAssembler::Sltu(dst, src, 1);
 }
 
 void LiftoffAssembler::emit_i32_set_cond(Condition cond, Register dst,
                                          Register lhs, Register rhs) {
-  TurboAssembler::CompareI(dst, lhs, Operand(rhs), cond);
+  MacroAssembler::CompareI(dst, lhs, Operand(rhs), cond);
 }
 
 void LiftoffAssembler::emit_i64_eqz(Register dst, LiftoffRegister src) {
-  TurboAssembler::Sltu(dst, src.gp(), 1);
+  MacroAssembler::Sltu(dst, src.gp(), 1);
 }
 
 void LiftoffAssembler::emit_i64_set_cond(Condition cond, Register dst,
                                          LiftoffRegister lhs,
                                          LiftoffRegister rhs) {
-  TurboAssembler::CompareI(dst, lhs.gp(), Operand(rhs.gp()), cond);
+  MacroAssembler::CompareI(dst, lhs.gp(), Operand(rhs.gp()), cond);
 }
 
 void LiftoffAssembler::IncrementSmi(LiftoffRegister dst, int offset) {
