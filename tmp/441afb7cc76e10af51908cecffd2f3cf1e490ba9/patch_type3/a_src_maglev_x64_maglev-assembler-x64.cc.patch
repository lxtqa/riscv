diff --git a/src/maglev/x64/maglev-assembler-x64.cc b/src/maglev/x64/maglev-assembler-x64.cc
index a778d115323..78c0c58227c 100644
--- a/src/maglev/x64/maglev-assembler-x64.cc
+++ b/src/maglev/x64/maglev-assembler-x64.cc
@@ -5,7 +5,6 @@
 #include "src/base/logging.h"
 #include "src/codegen/interface-descriptors-inl.h"
 #include "src/common/globals.h"
-#include "src/compiler/backend/instruction.h"
 #include "src/interpreter/bytecode-flags.h"
 #include "src/maglev/maglev-assembler-inl.h"
 #include "src/maglev/maglev-assembler.h"
@@ -635,9 +634,7 @@ void MaglevAssembler::TryTruncateDoubleToInt32(Register dst, DoubleRegister src,
 }
 
 void MaglevAssembler::Prologue(Graph* graph) {
-  if (!graph->is_osr()) {
-    BailoutIfDeoptimized(rbx);
-  }
+  BailoutIfDeoptimized(rbx);
 
   if (graph->has_recursive_calls()) {
     bind(code_gen_state()->entry_label());
@@ -646,7 +643,7 @@ void MaglevAssembler::Prologue(Graph* graph) {
   // Tiering support.
   // TODO(jgruber): Extract to a builtin (the tiering prologue is ~230 bytes
   // per Maglev code object on x64).
-  if (v8_flags.turbofan && !graph->is_osr()) {
+  if (v8_flags.turbofan) {
     // Scratch registers. Don't clobber regs related to the calling
     // convention (e.g. kJavaScriptCallArgCountRegister). Keep up-to-date
     // with deferred flags code.
@@ -671,44 +668,8 @@ void MaglevAssembler::Prologue(Graph* graph) {
         deferred_flags_need_processing);
   }
 
-  if (graph->is_osr()) {
-    uint32_t source_frame_size =
-        graph->min_maglev_stackslots_for_unoptimized_frame_size();
-
-    if (v8_flags.maglev_assert_stack_size && v8_flags.debug_code) {
-      movq(kScratchRegister, rbp);
-      subq(kScratchRegister, rsp);
-      cmpq(kScratchRegister,
-           Immediate(source_frame_size * kSystemPointerSize +
-                     StandardFrameConstants::kFixedFrameSizeFromFp));
-      Assert(equal, AbortReason::kOsrUnexpectedStackSize);
-    }
-
-    uint32_t target_frame_size =
-        graph->tagged_stack_slots() + graph->untagged_stack_slots();
-    CHECK_LE(source_frame_size, target_frame_size);
-
-    if (source_frame_size < target_frame_size) {
-      ASM_CODE_COMMENT_STRING(this, "Growing frame for OSR");
-      Move(kScratchRegister, 0);
-      uint32_t additional_tagged =
-          source_frame_size < graph->tagged_stack_slots()
-              ? graph->tagged_stack_slots() - source_frame_size
-              : 0;
-      for (size_t i = 0; i < additional_tagged; ++i) {
-        pushq(kScratchRegister);
-      }
-      uint32_t size_so_far = source_frame_size + additional_tagged;
-      CHECK_LE(size_so_far, target_frame_size);
-      if (size_so_far < target_frame_size) {
-        subq(rsp,
-             Immediate((target_frame_size - size_so_far) * kSystemPointerSize));
-      }
-    }
-    return;
-  }
-
   EnterFrame(StackFrame::MAGLEV);
+
   // Save arguments in frame.
   // TODO(leszeks): Consider eliding this frame if we don't make any calls
   // that could clobber these registers.
