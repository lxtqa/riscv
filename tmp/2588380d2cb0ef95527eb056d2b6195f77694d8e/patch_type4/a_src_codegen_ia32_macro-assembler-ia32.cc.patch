diff --git a/src/codegen/ia32/macro-assembler-ia32.cc b/src/codegen/ia32/macro-assembler-ia32.cc
index 08c2e80ddb3..16298ed5364 100644
--- a/src/codegen/ia32/macro-assembler-ia32.cc
+++ b/src/codegen/ia32/macro-assembler-ia32.cc
@@ -76,11 +76,13 @@ Operand StackArgumentsAccessor::GetArgumentOperand(int index) const {
 // MacroAssembler implementation.
 
 void TurboAssembler::InitializeRootRegister() {
+  ASM_CODE_COMMENT(this);
   ExternalReference isolate_root = ExternalReference::isolate_root(isolate());
   Move(kRootRegister, Immediate(isolate_root));
 }
 
 void TurboAssembler::LoadRoot(Register destination, RootIndex index) {
+  ASM_CODE_COMMENT(this);
   if (root_array_available()) {
     mov(destination,
         Operand(kRootRegister, RootRegisterOffsetForRootIndex(index)));
@@ -107,6 +109,7 @@ void TurboAssembler::LoadRoot(Register destination, RootIndex index) {
 
 void TurboAssembler::CompareRoot(Register with, Register scratch,
                                  RootIndex index) {
+  ASM_CODE_COMMENT(this);
   if (root_array_available()) {
     CompareRoot(with, index);
   } else {
@@ -118,6 +121,7 @@ void TurboAssembler::CompareRoot(Register with, Register scratch,
 }
 
 void TurboAssembler::CompareRoot(Register with, RootIndex index) {
+  ASM_CODE_COMMENT(this);
   if (root_array_available()) {
     cmp(with, Operand(kRootRegister, RootRegisterOffsetForRootIndex(index)));
     return;
@@ -133,6 +137,7 @@ void TurboAssembler::CompareRoot(Register with, RootIndex index) {
 }
 
 void MacroAssembler::PushRoot(RootIndex index) {
+  ASM_CODE_COMMENT(this);
   if (root_array_available()) {
     DCHECK(RootsTable::IsImmortalImmovable(index));
     push(Operand(kRootRegister, RootRegisterOffsetForRootIndex(index)));
@@ -164,6 +169,7 @@ void MacroAssembler::JumpIfIsInRange(Register value, unsigned lower_limit,
 
 void TurboAssembler::PushArray(Register array, Register size, Register scratch,
                                PushArrayOrder order) {
+  ASM_CODE_COMMENT(this);
   DCHECK(!AreAliased(array, size, scratch));
   Register counter = scratch;
   Label loop, entry;
@@ -243,6 +249,7 @@ Operand TurboAssembler::HeapObjectAsOperand(Handle<HeapObject> object) {
 
 void TurboAssembler::LoadFromConstantsTable(Register destination,
                                             int constant_index) {
+  ASM_CODE_COMMENT(this);
   DCHECK(RootsTable::IsImmortalImmovable(RootIndex::kBuiltinsConstantsTable));
   LoadRoot(destination, RootIndex::kBuiltinsConstantsTable);
   mov(destination,
@@ -251,6 +258,7 @@ void TurboAssembler::LoadFromConstantsTable(Register destination,
 
 void TurboAssembler::LoadRootRegisterOffset(Register destination,
                                             intptr_t offset) {
+  ASM_CODE_COMMENT(this);
   DCHECK(is_int32(offset));
   DCHECK(root_array_available());
   if (offset == 0) {
@@ -261,6 +269,7 @@ void TurboAssembler::LoadRootRegisterOffset(Register destination,
 }
 
 void TurboAssembler::LoadRootRelative(Register destination, int32_t offset) {
+  ASM_CODE_COMMENT(this);
   DCHECK(root_array_available());
   mov(destination, Operand(kRootRegister, offset));
 }
@@ -301,6 +310,7 @@ int TurboAssembler::RequiredStackSizeForCallerSaved(SaveFPRegsMode fp_mode,
 
 int TurboAssembler::PushCallerSaved(SaveFPRegsMode fp_mode, Register exclusion1,
                                     Register exclusion2, Register exclusion3) {
+  ASM_CODE_COMMENT(this);
   // We don't allow a GC during a store buffer overflow so there is no need to
   // store the registers in any particular way, but we do have to store and
   // restore them.
@@ -333,6 +343,7 @@ int TurboAssembler::PushCallerSaved(SaveFPRegsMode fp_mode, Register exclusion1,
 
 int TurboAssembler::PopCallerSaved(SaveFPRegsMode fp_mode, Register exclusion1,
                                    Register exclusion2, Register exclusion3) {
+  ASM_CODE_COMMENT(this);
   int bytes = 0;
   if (fp_mode == SaveFPRegsMode::kSave) {
     // Restore all XMM registers except XMM0.
@@ -365,6 +376,7 @@ void MacroAssembler::RecordWriteField(Register object, int offset,
                                       SaveFPRegsMode save_fp,
                                       RememberedSetAction remembered_set_action,
                                       SmiCheck smi_check) {
+  ASM_CODE_COMMENT(this);
   // First, check if a write barrier is even needed. The tests below
   // catch stores of Smis.
   Label done;
@@ -402,6 +414,7 @@ void MacroAssembler::RecordWriteField(Register object, int offset,
 
 void TurboAssembler::MaybeSaveRegisters(RegList registers) {
   if (registers == 0) return;
+  ASM_CODE_COMMENT(this);
   for (int i = 0; i < Register::kNumRegisters; ++i) {
     if ((registers >> i) & 1u) {
       push(Register::from_code(i));
@@ -411,6 +424,7 @@ void TurboAssembler::MaybeSaveRegisters(RegList registers) {
 
 void TurboAssembler::MaybeRestoreRegisters(RegList registers) {
   if (registers == 0) return;
+  ASM_CODE_COMMENT(this);
   for (int i = Register::kNumRegisters - 1; i >= 0; --i) {
     if ((registers >> i) & 1u) {
       pop(Register::from_code(i));
@@ -421,6 +435,7 @@ void TurboAssembler::MaybeRestoreRegisters(RegList registers) {
 void TurboAssembler::CallEphemeronKeyBarrier(Register object,
                                              Register slot_address,
                                              SaveFPRegsMode fp_mode) {
+  ASM_CODE_COMMENT(this);
   DCHECK(!AreAliased(object, slot_address));
   RegList registers =
       WriteBarrierDescriptor::ComputeSavedRegisters(object, slot_address);
@@ -446,6 +461,7 @@ void TurboAssembler::CallRecordWriteStubSaveRegisters(
     Register object, Register slot_address,
     RememberedSetAction remembered_set_action, SaveFPRegsMode fp_mode,
     StubCallMode mode) {
+  ASM_CODE_COMMENT(this);
   DCHECK(!AreAliased(object, slot_address));
   RegList registers =
       WriteBarrierDescriptor::ComputeSavedRegisters(object, slot_address);
@@ -470,6 +486,7 @@ void TurboAssembler::CallRecordWriteStub(
     Register object, Register slot_address,
     RememberedSetAction remembered_set_action, SaveFPRegsMode fp_mode,
     StubCallMode mode) {
+  ASM_CODE_COMMENT(this);
   // Use CallRecordWriteStubSaveRegisters if the object and slot registers
   // need to be caller saved.
   DCHECK_EQ(WriteBarrierDescriptor::ObjectRegister(), object);
@@ -499,6 +516,7 @@ void MacroAssembler::RecordWrite(Register object, Register slot_address,
                                  Register value, SaveFPRegsMode fp_mode,
                                  RememberedSetAction remembered_set_action,
                                  SmiCheck smi_check) {
+  ASM_CODE_COMMENT(this);
   DCHECK(!AreAliased(object, value, slot_address));
   AssertNotSmi(object);
 
@@ -509,6 +527,7 @@ void MacroAssembler::RecordWrite(Register object, Register slot_address,
   }
 
   if (FLAG_debug_code) {
+    ASM_CODE_COMMENT_STRING(this, "Verify slot_address");
     Label ok;
     cmp(value, Operand(slot_address, 0));
     j(equal, &ok, Label::kNear);
@@ -542,6 +561,7 @@ void MacroAssembler::RecordWrite(Register object, Register slot_address,
   // Clobber clobbered registers when running with the debug-code flag
   // turned on to provoke errors.
   if (FLAG_debug_code) {
+    ASM_CODE_COMMENT_STRING(this, "Clobber slot_address and value");
     mov(slot_address, Immediate(bit_cast<int32_t>(kZapValue)));
     mov(value, Immediate(bit_cast<int32_t>(kZapValue)));
   }
@@ -623,6 +643,7 @@ void TurboAssembler::Pmulhrsw(XMMRegister dst, XMMRegister src1,
 
 void TurboAssembler::I16x8Q15MulRSatS(XMMRegister dst, XMMRegister src1,
                                       XMMRegister src2, XMMRegister scratch) {
+  ASM_CODE_COMMENT(this);
   // k = i16x8.splat(0x8000)
   Pcmpeqd(scratch, scratch);
   Psllw(scratch, scratch, byte{15});
@@ -635,6 +656,7 @@ void TurboAssembler::I16x8Q15MulRSatS(XMMRegister dst, XMMRegister src1,
 void TurboAssembler::I8x16Popcnt(XMMRegister dst, XMMRegister src,
                                  XMMRegister tmp1, XMMRegister tmp2,
                                  Register scratch) {
+  ASM_CODE_COMMENT(this);
   DCHECK_NE(dst, tmp1);
   DCHECK_NE(src, tmp1);
   DCHECK_NE(dst, tmp2);
@@ -723,6 +745,7 @@ void TurboAssembler::F64x2ConvertLowI32x4U(XMMRegister dst, XMMRegister src,
 void TurboAssembler::I32x4TruncSatF64x2SZero(XMMRegister dst, XMMRegister src,
                                              XMMRegister scratch,
                                              Register tmp) {
+  ASM_CODE_COMMENT(this);
   if (CpuFeatures::IsSupported(AVX)) {
     CpuFeatureScope avx_scope(this, AVX);
     XMMRegister original_dst = dst;
@@ -763,6 +786,7 @@ void TurboAssembler::I32x4TruncSatF64x2SZero(XMMRegister dst, XMMRegister src,
 void TurboAssembler::I32x4TruncSatF64x2UZero(XMMRegister dst, XMMRegister src,
                                              XMMRegister scratch,
                                              Register tmp) {
+  ASM_CODE_COMMENT(this);
   if (CpuFeatures::IsSupported(AVX)) {
     CpuFeatureScope avx_scope(this, AVX);
     vxorpd(scratch, scratch, scratch);
@@ -851,6 +875,7 @@ void TurboAssembler::I32x4ExtAddPairwiseI16x8S(XMMRegister dst, XMMRegister src,
 
 void TurboAssembler::I32x4ExtAddPairwiseI16x8U(XMMRegister dst, XMMRegister src,
                                                XMMRegister tmp) {
+  ASM_CODE_COMMENT(this);
   if (CpuFeatures::IsSupported(AVX)) {
     CpuFeatureScope avx_scope(this, AVX);
     // src = |a|b|c|d|e|f|g|h| (low)
@@ -928,6 +953,7 @@ void TurboAssembler::ShlPair(Register high, Register low, uint8_t shift) {
 }
 
 void TurboAssembler::ShlPair_cl(Register high, Register low) {
+  ASM_CODE_COMMENT(this);
   shld_cl(high, low);
   shl_cl(low);
   Label done;
@@ -951,6 +977,7 @@ void TurboAssembler::ShrPair(Register high, Register low, uint8_t shift) {
 }
 
 void TurboAssembler::ShrPair_cl(Register high, Register low) {
+  ASM_CODE_COMMENT(this);
   shrd_cl(low, high);
   shr_cl(high);
   Label done;
@@ -962,6 +989,7 @@ void TurboAssembler::ShrPair_cl(Register high, Register low) {
 }
 
 void TurboAssembler::SarPair(Register high, Register low, uint8_t shift) {
+  ASM_CODE_COMMENT(this);
   DCHECK_GE(63, shift);
   if (shift >= 32) {
     mov(low, high);
@@ -974,6 +1002,7 @@ void TurboAssembler::SarPair(Register high, Register low, uint8_t shift) {
 }
 
 void TurboAssembler::SarPair_cl(Register high, Register low) {
+  ASM_CODE_COMMENT(this);
   shrd_cl(low, high);
   sar_cl(high);
   Label done;
@@ -990,6 +1019,7 @@ void TurboAssembler::LoadMap(Register destination, Register object) {
 
 void MacroAssembler::CmpObjectType(Register heap_object, InstanceType type,
                                    Register map) {
+  ASM_CODE_COMMENT(this);
   LoadMap(map, heap_object);
   CmpInstanceType(map, type);
 }
@@ -1001,6 +1031,7 @@ void MacroAssembler::CmpInstanceType(Register map, InstanceType type) {
 void MacroAssembler::CmpInstanceTypeRange(Register map, Register scratch,
                                           InstanceType lower_limit,
                                           InstanceType higher_limit) {
+  ASM_CODE_COMMENT(this);
   DCHECK_LT(lower_limit, higher_limit);
   movzx_w(scratch, FieldOperand(map, Map::kInstanceTypeOffset));
   lea(scratch, Operand(scratch, 0u - lower_limit));
@@ -1009,6 +1040,7 @@ void MacroAssembler::CmpInstanceTypeRange(Register map, Register scratch,
 
 void MacroAssembler::AssertSmi(Register object) {
   if (FLAG_debug_code) {
+    ASM_CODE_COMMENT(this);
     test(object, Immediate(kSmiTagMask));
     Check(equal, AbortReason::kOperandIsNotASmi);
   }
@@ -1016,6 +1048,7 @@ void MacroAssembler::AssertSmi(Register object) {
 
 void MacroAssembler::AssertConstructor(Register object) {
   if (FLAG_debug_code) {
+    ASM_CODE_COMMENT(this);
     test(object, Immediate(kSmiTagMask));
     Check(not_equal, AbortReason::kOperandIsASmiAndNotAConstructor);
     Push(object);
@@ -1029,6 +1062,7 @@ void MacroAssembler::AssertConstructor(Register object) {
 
 void MacroAssembler::AssertFunction(Register object, Register scratch) {
   if (FLAG_debug_code) {
+    ASM_CODE_COMMENT(this);
     test(object, Immediate(kSmiTagMask));
     Check(not_equal, AbortReason::kOperandIsASmiAndNotAFunction);
     Push(object);
@@ -1042,6 +1076,7 @@ void MacroAssembler::AssertFunction(Register object, Register scratch) {
 
 void MacroAssembler::AssertBoundFunction(Register object) {
   if (FLAG_debug_code) {
+    ASM_CODE_COMMENT(this);
     test(object, Immediate(kSmiTagMask));
     Check(not_equal, AbortReason::kOperandIsASmiAndNotABoundFunction);
     Push(object);
@@ -1053,6 +1088,7 @@ void MacroAssembler::AssertBoundFunction(Register object) {
 
 void MacroAssembler::AssertGeneratorObject(Register object) {
   if (!FLAG_debug_code) return;
+  ASM_CODE_COMMENT(this);
 
   test(object, Immediate(kSmiTagMask));
   Check(not_equal, AbortReason::kOperandIsASmiAndNotAGeneratorObject);
@@ -1085,6 +1121,7 @@ void MacroAssembler::AssertGeneratorObject(Register object) {
 void MacroAssembler::AssertUndefinedOrAllocationSite(Register object,
                                                      Register scratch) {
   if (FLAG_debug_code) {
+    ASM_CODE_COMMENT(this);
     Label done_checking;
     AssertNotSmi(object);
     CompareRoot(object, scratch, RootIndex::kUndefinedValue);
@@ -1098,18 +1135,21 @@ void MacroAssembler::AssertUndefinedOrAllocationSite(Register object,
 
 void MacroAssembler::AssertNotSmi(Register object) {
   if (FLAG_debug_code) {
+    ASM_CODE_COMMENT(this);
     test(object, Immediate(kSmiTagMask));
     Check(not_equal, AbortReason::kOperandIsASmi);
   }
 }
 
 void TurboAssembler::StubPrologue(StackFrame::Type type) {
+  ASM_CODE_COMMENT(this);
   push(ebp);  // Caller's frame pointer.
   mov(ebp, esp);
   push(Immediate(StackFrame::TypeToMarker(type)));
 }
 
 void TurboAssembler::Prologue() {
+  ASM_CODE_COMMENT(this);
   push(ebp);  // Caller's frame pointer.
   mov(ebp, esp);
   push(kContextRegister);                 // Callee's context.
@@ -1118,6 +1158,7 @@ void TurboAssembler::Prologue() {
 }
 
 void TurboAssembler::EnterFrame(StackFrame::Type type) {
+  ASM_CODE_COMMENT(this);
   push(ebp);
   mov(ebp, esp);
   if (!StackFrame::IsJavaScript(type)) {
@@ -1126,6 +1167,7 @@ void TurboAssembler::EnterFrame(StackFrame::Type type) {
 }
 
 void TurboAssembler::LeaveFrame(StackFrame::Type type) {
+  ASM_CODE_COMMENT(this);
   if (FLAG_debug_code && !StackFrame::IsJavaScript(type)) {
     cmp(Operand(ebp, CommonFrameConstants::kContextOrFrameTypeOffset),
         Immediate(StackFrame::TypeToMarker(type)));
@@ -1136,6 +1178,7 @@ void TurboAssembler::LeaveFrame(StackFrame::Type type) {
 
 #ifdef V8_OS_WIN
 void TurboAssembler::AllocateStackSpace(Register bytes_scratch) {
+  ASM_CODE_COMMENT(this);
   // In windows, we cannot increment the stack size by more than one page
   // (minimum page size is 4KB) without accessing at least one byte on the
   // page. Check this:
@@ -1157,6 +1200,7 @@ void TurboAssembler::AllocateStackSpace(Register bytes_scratch) {
 }
 
 void TurboAssembler::AllocateStackSpace(int bytes) {
+  ASM_CODE_COMMENT(this);
   DCHECK_GE(bytes, 0);
   while (bytes > kStackPageSize) {
     sub(esp, Immediate(kStackPageSize));
@@ -1170,6 +1214,7 @@ void TurboAssembler::AllocateStackSpace(int bytes) {
 
 void MacroAssembler::EnterExitFramePrologue(StackFrame::Type frame_type,
                                             Register scratch) {
+  ASM_CODE_COMMENT(this);
   DCHECK(frame_type == StackFrame::EXIT ||
          frame_type == StackFrame::BUILTIN_EXIT);
 
@@ -1203,6 +1248,7 @@ void MacroAssembler::EnterExitFramePrologue(StackFrame::Type frame_type,
 }
 
 void MacroAssembler::EnterExitFrameEpilogue(int argc, bool save_doubles) {
+  ASM_CODE_COMMENT(this);
   // Optionally save all XMM registers.
   if (save_doubles) {
     int space =
@@ -1230,6 +1276,7 @@ void MacroAssembler::EnterExitFrameEpilogue(int argc, bool save_doubles) {
 
 void MacroAssembler::EnterExitFrame(int argc, bool save_doubles,
                                     StackFrame::Type frame_type) {
+  ASM_CODE_COMMENT(this);
   EnterExitFramePrologue(frame_type, edi);
 
   // Set up argc and argv in callee-saved registers.
@@ -1247,6 +1294,7 @@ void MacroAssembler::EnterApiExitFrame(int argc, Register scratch) {
 }
 
 void MacroAssembler::LeaveExitFrame(bool save_doubles, bool pop_arguments) {
+  ASM_CODE_COMMENT(this);
   // Optionally restore all XMM registers.
   if (save_doubles) {
     const int offset = -ExitFrameConstants::kFixedFrameSizeFromFp;
@@ -1275,6 +1323,7 @@ void MacroAssembler::LeaveExitFrame(bool save_doubles, bool pop_arguments) {
 }
 
 void MacroAssembler::LeaveExitFrameEpilogue() {
+  ASM_CODE_COMMENT(this);
   // Clear the top frame.
   ExternalReference c_entry_fp_address =
       ExternalReference::Create(IsolateAddressId::kCEntryFPAddress, isolate());
@@ -1293,6 +1342,7 @@ void MacroAssembler::LeaveExitFrameEpilogue() {
 }
 
 void MacroAssembler::LeaveApiExitFrame() {
+  ASM_CODE_COMMENT(this);
   mov(esp, ebp);
   pop(ebp);
 
@@ -1300,6 +1350,7 @@ void MacroAssembler::LeaveApiExitFrame() {
 }
 
 void MacroAssembler::PushStackHandler(Register scratch) {
+  ASM_CODE_COMMENT(this);
   // Adjust this code if not the case.
   STATIC_ASSERT(StackHandlerConstants::kSize == 2 * kSystemPointerSize);
   STATIC_ASSERT(StackHandlerConstants::kNextOffset == 0);
@@ -1316,6 +1367,7 @@ void MacroAssembler::PushStackHandler(Register scratch) {
 }
 
 void MacroAssembler::PopStackHandler(Register scratch) {
+  ASM_CODE_COMMENT(this);
   STATIC_ASSERT(StackHandlerConstants::kNextOffset == 0);
   ExternalReference handler_address =
       ExternalReference::Create(IsolateAddressId::kHandlerAddress, isolate());
@@ -1325,6 +1377,7 @@ void MacroAssembler::PopStackHandler(Register scratch) {
 
 void MacroAssembler::CallRuntime(const Runtime::Function* f, int num_arguments,
                                  SaveFPRegsMode save_doubles) {
+  ASM_CODE_COMMENT(this);
   // If the expected number of arguments of the runtime function is
   // constant, we check that the actual number of arguments match the
   // expectation.
@@ -1351,7 +1404,7 @@ void MacroAssembler::TailCallRuntime(Runtime::FunctionId fid) {
   //  For runtime functions with variable arguments:
   //  -- eax                    : number of  arguments
   // -----------------------------------
-
+  ASM_CODE_COMMENT(this);
   const Runtime::Function* function = Runtime::FunctionForId(fid);
   DCHECK_EQ(1, function->result_size);
   if (function->nargs >= 0) {
@@ -1366,6 +1419,7 @@ void MacroAssembler::TailCallRuntime(Runtime::FunctionId fid) {
 
 void MacroAssembler::JumpToExternalReference(const ExternalReference& ext,
                                              bool builtin_exit_frame) {
+  ASM_CODE_COMMENT(this);
   // Set the entry point and jump to the C entry runtime stub.
   Move(kRuntimeCallFunctionRegister, Immediate(ext));
   Handle<Code> code = CodeFactory::CEntry(isolate(), 1, SaveFPRegsMode::kIgnore,
@@ -1380,6 +1434,7 @@ void MacroAssembler::JumpToInstructionStream(Address entry) {
 void TurboAssembler::PrepareForTailCall(
     Register callee_args_count, Register caller_args_count, Register scratch0,
     Register scratch1, int number_of_temp_values_after_return_address) {
+  ASM_CODE_COMMENT(this);
   DCHECK(!AreAliased(callee_args_count, caller_args_count, scratch0, scratch1));
 
   // Calculate the destination address where we will put the return address
@@ -1431,6 +1486,7 @@ void TurboAssembler::PrepareForTailCall(
 }
 
 void MacroAssembler::CompareStackLimit(Register with, StackLimitKind kind) {
+  ASM_CODE_COMMENT(this);
   DCHECK(root_array_available());
   Isolate* isolate = this->isolate();
   // Address through the root register. No load is needed.
@@ -1448,6 +1504,7 @@ void MacroAssembler::CompareStackLimit(Register with, StackLimitKind kind) {
 void MacroAssembler::StackOverflowCheck(Register num_args, Register scratch,
                                         Label* stack_overflow,
                                         bool include_receiver) {
+  ASM_CODE_COMMENT(this);
   DCHECK_NE(num_args, scratch);
   // Check the stack for overflow. We are not trying to catch
   // interruptions (e.g. debug break and preemption) here, so the "real stack
@@ -1474,55 +1531,56 @@ void MacroAssembler::StackOverflowCheck(Register num_args, Register scratch,
 void MacroAssembler::InvokePrologue(Register expected_parameter_count,
                                     Register actual_parameter_count,
                                     Label* done, InvokeType type) {
-  if (expected_parameter_count != actual_parameter_count) {
-    DCHECK_EQ(actual_parameter_count, eax);
-    DCHECK_EQ(expected_parameter_count, ecx);
-    Label regular_invoke;
-
-    // If the expected parameter count is equal to the adaptor sentinel, no need
-    // to push undefined value as arguments.
-    cmp(expected_parameter_count, Immediate(kDontAdaptArgumentsSentinel));
-    j(equal, &regular_invoke, Label::kFar);
-
-    // If overapplication or if the actual argument count is equal to the
-    // formal parameter count, no need to push extra undefined values.
-    sub(expected_parameter_count, actual_parameter_count);
-    j(less_equal, &regular_invoke, Label::kFar);
-
-    // We need to preserve edx, edi, esi and ebx.
-    movd(xmm0, edx);
-    movd(xmm1, edi);
-    movd(xmm2, esi);
-    movd(xmm3, ebx);
-
-    Label stack_overflow;
-    StackOverflowCheck(expected_parameter_count, edx, &stack_overflow);
-
-    Register scratch = esi;
-
-    // Underapplication. Move the arguments already in the stack, including the
-    // receiver and the return address.
-    {
-      Label copy, check;
-      Register src = edx, dest = esp, num = edi, current = ebx;
-      mov(src, esp);
-      lea(scratch,
-          Operand(expected_parameter_count, times_system_pointer_size, 0));
-      AllocateStackSpace(scratch);
-      // Extra words are the receiver and the return address (if a jump).
-      int extra_words = type == InvokeType::kCall ? 1 : 2;
-      lea(num, Operand(eax, extra_words));  // Number of words to copy.
-      Move(current, 0);
-      // Fall-through to the loop body because there are non-zero words to copy.
-      bind(&copy);
-      mov(scratch, Operand(src, current, times_system_pointer_size, 0));
-      mov(Operand(dest, current, times_system_pointer_size, 0), scratch);
-      inc(current);
-      bind(&check);
-      cmp(current, num);
-      j(less, &copy);
-      lea(edx, Operand(esp, num, times_system_pointer_size, 0));
-    }
+  if (expected_parameter_count == actual_parameter_count) return;
+  ASM_CODE_COMMENT(this);
+  DCHECK_EQ(actual_parameter_count, eax);
+  DCHECK_EQ(expected_parameter_count, ecx);
+  Label regular_invoke;
+
+  // If the expected parameter count is equal to the adaptor sentinel, no need
+  // to push undefined value as arguments.
+  cmp(expected_parameter_count, Immediate(kDontAdaptArgumentsSentinel));
+  j(equal, &regular_invoke, Label::kFar);
+
+  // If overapplication or if the actual argument count is equal to the
+  // formal parameter count, no need to push extra undefined values.
+  sub(expected_parameter_count, actual_parameter_count);
+  j(less_equal, &regular_invoke, Label::kFar);
+
+  // We need to preserve edx, edi, esi and ebx.
+  movd(xmm0, edx);
+  movd(xmm1, edi);
+  movd(xmm2, esi);
+  movd(xmm3, ebx);
+
+  Label stack_overflow;
+  StackOverflowCheck(expected_parameter_count, edx, &stack_overflow);
+
+  Register scratch = esi;
+
+  // Underapplication. Move the arguments already in the stack, including the
+  // receiver and the return address.
+  {
+    Label copy, check;
+    Register src = edx, dest = esp, num = edi, current = ebx;
+    mov(src, esp);
+    lea(scratch,
+        Operand(expected_parameter_count, times_system_pointer_size, 0));
+    AllocateStackSpace(scratch);
+    // Extra words are the receiver and the return address (if a jump).
+    int extra_words = type == InvokeType::kCall ? 1 : 2;
+    lea(num, Operand(eax, extra_words));  // Number of words to copy.
+    Move(current, 0);
+    // Fall-through to the loop body because there are non-zero words to copy.
+    bind(&copy);
+    mov(scratch, Operand(src, current, times_system_pointer_size, 0));
+    mov(Operand(dest, current, times_system_pointer_size, 0), scratch);
+    inc(current);
+    bind(&check);
+    cmp(current, num);
+    j(less, &copy);
+    lea(edx, Operand(esp, num, times_system_pointer_size, 0));
+  }
 
     // Fill remaining expected arguments with undefined values.
     movd(ebx, xmm3);  // Restore root.
@@ -1552,12 +1610,12 @@ void MacroAssembler::InvokePrologue(Register expected_parameter_count,
     }
 
     bind(&regular_invoke);
-  }
 }
 
 void MacroAssembler::CallDebugOnFunctionCall(Register fun, Register new_target,
                                              Register expected_parameter_count,
                                              Register actual_parameter_count) {
+  ASM_CODE_COMMENT(this);
   FrameScope frame(this, has_frame() ? StackFrame::NONE : StackFrame::INTERNAL);
   SmiTag(expected_parameter_count);
   Push(expected_parameter_count);
@@ -1590,6 +1648,7 @@ void MacroAssembler::InvokeFunctionCode(Register function, Register new_target,
                                         Register expected_parameter_count,
                                         Register actual_parameter_count,
                                         InvokeType type) {
+  ASM_CODE_COMMENT(this);
   // You can't call a function without a valid frame.
   DCHECK_IMPLIES(type == InvokeType::kCall, has_frame());
   DCHECK_EQ(function, edi);
@@ -1643,6 +1702,7 @@ void MacroAssembler::InvokeFunctionCode(Register function, Register new_target,
 void MacroAssembler::InvokeFunction(Register fun, Register new_target,
                                     Register actual_parameter_count,
                                     InvokeType type) {
+  ASM_CODE_COMMENT(this);
   // You can't call a function without a valid frame.
   DCHECK(type == InvokeType::kJump || has_frame());
 
@@ -1660,6 +1720,7 @@ void MacroAssembler::LoadGlobalProxy(Register dst) {
 }
 
 void MacroAssembler::LoadNativeContextSlot(Register destination, int index) {
+  ASM_CODE_COMMENT(this);
   // Load the native context from the current context.
   LoadMap(destination, esi);
   mov(destination,
@@ -1984,6 +2045,7 @@ void TurboAssembler::Popcnt(Register dst, Operand src) {
 }
 
 void MacroAssembler::LoadWeakValue(Register in_out, Label* target_if_cleared) {
+  ASM_CODE_COMMENT(this);
   cmp(in_out, Immediate(kClearedWeakHeapObjectLower32));
   j(equal, target_if_cleared);
 
@@ -1994,6 +2056,7 @@ void MacroAssembler::EmitIncrementCounter(StatsCounter* counter, int value,
                                           Register scratch) {
   DCHECK_GT(value, 0);
   if (FLAG_native_code_counters && counter->Enabled()) {
+    ASM_CODE_COMMENT(this);
     Operand operand =
         ExternalReferenceAsOperand(ExternalReference::Create(counter), scratch);
     if (value == 1) {
@@ -2008,6 +2071,7 @@ void MacroAssembler::EmitDecrementCounter(StatsCounter* counter, int value,
                                           Register scratch) {
   DCHECK_GT(value, 0);
   if (FLAG_native_code_counters && counter->Enabled()) {
+    ASM_CODE_COMMENT(this);
     Operand operand =
         ExternalReferenceAsOperand(ExternalReference::Create(counter), scratch);
     if (value == 1) {
@@ -2035,6 +2099,7 @@ void TurboAssembler::Check(Condition cc, AbortReason reason) {
 }
 
 void TurboAssembler::CheckStackAlignment() {
+  ASM_CODE_COMMENT(this);
   int frame_alignment = base::OS::ActivationFrameAlignment();
   int frame_alignment_mask = frame_alignment - 1;
   if (frame_alignment > kSystemPointerSize) {
@@ -2086,6 +2151,7 @@ void TurboAssembler::Abort(AbortReason reason) {
 }
 
 void TurboAssembler::PrepareCallCFunction(int num_arguments, Register scratch) {
+  ASM_CODE_COMMENT(this);
   int frame_alignment = base::OS::ActivationFrameAlignment();
   if (frame_alignment != 0) {
     // Make stack end at alignment and make room for num_arguments words
@@ -2108,6 +2174,7 @@ void TurboAssembler::CallCFunction(ExternalReference function,
 }
 
 void TurboAssembler::CallCFunction(Register function, int num_arguments) {
+  ASM_CODE_COMMENT(this);
   DCHECK_LE(num_arguments, kMaxCParameters);
   DCHECK(has_frame());
   // Check stack alignment.
@@ -2166,6 +2233,7 @@ void TurboAssembler::PushPC() {
 }
 
 void TurboAssembler::Call(Handle<Code> code_object, RelocInfo::Mode rmode) {
+  ASM_CODE_COMMENT(this);
   DCHECK_IMPLIES(options().isolate_independent_code,
                  Builtins::IsIsolateIndependentBuiltin(*code_object));
   if (options().inline_offheap_trampolines) {
@@ -2181,6 +2249,7 @@ void TurboAssembler::Call(Handle<Code> code_object, RelocInfo::Mode rmode) {
 }
 
 void TurboAssembler::LoadEntryFromBuiltinIndex(Register builtin_index) {
+  ASM_CODE_COMMENT(this);
   STATIC_ASSERT(kSystemPointerSize == 4);
   STATIC_ASSERT(kSmiShiftSize == 0);
   STATIC_ASSERT(kSmiTagSize == 1);
@@ -2196,22 +2265,26 @@ void TurboAssembler::LoadEntryFromBuiltinIndex(Register builtin_index) {
 }
 
 void TurboAssembler::CallBuiltinByIndex(Register builtin_index) {
+  ASM_CODE_COMMENT(this);
   LoadEntryFromBuiltinIndex(builtin_index);
   call(builtin_index);
 }
 
 void TurboAssembler::CallBuiltin(Builtin builtin) {
-  RecordCommentForOffHeapTrampoline(builtin);
+  ASM_CODE_COMMENT_STRING(this, CommentForOffHeapTrampoline("call", builtin));
+  DCHECK(Builtins::IsBuiltinId(builtin));
   call(BuiltinEntry(builtin), RelocInfo::OFF_HEAP_TARGET);
 }
 
 Operand TurboAssembler::EntryFromBuiltinAsOperand(Builtin builtin) {
+  ASM_CODE_COMMENT(this);
   return Operand(kRootRegister,
                  IsolateData::builtin_entry_slot_offset(builtin));
 }
 
 void TurboAssembler::LoadCodeObjectEntry(Register destination,
                                          Register code_object) {
+  ASM_CODE_COMMENT(this);
   // Code objects are called differently depending on whether we are generating
   // builtin code (which will later be embedded into the binary) or compiling
   // user JS code at runtime.
@@ -2254,11 +2327,13 @@ void TurboAssembler::LoadCodeObjectEntry(Register destination,
 }
 
 void TurboAssembler::CallCodeObject(Register code_object) {
+  ASM_CODE_COMMENT(this);
   LoadCodeObjectEntry(code_object, code_object);
   call(code_object);
 }
 
 void TurboAssembler::JumpCodeObject(Register code_object, JumpMode jump_mode) {
+  ASM_CODE_COMMENT(this);
   LoadCodeObjectEntry(code_object, code_object);
   switch (jump_mode) {
     case JumpMode::kJump:
@@ -2294,6 +2369,7 @@ void TurboAssembler::Jump(Handle<Code> code_object, RelocInfo::Mode rmode) {
 }
 
 void TurboAssembler::RetpolineCall(Register reg) {
+  ASM_CODE_COMMENT(this);
   Label setup_return, setup_target, inner_indirect_branch, capture_spec;
 
   jmp(&setup_return);  // Jump past the entire retpoline below.
@@ -2314,6 +2390,7 @@ void TurboAssembler::RetpolineCall(Register reg) {
 }
 
 void TurboAssembler::RetpolineCall(Address destination, RelocInfo::Mode rmode) {
+  ASM_CODE_COMMENT(this);
   Label setup_return, setup_target, inner_indirect_branch, capture_spec;
 
   jmp(&setup_return);  // Jump past the entire retpoline below.
@@ -2334,6 +2411,7 @@ void TurboAssembler::RetpolineCall(Address destination, RelocInfo::Mode rmode) {
 }
 
 void TurboAssembler::RetpolineJump(Register reg) {
+  ASM_CODE_COMMENT(this);
   Label setup_target, capture_spec;
 
   call(&setup_target);
@@ -2350,6 +2428,7 @@ void TurboAssembler::RetpolineJump(Register reg) {
 void TurboAssembler::CheckPageFlag(Register object, Register scratch, int mask,
                                    Condition cc, Label* condition_met,
                                    Label::Distance condition_met_distance) {
+  ASM_CODE_COMMENT(this);
   DCHECK(cc == zero || cc == not_zero);
   if (scratch == object) {
     and_(scratch, Immediate(~kPageAlignmentMask));
@@ -2366,6 +2445,7 @@ void TurboAssembler::CheckPageFlag(Register object, Register scratch, int mask,
 }
 
 void TurboAssembler::ComputeCodeStartAddress(Register dst) {
+  ASM_CODE_COMMENT(this);
   // In order to get the address of the current instruction, we first need
   // to use a call and then use a pop, thus pushing the return address to
   // the stack and then popping it into the register.
@@ -2382,6 +2462,7 @@ void TurboAssembler::ComputeCodeStartAddress(Register dst) {
 void TurboAssembler::CallForDeoptimization(Builtin target, int, Label* exit,
                                            DeoptimizeKind kind, Label* ret,
                                            Label*) {
+  ASM_CODE_COMMENT(this);
   CallBuiltin(target);
   DCHECK_EQ(SizeOfCodeGeneratedSince(exit),
             (kind == DeoptimizeKind::kLazy)
