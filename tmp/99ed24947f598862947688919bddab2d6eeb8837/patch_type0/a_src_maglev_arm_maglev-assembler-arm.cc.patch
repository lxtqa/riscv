diff --git a/src/maglev/arm/maglev-assembler-arm.cc b/src/maglev/arm/maglev-assembler-arm.cc
index b2e95913e1c..0afbac4eb5b 100644
--- a/src/maglev/arm/maglev-assembler-arm.cc
+++ b/src/maglev/arm/maglev-assembler-arm.cc
@@ -79,21 +79,64 @@ void MaglevAssembler::Allocate(RegisterSnapshot register_snapshot,
   bind(*done);
 }
 
+void MaglevAssembler::OSRPrologue(Graph* graph) {
+  ScratchRegisterScope temps(this);
+  Register scratch = temps.Acquire();
+
+  DCHECK(graph->is_osr());
+  CHECK(!graph->has_recursive_calls());
+
+  uint32_t source_frame_size =
+      graph->min_maglev_stackslots_for_unoptimized_frame_size();
+
+  if (v8_flags.maglev_assert_stack_size && v8_flags.debug_code) {
+    add(scratch, sp,
+        Operand(source_frame_size * kSystemPointerSize +
+                StandardFrameConstants::kFixedFrameSizeFromFp));
+    cmp(scratch, fp);
+    Assert(eq, AbortReason::kOsrUnexpectedStackSize);
+  }
+
+  uint32_t target_frame_size =
+      graph->tagged_stack_slots() + graph->untagged_stack_slots();
+  CHECK_LE(source_frame_size, target_frame_size);
+
+  if (source_frame_size < target_frame_size) {
+    ASM_CODE_COMMENT_STRING(this, "Growing frame for OSR");
+    uint32_t additional_tagged =
+        source_frame_size < graph->tagged_stack_slots()
+            ? graph->tagged_stack_slots() - source_frame_size
+            : 0;
+    if (additional_tagged) {
+      Move(scratch, 0);
+    }
+    for (size_t i = 0; i < additional_tagged; ++i) {
+      Push(scratch);
+    }
+    uint32_t size_so_far = source_frame_size + additional_tagged;
+    CHECK_LE(size_so_far, target_frame_size);
+    if (size_so_far < target_frame_size) {
+      sub(sp, sp,
+          Operand((target_frame_size - size_so_far) * kSystemPointerSize));
+    }
+  }
+}
+
 void MaglevAssembler::Prologue(Graph* graph) {
   ScratchRegisterScope temps(this);
   temps.Include({r4, r8});
-  if (!graph->is_osr()) {
-    BailoutIfDeoptimized();
-  }
 
-  CHECK_IMPLIES(graph->is_osr(), !graph->has_recursive_calls());
+  DCHECK(!graph->is_osr());
+
+  BailoutIfDeoptimized();
+
   if (graph->has_recursive_calls()) {
     bind(code_gen_state()->entry_label());
   }
 
   // Tiering support.
   // TODO(jgruber): Extract to a builtin.
-  if (v8_flags.turbofan && !graph->is_osr()) {
+  if (v8_flags.turbofan) {
     ScratchRegisterScope temps(this);
     Register flags = temps.Acquire();
     Register feedback_vector = temps.Acquire();
@@ -115,47 +158,6 @@ void MaglevAssembler::Prologue(Graph* graph) {
         deferred_flags_need_processing);
   }
 
-  if (graph->is_osr()) {
-    Register scratch = temps.Acquire();
-
-    uint32_t source_frame_size =
-        graph->min_maglev_stackslots_for_unoptimized_frame_size();
-
-    if (v8_flags.maglev_assert_stack_size && v8_flags.debug_code) {
-      add(scratch, sp,
-          Operand(source_frame_size * kSystemPointerSize +
-                  StandardFrameConstants::kFixedFrameSizeFromFp),
-          SetCC);
-      cmp(scratch, fp);
-      Assert(eq, AbortReason::kOsrUnexpectedStackSize);
-    }
-
-    uint32_t target_frame_size =
-        graph->tagged_stack_slots() + graph->untagged_stack_slots();
-    CHECK_LE(source_frame_size, target_frame_size);
-
-    if (source_frame_size < target_frame_size) {
-      ASM_CODE_COMMENT_STRING(this, "Growing frame for OSR");
-      uint32_t additional_tagged =
-          source_frame_size < graph->tagged_stack_slots()
-              ? graph->tagged_stack_slots() - source_frame_size
-              : 0;
-      if (additional_tagged) {
-        Move(scratch, 0);
-      }
-      for (size_t i = 0; i < additional_tagged; ++i) {
-        Push(scratch);
-      }
-      uint32_t size_so_far = source_frame_size + additional_tagged;
-      CHECK_LE(size_so_far, target_frame_size);
-      if (size_so_far < target_frame_size) {
-        sub(sp, sp,
-            Operand((target_frame_size - size_so_far) * kSystemPointerSize));
-      }
-    }
-    return;
-  }
-
   EnterFrame(StackFrame::MAGLEV);
   // Save arguments in frame.
   // TODO(leszeks): Consider eliding this frame if we don't make any calls
