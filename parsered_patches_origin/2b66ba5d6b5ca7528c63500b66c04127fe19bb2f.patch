From 2b66ba5d6b5ca7528c63500b66c04127fe19bb2f Mon Sep 17 00:00:00 2001
From: Ng Zhi An <zhin@chromium.org>
Date: Fri, 5 Mar 2021 15:56:29 -0800
Subject: [PATCH] [wasm-simd] Rename vXXXX.all_true to iXXXX.all_true

This is done with a script that does something like:

files=$(ag 'v\d\d?x\d\d?[._]?all_?true' -l)
sed -i 's/V\(8x16\|16x8\|32x4\|64x2\)\([._]\?\)\([aA]ll_\?[tT]rue\)/I\1\2\3/g' $(files)
sed -i 's/v\(8x16\|16x8\|32x4\|64x2\)\([._]\?\)\([aA]ll_\?[tT]rue\)/i\1\2\3/g' $(files)

And manual fixups in test-run-wasm-simd.cc and wasm-opcodes-inl.h.

Bug: v8:10946
Change-Id: Ib5dad388dd6dd9cd0fb575ad961dffc189a2e6ef
Reviewed-on: https://chromium-review.googlesource.com/c/v8/v8/+/2740488
Reviewed-by: Bill Budge <bbudge@chromium.org>
Commit-Queue: Zhi An Ng <zhin@chromium.org>
Cr-Commit-Position: refs/heads/master@{#73309}
---
 src/codegen/arm/macro-assembler-arm.cc           |  2 +-
 src/codegen/arm/macro-assembler-arm.h            |  2 +-
 src/codegen/arm64/macro-assembler-arm64.cc       |  2 +-
 src/codegen/arm64/macro-assembler-arm64.h        |  2 +-
 src/compiler/backend/arm/code-generator-arm.cc   | 10 +++++-----
 src/compiler/backend/arm/instruction-codes-arm.h |  8 ++++----
 .../backend/arm/instruction-scheduler-arm.cc     |  8 ++++----
 .../backend/arm/instruction-selector-arm.cc      |  8 ++++----
 .../backend/arm64/code-generator-arm64.cc        | 10 +++++-----
 .../backend/arm64/instruction-codes-arm64.h      |  8 ++++----
 .../backend/arm64/instruction-scheduler-arm64.cc |  8 ++++----
 .../backend/arm64/instruction-selector-arm64.cc  |  8 ++++----
 src/compiler/backend/ia32/code-generator-ia32.cc |  8 ++++----
 .../backend/ia32/instruction-codes-ia32.h        |  8 ++++----
 .../backend/ia32/instruction-scheduler-ia32.cc   |  8 ++++----
 .../backend/ia32/instruction-selector-ia32.cc    |  8 ++++----
 src/compiler/backend/instruction-selector.cc     | 16 ++++++++--------
 src/compiler/backend/mips/code-generator-mips.cc |  8 ++++----
 .../backend/mips/instruction-codes-mips.h        |  8 ++++----
 .../backend/mips/instruction-scheduler-mips.cc   |  8 ++++----
 .../backend/mips/instruction-selector-mips.cc    |  8 ++++----
 .../backend/mips64/code-generator-mips64.cc      |  8 ++++----
 .../backend/mips64/instruction-codes-mips64.h    |  8 ++++----
 .../mips64/instruction-scheduler-mips64.cc       |  8 ++++----
 .../mips64/instruction-selector-mips64.cc        |  8 ++++----
 src/compiler/backend/ppc/code-generator-ppc.cc   |  8 ++++----
 src/compiler/backend/ppc/instruction-codes-ppc.h |  8 ++++----
 .../backend/ppc/instruction-scheduler-ppc.cc     |  8 ++++----
 .../backend/ppc/instruction-selector-ppc.cc      |  8 ++++----
 .../backend/riscv64/instruction-codes-riscv64.h  |  6 +++---
 .../riscv64/instruction-scheduler-riscv64.cc     |  6 +++---
 .../riscv64/instruction-selector-riscv64.cc      |  6 +++---
 src/compiler/backend/s390/code-generator-s390.cc |  8 ++++----
 .../backend/s390/instruction-codes-s390.h        |  8 ++++----
 .../backend/s390/instruction-scheduler-s390.cc   |  8 ++++----
 .../backend/s390/instruction-selector-s390.cc    |  8 ++++----
 src/compiler/backend/x64/code-generator-x64.cc   |  8 ++++----
 src/compiler/backend/x64/instruction-codes-x64.h |  8 ++++----
 .../backend/x64/instruction-scheduler-x64.cc     |  8 ++++----
 .../backend/x64/instruction-selector-x64.cc      |  8 ++++----
 src/compiler/machine-operator.cc                 |  8 ++++----
 src/compiler/machine-operator.h                  |  8 ++++----
 src/compiler/opcodes.h                           |  8 ++++----
 src/compiler/simd-scalar-lowering.cc             | 16 ++++++++--------
 src/compiler/wasm-compiler.cc                    | 16 ++++++++--------
 src/wasm/baseline/arm/liftoff-assembler-arm.h    | 10 +++++-----
 .../baseline/arm64/liftoff-assembler-arm64.h     | 10 +++++-----
 src/wasm/baseline/ia32/liftoff-assembler-ia32.h  |  8 ++++----
 src/wasm/baseline/liftoff-assembler.h            |  8 ++++----
 src/wasm/baseline/liftoff-compiler.cc            | 16 ++++++++--------
 src/wasm/baseline/mips/liftoff-assembler-mips.h  | 16 ++++++++--------
 .../baseline/mips64/liftoff-assembler-mips64.h   |  8 ++++----
 src/wasm/baseline/ppc/liftoff-assembler-ppc.h    | 16 ++++++++--------
 .../baseline/riscv64/liftoff-assembler-riscv64.h | 12 ++++++------
 src/wasm/baseline/s390/liftoff-assembler-s390.h  | 16 ++++++++--------
 src/wasm/baseline/x64/liftoff-assembler-x64.h    |  8 ++++----
 src/wasm/wasm-opcodes-inl.h                      |  5 +----
 src/wasm/wasm-opcodes.h                          |  8 ++++----
 .../wasm/test-run-wasm-simd-scalar-lowering.cc   |  6 +++---
 test/cctest/wasm/test-run-wasm-simd.cc           | 12 ++++++------
 test/common/wasm/wasm-interpreter.cc             |  8 ++++----
 test/fuzzer/wasm-compile.cc                      |  8 ++++----
 test/mjsunit/regress/wasm/regress-10831.js       |  2 +-
 test/mjsunit/wasm/exceptions-simd.js             |  2 +-
 test/mjsunit/wasm/wasm-module-builder.js         |  8 ++++----
 65 files changed, 271 insertions(+), 274 deletions(-)

diff --git a/src/codegen/arm/macro-assembler-arm.cc b/src/codegen/arm/macro-assembler-arm.cc
index 1f490d29d2..12f786f06c 100644
--- a/src/codegen/arm/macro-assembler-arm.cc
+++ b/src/codegen/arm/macro-assembler-arm.cc
@@ -2682,7 +2682,7 @@ void TurboAssembler::I64x2GeS(QwNeonRegister dst, QwNeonRegister src1,
   vmvn(dst, dst);
 }
 
-void TurboAssembler::V64x2AllTrue(Register dst, QwNeonRegister src) {
+void TurboAssembler::I64x2AllTrue(Register dst, QwNeonRegister src) {
   UseScratchRegisterScope temps(this);
   QwNeonRegister tmp = temps.AcquireQ();
   // src = | a | b | c | d |
diff --git a/src/codegen/arm/macro-assembler-arm.h b/src/codegen/arm/macro-assembler-arm.h
index 6f0c67474f..fcbb427a19 100644
--- a/src/codegen/arm/macro-assembler-arm.h
+++ b/src/codegen/arm/macro-assembler-arm.h
@@ -578,7 +578,7 @@ class V8_EXPORT_PRIVATE TurboAssembler : public TurboAssemblerBase {
   void I64x2Ne(QwNeonRegister dst, QwNeonRegister src1, QwNeonRegister src2);
   void I64x2GtS(QwNeonRegister dst, QwNeonRegister src1, QwNeonRegister src2);
   void I64x2GeS(QwNeonRegister dst, QwNeonRegister src1, QwNeonRegister src2);
-  void V64x2AllTrue(Register dst, QwNeonRegister src);
+  void I64x2AllTrue(Register dst, QwNeonRegister src);
   void I64x2Abs(QwNeonRegister dst, QwNeonRegister src);
   void F64x2ConvertLowI32x4S(QwNeonRegister dst, QwNeonRegister src);
   void F64x2ConvertLowI32x4U(QwNeonRegister dst, QwNeonRegister src);
diff --git a/src/codegen/arm64/macro-assembler-arm64.cc b/src/codegen/arm64/macro-assembler-arm64.cc
index c55ddd1c74..8358d20105 100644
--- a/src/codegen/arm64/macro-assembler-arm64.cc
+++ b/src/codegen/arm64/macro-assembler-arm64.cc
@@ -3466,7 +3466,7 @@ void TurboAssembler::I64x2BitMask(Register dst, VRegister src) {
   Add(dst.W(), dst.W(), Operand(tmp2.W(), LSL, 1));
 }
 
-void TurboAssembler::V64x2AllTrue(Register dst, VRegister src) {
+void TurboAssembler::I64x2AllTrue(Register dst, VRegister src) {
   UseScratchRegisterScope scope(this);
   VRegister tmp = scope.AcquireV(kFormat2D);
   Cmeq(tmp.V2D(), src.V2D(), 0);
diff --git a/src/codegen/arm64/macro-assembler-arm64.h b/src/codegen/arm64/macro-assembler-arm64.h
index 8cf3a2b979..4fa62574fa 100644
--- a/src/codegen/arm64/macro-assembler-arm64.h
+++ b/src/codegen/arm64/macro-assembler-arm64.h
@@ -1382,7 +1382,7 @@ class V8_EXPORT_PRIVATE TurboAssembler : public TurboAssemblerBase {
   // instructions. These helpers allow us to define the optimal code sequence,
   // and be used in both TurboFan and Liftoff.
   void I64x2BitMask(Register dst, VRegister src);
-  void V64x2AllTrue(Register dst, VRegister src);
+  void I64x2AllTrue(Register dst, VRegister src);
 
  protected:
   // The actual Push and Pop implementations. These don't generate any code
diff --git a/src/compiler/backend/arm/code-generator-arm.cc b/src/compiler/backend/arm/code-generator-arm.cc
index d5eba520fd..15867f0b64 100644
--- a/src/compiler/backend/arm/code-generator-arm.cc
+++ b/src/compiler/backend/arm/code-generator-arm.cc
@@ -3224,11 +3224,11 @@ CodeGenerator::CodeGenResult CodeGenerator::AssembleArchInstruction(
       __ mov(i.OutputRegister(), Operand(1), LeaveCC, ne);
       break;
     }
-    case kArmV64x2AllTrue: {
-      __ V64x2AllTrue(i.OutputRegister(), i.InputSimd128Register(0));
+    case kArmI64x2AllTrue: {
+      __ I64x2AllTrue(i.OutputRegister(), i.InputSimd128Register(0));
       break;
     }
-    case kArmV32x4AllTrue: {
+    case kArmI32x4AllTrue: {
       const QwNeonRegister& src = i.InputSimd128Register(0);
       UseScratchRegisterScope temps(tasm());
       DwVfpRegister scratch = temps.AcquireD();
@@ -3239,7 +3239,7 @@ CodeGenerator::CodeGenResult CodeGenerator::AssembleArchInstruction(
       __ mov(i.OutputRegister(), Operand(1), LeaveCC, ne);
       break;
     }
-    case kArmV16x8AllTrue: {
+    case kArmI16x8AllTrue: {
       const QwNeonRegister& src = i.InputSimd128Register(0);
       UseScratchRegisterScope temps(tasm());
       DwVfpRegister scratch = temps.AcquireD();
@@ -3251,7 +3251,7 @@ CodeGenerator::CodeGenResult CodeGenerator::AssembleArchInstruction(
       __ mov(i.OutputRegister(), Operand(1), LeaveCC, ne);
       break;
     }
-    case kArmV8x16AllTrue: {
+    case kArmI8x16AllTrue: {
       const QwNeonRegister& src = i.InputSimd128Register(0);
       UseScratchRegisterScope temps(tasm());
       DwVfpRegister scratch = temps.AcquireD();
diff --git a/src/compiler/backend/arm/instruction-codes-arm.h b/src/compiler/backend/arm/instruction-codes-arm.h
index 4b9ff54675..8cec45cd0c 100644
--- a/src/compiler/backend/arm/instruction-codes-arm.h
+++ b/src/compiler/backend/arm/instruction-codes-arm.h
@@ -332,11 +332,11 @@ namespace compiler {
   V(ArmS8x8Reverse)                \
   V(ArmS8x4Reverse)                \
   V(ArmS8x2Reverse)                \
-  V(ArmV64x2AllTrue)               \
-  V(ArmV32x4AllTrue)               \
-  V(ArmV16x8AllTrue)               \
+  V(ArmI64x2AllTrue)               \
+  V(ArmI32x4AllTrue)               \
+  V(ArmI16x8AllTrue)               \
   V(ArmV128AnyTrue)                \
-  V(ArmV8x16AllTrue)               \
+  V(ArmI8x16AllTrue)               \
   V(ArmS128Load8Splat)             \
   V(ArmS128Load16Splat)            \
   V(ArmS128Load32Splat)            \
diff --git a/src/compiler/backend/arm/instruction-scheduler-arm.cc b/src/compiler/backend/arm/instruction-scheduler-arm.cc
index a548a1329a..cb5cd568b0 100644
--- a/src/compiler/backend/arm/instruction-scheduler-arm.cc
+++ b/src/compiler/backend/arm/instruction-scheduler-arm.cc
@@ -312,11 +312,11 @@ int InstructionScheduler::GetTargetInstructionFlags(
     case kArmS8x8Reverse:
     case kArmS8x4Reverse:
     case kArmS8x2Reverse:
-    case kArmV64x2AllTrue:
-    case kArmV32x4AllTrue:
-    case kArmV16x8AllTrue:
+    case kArmI64x2AllTrue:
+    case kArmI32x4AllTrue:
+    case kArmI16x8AllTrue:
     case kArmV128AnyTrue:
-    case kArmV8x16AllTrue:
+    case kArmI8x16AllTrue:
       return kNoOpcodeFlags;
 
     case kArmVldrF32:
diff --git a/src/compiler/backend/arm/instruction-selector-arm.cc b/src/compiler/backend/arm/instruction-selector-arm.cc
index ec0d5c76b0..d28ada322d 100644
--- a/src/compiler/backend/arm/instruction-selector-arm.cc
+++ b/src/compiler/backend/arm/instruction-selector-arm.cc
@@ -2588,11 +2588,11 @@ void InstructionSelector::VisitWord32AtomicPairCompareExchange(Node* node) {
   V(I8x16Abs, kArmI8x16Abs)                             \
   V(I8x16Popcnt, kArmVcnt)                              \
   V(S128Not, kArmS128Not)                               \
-  V(V64x2AllTrue, kArmV64x2AllTrue)                     \
-  V(V32x4AllTrue, kArmV32x4AllTrue)                     \
-  V(V16x8AllTrue, kArmV16x8AllTrue)                     \
+  V(I64x2AllTrue, kArmI64x2AllTrue)                     \
+  V(I32x4AllTrue, kArmI32x4AllTrue)                     \
+  V(I16x8AllTrue, kArmI16x8AllTrue)                     \
   V(V128AnyTrue, kArmV128AnyTrue)                       \
-  V(V8x16AllTrue, kArmV8x16AllTrue)
+  V(I8x16AllTrue, kArmI8x16AllTrue)
 
 #define SIMD_SHIFT_OP_LIST(V) \
   V(I64x2Shl, 64)             \
diff --git a/src/compiler/backend/arm64/code-generator-arm64.cc b/src/compiler/backend/arm64/code-generator-arm64.cc
index 18a7e41211..cad83f927b 100644
--- a/src/compiler/backend/arm64/code-generator-arm64.cc
+++ b/src/compiler/backend/arm64/code-generator-arm64.cc
@@ -2836,8 +2836,8 @@ CodeGenerator::CodeGenResult CodeGenerator::AssembleArchInstruction(
       __ Uxtl(i.OutputSimd128Register().V2D(), i.OutputSimd128Register().V2S());
       break;
     }
-    case kArm64V64x2AllTrue: {
-      __ V64x2AllTrue(i.OutputRegister32(), i.InputSimd128Register(0));
+    case kArm64I64x2AllTrue: {
+      __ I64x2AllTrue(i.OutputRegister32(), i.InputSimd128Register(0));
       break;
     }
 #define SIMD_REDUCE_OP_CASE(Op, Instr, format, FORMAT)     \
@@ -2852,9 +2852,9 @@ CodeGenerator::CodeGenResult CodeGenerator::AssembleArchInstruction(
   }
       // For AnyTrue, the format does not matter.
       SIMD_REDUCE_OP_CASE(kArm64V128AnyTrue, Umaxv, kFormatS, 4S);
-      SIMD_REDUCE_OP_CASE(kArm64V32x4AllTrue, Uminv, kFormatS, 4S);
-      SIMD_REDUCE_OP_CASE(kArm64V16x8AllTrue, Uminv, kFormatH, 8H);
-      SIMD_REDUCE_OP_CASE(kArm64V8x16AllTrue, Uminv, kFormatB, 16B);
+      SIMD_REDUCE_OP_CASE(kArm64I32x4AllTrue, Uminv, kFormatS, 4S);
+      SIMD_REDUCE_OP_CASE(kArm64I16x8AllTrue, Uminv, kFormatH, 8H);
+      SIMD_REDUCE_OP_CASE(kArm64I8x16AllTrue, Uminv, kFormatB, 16B);
   }
   return kSuccess;
 }  // NOLINT(readability/fn_size)
diff --git a/src/compiler/backend/arm64/instruction-codes-arm64.h b/src/compiler/backend/arm64/instruction-codes-arm64.h
index 31bb53638d..5285e1dabc 100644
--- a/src/compiler/backend/arm64/instruction-codes-arm64.h
+++ b/src/compiler/backend/arm64/instruction-codes-arm64.h
@@ -375,10 +375,10 @@ namespace compiler {
   V(Arm64S8x4Reverse)                       \
   V(Arm64S8x2Reverse)                       \
   V(Arm64V128AnyTrue)                       \
-  V(Arm64V64x2AllTrue)                      \
-  V(Arm64V32x4AllTrue)                      \
-  V(Arm64V16x8AllTrue)                      \
-  V(Arm64V8x16AllTrue)                      \
+  V(Arm64I64x2AllTrue)                      \
+  V(Arm64I32x4AllTrue)                      \
+  V(Arm64I16x8AllTrue)                      \
+  V(Arm64I8x16AllTrue)                      \
   V(Arm64LoadSplat)                         \
   V(Arm64LoadLane)                          \
   V(Arm64StoreLane)                         \
diff --git a/src/compiler/backend/arm64/instruction-scheduler-arm64.cc b/src/compiler/backend/arm64/instruction-scheduler-arm64.cc
index 9da3b44f56..268cd9a961 100644
--- a/src/compiler/backend/arm64/instruction-scheduler-arm64.cc
+++ b/src/compiler/backend/arm64/instruction-scheduler-arm64.cc
@@ -344,10 +344,10 @@ int InstructionScheduler::GetTargetInstructionFlags(
     case kArm64S8x4Reverse:
     case kArm64S8x2Reverse:
     case kArm64V128AnyTrue:
-    case kArm64V64x2AllTrue:
-    case kArm64V32x4AllTrue:
-    case kArm64V16x8AllTrue:
-    case kArm64V8x16AllTrue:
+    case kArm64I64x2AllTrue:
+    case kArm64I32x4AllTrue:
+    case kArm64I16x8AllTrue:
+    case kArm64I8x16AllTrue:
     case kArm64TestAndBranch32:
     case kArm64TestAndBranch:
     case kArm64CompareAndBranch32:
diff --git a/src/compiler/backend/arm64/instruction-selector-arm64.cc b/src/compiler/backend/arm64/instruction-selector-arm64.cc
index 9effd783de..c475b74a8f 100644
--- a/src/compiler/backend/arm64/instruction-selector-arm64.cc
+++ b/src/compiler/backend/arm64/instruction-selector-arm64.cc
@@ -3435,10 +3435,10 @@ void InstructionSelector::VisitInt64AbsWithOverflow(Node* node) {
   V(I8x16BitMask, kArm64I8x16BitMask)                       \
   V(S128Not, kArm64S128Not)                                 \
   V(V128AnyTrue, kArm64V128AnyTrue)                         \
-  V(V64x2AllTrue, kArm64V64x2AllTrue)                       \
-  V(V32x4AllTrue, kArm64V32x4AllTrue)                       \
-  V(V16x8AllTrue, kArm64V16x8AllTrue)                       \
-  V(V8x16AllTrue, kArm64V8x16AllTrue)
+  V(I64x2AllTrue, kArm64I64x2AllTrue)                       \
+  V(I32x4AllTrue, kArm64I32x4AllTrue)                       \
+  V(I16x8AllTrue, kArm64I16x8AllTrue)                       \
+  V(I8x16AllTrue, kArm64I8x16AllTrue)
 
 #define SIMD_SHIFT_OP_LIST(V) \
   V(I64x2Shl, 64)             \
diff --git a/src/compiler/backend/ia32/code-generator-ia32.cc b/src/compiler/backend/ia32/code-generator-ia32.cc
index cdac75dd01..88c8a99b42 100644
--- a/src/compiler/backend/ia32/code-generator-ia32.cc
+++ b/src/compiler/backend/ia32/code-generator-ia32.cc
@@ -4058,16 +4058,16 @@ CodeGenerator::CodeGenResult CodeGenerator::AssembleArchInstruction(
     // comparison instruction used matters, e.g. given 0xff00, pcmpeqb returns
     // 0x0011, pcmpeqw returns 0x0000, ptest will set ZF to 0 and 1
     // respectively.
-    case kIA32V64x2AllTrue:
+    case kIA32I64x2AllTrue:
       ASSEMBLE_SIMD_ALL_TRUE(Pcmpeqq);
       break;
-    case kIA32V32x4AllTrue:
+    case kIA32I32x4AllTrue:
       ASSEMBLE_SIMD_ALL_TRUE(Pcmpeqd);
       break;
-    case kIA32V16x8AllTrue:
+    case kIA32I16x8AllTrue:
       ASSEMBLE_SIMD_ALL_TRUE(pcmpeqw);
       break;
-    case kIA32V8x16AllTrue: {
+    case kIA32I8x16AllTrue: {
       ASSEMBLE_SIMD_ALL_TRUE(pcmpeqb);
       break;
     }
diff --git a/src/compiler/backend/ia32/instruction-codes-ia32.h b/src/compiler/backend/ia32/instruction-codes-ia32.h
index c13c2edb2b..42f4437266 100644
--- a/src/compiler/backend/ia32/instruction-codes-ia32.h
+++ b/src/compiler/backend/ia32/instruction-codes-ia32.h
@@ -399,10 +399,10 @@ namespace compiler {
   V(SSES8x2Reverse)                \
   V(AVXS8x2Reverse)                \
   V(IA32S128AnyTrue)               \
-  V(IA32V64x2AllTrue)              \
-  V(IA32V32x4AllTrue)              \
-  V(IA32V16x8AllTrue)              \
-  V(IA32V8x16AllTrue)              \
+  V(IA32I64x2AllTrue)              \
+  V(IA32I32x4AllTrue)              \
+  V(IA32I16x8AllTrue)              \
+  V(IA32I8x16AllTrue)              \
   V(IA32Prefetch)                  \
   V(IA32PrefetchNta)               \
   V(IA32Word32AtomicPairLoad)      \
diff --git a/src/compiler/backend/ia32/instruction-scheduler-ia32.cc b/src/compiler/backend/ia32/instruction-scheduler-ia32.cc
index 0b31131712..1df171e9e7 100644
--- a/src/compiler/backend/ia32/instruction-scheduler-ia32.cc
+++ b/src/compiler/backend/ia32/instruction-scheduler-ia32.cc
@@ -374,10 +374,10 @@ int InstructionScheduler::GetTargetInstructionFlags(
     case kSSES8x2Reverse:
     case kAVXS8x2Reverse:
     case kIA32S128AnyTrue:
-    case kIA32V64x2AllTrue:
-    case kIA32V32x4AllTrue:
-    case kIA32V16x8AllTrue:
-    case kIA32V8x16AllTrue:
+    case kIA32I64x2AllTrue:
+    case kIA32I32x4AllTrue:
+    case kIA32I16x8AllTrue:
+    case kIA32I8x16AllTrue:
       return (instr->addressing_mode() == kMode_None)
                  ? kNoOpcodeFlags
                  : kIsLoadOperation | kHasSideEffect;
diff --git a/src/compiler/backend/ia32/instruction-selector-ia32.cc b/src/compiler/backend/ia32/instruction-selector-ia32.cc
index 4bf436b708..e6d5431a96 100644
--- a/src/compiler/backend/ia32/instruction-selector-ia32.cc
+++ b/src/compiler/backend/ia32/instruction-selector-ia32.cc
@@ -2332,10 +2332,10 @@ void InstructionSelector::VisitWord32AtomicPairCompareExchange(Node* node) {
   V(S128Not)
 
 #define SIMD_ALLTRUE_LIST(V) \
-  V(V64x2AllTrue)            \
-  V(V32x4AllTrue)            \
-  V(V16x8AllTrue)            \
-  V(V8x16AllTrue)
+  V(I64x2AllTrue)            \
+  V(I32x4AllTrue)            \
+  V(I16x8AllTrue)            \
+  V(I8x16AllTrue)
 
 #define SIMD_SHIFT_OPCODES_UNIFED_SSE_AVX(V) \
   V(I64x2Shl)                                \
diff --git a/src/compiler/backend/instruction-selector.cc b/src/compiler/backend/instruction-selector.cc
index 8f58806e89..7d5094ec82 100644
--- a/src/compiler/backend/instruction-selector.cc
+++ b/src/compiler/backend/instruction-selector.cc
@@ -2297,14 +2297,14 @@ void InstructionSelector::VisitNode(Node* node) {
       return MarkAsSimd128(node), VisitI8x16Shuffle(node);
     case IrOpcode::kV128AnyTrue:
       return MarkAsWord32(node), VisitV128AnyTrue(node);
-    case IrOpcode::kV64x2AllTrue:
-      return MarkAsWord32(node), VisitV64x2AllTrue(node);
-    case IrOpcode::kV32x4AllTrue:
-      return MarkAsWord32(node), VisitV32x4AllTrue(node);
-    case IrOpcode::kV16x8AllTrue:
-      return MarkAsWord32(node), VisitV16x8AllTrue(node);
-    case IrOpcode::kV8x16AllTrue:
-      return MarkAsWord32(node), VisitV8x16AllTrue(node);
+    case IrOpcode::kI64x2AllTrue:
+      return MarkAsWord32(node), VisitI64x2AllTrue(node);
+    case IrOpcode::kI32x4AllTrue:
+      return MarkAsWord32(node), VisitI32x4AllTrue(node);
+    case IrOpcode::kI16x8AllTrue:
+      return MarkAsWord32(node), VisitI16x8AllTrue(node);
+    case IrOpcode::kI8x16AllTrue:
+      return MarkAsWord32(node), VisitI8x16AllTrue(node);
     default:
       FATAL("Unexpected operator #%d:%s @ node #%d", node->opcode(),
             node->op()->mnemonic(), node->id());
diff --git a/src/compiler/backend/mips/code-generator-mips.cc b/src/compiler/backend/mips/code-generator-mips.cc
index 0f8166e3b0..4be884b084 100644
--- a/src/compiler/backend/mips/code-generator-mips.cc
+++ b/src/compiler/backend/mips/code-generator-mips.cc
@@ -3177,7 +3177,7 @@ CodeGenerator::CodeGenResult CodeGenerator::AssembleArchInstruction(
       __ bind(&all_false);
       break;
     }
-    case kMipsV64x2AllTrue: {
+    case kMipsI64x2AllTrue: {
       CpuFeatureScope msa_scope(tasm(), MIPS_SIMD);
       Register dst = i.OutputRegister();
       Label all_true;
@@ -3188,7 +3188,7 @@ CodeGenerator::CodeGenResult CodeGenerator::AssembleArchInstruction(
       __ bind(&all_true);
       break;
     }
-    case kMipsV32x4AllTrue: {
+    case kMipsI32x4AllTrue: {
       CpuFeatureScope msa_scope(tasm(), MIPS_SIMD);
       Register dst = i.OutputRegister();
       Label all_true;
@@ -3199,7 +3199,7 @@ CodeGenerator::CodeGenResult CodeGenerator::AssembleArchInstruction(
       __ bind(&all_true);
       break;
     }
-    case kMipsV16x8AllTrue: {
+    case kMipsI16x8AllTrue: {
       CpuFeatureScope msa_scope(tasm(), MIPS_SIMD);
       Register dst = i.OutputRegister();
       Label all_true;
@@ -3210,7 +3210,7 @@ CodeGenerator::CodeGenResult CodeGenerator::AssembleArchInstruction(
       __ bind(&all_true);
       break;
     }
-    case kMipsV8x16AllTrue: {
+    case kMipsI8x16AllTrue: {
       CpuFeatureScope msa_scope(tasm(), MIPS_SIMD);
       Register dst = i.OutputRegister();
       Label all_true;
diff --git a/src/compiler/backend/mips/instruction-codes-mips.h b/src/compiler/backend/mips/instruction-codes-mips.h
index 9f9311bd66..40f1ef3e98 100644
--- a/src/compiler/backend/mips/instruction-codes-mips.h
+++ b/src/compiler/backend/mips/instruction-codes-mips.h
@@ -310,10 +310,10 @@ namespace compiler {
   V(MipsS128Not)                   \
   V(MipsS128Select)                \
   V(MipsS128AndNot)                \
-  V(MipsV64x2AllTrue)              \
-  V(MipsV32x4AllTrue)              \
-  V(MipsV16x8AllTrue)              \
-  V(MipsV8x16AllTrue)              \
+  V(MipsI64x2AllTrue)              \
+  V(MipsI32x4AllTrue)              \
+  V(MipsI16x8AllTrue)              \
+  V(MipsI8x16AllTrue)              \
   V(MipsV128AnyTrue)               \
   V(MipsS32x4InterleaveRight)      \
   V(MipsS32x4InterleaveLeft)       \
diff --git a/src/compiler/backend/mips/instruction-scheduler-mips.cc b/src/compiler/backend/mips/instruction-scheduler-mips.cc
index c6a5617d00..d246006cc8 100644
--- a/src/compiler/backend/mips/instruction-scheduler-mips.cc
+++ b/src/compiler/backend/mips/instruction-scheduler-mips.cc
@@ -284,10 +284,10 @@ int InstructionScheduler::GetTargetInstructionFlags(
     case kMipsS16x8InterleaveRight:
     case kMipsS16x8PackEven:
     case kMipsS16x8PackOdd:
-    case kMipsV64x2AllTrue:
-    case kMipsV32x4AllTrue:
-    case kMipsV16x8AllTrue:
-    case kMipsV8x16AllTrue:
+    case kMipsI64x2AllTrue:
+    case kMipsI32x4AllTrue:
+    case kMipsI16x8AllTrue:
+    case kMipsI8x16AllTrue:
     case kMipsV128AnyTrue:
     case kMipsS32x4InterleaveEven:
     case kMipsS32x4InterleaveLeft:
diff --git a/src/compiler/backend/mips/instruction-selector-mips.cc b/src/compiler/backend/mips/instruction-selector-mips.cc
index 749ba15863..6b877f49ef 100644
--- a/src/compiler/backend/mips/instruction-selector-mips.cc
+++ b/src/compiler/backend/mips/instruction-selector-mips.cc
@@ -2169,10 +2169,10 @@ void InstructionSelector::VisitInt64AbsWithOverflow(Node* node) {
   V(I8x16Popcnt, kMipsI8x16Popcnt)                             \
   V(I8x16BitMask, kMipsI8x16BitMask)                           \
   V(S128Not, kMipsS128Not)                                     \
-  V(V64x2AllTrue, kMipsV64x2AllTrue)                           \
-  V(V32x4AllTrue, kMipsV32x4AllTrue)                           \
-  V(V16x8AllTrue, kMipsV16x8AllTrue)                           \
-  V(V8x16AllTrue, kMipsV8x16AllTrue)                           \
+  V(I64x2AllTrue, kMipsI64x2AllTrue)                           \
+  V(I32x4AllTrue, kMipsI32x4AllTrue)                           \
+  V(I16x8AllTrue, kMipsI16x8AllTrue)                           \
+  V(I8x16AllTrue, kMipsI8x16AllTrue)                           \
   V(V128AnyTrue, kMipsV128AnyTrue)
 
 #define SIMD_SHIFT_OP_LIST(V) \
diff --git a/src/compiler/backend/mips64/code-generator-mips64.cc b/src/compiler/backend/mips64/code-generator-mips64.cc
index 47c05200d3..5491309596 100644
--- a/src/compiler/backend/mips64/code-generator-mips64.cc
+++ b/src/compiler/backend/mips64/code-generator-mips64.cc
@@ -3336,7 +3336,7 @@ CodeGenerator::CodeGenResult CodeGenerator::AssembleArchInstruction(
       __ bind(&all_false);
       break;
     }
-    case kMips64V64x2AllTrue: {
+    case kMips64I64x2AllTrue: {
       CpuFeatureScope msa_scope(tasm(), MIPS_SIMD);
       Register dst = i.OutputRegister();
       Label all_true;
@@ -3347,7 +3347,7 @@ CodeGenerator::CodeGenResult CodeGenerator::AssembleArchInstruction(
       __ bind(&all_true);
       break;
     }
-    case kMips64V32x4AllTrue: {
+    case kMips64I32x4AllTrue: {
       CpuFeatureScope msa_scope(tasm(), MIPS_SIMD);
       Register dst = i.OutputRegister();
       Label all_true;
@@ -3358,7 +3358,7 @@ CodeGenerator::CodeGenResult CodeGenerator::AssembleArchInstruction(
       __ bind(&all_true);
       break;
     }
-    case kMips64V16x8AllTrue: {
+    case kMips64I16x8AllTrue: {
       CpuFeatureScope msa_scope(tasm(), MIPS_SIMD);
       Register dst = i.OutputRegister();
       Label all_true;
@@ -3369,7 +3369,7 @@ CodeGenerator::CodeGenResult CodeGenerator::AssembleArchInstruction(
       __ bind(&all_true);
       break;
     }
-    case kMips64V8x16AllTrue: {
+    case kMips64I8x16AllTrue: {
       CpuFeatureScope msa_scope(tasm(), MIPS_SIMD);
       Register dst = i.OutputRegister();
       Label all_true;
diff --git a/src/compiler/backend/mips64/instruction-codes-mips64.h b/src/compiler/backend/mips64/instruction-codes-mips64.h
index a4a1410a92..e1b40a4be5 100644
--- a/src/compiler/backend/mips64/instruction-codes-mips64.h
+++ b/src/compiler/backend/mips64/instruction-codes-mips64.h
@@ -332,10 +332,10 @@ namespace compiler {
   V(Mips64S128Not)                           \
   V(Mips64S128Select)                        \
   V(Mips64S128AndNot)                        \
-  V(Mips64V64x2AllTrue)                      \
-  V(Mips64V32x4AllTrue)                      \
-  V(Mips64V16x8AllTrue)                      \
-  V(Mips64V8x16AllTrue)                      \
+  V(Mips64I64x2AllTrue)                      \
+  V(Mips64I32x4AllTrue)                      \
+  V(Mips64I16x8AllTrue)                      \
+  V(Mips64I8x16AllTrue)                      \
   V(Mips64V128AnyTrue)                       \
   V(Mips64S32x4InterleaveRight)              \
   V(Mips64S32x4InterleaveLeft)               \
diff --git a/src/compiler/backend/mips64/instruction-scheduler-mips64.cc b/src/compiler/backend/mips64/instruction-scheduler-mips64.cc
index f3cee21214..3b0e5b85fb 100644
--- a/src/compiler/backend/mips64/instruction-scheduler-mips64.cc
+++ b/src/compiler/backend/mips64/instruction-scheduler-mips64.cc
@@ -300,10 +300,10 @@ int InstructionScheduler::GetTargetInstructionFlags(
     case kMips64S16x8PackOdd:
     case kMips64S16x2Reverse:
     case kMips64S16x4Reverse:
-    case kMips64V64x2AllTrue:
-    case kMips64V32x4AllTrue:
-    case kMips64V16x8AllTrue:
-    case kMips64V8x16AllTrue:
+    case kMips64I64x2AllTrue:
+    case kMips64I32x4AllTrue:
+    case kMips64I16x8AllTrue:
+    case kMips64I8x16AllTrue:
     case kMips64V128AnyTrue:
     case kMips64S32x4InterleaveEven:
     case kMips64S32x4InterleaveOdd:
diff --git a/src/compiler/backend/mips64/instruction-selector-mips64.cc b/src/compiler/backend/mips64/instruction-selector-mips64.cc
index a787d0ab67..1aac69e765 100644
--- a/src/compiler/backend/mips64/instruction-selector-mips64.cc
+++ b/src/compiler/backend/mips64/instruction-selector-mips64.cc
@@ -2903,10 +2903,10 @@ void InstructionSelector::VisitInt64AbsWithOverflow(Node* node) {
   V(I8x16Popcnt, kMips64I8x16Popcnt)                         \
   V(I8x16BitMask, kMips64I8x16BitMask)                       \
   V(S128Not, kMips64S128Not)                                 \
-  V(V64x2AllTrue, kMips64V64x2AllTrue)                       \
-  V(V32x4AllTrue, kMips64V32x4AllTrue)                       \
-  V(V16x8AllTrue, kMips64V16x8AllTrue)                       \
-  V(V8x16AllTrue, kMips64V8x16AllTrue)                       \
+  V(I64x2AllTrue, kMips64I64x2AllTrue)                       \
+  V(I32x4AllTrue, kMips64I32x4AllTrue)                       \
+  V(I16x8AllTrue, kMips64I16x8AllTrue)                       \
+  V(I8x16AllTrue, kMips64I8x16AllTrue)                       \
   V(V128AnyTrue, kMips64V128AnyTrue)
 
 #define SIMD_SHIFT_OP_LIST(V) \
diff --git a/src/compiler/backend/ppc/code-generator-ppc.cc b/src/compiler/backend/ppc/code-generator-ppc.cc
index 92c39b352e..edb9dd77ac 100644
--- a/src/compiler/backend/ppc/code-generator-ppc.cc
+++ b/src/compiler/backend/ppc/code-generator-ppc.cc
@@ -3001,19 +3001,19 @@ CodeGenerator::CodeGenResult CodeGenerator::AssembleArchInstruction(
   __ mtcrf(0xFF, r0); /* Clear cr.*/                                   \
   __ opcode(kScratchSimd128Reg, src, kScratchSimd128Reg, SetRC);       \
   __ isel(dst, ip, r0, bit_number);
-    case kPPC_V64x2AllTrue: {
+    case kPPC_I64x2AllTrue: {
       SIMD_ALL_TRUE(vcmpgtud)
       break;
     }
-    case kPPC_V32x4AllTrue: {
+    case kPPC_I32x4AllTrue: {
       SIMD_ALL_TRUE(vcmpgtuw)
       break;
     }
-    case kPPC_V16x8AllTrue: {
+    case kPPC_I16x8AllTrue: {
       SIMD_ALL_TRUE(vcmpgtuh)
       break;
     }
-    case kPPC_V8x16AllTrue: {
+    case kPPC_I8x16AllTrue: {
       SIMD_ALL_TRUE(vcmpgtub)
       break;
     }
diff --git a/src/compiler/backend/ppc/instruction-codes-ppc.h b/src/compiler/backend/ppc/instruction-codes-ppc.h
index df0fadc492..8635852438 100644
--- a/src/compiler/backend/ppc/instruction-codes-ppc.h
+++ b/src/compiler/backend/ppc/instruction-codes-ppc.h
@@ -368,10 +368,10 @@ namespace compiler {
   V(PPC_I8x16Shuffle)                \
   V(PPC_I8x16Swizzle)                \
   V(PPC_I8x16BitMask)                \
-  V(PPC_V64x2AllTrue)                \
-  V(PPC_V32x4AllTrue)                \
-  V(PPC_V16x8AllTrue)                \
-  V(PPC_V8x16AllTrue)                \
+  V(PPC_I64x2AllTrue)                \
+  V(PPC_I32x4AllTrue)                \
+  V(PPC_I16x8AllTrue)                \
+  V(PPC_I8x16AllTrue)                \
   V(PPC_V128AnyTrue)                 \
   V(PPC_S128And)                     \
   V(PPC_S128Or)                      \
diff --git a/src/compiler/backend/ppc/instruction-scheduler-ppc.cc b/src/compiler/backend/ppc/instruction-scheduler-ppc.cc
index 6d26d992cb..c7f4748c26 100644
--- a/src/compiler/backend/ppc/instruction-scheduler-ppc.cc
+++ b/src/compiler/backend/ppc/instruction-scheduler-ppc.cc
@@ -291,10 +291,10 @@ int InstructionScheduler::GetTargetInstructionFlags(
     case kPPC_I8x16Shuffle:
     case kPPC_I8x16Swizzle:
     case kPPC_I8x16BitMask:
-    case kPPC_V64x2AllTrue:
-    case kPPC_V32x4AllTrue:
-    case kPPC_V16x8AllTrue:
-    case kPPC_V8x16AllTrue:
+    case kPPC_I64x2AllTrue:
+    case kPPC_I32x4AllTrue:
+    case kPPC_I16x8AllTrue:
+    case kPPC_I8x16AllTrue:
     case kPPC_V128AnyTrue:
     case kPPC_S128And:
     case kPPC_S128Or:
diff --git a/src/compiler/backend/ppc/instruction-selector-ppc.cc b/src/compiler/backend/ppc/instruction-selector-ppc.cc
index 72dae6bcfd..ccb658532e 100644
--- a/src/compiler/backend/ppc/instruction-selector-ppc.cc
+++ b/src/compiler/backend/ppc/instruction-selector-ppc.cc
@@ -2299,10 +2299,10 @@ void InstructionSelector::VisitInt64AbsWithOverflow(Node* node) {
 
 #define SIMD_BOOL_LIST(V) \
   V(V128AnyTrue)          \
-  V(V64x2AllTrue)         \
-  V(V32x4AllTrue)         \
-  V(V16x8AllTrue)         \
-  V(V8x16AllTrue)
+  V(I64x2AllTrue)         \
+  V(I32x4AllTrue)         \
+  V(I16x8AllTrue)         \
+  V(I8x16AllTrue)
 
 #define SIMD_VISIT_SPLAT(Type)                               \
   void InstructionSelector::Visit##Type##Splat(Node* node) { \
diff --git a/src/compiler/backend/riscv64/instruction-codes-riscv64.h b/src/compiler/backend/riscv64/instruction-codes-riscv64.h
index fae854ec02..6965104451 100644
--- a/src/compiler/backend/riscv64/instruction-codes-riscv64.h
+++ b/src/compiler/backend/riscv64/instruction-codes-riscv64.h
@@ -328,10 +328,10 @@ namespace compiler {
   V(RiscvS128Not)                           \
   V(RiscvS128Select)                        \
   V(RiscvS128AndNot)                        \
-  V(RiscvV32x4AllTrue)                      \
-  V(RiscvV16x8AllTrue)                      \
+  V(RiscvI32x4AllTrue)                      \
+  V(RiscvI16x8AllTrue)                      \
   V(RiscvV128AnyTrue)                       \
-  V(RiscvV8x16AllTrue)                      \
+  V(RiscvI8x16AllTrue)                      \
   V(RiscvS32x4InterleaveRight)              \
   V(RiscvS32x4InterleaveLeft)               \
   V(RiscvS32x4PackEven)                     \
diff --git a/src/compiler/backend/riscv64/instruction-scheduler-riscv64.cc b/src/compiler/backend/riscv64/instruction-scheduler-riscv64.cc
index fdc1346902..f77d7e8a21 100644
--- a/src/compiler/backend/riscv64/instruction-scheduler-riscv64.cc
+++ b/src/compiler/backend/riscv64/instruction-scheduler-riscv64.cc
@@ -295,9 +295,9 @@ int InstructionScheduler::GetTargetInstructionFlags(
     case kRiscvS16x8PackOdd:
     case kRiscvS16x2Reverse:
     case kRiscvS16x4Reverse:
-    case kRiscvV8x16AllTrue:
-    case kRiscvV32x4AllTrue:
-    case kRiscvV16x8AllTrue:
+    case kRiscvI8x16AllTrue:
+    case kRiscvI32x4AllTrue:
+    case kRiscvI16x8AllTrue:
     case kRiscvV128AnyTrue:
     case kRiscvS32x4InterleaveEven:
     case kRiscvS32x4InterleaveOdd:
diff --git a/src/compiler/backend/riscv64/instruction-selector-riscv64.cc b/src/compiler/backend/riscv64/instruction-selector-riscv64.cc
index 4d86fd02a3..15818b413b 100644
--- a/src/compiler/backend/riscv64/instruction-selector-riscv64.cc
+++ b/src/compiler/backend/riscv64/instruction-selector-riscv64.cc
@@ -2631,9 +2631,9 @@ void InstructionSelector::VisitInt64AbsWithOverflow(Node* node) {
   V(I8x16Popcnt, kRiscvI8x16Popcnt)                         \
   V(S128Not, kRiscvS128Not)                                 \
   V(V128AnyTrue, kRiscvV128AnyTrue)                         \
-  V(V32x4AllTrue, kRiscvV32x4AllTrue)                       \
-  V(V16x8AllTrue, kRiscvV16x8AllTrue)                       \
-  V(V8x16AllTrue, kRiscvV8x16AllTrue)
+  V(I32x4AllTrue, kRiscvI32x4AllTrue)                       \
+  V(I16x8AllTrue, kRiscvI16x8AllTrue)                       \
+  V(I8x16AllTrue, kRiscvI8x16AllTrue)
 
 #define SIMD_SHIFT_OP_LIST(V) \
   V(I64x2Shl)                 \
diff --git a/src/compiler/backend/s390/code-generator-s390.cc b/src/compiler/backend/s390/code-generator-s390.cc
index 202f1c4c49..36fb0ad8f0 100644
--- a/src/compiler/backend/s390/code-generator-s390.cc
+++ b/src/compiler/backend/s390/code-generator-s390.cc
@@ -3418,19 +3418,19 @@ CodeGenerator::CodeGenResult CodeGenerator::AssembleArchInstruction(
   __ vtm(kScratchDoubleReg, kScratchDoubleReg, Condition(0), Condition(0),     \
          Condition(0));                                                        \
   __ locgr(Condition(8), dst, temp);
-    case kS390_V64x2AllTrue: {
+    case kS390_I64x2AllTrue: {
       SIMD_ALL_TRUE(3)
       break;
     }
-    case kS390_V32x4AllTrue: {
+    case kS390_I32x4AllTrue: {
       SIMD_ALL_TRUE(2)
       break;
     }
-    case kS390_V16x8AllTrue: {
+    case kS390_I16x8AllTrue: {
       SIMD_ALL_TRUE(1)
       break;
     }
-    case kS390_V8x16AllTrue: {
+    case kS390_I8x16AllTrue: {
       SIMD_ALL_TRUE(0)
       break;
     }
diff --git a/src/compiler/backend/s390/instruction-codes-s390.h b/src/compiler/backend/s390/instruction-codes-s390.h
index 91696034f2..823160ed15 100644
--- a/src/compiler/backend/s390/instruction-codes-s390.h
+++ b/src/compiler/backend/s390/instruction-codes-s390.h
@@ -380,10 +380,10 @@ namespace compiler {
   V(S390_I8x16Shuffle)                      \
   V(S390_I8x16Swizzle)                      \
   V(S390_I8x16Popcnt)                       \
-  V(S390_V64x2AllTrue)                      \
-  V(S390_V32x4AllTrue)                      \
-  V(S390_V16x8AllTrue)                      \
-  V(S390_V8x16AllTrue)                      \
+  V(S390_I64x2AllTrue)                      \
+  V(S390_I32x4AllTrue)                      \
+  V(S390_I16x8AllTrue)                      \
+  V(S390_I8x16AllTrue)                      \
   V(S390_V128AnyTrue)                       \
   V(S390_S128And)                           \
   V(S390_S128Or)                            \
diff --git a/src/compiler/backend/s390/instruction-scheduler-s390.cc b/src/compiler/backend/s390/instruction-scheduler-s390.cc
index 937d144d6e..215afcb3a6 100644
--- a/src/compiler/backend/s390/instruction-scheduler-s390.cc
+++ b/src/compiler/backend/s390/instruction-scheduler-s390.cc
@@ -327,10 +327,10 @@ int InstructionScheduler::GetTargetInstructionFlags(
     case kS390_I8x16Shuffle:
     case kS390_I8x16Swizzle:
     case kS390_I8x16Popcnt:
-    case kS390_V64x2AllTrue:
-    case kS390_V32x4AllTrue:
-    case kS390_V16x8AllTrue:
-    case kS390_V8x16AllTrue:
+    case kS390_I64x2AllTrue:
+    case kS390_I32x4AllTrue:
+    case kS390_I16x8AllTrue:
+    case kS390_I8x16AllTrue:
     case kS390_V128AnyTrue:
     case kS390_S128And:
     case kS390_S128Or:
diff --git a/src/compiler/backend/s390/instruction-selector-s390.cc b/src/compiler/backend/s390/instruction-selector-s390.cc
index 143ba59f77..c170dbaca8 100644
--- a/src/compiler/backend/s390/instruction-selector-s390.cc
+++ b/src/compiler/backend/s390/instruction-selector-s390.cc
@@ -2562,10 +2562,10 @@ void InstructionSelector::VisitWord64AtomicStore(Node* node) {
 
 #define SIMD_BOOL_LIST(V) \
   V(V128AnyTrue)          \
-  V(V64x2AllTrue)         \
-  V(V32x4AllTrue)         \
-  V(V16x8AllTrue)         \
-  V(V8x16AllTrue)
+  V(I64x2AllTrue)         \
+  V(I32x4AllTrue)         \
+  V(I16x8AllTrue)         \
+  V(I8x16AllTrue)
 
 #define SIMD_CONVERSION_LIST(V) \
   V(I32x4SConvertF32x4)         \
diff --git a/src/compiler/backend/x64/code-generator-x64.cc b/src/compiler/backend/x64/code-generator-x64.cc
index 09c3a2f97b..61ab3a08e7 100644
--- a/src/compiler/backend/x64/code-generator-x64.cc
+++ b/src/compiler/backend/x64/code-generator-x64.cc
@@ -4057,19 +4057,19 @@ CodeGenerator::CodeGenResult CodeGenerator::AssembleArchInstruction(
     // comparison instruction used matters, e.g. given 0xff00, pcmpeqb returns
     // 0x0011, pcmpeqw returns 0x0000, ptest will set ZF to 0 and 1
     // respectively.
-    case kX64V64x2AllTrue: {
+    case kX64I64x2AllTrue: {
       ASSEMBLE_SIMD_ALL_TRUE(Pcmpeqq);
       break;
     }
-    case kX64V32x4AllTrue: {
+    case kX64I32x4AllTrue: {
       ASSEMBLE_SIMD_ALL_TRUE(Pcmpeqd);
       break;
     }
-    case kX64V16x8AllTrue: {
+    case kX64I16x8AllTrue: {
       ASSEMBLE_SIMD_ALL_TRUE(Pcmpeqw);
       break;
     }
-    case kX64V8x16AllTrue: {
+    case kX64I8x16AllTrue: {
       ASSEMBLE_SIMD_ALL_TRUE(Pcmpeqb);
       break;
     }
diff --git a/src/compiler/backend/x64/instruction-codes-x64.h b/src/compiler/backend/x64/instruction-codes-x64.h
index 074d4b8e45..ccd9a82575 100644
--- a/src/compiler/backend/x64/instruction-codes-x64.h
+++ b/src/compiler/backend/x64/instruction-codes-x64.h
@@ -386,10 +386,10 @@ namespace compiler {
   V(X64S8x4Reverse)                       \
   V(X64S8x2Reverse)                       \
   V(X64V128AnyTrue)                       \
-  V(X64V64x2AllTrue)                      \
-  V(X64V32x4AllTrue)                      \
-  V(X64V16x8AllTrue)                      \
-  V(X64V8x16AllTrue)                      \
+  V(X64I64x2AllTrue)                      \
+  V(X64I32x4AllTrue)                      \
+  V(X64I16x8AllTrue)                      \
+  V(X64I8x16AllTrue)                      \
   V(X64Prefetch)                          \
   V(X64PrefetchNta)                       \
   V(X64Word64AtomicAddUint8)              \
diff --git a/src/compiler/backend/x64/instruction-scheduler-x64.cc b/src/compiler/backend/x64/instruction-scheduler-x64.cc
index b4f1b9b59a..30b8a549b5 100644
--- a/src/compiler/backend/x64/instruction-scheduler-x64.cc
+++ b/src/compiler/backend/x64/instruction-scheduler-x64.cc
@@ -313,9 +313,9 @@ int InstructionScheduler::GetTargetInstructionFlags(
     case kX64S128Zero:
     case kX64S128AllOnes:
     case kX64S128AndNot:
-    case kX64V64x2AllTrue:
-    case kX64V32x4AllTrue:
-    case kX64V16x8AllTrue:
+    case kX64I64x2AllTrue:
+    case kX64I32x4AllTrue:
+    case kX64I16x8AllTrue:
     case kX64I8x16Swizzle:
     case kX64I8x16Shuffle:
     case kX64I8x16Popcnt:
@@ -347,7 +347,7 @@ int InstructionScheduler::GetTargetInstructionFlags(
     case kX64S8x4Reverse:
     case kX64S8x2Reverse:
     case kX64V128AnyTrue:
-    case kX64V8x16AllTrue:
+    case kX64I8x16AllTrue:
       return (instr->addressing_mode() == kMode_None)
                  ? kNoOpcodeFlags
                  : kIsLoadOperation | kHasSideEffect;
diff --git a/src/compiler/backend/x64/instruction-selector-x64.cc b/src/compiler/backend/x64/instruction-selector-x64.cc
index 7589c5a1dc..537cb816d3 100644
--- a/src/compiler/backend/x64/instruction-selector-x64.cc
+++ b/src/compiler/backend/x64/instruction-selector-x64.cc
@@ -2959,10 +2959,10 @@ VISIT_ATOMIC_BINOP(Xor)
   V(I8x16Neg)               \
   V(I8x16Abs)               \
   V(I8x16BitMask)           \
-  V(V64x2AllTrue)           \
-  V(V32x4AllTrue)           \
-  V(V16x8AllTrue)           \
-  V(V8x16AllTrue)           \
+  V(I64x2AllTrue)           \
+  V(I32x4AllTrue)           \
+  V(I16x8AllTrue)           \
+  V(I8x16AllTrue)           \
   V(S128Not)
 
 #define SIMD_SHIFT_OPCODES(V) \
diff --git a/src/compiler/machine-operator.cc b/src/compiler/machine-operator.cc
index 2c5a0c23f1..d56a03c6be 100644
--- a/src/compiler/machine-operator.cc
+++ b/src/compiler/machine-operator.cc
@@ -556,10 +556,10 @@ std::ostream& operator<<(std::ostream& os, TruncateKind kind) {
   V(S128Select, Operator::kNoProperties, 3, 0, 1)                          \
   V(S128AndNot, Operator::kNoProperties, 2, 0, 1)                          \
   V(V128AnyTrue, Operator::kNoProperties, 1, 0, 1)                         \
-  V(V64x2AllTrue, Operator::kNoProperties, 1, 0, 1)                        \
-  V(V32x4AllTrue, Operator::kNoProperties, 1, 0, 1)                        \
-  V(V16x8AllTrue, Operator::kNoProperties, 1, 0, 1)                        \
-  V(V8x16AllTrue, Operator::kNoProperties, 1, 0, 1)                        \
+  V(I64x2AllTrue, Operator::kNoProperties, 1, 0, 1)                        \
+  V(I32x4AllTrue, Operator::kNoProperties, 1, 0, 1)                        \
+  V(I16x8AllTrue, Operator::kNoProperties, 1, 0, 1)                        \
+  V(I8x16AllTrue, Operator::kNoProperties, 1, 0, 1)                        \
   V(I8x16Swizzle, Operator::kNoProperties, 2, 0, 1)
 
 // The format is:
diff --git a/src/compiler/machine-operator.h b/src/compiler/machine-operator.h
index b8ad67c9a0..906ded120a 100644
--- a/src/compiler/machine-operator.h
+++ b/src/compiler/machine-operator.h
@@ -818,10 +818,10 @@ class V8_EXPORT_PRIVATE MachineOperatorBuilder final
   const Operator* I8x16Shuffle(const uint8_t shuffle[16]);
 
   const Operator* V128AnyTrue();
-  const Operator* V64x2AllTrue();
-  const Operator* V32x4AllTrue();
-  const Operator* V16x8AllTrue();
-  const Operator* V8x16AllTrue();
+  const Operator* I64x2AllTrue();
+  const Operator* I32x4AllTrue();
+  const Operator* I16x8AllTrue();
+  const Operator* I8x16AllTrue();
 
   // load [base + index]
   const Operator* Load(LoadRepresentation rep);
diff --git a/src/compiler/opcodes.h b/src/compiler/opcodes.h
index 0fe0a935e6..a603c5c583 100644
--- a/src/compiler/opcodes.h
+++ b/src/compiler/opcodes.h
@@ -976,10 +976,10 @@
   V(I8x16Swizzle)               \
   V(I8x16Shuffle)               \
   V(V128AnyTrue)                \
-  V(V64x2AllTrue)               \
-  V(V32x4AllTrue)               \
-  V(V16x8AllTrue)               \
-  V(V8x16AllTrue)               \
+  V(I64x2AllTrue)               \
+  V(I32x4AllTrue)               \
+  V(I16x8AllTrue)               \
+  V(I8x16AllTrue)               \
   V(LoadTransform)              \
   V(PrefetchTemporal)           \
   V(PrefetchNonTemporal)        \
diff --git a/src/compiler/simd-scalar-lowering.cc b/src/compiler/simd-scalar-lowering.cc
index 3537efb616..a79809e7d7 100644
--- a/src/compiler/simd-scalar-lowering.cc
+++ b/src/compiler/simd-scalar-lowering.cc
@@ -169,11 +169,11 @@ void SimdScalarLowering::LowerGraph() {
   V(S128Not)                      \
   V(S128AndNot)                   \
   V(S128Select)                   \
-  V(V64x2AllTrue)                 \
-  V(V32x4AllTrue)                 \
-  V(V16x8AllTrue)                 \
+  V(I64x2AllTrue)                 \
+  V(I32x4AllTrue)                 \
+  V(I16x8AllTrue)                 \
   V(V128AnyTrue)                  \
-  V(V8x16AllTrue)                 \
+  V(I8x16AllTrue)                 \
   V(I32x4BitMask)                 \
   V(I32x4ExtMulLowI16x8S)         \
   V(I32x4ExtMulLowI16x8U)         \
@@ -2266,19 +2266,19 @@ void SimdScalarLowering::LowerNode(Node* node) {
       ReplaceNode(node, rep_node, 1);
       break;
     }
-    case IrOpcode::kV64x2AllTrue: {
+    case IrOpcode::kI64x2AllTrue: {
       LowerAllTrueOp(node, SimdType::kInt64x2);
       break;
     }
-    case IrOpcode::kV32x4AllTrue: {
+    case IrOpcode::kI32x4AllTrue: {
       LowerAllTrueOp(node, SimdType::kInt32x4);
       break;
     }
-    case IrOpcode::kV16x8AllTrue: {
+    case IrOpcode::kI16x8AllTrue: {
       LowerAllTrueOp(node, SimdType::kInt16x8);
       break;
     }
-    case IrOpcode::kV8x16AllTrue: {
+    case IrOpcode::kI8x16AllTrue: {
       LowerAllTrueOp(node, SimdType::kInt8x16);
       break;
     }
diff --git a/src/compiler/wasm-compiler.cc b/src/compiler/wasm-compiler.cc
index 2d960a2dee..1ef6e56adf 100644
--- a/src/compiler/wasm-compiler.cc
+++ b/src/compiler/wasm-compiler.cc
@@ -5112,16 +5112,16 @@ Node* WasmGraphBuilder::SimdOp(wasm::WasmOpcode opcode, Node* const* inputs) {
     case wasm::kExprS128AndNot:
       return graph()->NewNode(mcgraph()->machine()->S128AndNot(), inputs[0],
                               inputs[1]);
-    case wasm::kExprV64x2AllTrue:
-      return graph()->NewNode(mcgraph()->machine()->V64x2AllTrue(), inputs[0]);
-    case wasm::kExprV32x4AllTrue:
-      return graph()->NewNode(mcgraph()->machine()->V32x4AllTrue(), inputs[0]);
-    case wasm::kExprV16x8AllTrue:
-      return graph()->NewNode(mcgraph()->machine()->V16x8AllTrue(), inputs[0]);
+    case wasm::kExprI64x2AllTrue:
+      return graph()->NewNode(mcgraph()->machine()->I64x2AllTrue(), inputs[0]);
+    case wasm::kExprI32x4AllTrue:
+      return graph()->NewNode(mcgraph()->machine()->I32x4AllTrue(), inputs[0]);
+    case wasm::kExprI16x8AllTrue:
+      return graph()->NewNode(mcgraph()->machine()->I16x8AllTrue(), inputs[0]);
     case wasm::kExprV128AnyTrue:
       return graph()->NewNode(mcgraph()->machine()->V128AnyTrue(), inputs[0]);
-    case wasm::kExprV8x16AllTrue:
-      return graph()->NewNode(mcgraph()->machine()->V8x16AllTrue(), inputs[0]);
+    case wasm::kExprI8x16AllTrue:
+      return graph()->NewNode(mcgraph()->machine()->I8x16AllTrue(), inputs[0]);
     case wasm::kExprI8x16Swizzle:
       return graph()->NewNode(mcgraph()->machine()->I8x16Swizzle(), inputs[0],
                               inputs[1]);
diff --git a/src/wasm/baseline/arm/liftoff-assembler-arm.h b/src/wasm/baseline/arm/liftoff-assembler-arm.h
index 12b70a2fe4..36210385b1 100644
--- a/src/wasm/baseline/arm/liftoff-assembler-arm.h
+++ b/src/wasm/baseline/arm/liftoff-assembler-arm.h
@@ -2834,9 +2834,9 @@ void LiftoffAssembler::emit_i64x2_neg(LiftoffRegister dst,
        liftoff::GetSimd128Register(src));
 }
 
-void LiftoffAssembler::emit_v64x2_alltrue(LiftoffRegister dst,
+void LiftoffAssembler::emit_i64x2_alltrue(LiftoffRegister dst,
                                           LiftoffRegister src) {
-  V64x2AllTrue(dst.gp(), liftoff::GetSimd128Register(src));
+  I64x2AllTrue(dst.gp(), liftoff::GetSimd128Register(src));
 }
 
 void LiftoffAssembler::emit_i64x2_shl(LiftoffRegister dst, LiftoffRegister lhs,
@@ -3012,7 +3012,7 @@ void LiftoffAssembler::emit_i32x4_neg(LiftoffRegister dst,
        liftoff::GetSimd128Register(src));
 }
 
-void LiftoffAssembler::emit_v32x4_alltrue(LiftoffRegister dst,
+void LiftoffAssembler::emit_i32x4_alltrue(LiftoffRegister dst,
                                           LiftoffRegister src) {
   UseScratchRegisterScope temps(this);
   DwVfpRegister scratch = temps.AcquireD();
@@ -3196,7 +3196,7 @@ void LiftoffAssembler::emit_i16x8_neg(LiftoffRegister dst,
        liftoff::GetSimd128Register(src));
 }
 
-void LiftoffAssembler::emit_v16x8_alltrue(LiftoffRegister dst,
+void LiftoffAssembler::emit_i16x8_alltrue(LiftoffRegister dst,
                                           LiftoffRegister src) {
   UseScratchRegisterScope temps(this);
   DwVfpRegister scratch = temps.AcquireD();
@@ -3505,7 +3505,7 @@ void LiftoffAssembler::emit_v128_anytrue(LiftoffRegister dst,
   liftoff::EmitAnyTrue(this, dst, src);
 }
 
-void LiftoffAssembler::emit_v8x16_alltrue(LiftoffRegister dst,
+void LiftoffAssembler::emit_i8x16_alltrue(LiftoffRegister dst,
                                           LiftoffRegister src) {
   UseScratchRegisterScope temps(this);
   DwVfpRegister scratch = temps.AcquireD();
diff --git a/src/wasm/baseline/arm64/liftoff-assembler-arm64.h b/src/wasm/baseline/arm64/liftoff-assembler-arm64.h
index 0c9f6f7d8d..1d7b51a1df 100644
--- a/src/wasm/baseline/arm64/liftoff-assembler-arm64.h
+++ b/src/wasm/baseline/arm64/liftoff-assembler-arm64.h
@@ -2014,9 +2014,9 @@ void LiftoffAssembler::emit_i64x2_neg(LiftoffRegister dst,
   Neg(dst.fp().V2D(), src.fp().V2D());
 }
 
-void LiftoffAssembler::emit_v64x2_alltrue(LiftoffRegister dst,
+void LiftoffAssembler::emit_i64x2_alltrue(LiftoffRegister dst,
                                           LiftoffRegister src) {
-  V64x2AllTrue(dst.gp(), src.fp());
+  I64x2AllTrue(dst.gp(), src.fp());
 }
 
 void LiftoffAssembler::emit_i64x2_shl(LiftoffRegister dst, LiftoffRegister lhs,
@@ -2165,7 +2165,7 @@ void LiftoffAssembler::emit_i32x4_neg(LiftoffRegister dst,
   Neg(dst.fp().V4S(), src.fp().V4S());
 }
 
-void LiftoffAssembler::emit_v32x4_alltrue(LiftoffRegister dst,
+void LiftoffAssembler::emit_i32x4_alltrue(LiftoffRegister dst,
                                           LiftoffRegister src) {
   liftoff::EmitAllTrue(this, dst, src, kFormat4S);
 }
@@ -2341,7 +2341,7 @@ void LiftoffAssembler::emit_i16x8_neg(LiftoffRegister dst,
   Neg(dst.fp().V8H(), src.fp().V8H());
 }
 
-void LiftoffAssembler::emit_v16x8_alltrue(LiftoffRegister dst,
+void LiftoffAssembler::emit_i16x8_alltrue(LiftoffRegister dst,
                                           LiftoffRegister src) {
   liftoff::EmitAllTrue(this, dst, src, kFormat8H);
 }
@@ -2547,7 +2547,7 @@ void LiftoffAssembler::emit_v128_anytrue(LiftoffRegister dst,
   liftoff::EmitAnyTrue(this, dst, src);
 }
 
-void LiftoffAssembler::emit_v8x16_alltrue(LiftoffRegister dst,
+void LiftoffAssembler::emit_i8x16_alltrue(LiftoffRegister dst,
                                           LiftoffRegister src) {
   liftoff::EmitAllTrue(this, dst, src, kFormat16B);
 }
diff --git a/src/wasm/baseline/ia32/liftoff-assembler-ia32.h b/src/wasm/baseline/ia32/liftoff-assembler-ia32.h
index c707c627ab..ce4d86f312 100644
--- a/src/wasm/baseline/ia32/liftoff-assembler-ia32.h
+++ b/src/wasm/baseline/ia32/liftoff-assembler-ia32.h
@@ -3317,7 +3317,7 @@ void LiftoffAssembler::emit_v128_anytrue(LiftoffRegister dst,
   liftoff::EmitAnyTrue(this, dst, src);
 }
 
-void LiftoffAssembler::emit_v8x16_alltrue(LiftoffRegister dst,
+void LiftoffAssembler::emit_i8x16_alltrue(LiftoffRegister dst,
                                           LiftoffRegister src) {
   liftoff::EmitAllTrue<&TurboAssembler::Pcmpeqb>(this, dst, src);
 }
@@ -3494,7 +3494,7 @@ void LiftoffAssembler::emit_i16x8_neg(LiftoffRegister dst,
   }
 }
 
-void LiftoffAssembler::emit_v16x8_alltrue(LiftoffRegister dst,
+void LiftoffAssembler::emit_i16x8_alltrue(LiftoffRegister dst,
                                           LiftoffRegister src) {
   liftoff::EmitAllTrue<&TurboAssembler::Pcmpeqw>(this, dst, src);
 }
@@ -3677,7 +3677,7 @@ void LiftoffAssembler::emit_i32x4_neg(LiftoffRegister dst,
   }
 }
 
-void LiftoffAssembler::emit_v32x4_alltrue(LiftoffRegister dst,
+void LiftoffAssembler::emit_i32x4_alltrue(LiftoffRegister dst,
                                           LiftoffRegister src) {
   liftoff::EmitAllTrue<&TurboAssembler::Pcmpeqd>(this, dst, src);
 }
@@ -3858,7 +3858,7 @@ void LiftoffAssembler::emit_i64x2_neg(LiftoffRegister dst,
   }
 }
 
-void LiftoffAssembler::emit_v64x2_alltrue(LiftoffRegister dst,
+void LiftoffAssembler::emit_i64x2_alltrue(LiftoffRegister dst,
                                           LiftoffRegister src) {
   liftoff::EmitAllTrue<&TurboAssembler::Pcmpeqq>(this, dst, src, SSE4_1);
 }
diff --git a/src/wasm/baseline/liftoff-assembler.h b/src/wasm/baseline/liftoff-assembler.h
index c10762abf1..a9b383dfc8 100644
--- a/src/wasm/baseline/liftoff-assembler.h
+++ b/src/wasm/baseline/liftoff-assembler.h
@@ -1044,7 +1044,7 @@ class LiftoffAssembler : public TurboAssembler {
                                LiftoffRegister src2, LiftoffRegister mask);
   inline void emit_i8x16_neg(LiftoffRegister dst, LiftoffRegister src);
   inline void emit_v128_anytrue(LiftoffRegister dst, LiftoffRegister src);
-  inline void emit_v8x16_alltrue(LiftoffRegister dst, LiftoffRegister src);
+  inline void emit_i8x16_alltrue(LiftoffRegister dst, LiftoffRegister src);
   inline void emit_i8x16_bitmask(LiftoffRegister dst, LiftoffRegister src);
   inline void emit_i8x16_shl(LiftoffRegister dst, LiftoffRegister lhs,
                              LiftoffRegister rhs);
@@ -1079,7 +1079,7 @@ class LiftoffAssembler : public TurboAssembler {
   inline void emit_i8x16_max_u(LiftoffRegister dst, LiftoffRegister lhs,
                                LiftoffRegister rhs);
   inline void emit_i16x8_neg(LiftoffRegister dst, LiftoffRegister src);
-  inline void emit_v16x8_alltrue(LiftoffRegister dst, LiftoffRegister src);
+  inline void emit_i16x8_alltrue(LiftoffRegister dst, LiftoffRegister src);
   inline void emit_i16x8_bitmask(LiftoffRegister dst, LiftoffRegister src);
   inline void emit_i16x8_shl(LiftoffRegister dst, LiftoffRegister lhs,
                              LiftoffRegister rhs);
@@ -1135,7 +1135,7 @@ class LiftoffAssembler : public TurboAssembler {
                                        LiftoffRegister src1,
                                        LiftoffRegister src2);
   inline void emit_i32x4_neg(LiftoffRegister dst, LiftoffRegister src);
-  inline void emit_v32x4_alltrue(LiftoffRegister dst, LiftoffRegister src);
+  inline void emit_i32x4_alltrue(LiftoffRegister dst, LiftoffRegister src);
   inline void emit_i32x4_bitmask(LiftoffRegister dst, LiftoffRegister src);
   inline void emit_i32x4_shl(LiftoffRegister dst, LiftoffRegister lhs,
                              LiftoffRegister rhs);
@@ -1182,7 +1182,7 @@ class LiftoffAssembler : public TurboAssembler {
                                              LiftoffRegister src1,
                                              LiftoffRegister src2);
   inline void emit_i64x2_neg(LiftoffRegister dst, LiftoffRegister src);
-  inline void emit_v64x2_alltrue(LiftoffRegister dst, LiftoffRegister src);
+  inline void emit_i64x2_alltrue(LiftoffRegister dst, LiftoffRegister src);
   inline void emit_i64x2_shl(LiftoffRegister dst, LiftoffRegister lhs,
                              LiftoffRegister rhs);
   inline void emit_i64x2_shli(LiftoffRegister dst, LiftoffRegister lhs,
diff --git a/src/wasm/baseline/liftoff-compiler.cc b/src/wasm/baseline/liftoff-compiler.cc
index 648456004e..68ae1e5a83 100644
--- a/src/wasm/baseline/liftoff-compiler.cc
+++ b/src/wasm/baseline/liftoff-compiler.cc
@@ -3223,8 +3223,8 @@ class LiftoffCompiler {
         return EmitUnOp<kS128, kS128>(&LiftoffAssembler::emit_i8x16_neg);
       case wasm::kExprV128AnyTrue:
         return EmitUnOp<kS128, kI32>(&LiftoffAssembler::emit_v128_anytrue);
-      case wasm::kExprV8x16AllTrue:
-        return EmitUnOp<kS128, kI32>(&LiftoffAssembler::emit_v8x16_alltrue);
+      case wasm::kExprI8x16AllTrue:
+        return EmitUnOp<kS128, kI32>(&LiftoffAssembler::emit_i8x16_alltrue);
       case wasm::kExprI8x16BitMask:
         return EmitUnOp<kS128, kI32>(&LiftoffAssembler::emit_i8x16_bitmask);
       case wasm::kExprI8x16Shl:
@@ -3258,8 +3258,8 @@ class LiftoffCompiler {
         return EmitBinOp<kS128, kS128>(&LiftoffAssembler::emit_i8x16_max_u);
       case wasm::kExprI16x8Neg:
         return EmitUnOp<kS128, kS128>(&LiftoffAssembler::emit_i16x8_neg);
-      case wasm::kExprV16x8AllTrue:
-        return EmitUnOp<kS128, kI32>(&LiftoffAssembler::emit_v16x8_alltrue);
+      case wasm::kExprI16x8AllTrue:
+        return EmitUnOp<kS128, kI32>(&LiftoffAssembler::emit_i16x8_alltrue);
       case wasm::kExprI16x8BitMask:
         return EmitUnOp<kS128, kI32>(&LiftoffAssembler::emit_i16x8_bitmask);
       case wasm::kExprI16x8Shl:
@@ -3316,8 +3316,8 @@ class LiftoffCompiler {
             &LiftoffAssembler::emit_i16x8_q15mulr_sat_s);
       case wasm::kExprI32x4Neg:
         return EmitUnOp<kS128, kS128>(&LiftoffAssembler::emit_i32x4_neg);
-      case wasm::kExprV32x4AllTrue:
-        return EmitUnOp<kS128, kI32>(&LiftoffAssembler::emit_v32x4_alltrue);
+      case wasm::kExprI32x4AllTrue:
+        return EmitUnOp<kS128, kI32>(&LiftoffAssembler::emit_i32x4_alltrue);
       case wasm::kExprI32x4BitMask:
         return EmitUnOp<kS128, kI32>(&LiftoffAssembler::emit_i32x4_bitmask);
       case wasm::kExprI32x4Shl:
@@ -3366,8 +3366,8 @@ class LiftoffCompiler {
             &LiftoffAssembler::emit_i32x4_extmul_high_i16x8_u);
       case wasm::kExprI64x2Neg:
         return EmitUnOp<kS128, kS128>(&LiftoffAssembler::emit_i64x2_neg);
-      case wasm::kExprV64x2AllTrue:
-        return EmitUnOp<kS128, kI32>(&LiftoffAssembler::emit_v64x2_alltrue);
+      case wasm::kExprI64x2AllTrue:
+        return EmitUnOp<kS128, kI32>(&LiftoffAssembler::emit_i64x2_alltrue);
       case wasm::kExprI64x2Shl:
         return EmitSimdShiftOp(&LiftoffAssembler::emit_i64x2_shl,
                                &LiftoffAssembler::emit_i64x2_shli);
diff --git a/src/wasm/baseline/mips/liftoff-assembler-mips.h b/src/wasm/baseline/mips/liftoff-assembler-mips.h
index 4d5b76868b..03d8118745 100644
--- a/src/wasm/baseline/mips/liftoff-assembler-mips.h
+++ b/src/wasm/baseline/mips/liftoff-assembler-mips.h
@@ -2018,9 +2018,9 @@ void LiftoffAssembler::emit_v128_anytrue(LiftoffRegister dst,
   bailout(kSimd, "emit_v128_anytrue");
 }
 
-void LiftoffAssembler::emit_v8x16_alltrue(LiftoffRegister dst,
+void LiftoffAssembler::emit_i8x16_alltrue(LiftoffRegister dst,
                                           LiftoffRegister src) {
-  bailout(kSimd, "emit_v8x16_alltrue");
+  bailout(kSimd, "emit_i8x16_alltrue");
 }
 
 void LiftoffAssembler::emit_i8x16_bitmask(LiftoffRegister dst,
@@ -2128,9 +2128,9 @@ void LiftoffAssembler::emit_i16x8_neg(LiftoffRegister dst,
   bailout(kSimd, "emit_i16x8_neg");
 }
 
-void LiftoffAssembler::emit_v16x8_alltrue(LiftoffRegister dst,
+void LiftoffAssembler::emit_i16x8_alltrue(LiftoffRegister dst,
                                           LiftoffRegister src) {
-  bailout(kSimd, "emit_v16x8_alltrue");
+  bailout(kSimd, "emit_i16x8_alltrue");
 }
 
 void LiftoffAssembler::emit_i16x8_bitmask(LiftoffRegister dst,
@@ -2248,9 +2248,9 @@ void LiftoffAssembler::emit_i32x4_neg(LiftoffRegister dst,
   bailout(kSimd, "emit_i32x4_neg");
 }
 
-void LiftoffAssembler::emit_v32x4_alltrue(LiftoffRegister dst,
+void LiftoffAssembler::emit_i32x4_alltrue(LiftoffRegister dst,
                                           LiftoffRegister src) {
-  bailout(kSimd, "emit_v32x4_alltrue");
+  bailout(kSimd, "emit_i32x4_alltrue");
 }
 
 void LiftoffAssembler::emit_i32x4_bitmask(LiftoffRegister dst,
@@ -2350,9 +2350,9 @@ void LiftoffAssembler::emit_i64x2_neg(LiftoffRegister dst,
   bailout(kSimd, "emit_i64x2_neg");
 }
 
-void LiftoffAssembler::emit_v64x2_alltrue(LiftoffRegister dst,
+void LiftoffAssembler::emit_i64x2_alltrue(LiftoffRegister dst,
                                           LiftoffRegister src) {
-  bailout(kSimd, "emit_v64x2_alltrue");
+  bailout(kSimd, "emit_i64x2_alltrue");
 }
 
 void LiftoffAssembler::emit_i64x2_bitmask(LiftoffRegister dst,
diff --git a/src/wasm/baseline/mips64/liftoff-assembler-mips64.h b/src/wasm/baseline/mips64/liftoff-assembler-mips64.h
index 836df491cc..8bf5b0ea17 100644
--- a/src/wasm/baseline/mips64/liftoff-assembler-mips64.h
+++ b/src/wasm/baseline/mips64/liftoff-assembler-mips64.h
@@ -1983,7 +1983,7 @@ void LiftoffAssembler::emit_v128_anytrue(LiftoffRegister dst,
   liftoff::EmitAnyTrue(this, dst, src);
 }
 
-void LiftoffAssembler::emit_v8x16_alltrue(LiftoffRegister dst,
+void LiftoffAssembler::emit_i8x16_alltrue(LiftoffRegister dst,
                                           LiftoffRegister src) {
   liftoff::EmitAllTrue(this, dst, src, MSA_BRANCH_B);
 }
@@ -2108,7 +2108,7 @@ void LiftoffAssembler::emit_i16x8_neg(LiftoffRegister dst,
   subv_h(dst.fp().toW(), kSimd128RegZero, src.fp().toW());
 }
 
-void LiftoffAssembler::emit_v16x8_alltrue(LiftoffRegister dst,
+void LiftoffAssembler::emit_i16x8_alltrue(LiftoffRegister dst,
                                           LiftoffRegister src) {
   liftoff::EmitAllTrue(this, dst, src, MSA_BRANCH_H);
 }
@@ -2232,7 +2232,7 @@ void LiftoffAssembler::emit_i32x4_neg(LiftoffRegister dst,
   subv_w(dst.fp().toW(), kSimd128RegZero, src.fp().toW());
 }
 
-void LiftoffAssembler::emit_v32x4_alltrue(LiftoffRegister dst,
+void LiftoffAssembler::emit_i32x4_alltrue(LiftoffRegister dst,
                                           LiftoffRegister src) {
   liftoff::EmitAllTrue(this, dst, src, MSA_BRANCH_W);
 }
@@ -2336,7 +2336,7 @@ void LiftoffAssembler::emit_i64x2_neg(LiftoffRegister dst,
   subv_d(dst.fp().toW(), kSimd128RegZero, src.fp().toW());
 }
 
-void LiftoffAssembler::emit_v64x2_alltrue(LiftoffRegister dst,
+void LiftoffAssembler::emit_i64x2_alltrue(LiftoffRegister dst,
                                           LiftoffRegister src) {
   liftoff::EmitAllTrue(this, dst, src, MSA_BRANCH_D);
 }
diff --git a/src/wasm/baseline/ppc/liftoff-assembler-ppc.h b/src/wasm/baseline/ppc/liftoff-assembler-ppc.h
index 4e778043b6..3d3207a92e 100644
--- a/src/wasm/baseline/ppc/liftoff-assembler-ppc.h
+++ b/src/wasm/baseline/ppc/liftoff-assembler-ppc.h
@@ -843,9 +843,9 @@ void LiftoffAssembler::emit_i64x2_neg(LiftoffRegister dst,
   bailout(kUnsupportedArchitecture, "emit_i64x2neg");
 }
 
-void LiftoffAssembler::emit_v64x2_alltrue(LiftoffRegister dst,
+void LiftoffAssembler::emit_i64x2_alltrue(LiftoffRegister dst,
                                           LiftoffRegister src) {
-  bailout(kSimd, "v64x2_alltrue");
+  bailout(kSimd, "i64x2_alltrue");
 }
 
 void LiftoffAssembler::emit_i64x2_shl(LiftoffRegister dst, LiftoffRegister lhs,
@@ -967,9 +967,9 @@ void LiftoffAssembler::emit_i32x4_neg(LiftoffRegister dst,
   bailout(kUnsupportedArchitecture, "emit_i32x4neg");
 }
 
-void LiftoffAssembler::emit_v32x4_alltrue(LiftoffRegister dst,
+void LiftoffAssembler::emit_i32x4_alltrue(LiftoffRegister dst,
                                           LiftoffRegister src) {
-  bailout(kSimd, "v32x4_alltrue");
+  bailout(kSimd, "i32x4_alltrue");
 }
 
 void LiftoffAssembler::emit_i32x4_bitmask(LiftoffRegister dst,
@@ -1098,9 +1098,9 @@ void LiftoffAssembler::emit_i16x8_neg(LiftoffRegister dst,
   bailout(kUnsupportedArchitecture, "emit_i16x8neg");
 }
 
-void LiftoffAssembler::emit_v16x8_alltrue(LiftoffRegister dst,
+void LiftoffAssembler::emit_i16x8_alltrue(LiftoffRegister dst,
                                           LiftoffRegister src) {
-  bailout(kSimd, "v16x8_alltrue");
+  bailout(kSimd, "i16x8_alltrue");
 }
 
 void LiftoffAssembler::emit_i16x8_bitmask(LiftoffRegister dst,
@@ -1303,9 +1303,9 @@ void LiftoffAssembler::emit_v128_anytrue(LiftoffRegister dst,
   bailout(kSimd, "v8x16_anytrue");
 }
 
-void LiftoffAssembler::emit_v8x16_alltrue(LiftoffRegister dst,
+void LiftoffAssembler::emit_i8x16_alltrue(LiftoffRegister dst,
                                           LiftoffRegister src) {
-  bailout(kSimd, "v8x16_alltrue");
+  bailout(kSimd, "i8x16_alltrue");
 }
 
 void LiftoffAssembler::emit_i8x16_bitmask(LiftoffRegister dst,
diff --git a/src/wasm/baseline/riscv64/liftoff-assembler-riscv64.h b/src/wasm/baseline/riscv64/liftoff-assembler-riscv64.h
index 2f624f79f5..f73cfd2f97 100644
--- a/src/wasm/baseline/riscv64/liftoff-assembler-riscv64.h
+++ b/src/wasm/baseline/riscv64/liftoff-assembler-riscv64.h
@@ -1599,9 +1599,9 @@ void LiftoffAssembler::emit_v128_anytrue(LiftoffRegister dst,
   bailout(kSimd, "emit_v128_anytrue");
 }
 
-void LiftoffAssembler::emit_v8x16_alltrue(LiftoffRegister dst,
+void LiftoffAssembler::emit_i8x16_alltrue(LiftoffRegister dst,
                                           LiftoffRegister src) {
-  bailout(kSimd, "emit_v8x16_alltrue");
+  bailout(kSimd, "emit_i8x16_alltrue");
 }
 
 void LiftoffAssembler::emit_i8x16_bitmask(LiftoffRegister dst,
@@ -1709,9 +1709,9 @@ void LiftoffAssembler::emit_i16x8_neg(LiftoffRegister dst,
   bailout(kSimd, "emit_i16x8_neg");
 }
 
-void LiftoffAssembler::emit_v16x8_alltrue(LiftoffRegister dst,
+void LiftoffAssembler::emit_i16x8_alltrue(LiftoffRegister dst,
                                           LiftoffRegister src) {
-  bailout(kSimd, "emit_v16x8_alltrue");
+  bailout(kSimd, "emit_i16x8_alltrue");
 }
 
 void LiftoffAssembler::emit_i16x8_bitmask(LiftoffRegister dst,
@@ -1819,9 +1819,9 @@ void LiftoffAssembler::emit_i32x4_neg(LiftoffRegister dst,
   bailout(kSimd, "emit_i32x4_neg");
 }
 
-void LiftoffAssembler::emit_v32x4_alltrue(LiftoffRegister dst,
+void LiftoffAssembler::emit_i32x4_alltrue(LiftoffRegister dst,
                                           LiftoffRegister src) {
-  bailout(kSimd, "emit_v32x4_alltrue");
+  bailout(kSimd, "emit_i32x4_alltrue");
 }
 
 void LiftoffAssembler::emit_i32x4_bitmask(LiftoffRegister dst,
diff --git a/src/wasm/baseline/s390/liftoff-assembler-s390.h b/src/wasm/baseline/s390/liftoff-assembler-s390.h
index 46b1078a20..e09917c399 100644
--- a/src/wasm/baseline/s390/liftoff-assembler-s390.h
+++ b/src/wasm/baseline/s390/liftoff-assembler-s390.h
@@ -1804,9 +1804,9 @@ void LiftoffAssembler::emit_i64x2_neg(LiftoffRegister dst,
   bailout(kUnsupportedArchitecture, "emit_i64x2neg");
 }
 
-void LiftoffAssembler::emit_v64x2_alltrue(LiftoffRegister dst,
+void LiftoffAssembler::emit_i64x2_alltrue(LiftoffRegister dst,
                                           LiftoffRegister src) {
-  bailout(kSimd, "v64x2_alltrue");
+  bailout(kSimd, "i64x2_alltrue");
 }
 
 void LiftoffAssembler::emit_i64x2_shl(LiftoffRegister dst, LiftoffRegister lhs,
@@ -1928,9 +1928,9 @@ void LiftoffAssembler::emit_i32x4_neg(LiftoffRegister dst,
   bailout(kUnsupportedArchitecture, "emit_i32x4neg");
 }
 
-void LiftoffAssembler::emit_v32x4_alltrue(LiftoffRegister dst,
+void LiftoffAssembler::emit_i32x4_alltrue(LiftoffRegister dst,
                                           LiftoffRegister src) {
-  bailout(kSimd, "v32x4_alltrue");
+  bailout(kSimd, "i32x4_alltrue");
 }
 
 void LiftoffAssembler::emit_i32x4_bitmask(LiftoffRegister dst,
@@ -2059,9 +2059,9 @@ void LiftoffAssembler::emit_i16x8_neg(LiftoffRegister dst,
   bailout(kUnsupportedArchitecture, "emit_i16x8neg");
 }
 
-void LiftoffAssembler::emit_v16x8_alltrue(LiftoffRegister dst,
+void LiftoffAssembler::emit_i16x8_alltrue(LiftoffRegister dst,
                                           LiftoffRegister src) {
-  bailout(kSimd, "v16x8_alltrue");
+  bailout(kSimd, "i16x8_alltrue");
 }
 
 void LiftoffAssembler::emit_i16x8_bitmask(LiftoffRegister dst,
@@ -2270,9 +2270,9 @@ void LiftoffAssembler::emit_v128_anytrue(LiftoffRegister dst,
   bailout(kSimd, "v8x16_anytrue");
 }
 
-void LiftoffAssembler::emit_v8x16_alltrue(LiftoffRegister dst,
+void LiftoffAssembler::emit_i8x16_alltrue(LiftoffRegister dst,
                                           LiftoffRegister src) {
-  bailout(kSimd, "v8x16_alltrue");
+  bailout(kSimd, "i8x16_alltrue");
 }
 
 void LiftoffAssembler::emit_i8x16_bitmask(LiftoffRegister dst,
diff --git a/src/wasm/baseline/x64/liftoff-assembler-x64.h b/src/wasm/baseline/x64/liftoff-assembler-x64.h
index ef8afbd3cf..878696f8d1 100644
--- a/src/wasm/baseline/x64/liftoff-assembler-x64.h
+++ b/src/wasm/baseline/x64/liftoff-assembler-x64.h
@@ -2890,7 +2890,7 @@ void LiftoffAssembler::emit_v128_anytrue(LiftoffRegister dst,
   liftoff::EmitAnyTrue(this, dst, src);
 }
 
-void LiftoffAssembler::emit_v8x16_alltrue(LiftoffRegister dst,
+void LiftoffAssembler::emit_i8x16_alltrue(LiftoffRegister dst,
                                           LiftoffRegister src) {
   liftoff::EmitAllTrue<&TurboAssembler::Pcmpeqb>(this, dst, src);
 }
@@ -3067,7 +3067,7 @@ void LiftoffAssembler::emit_i16x8_neg(LiftoffRegister dst,
   }
 }
 
-void LiftoffAssembler::emit_v16x8_alltrue(LiftoffRegister dst,
+void LiftoffAssembler::emit_i16x8_alltrue(LiftoffRegister dst,
                                           LiftoffRegister src) {
   liftoff::EmitAllTrue<&TurboAssembler::Pcmpeqw>(this, dst, src);
 }
@@ -3249,7 +3249,7 @@ void LiftoffAssembler::emit_i32x4_neg(LiftoffRegister dst,
   }
 }
 
-void LiftoffAssembler::emit_v32x4_alltrue(LiftoffRegister dst,
+void LiftoffAssembler::emit_i32x4_alltrue(LiftoffRegister dst,
                                           LiftoffRegister src) {
   liftoff::EmitAllTrue<&TurboAssembler::Pcmpeqd>(this, dst, src);
 }
@@ -3427,7 +3427,7 @@ void LiftoffAssembler::emit_i64x2_neg(LiftoffRegister dst,
   }
 }
 
-void LiftoffAssembler::emit_v64x2_alltrue(LiftoffRegister dst,
+void LiftoffAssembler::emit_i64x2_alltrue(LiftoffRegister dst,
                                           LiftoffRegister src) {
   liftoff::EmitAllTrue<&TurboAssembler::Pcmpeqq>(this, dst, src, SSE4_1);
 }
diff --git a/src/wasm/wasm-opcodes-inl.h b/src/wasm/wasm-opcodes-inl.h
index d0023878f5..4bfa15ec37 100644
--- a/src/wasm/wasm-opcodes-inl.h
+++ b/src/wasm/wasm-opcodes-inl.h
@@ -54,9 +54,6 @@ namespace wasm {
       CASE_I8x16_OP(name, str)
 #define CASE_SIMDI_NO64X2_OP(name, str) \
   CASE_I32x4_OP(name, str) CASE_I16x8_OP(name, str) CASE_I8x16_OP(name, str)
-#define CASE_SIMDV_OP(name, str)                                             \
-  CASE_V64x2_OP(name, str) CASE_V32x4_OP(name, str) CASE_V16x8_OP(name, str) \
-      CASE_V8x16_OP(name, str)
 #define CASE_SIGN_OP(TYPE, name, str) \
   CASE_##TYPE##_OP(name##S, str "_s") CASE_##TYPE##_OP(name##U, str "_u")
 #define CASE_UNSIGNED_OP(TYPE, name, str) CASE_##TYPE##_OP(name##U, str "_u")
@@ -302,7 +299,7 @@ constexpr const char* WasmOpcodes::OpcodeName(WasmOpcode opcode) {
     CASE_I8x16_OP(Swizzle, "swizzle")
     CASE_I8x16_OP(Shuffle, "shuffle")
     CASE_V128_OP(AnyTrue, "any_true")
-    CASE_SIMDV_OP(AllTrue, "all_true")
+    CASE_SIMDI_OP(AllTrue, "all_true")
     CASE_SIMDF_OP(Qfma, "qfma")
     CASE_SIMDF_OP(Qfms, "qfms")
 
diff --git a/src/wasm/wasm-opcodes.h b/src/wasm/wasm-opcodes.h
index 001db7e4b9..ba3cad050b 100644
--- a/src/wasm/wasm-opcodes.h
+++ b/src/wasm/wasm-opcodes.h
@@ -372,7 +372,7 @@ bool V8_EXPORT_PRIVATE IsJSCompatibleSignature(const FunctionSig* sig,
   V(I8x16Abs, 0xfd60, s_s)                   \
   V(I8x16Neg, 0xfd61, s_s)                   \
   V(I8x16Popcnt, 0xfd62, s_s)                \
-  V(V8x16AllTrue, 0xfd63, i_s)               \
+  V(I8x16AllTrue, 0xfd63, i_s)               \
   V(I8x16BitMask, 0xfd64, i_s)               \
   V(I8x16SConvertI16x8, 0xfd65, s_ss)        \
   V(I8x16UConvertI16x8, 0xfd66, s_ss)        \
@@ -404,7 +404,7 @@ bool V8_EXPORT_PRIVATE IsJSCompatibleSignature(const FunctionSig* sig,
   V(I16x8Abs, 0xfd80, s_s)                   \
   V(I16x8Neg, 0xfd81, s_s)                   \
   V(I16x8Q15MulRSatS, 0xfd82, s_ss)          \
-  V(V16x8AllTrue, 0xfd83, i_s)               \
+  V(I16x8AllTrue, 0xfd83, i_s)               \
   V(I16x8BitMask, 0xfd84, i_s)               \
   V(I16x8SConvertI32x4, 0xfd85, s_ss)        \
   V(I16x8UConvertI32x4, 0xfd86, s_ss)        \
@@ -434,7 +434,7 @@ bool V8_EXPORT_PRIVATE IsJSCompatibleSignature(const FunctionSig* sig,
   V(I16x8ExtMulHighI8x16U, 0xfd9f, s_ss)     \
   V(I32x4Abs, 0xfda0, s_s)                   \
   V(I32x4Neg, 0xfda1, s_s)                   \
-  V(V32x4AllTrue, 0xfda3, i_s)               \
+  V(I32x4AllTrue, 0xfda3, i_s)               \
   V(I32x4BitMask, 0xfda4, i_s)               \
   V(I32x4SConvertI16x8Low, 0xfda7, s_s)      \
   V(I32x4SConvertI16x8High, 0xfda8, s_s)     \
@@ -457,7 +457,7 @@ bool V8_EXPORT_PRIVATE IsJSCompatibleSignature(const FunctionSig* sig,
   V(I32x4ExtMulHighI16x8U, 0xfdbf, s_ss)     \
   V(I64x2Abs, 0xfdc0, s_s)                   \
   V(I64x2Neg, 0xfdc1, s_s)                   \
-  V(V64x2AllTrue, 0xfdc3, i_s)               \
+  V(I64x2AllTrue, 0xfdc3, i_s)               \
   V(I64x2BitMask, 0xfdc4, i_s)               \
   V(I64x2SConvertI32x4Low, 0xfdc7, s_s)      \
   V(I64x2SConvertI32x4High, 0xfdc8, s_s)     \
diff --git a/test/cctest/wasm/test-run-wasm-simd-scalar-lowering.cc b/test/cctest/wasm/test-run-wasm-simd-scalar-lowering.cc
index 4c5309aae5..c0cc3c7dac 100644
--- a/test/cctest/wasm/test-run-wasm-simd-scalar-lowering.cc
+++ b/test/cctest/wasm/test-run-wasm-simd-scalar-lowering.cc
@@ -193,7 +193,7 @@ WASM_SIMD_TEST(AllTrue_DifferentShapes) {
     WasmRunner<int32_t, int32_t> r(execution_tier, lower_simd);
 
     BUILD(r, WASM_SIMD_I32x4_SPLAT(WASM_LOCAL_GET(0)),
-          WASM_SIMD_OP(kExprV8x16AllTrue));
+          WASM_SIMD_OP(kExprI8x16AllTrue));
 
     CHECK_EQ(0, r.Call(0x00FF00FF));
   }
@@ -202,7 +202,7 @@ WASM_SIMD_TEST(AllTrue_DifferentShapes) {
     WasmRunner<int32_t, int32_t> r(execution_tier, lower_simd);
 
     BUILD(r, WASM_SIMD_I32x4_SPLAT(WASM_LOCAL_GET(0)),
-          WASM_SIMD_OP(kExprV16x8AllTrue));
+          WASM_SIMD_OP(kExprI16x8AllTrue));
 
     CHECK_EQ(0, r.Call(0x000000FF));
   }
@@ -212,7 +212,7 @@ WASM_SIMD_TEST(AllTrue_DifferentShapes) {
     WasmRunner<int32_t, float> r(execution_tier, lower_simd);
 
     BUILD(r, WASM_SIMD_F32x4_SPLAT(WASM_LOCAL_GET(0)),
-          WASM_SIMD_OP(kExprV16x8AllTrue));
+          WASM_SIMD_OP(kExprI16x8AllTrue));
 
     CHECK_EQ(1, r.Call(0x000F000F));
   }
diff --git a/test/cctest/wasm/test-run-wasm-simd.cc b/test/cctest/wasm/test-run-wasm-simd.cc
index 363724ca3f..d1c4d7c52d 100644
--- a/test/cctest/wasm/test-run-wasm-simd.cc
+++ b/test/cctest/wasm/test-run-wasm-simd.cc
@@ -3321,14 +3321,14 @@ WASM_SIMD_TEST(S8x16MultiShuffleFuzz) {
           WASM_IF(WASM_I32_NE(WASM_LOCAL_GET(reduced), WASM_ZERO),             \
                   WASM_RETURN1(WASM_ZERO)),                                    \
           WASM_LOCAL_SET(                                                      \
-              reduced, WASM_SIMD_UNOP(kExprV##format##AllTrue,                 \
+              reduced, WASM_SIMD_UNOP(kExprI##format##AllTrue,                 \
                                       WASM_SIMD_BINOP(kExprI##format##Eq,      \
                                                       WASM_LOCAL_GET(zero),    \
                                                       WASM_LOCAL_GET(zero)))), \
           WASM_IF(WASM_I32_EQ(WASM_LOCAL_GET(reduced), WASM_ZERO),             \
                   WASM_RETURN1(WASM_ZERO)),                                    \
           WASM_LOCAL_SET(                                                      \
-              reduced, WASM_SIMD_UNOP(kExprV##format##AllTrue,                 \
+              reduced, WASM_SIMD_UNOP(kExprI##format##AllTrue,                 \
                                       WASM_SIMD_BINOP(kExprI##format##Ne,      \
                                                       WASM_LOCAL_GET(zero),    \
                                                       WASM_LOCAL_GET(zero)))), \
@@ -3352,14 +3352,14 @@ WASM_SIMD_TEST(S8x16MultiShuffleFuzz) {
           WASM_IF(WASM_I32_EQ(WASM_LOCAL_GET(reduced), WASM_ZERO),             \
                   WASM_RETURN1(WASM_ZERO)),                                    \
           WASM_LOCAL_SET(                                                      \
-              reduced, WASM_SIMD_UNOP(kExprV##format##AllTrue,                 \
+              reduced, WASM_SIMD_UNOP(kExprI##format##AllTrue,                 \
                                       WASM_SIMD_BINOP(kExprI##format##Eq,      \
                                                       WASM_LOCAL_GET(one_one), \
                                                       WASM_LOCAL_GET(zero)))), \
           WASM_IF(WASM_I32_NE(WASM_LOCAL_GET(reduced), WASM_ZERO),             \
                   WASM_RETURN1(WASM_ZERO)),                                    \
           WASM_LOCAL_SET(                                                      \
-              reduced, WASM_SIMD_UNOP(kExprV##format##AllTrue,                 \
+              reduced, WASM_SIMD_UNOP(kExprI##format##AllTrue,                 \
                                       WASM_SIMD_BINOP(kExprI##format##Ne,      \
                                                       WASM_LOCAL_GET(one_one), \
                                                       WASM_LOCAL_GET(zero)))), \
@@ -4251,14 +4251,14 @@ WASM_SIMD_TEST(V128AnytrueWithNegativeZero) {
 }
 
 #define WASM_SIMD_ALLTRUE_TEST(format, lanes, max, param_type)                \
-  WASM_SIMD_TEST(V##format##AllTrue) {                                        \
+  WASM_SIMD_TEST(I##format##AllTrue) {                                        \
     WasmRunner<int32_t, param_type> r(execution_tier, lower_simd);            \
     if (lanes == 2 && lower_simd == kLowerSimd) return;                       \
     byte simd = r.AllocateLocal(kWasmS128);                                   \
     BUILD(                                                                    \
         r,                                                                    \
         WASM_LOCAL_SET(simd, WASM_SIMD_I##format##_SPLAT(WASM_LOCAL_GET(0))), \
-        WASM_SIMD_UNOP(kExprV##format##AllTrue, WASM_LOCAL_GET(simd)));       \
+        WASM_SIMD_UNOP(kExprI##format##AllTrue, WASM_LOCAL_GET(simd)));       \
     CHECK_EQ(1, r.Call(max));                                                 \
     CHECK_EQ(1, r.Call(0x1));                                                 \
     CHECK_EQ(0, r.Call(0));                                                   \
diff --git a/test/common/wasm/wasm-interpreter.cc b/test/common/wasm/wasm-interpreter.cc
index a7a009da6f..ec7f892962 100644
--- a/test/common/wasm/wasm-interpreter.cc
+++ b/test/common/wasm/wasm-interpreter.cc
@@ -2819,10 +2819,10 @@ class WasmInterpreterInternals {
     Push(WasmValue(res));                                 \
     return true;                                          \
   }
-        REDUCTION_CASE(V64x2AllTrue, i64x2, int2, 2, &)
-        REDUCTION_CASE(V32x4AllTrue, i32x4, int4, 4, &)
-        REDUCTION_CASE(V16x8AllTrue, i16x8, int8, 8, &)
-        REDUCTION_CASE(V8x16AllTrue, i8x16, int16, 16, &)
+        REDUCTION_CASE(I64x2AllTrue, i64x2, int2, 2, &)
+        REDUCTION_CASE(I32x4AllTrue, i32x4, int4, 4, &)
+        REDUCTION_CASE(I16x8AllTrue, i16x8, int8, 8, &)
+        REDUCTION_CASE(I8x16AllTrue, i8x16, int16, 16, &)
 #undef REDUCTION_CASE
 #define QFM_CASE(op, name, stype, count, operation)                           \
   case kExpr##op: {                                                           \
diff --git a/test/fuzzer/wasm-compile.cc b/test/fuzzer/wasm-compile.cc
index c8197efdb9..3965c34c22 100644
--- a/test/fuzzer/wasm-compile.cc
+++ b/test/fuzzer/wasm-compile.cc
@@ -1001,13 +1001,13 @@ void WasmGenerator::Generate<kI32>(DataRange* data) {
                                 kI32>,
 
       &WasmGenerator::op_with_prefix<kExprV128AnyTrue, kS128>,
-      &WasmGenerator::op_with_prefix<kExprV8x16AllTrue, kS128>,
+      &WasmGenerator::op_with_prefix<kExprI8x16AllTrue, kS128>,
       &WasmGenerator::op_with_prefix<kExprI8x16BitMask, kS128>,
-      &WasmGenerator::op_with_prefix<kExprV16x8AllTrue, kS128>,
+      &WasmGenerator::op_with_prefix<kExprI16x8AllTrue, kS128>,
       &WasmGenerator::op_with_prefix<kExprI16x8BitMask, kS128>,
-      &WasmGenerator::op_with_prefix<kExprV32x4AllTrue, kS128>,
+      &WasmGenerator::op_with_prefix<kExprI32x4AllTrue, kS128>,
       &WasmGenerator::op_with_prefix<kExprI32x4BitMask, kS128>,
-      &WasmGenerator::op_with_prefix<kExprV64x2AllTrue, kS128>,
+      &WasmGenerator::op_with_prefix<kExprI64x2AllTrue, kS128>,
       &WasmGenerator::op_with_prefix<kExprI64x2BitMask, kS128>,
       &WasmGenerator::simd_lane_op<kExprI8x16ExtractLaneS, 16, kS128>,
       &WasmGenerator::simd_lane_op<kExprI8x16ExtractLaneU, 16, kS128>,
diff --git a/test/mjsunit/regress/wasm/regress-10831.js b/test/mjsunit/regress/wasm/regress-10831.js
index 58c6c4dec1..29334684ed 100644
--- a/test/mjsunit/regress/wasm/regress-10831.js
+++ b/test/mjsunit/regress/wasm/regress-10831.js
@@ -39,7 +39,7 @@ kExprI32Const, 0xfc, 0xf8, 0x01,  // i32.const
 kSimdPrefix, kExprI8x16Splat,  // i8x16.splat
 kSimdPrefix, kExprF64x2Max, 0x01,  // f64x2.max
 kSimdPrefix, kExprI16x8MaxS, 0x01,  // i16x8.max_s
-kSimdPrefix, kExprV8x16AllTrue,  // v8x16.all_true
+kSimdPrefix, kExprI8x16AllTrue,  // i8x16.all_true
 kExprEnd,  // end @70
 ]);
 builder.addExport('main', 0);
diff --git a/test/mjsunit/wasm/exceptions-simd.js b/test/mjsunit/wasm/exceptions-simd.js
index 9082a7f49e..ae2d8ee40c 100644
--- a/test/mjsunit/wasm/exceptions-simd.js
+++ b/test/mjsunit/wasm/exceptions-simd.js
@@ -40,7 +40,7 @@ load("test/mjsunit/wasm/exceptions-utils.js");
         kExprEnd,
         kExprLocalGet, 0,
         kSimdPrefix, kExprI32x4Eq,
-        kSimdPrefix, kExprV8x16AllTrue,
+        kSimdPrefix, kExprI8x16AllTrue,
       ])
       .exportFunc();
   var instance = builder.instantiate();
diff --git a/test/mjsunit/wasm/wasm-module-builder.js b/test/mjsunit/wasm/wasm-module-builder.js
index ed83e66e74..59a5237fbf 100644
--- a/test/mjsunit/wasm/wasm-module-builder.js
+++ b/test/mjsunit/wasm/wasm-module-builder.js
@@ -646,7 +646,7 @@ let kExprF64x2PromoteLowF32x4 = 0x5f;
 let kExprI8x16Abs = 0x60;
 let kExprI8x16Neg = 0x61;
 let kExprI8x16Popcnt = 0x62;
-let kExprV8x16AllTrue = 0x63;
+let kExprI8x16AllTrue = 0x63;
 let kExprI8x16BitMask = 0x64;
 let kExprI8x16SConvertI16x8 = 0x65;
 let kExprI8x16UConvertI16x8 = 0x66;
@@ -678,7 +678,7 @@ let kExprI32x4ExtAddPairwiseI16x8U = 0x7f;
 let kExprI16x8Abs = 0x80;
 let kExprI16x8Neg = 0x81;
 let kExprI16x8Q15MulRSatS = 0x82;
-let kExprV16x8AllTrue = 0x83;
+let kExprI16x8AllTrue = 0x83;
 let kExprI16x8BitMask = 0x84;
 let kExprI16x8SConvertI32x4 = 0x85;
 let kExprI16x8UConvertI32x4 = 0x86;
@@ -708,7 +708,7 @@ let kExprI16x8ExtMulLowI8x16U = 0x9e;
 let kExprI16x8ExtMulHighI8x16U = 0x9f;
 let kExprI32x4Abs = 0xa0;
 let kExprI32x4Neg = 0xa1;
-let kExprV32x4AllTrue = 0xa3;
+let kExprI32x4AllTrue = 0xa3;
 let kExprI32x4BitMask = 0xa4;
 let kExprI32x4SConvertI16x8Low = 0xa7;
 let kExprI32x4SConvertI16x8High = 0xa8;
@@ -731,7 +731,7 @@ let kExprI32x4ExtMulLowI16x8U = 0xbe;
 let kExprI32x4ExtMulHighI16x8U = 0xbf;
 let kExprI64x2Abs = 0xc0;
 let kExprI64x2Neg = 0xc1;
-let kExprV64x2AllTrue = 0xc3;
+let kExprI64x2AllTrue = 0xc3;
 let kExprI64x2BitMask = 0xc4;
 let kExprI64x2SConvertI32x4Low = 0xc7;
 let kExprI64x2SConvertI32x4High = 0xc8;
-- 
2.35.1

