From 313b85fbc37d4e7403602a2b782de63affd2b1d9 Mon Sep 17 00:00:00 2001
From: Lu Yahan <yahan@iscas.ac.cn>
Date: Thu, 17 Nov 2022 19:11:02 +0800
Subject: [PATCH] [riscv] Convert Opcode from enum to integer type.

Change-Id: I6a075df6cc9599b04c318340309a32743b433a37
Reviewed-on: https://chromium-review.googlesource.com/c/v8/v8/+/4032085
Reviewed-by: ji qiu <qiuji@iscas.ac.cn>
Commit-Queue: Yahan Lu <yahan@iscas.ac.cn>
Auto-Submit: Yahan Lu <yahan@iscas.ac.cn>
Cr-Commit-Position: refs/heads/main@{#84434}
---
 src/codegen/riscv/base-constants-riscv.h    |    2 +-
 src/codegen/riscv/constant-riscv-a.h        |   71 +-
 src/codegen/riscv/constant-riscv-c.h        |   90 +-
 src/codegen/riscv/constant-riscv-d.h        |   97 +-
 src/codegen/riscv/constant-riscv-f.h        |   86 +-
 src/codegen/riscv/constant-riscv-i.h        |  124 ++-
 src/codegen/riscv/constant-riscv-m.h        |   46 +-
 src/codegen/riscv/constant-riscv-v.h        | 1027 ++++++++++---------
 src/codegen/riscv/constant-riscv-zicsr.h    |   16 +-
 src/codegen/riscv/constant-riscv-zifencei.h |    4 +-
 src/codegen/riscv/extension-riscv-v.cc      |   37 +-
 src/codegen/riscv/extension-riscv-v.h       |   26 +-
 12 files changed, 886 insertions(+), 740 deletions(-)

diff --git a/src/codegen/riscv/base-constants-riscv.h b/src/codegen/riscv/base-constants-riscv.h
index bc38bfabc9f..968fbb2fc99 100644
--- a/src/codegen/riscv/base-constants-riscv.h
+++ b/src/codegen/riscv/base-constants-riscv.h
@@ -53,7 +53,7 @@ const uint32_t kLessSignificantWordInDoublewordOffset = 4;
 // Try https://content.riscv.org/wp-content/uploads/2017/05/riscv-spec-v2.2.pdf.
 namespace v8 {
 namespace internal {
-
+using Opcode = uint32_t;
 // Actual value of root register is offset from the root array's start
 // to take advantage of negative displacement values.
 // TODO(sigurds): Choose best value.
diff --git a/src/codegen/riscv/constant-riscv-a.h b/src/codegen/riscv/constant-riscv-a.h
index afd335ce592..c5090054c66 100644
--- a/src/codegen/riscv/constant-riscv-a.h
+++ b/src/codegen/riscv/constant-riscv-a.h
@@ -8,35 +8,56 @@
 namespace v8 {
 namespace internal {
 
-enum OpcodeRISCVA : uint32_t {
-  // RV32A Standard Extension
-  RO_LR_W = AMO | (0b010 << kFunct3Shift) | (0b00010 << kFunct5Shift),
-  RO_SC_W = AMO | (0b010 << kFunct3Shift) | (0b00011 << kFunct5Shift),
-  RO_AMOSWAP_W = AMO | (0b010 << kFunct3Shift) | (0b00001 << kFunct5Shift),
-  RO_AMOADD_W = AMO | (0b010 << kFunct3Shift) | (0b00000 << kFunct5Shift),
-  RO_AMOXOR_W = AMO | (0b010 << kFunct3Shift) | (0b00100 << kFunct5Shift),
-  RO_AMOAND_W = AMO | (0b010 << kFunct3Shift) | (0b01100 << kFunct5Shift),
-  RO_AMOOR_W = AMO | (0b010 << kFunct3Shift) | (0b01000 << kFunct5Shift),
-  RO_AMOMIN_W = AMO | (0b010 << kFunct3Shift) | (0b10000 << kFunct5Shift),
-  RO_AMOMAX_W = AMO | (0b010 << kFunct3Shift) | (0b10100 << kFunct5Shift),
-  RO_AMOMINU_W = AMO | (0b010 << kFunct3Shift) | (0b11000 << kFunct5Shift),
-  RO_AMOMAXU_W = AMO | (0b010 << kFunct3Shift) | (0b11100 << kFunct5Shift),
+// RV32A Standard Extension
+constexpr Opcode RO_LR_W =
+    AMO | (0b010 << kFunct3Shift) | (0b00010 << kFunct5Shift);
+constexpr Opcode RO_SC_W =
+    AMO | (0b010 << kFunct3Shift) | (0b00011 << kFunct5Shift);
+constexpr Opcode RO_AMOSWAP_W =
+    AMO | (0b010 << kFunct3Shift) | (0b00001 << kFunct5Shift);
+constexpr Opcode RO_AMOADD_W =
+    AMO | (0b010 << kFunct3Shift) | (0b00000 << kFunct5Shift);
+constexpr Opcode RO_AMOXOR_W =
+    AMO | (0b010 << kFunct3Shift) | (0b00100 << kFunct5Shift);
+constexpr Opcode RO_AMOAND_W =
+    AMO | (0b010 << kFunct3Shift) | (0b01100 << kFunct5Shift);
+constexpr Opcode RO_AMOOR_W =
+    AMO | (0b010 << kFunct3Shift) | (0b01000 << kFunct5Shift);
+constexpr Opcode RO_AMOMIN_W =
+    AMO | (0b010 << kFunct3Shift) | (0b10000 << kFunct5Shift);
+constexpr Opcode RO_AMOMAX_W =
+    AMO | (0b010 << kFunct3Shift) | (0b10100 << kFunct5Shift);
+constexpr Opcode RO_AMOMINU_W =
+    AMO | (0b010 << kFunct3Shift) | (0b11000 << kFunct5Shift);
+constexpr Opcode RO_AMOMAXU_W =
+    AMO | (0b010 << kFunct3Shift) | (0b11100 << kFunct5Shift);
 
 #ifdef V8_TARGET_ARCH_RISCV64
   // RV64A Standard Extension (in addition to RV32A)
-  RO_LR_D = AMO | (0b011 << kFunct3Shift) | (0b00010 << kFunct5Shift),
-  RO_SC_D = AMO | (0b011 << kFunct3Shift) | (0b00011 << kFunct5Shift),
-  RO_AMOSWAP_D = AMO | (0b011 << kFunct3Shift) | (0b00001 << kFunct5Shift),
-  RO_AMOADD_D = AMO | (0b011 << kFunct3Shift) | (0b00000 << kFunct5Shift),
-  RO_AMOXOR_D = AMO | (0b011 << kFunct3Shift) | (0b00100 << kFunct5Shift),
-  RO_AMOAND_D = AMO | (0b011 << kFunct3Shift) | (0b01100 << kFunct5Shift),
-  RO_AMOOR_D = AMO | (0b011 << kFunct3Shift) | (0b01000 << kFunct5Shift),
-  RO_AMOMIN_D = AMO | (0b011 << kFunct3Shift) | (0b10000 << kFunct5Shift),
-  RO_AMOMAX_D = AMO | (0b011 << kFunct3Shift) | (0b10100 << kFunct5Shift),
-  RO_AMOMINU_D = AMO | (0b011 << kFunct3Shift) | (0b11000 << kFunct5Shift),
-  RO_AMOMAXU_D = AMO | (0b011 << kFunct3Shift) | (0b11100 << kFunct5Shift),
+constexpr Opcode RO_LR_D =
+    AMO | (0b011 << kFunct3Shift) | (0b00010 << kFunct5Shift);
+constexpr Opcode RO_SC_D =
+    AMO | (0b011 << kFunct3Shift) | (0b00011 << kFunct5Shift);
+constexpr Opcode RO_AMOSWAP_D =
+    AMO | (0b011 << kFunct3Shift) | (0b00001 << kFunct5Shift);
+constexpr Opcode RO_AMOADD_D =
+    AMO | (0b011 << kFunct3Shift) | (0b00000 << kFunct5Shift);
+constexpr Opcode RO_AMOXOR_D =
+    AMO | (0b011 << kFunct3Shift) | (0b00100 << kFunct5Shift);
+constexpr Opcode RO_AMOAND_D =
+    AMO | (0b011 << kFunct3Shift) | (0b01100 << kFunct5Shift);
+constexpr Opcode RO_AMOOR_D =
+    AMO | (0b011 << kFunct3Shift) | (0b01000 << kFunct5Shift);
+constexpr Opcode RO_AMOMIN_D =
+    AMO | (0b011 << kFunct3Shift) | (0b10000 << kFunct5Shift);
+constexpr Opcode RO_AMOMAX_D =
+    AMO | (0b011 << kFunct3Shift) | (0b10100 << kFunct5Shift);
+constexpr Opcode RO_AMOMINU_D =
+    AMO | (0b011 << kFunct3Shift) | (0b11000 << kFunct5Shift);
+constexpr Opcode RO_AMOMAXU_D =
+    AMO | (0b011 << kFunct3Shift) | (0b11100 << kFunct5Shift);
 #endif  // V8_TARGET_ARCH_RISCV64
-};
+// clang-format on
 }  // namespace internal
 }  // namespace v8
 
diff --git a/src/codegen/riscv/constant-riscv-c.h b/src/codegen/riscv/constant-riscv-c.h
index 2f8a5047808..1377792f45e 100644
--- a/src/codegen/riscv/constant-riscv-c.h
+++ b/src/codegen/riscv/constant-riscv-c.h
@@ -8,55 +8,57 @@
 namespace v8 {
 namespace internal {
 
-enum OpcodeRISCVC : uint32_t {
+constexpr Opcode RO_C_ADDI4SPN = C0 | (0b000 << kRvcFunct3Shift);
+constexpr Opcode RO_C_ADDI16SP = C1 | (0b011 << kRvcFunct3Shift);
+constexpr Opcode RO_C_LW = C0 | (0b010 << kRvcFunct3Shift);
+constexpr Opcode RO_C_SW = C0 | (0b110 << kRvcFunct3Shift);
+constexpr Opcode RO_C_NOP_ADDI = C1 | (0b000 << kRvcFunct3Shift);
+constexpr Opcode RO_C_LI = C1 | (0b010 << kRvcFunct3Shift);
+constexpr Opcode RO_C_SUB =
+    C1 | (0b100011 << kRvcFunct6Shift) | (FUNCT2_0 << kRvcFunct2Shift);
+constexpr Opcode RO_C_XOR =
+    C1 | (0b100011 << kRvcFunct6Shift) | (FUNCT2_1 << kRvcFunct2Shift);
+constexpr Opcode RO_C_OR =
+    C1 | (0b100011 << kRvcFunct6Shift) | (FUNCT2_2 << kRvcFunct2Shift);
+constexpr Opcode RO_C_AND =
+    C1 | (0b100011 << kRvcFunct6Shift) | (FUNCT2_3 << kRvcFunct2Shift);
+constexpr Opcode RO_C_LUI_ADD = C1 | (0b011 << kRvcFunct3Shift);
+constexpr Opcode RO_C_MISC_ALU = C1 | (0b100 << kRvcFunct3Shift);
+constexpr Opcode RO_C_J = C1 | (0b101 << kRvcFunct3Shift);
+constexpr Opcode RO_C_BEQZ = C1 | (0b110 << kRvcFunct3Shift);
+constexpr Opcode RO_C_BNEZ = C1 | (0b111 << kRvcFunct3Shift);
+constexpr Opcode RO_C_SLLI = C2 | (0b000 << kRvcFunct3Shift);
+constexpr Opcode RO_C_LWSP = C2 | (0b010 << kRvcFunct3Shift);
+constexpr Opcode RO_C_JR_MV_ADD = C2 | (0b100 << kRvcFunct3Shift);
+constexpr Opcode RO_C_JR = C2 | (0b1000 << kRvcFunct4Shift);
+constexpr Opcode RO_C_MV = C2 | (0b1000 << kRvcFunct4Shift);
+constexpr Opcode RO_C_EBREAK = C2 | (0b1001 << kRvcFunct4Shift);
+constexpr Opcode RO_C_JALR = C2 | (0b1001 << kRvcFunct4Shift);
+constexpr Opcode RO_C_ADD = C2 | (0b1001 << kRvcFunct4Shift);
+constexpr Opcode RO_C_SWSP = C2 | (0b110 << kRvcFunct3Shift);
 
-  RO_C_ADDI4SPN = C0 | (0b000 << kRvcFunct3Shift),
-  RO_C_ADDI16SP = C1 | (0b011 << kRvcFunct3Shift),
-  RO_C_LW = C0 | (0b010 << kRvcFunct3Shift),
-  RO_C_SW = C0 | (0b110 << kRvcFunct3Shift),
-  RO_C_NOP_ADDI = C1 | (0b000 << kRvcFunct3Shift),
-  RO_C_LI = C1 | (0b010 << kRvcFunct3Shift),
-  RO_C_SUB = C1 | (0b100011 << kRvcFunct6Shift) | (FUNCT2_0 << kRvcFunct2Shift),
-  RO_C_XOR = C1 | (0b100011 << kRvcFunct6Shift) | (FUNCT2_1 << kRvcFunct2Shift),
-  RO_C_OR = C1 | (0b100011 << kRvcFunct6Shift) | (FUNCT2_2 << kRvcFunct2Shift),
-  RO_C_AND = C1 | (0b100011 << kRvcFunct6Shift) | (FUNCT2_3 << kRvcFunct2Shift),
-  RO_C_LUI_ADD = C1 | (0b011 << kRvcFunct3Shift),
-  RO_C_MISC_ALU = C1 | (0b100 << kRvcFunct3Shift),
-  RO_C_J = C1 | (0b101 << kRvcFunct3Shift),
-  RO_C_BEQZ = C1 | (0b110 << kRvcFunct3Shift),
-  RO_C_BNEZ = C1 | (0b111 << kRvcFunct3Shift),
-  RO_C_SLLI = C2 | (0b000 << kRvcFunct3Shift),
-  RO_C_LWSP = C2 | (0b010 << kRvcFunct3Shift),
-  RO_C_JR_MV_ADD = C2 | (0b100 << kRvcFunct3Shift),
-  RO_C_JR = C2 | (0b1000 << kRvcFunct4Shift),
-  RO_C_MV = C2 | (0b1000 << kRvcFunct4Shift),
-  RO_C_EBREAK = C2 | (0b1001 << kRvcFunct4Shift),
-  RO_C_JALR = C2 | (0b1001 << kRvcFunct4Shift),
-  RO_C_ADD = C2 | (0b1001 << kRvcFunct4Shift),
-  RO_C_SWSP = C2 | (0b110 << kRvcFunct3Shift),
-
-  RO_C_FSD = C0 | (0b101 << kRvcFunct3Shift),
-  RO_C_FLD = C0 | (0b001 << kRvcFunct3Shift),
-  RO_C_FLDSP = C2 | (0b001 << kRvcFunct3Shift),
-  RO_C_FSDSP = C2 | (0b101 << kRvcFunct3Shift),
+constexpr Opcode RO_C_FSD = C0 | (0b101 << kRvcFunct3Shift);
+constexpr Opcode RO_C_FLD = C0 | (0b001 << kRvcFunct3Shift);
+constexpr Opcode RO_C_FLDSP = C2 | (0b001 << kRvcFunct3Shift);
+constexpr Opcode RO_C_FSDSP = C2 | (0b101 << kRvcFunct3Shift);
 #ifdef V8_TARGET_ARCH_RISCV64
-  RO_C_LD = C0 | (0b011 << kRvcFunct3Shift),
-  RO_C_SD = C0 | (0b111 << kRvcFunct3Shift),
-  RO_C_LDSP = C2 | (0b011 << kRvcFunct3Shift),
-  RO_C_SDSP = C2 | (0b111 << kRvcFunct3Shift),
-  RO_C_ADDIW = C1 | (0b001 << kRvcFunct3Shift),
-  RO_C_SUBW =
-      C1 | (0b100111 << kRvcFunct6Shift) | (FUNCT2_0 << kRvcFunct2Shift),
-  RO_C_ADDW =
-      C1 | (0b100111 << kRvcFunct6Shift) | (FUNCT2_1 << kRvcFunct2Shift),
+constexpr Opcode RO_C_LD = C0 | (0b011 << kRvcFunct3Shift);
+constexpr Opcode RO_C_SD = C0 | (0b111 << kRvcFunct3Shift);
+constexpr Opcode RO_C_LDSP = C2 | (0b011 << kRvcFunct3Shift);
+constexpr Opcode RO_C_SDSP = C2 | (0b111 << kRvcFunct3Shift);
+constexpr Opcode RO_C_ADDIW = C1 | (0b001 << kRvcFunct3Shift);
+constexpr Opcode RO_C_SUBW =
+    C1 | (0b100111 << kRvcFunct6Shift) | (FUNCT2_0 << kRvcFunct2Shift);
+constexpr Opcode RO_C_ADDW =
+    C1 | (0b100111 << kRvcFunct6Shift) | (FUNCT2_1 << kRvcFunct2Shift);
 #endif
 #ifdef V8_TARGET_ARCH_RISCV32
-  RO_C_FLWSP = C2 | (0b011 << kRvcFunct3Shift),
-  RO_C_FSWSP = C2 | (0b111 << kRvcFunct3Shift),
-  RO_C_FLW = C0 | (0b011 << kRvcFunct3Shift),
-  RO_C_FSW = C0 | (0b111 << kRvcFunct3Shift),
+constexpr Opcode RO_C_FLWSP = C2 | (0b011 << kRvcFunct3Shift);
+constexpr Opcode RO_C_FSWSP = C2 | (0b111 << kRvcFunct3Shift);
+constexpr Opcode RO_C_FLW = C0 | (0b011 << kRvcFunct3Shift);
+constexpr Opcode RO_C_FSW = C0 | (0b111 << kRvcFunct3Shift);
 #endif
-};
+// clang-format on
 }  // namespace internal
 }  // namespace v8
 #endif  // V8_CODEGEN_RISCV_CONSTANT_RISCV_C_H_
diff --git a/src/codegen/riscv/constant-riscv-d.h b/src/codegen/riscv/constant-riscv-d.h
index 3fd0b251bdb..8f0f2fdccee 100644
--- a/src/codegen/riscv/constant-riscv-d.h
+++ b/src/codegen/riscv/constant-riscv-d.h
@@ -7,48 +7,69 @@
 namespace v8 {
 namespace internal {
 
-enum OpcodeRISCVD : uint32_t {
-  // RV32D Standard Extension
-  RO_FLD = LOAD_FP | (0b011 << kFunct3Shift),
-  RO_FSD = STORE_FP | (0b011 << kFunct3Shift),
-  RO_FMADD_D = MADD | (0b01 << kFunct2Shift),
-  RO_FMSUB_D = MSUB | (0b01 << kFunct2Shift),
-  RO_FNMSUB_D = NMSUB | (0b01 << kFunct2Shift),
-  RO_FNMADD_D = NMADD | (0b01 << kFunct2Shift),
-  RO_FADD_D = OP_FP | (0b0000001 << kFunct7Shift),
-  RO_FSUB_D = OP_FP | (0b0000101 << kFunct7Shift),
-  RO_FMUL_D = OP_FP | (0b0001001 << kFunct7Shift),
-  RO_FDIV_D = OP_FP | (0b0001101 << kFunct7Shift),
-  RO_FSQRT_D = OP_FP | (0b0101101 << kFunct7Shift) | (0b00000 << kRs2Shift),
-  RO_FSGNJ_D = OP_FP | (0b000 << kFunct3Shift) | (0b0010001 << kFunct7Shift),
-  RO_FSGNJN_D = OP_FP | (0b001 << kFunct3Shift) | (0b0010001 << kFunct7Shift),
-  RO_FSQNJX_D = OP_FP | (0b010 << kFunct3Shift) | (0b0010001 << kFunct7Shift),
-  RO_FMIN_D = OP_FP | (0b000 << kFunct3Shift) | (0b0010101 << kFunct7Shift),
-  RO_FMAX_D = OP_FP | (0b001 << kFunct3Shift) | (0b0010101 << kFunct7Shift),
-  RO_FCVT_S_D = OP_FP | (0b0100000 << kFunct7Shift) | (0b00001 << kRs2Shift),
-  RO_FCVT_D_S = OP_FP | (0b0100001 << kFunct7Shift) | (0b00000 << kRs2Shift),
-  RO_FEQ_D = OP_FP | (0b010 << kFunct3Shift) | (0b1010001 << kFunct7Shift),
-  RO_FLT_D = OP_FP | (0b001 << kFunct3Shift) | (0b1010001 << kFunct7Shift),
-  RO_FLE_D = OP_FP | (0b000 << kFunct3Shift) | (0b1010001 << kFunct7Shift),
-  RO_FCLASS_D = OP_FP | (0b001 << kFunct3Shift) | (0b1110001 << kFunct7Shift) |
-                (0b00000 << kRs2Shift),
-  RO_FCVT_W_D = OP_FP | (0b1100001 << kFunct7Shift) | (0b00000 << kRs2Shift),
-  RO_FCVT_WU_D = OP_FP | (0b1100001 << kFunct7Shift) | (0b00001 << kRs2Shift),
-  RO_FCVT_D_W = OP_FP | (0b1101001 << kFunct7Shift) | (0b00000 << kRs2Shift),
-  RO_FCVT_D_WU = OP_FP | (0b1101001 << kFunct7Shift) | (0b00001 << kRs2Shift),
+// RV32D Standard Extension
+constexpr Opcode RO_FLD = LOAD_FP | (0b011 << kFunct3Shift);
+constexpr Opcode RO_FSD = STORE_FP | (0b011 << kFunct3Shift);
+constexpr Opcode RO_FMADD_D = MADD | (0b01 << kFunct2Shift);
+constexpr Opcode RO_FMSUB_D = MSUB | (0b01 << kFunct2Shift);
+constexpr Opcode RO_FNMSUB_D = NMSUB | (0b01 << kFunct2Shift);
+constexpr Opcode RO_FNMADD_D = NMADD | (0b01 << kFunct2Shift);
+constexpr Opcode RO_FADD_D = OP_FP | (0b0000001 << kFunct7Shift);
+constexpr Opcode RO_FSUB_D = OP_FP | (0b0000101 << kFunct7Shift);
+constexpr Opcode RO_FMUL_D = OP_FP | (0b0001001 << kFunct7Shift);
+constexpr Opcode RO_FDIV_D = OP_FP | (0b0001101 << kFunct7Shift);
+constexpr Opcode RO_FSQRT_D =
+    OP_FP | (0b0101101 << kFunct7Shift) | (0b00000 << kRs2Shift);
+constexpr Opcode RO_FSGNJ_D =
+    OP_FP | (0b000 << kFunct3Shift) | (0b0010001 << kFunct7Shift);
+constexpr Opcode RO_FSGNJN_D =
+    OP_FP | (0b001 << kFunct3Shift) | (0b0010001 << kFunct7Shift);
+constexpr Opcode RO_FSQNJX_D =
+    OP_FP | (0b010 << kFunct3Shift) | (0b0010001 << kFunct7Shift);
+constexpr Opcode RO_FMIN_D =
+    OP_FP | (0b000 << kFunct3Shift) | (0b0010101 << kFunct7Shift);
+constexpr Opcode RO_FMAX_D =
+    OP_FP | (0b001 << kFunct3Shift) | (0b0010101 << kFunct7Shift);
+constexpr Opcode RO_FCVT_S_D =
+    OP_FP | (0b0100000 << kFunct7Shift) | (0b00001 << kRs2Shift);
+constexpr Opcode RO_FCVT_D_S =
+    OP_FP | (0b0100001 << kFunct7Shift) | (0b00000 << kRs2Shift);
+constexpr Opcode RO_FEQ_D =
+    OP_FP | (0b010 << kFunct3Shift) | (0b1010001 << kFunct7Shift);
+constexpr Opcode RO_FLT_D =
+    OP_FP | (0b001 << kFunct3Shift) | (0b1010001 << kFunct7Shift);
+constexpr Opcode RO_FLE_D =
+    OP_FP | (0b000 << kFunct3Shift) | (0b1010001 << kFunct7Shift);
+constexpr Opcode RO_FCLASS_D = OP_FP | (0b001 << kFunct3Shift) |
+                               (0b1110001 << kFunct7Shift) |
+                               (0b00000 << kRs2Shift);
+constexpr Opcode RO_FCVT_W_D =
+    OP_FP | (0b1100001 << kFunct7Shift) | (0b00000 << kRs2Shift);
+constexpr Opcode RO_FCVT_WU_D =
+    OP_FP | (0b1100001 << kFunct7Shift) | (0b00001 << kRs2Shift);
+constexpr Opcode RO_FCVT_D_W =
+    OP_FP | (0b1101001 << kFunct7Shift) | (0b00000 << kRs2Shift);
+constexpr Opcode RO_FCVT_D_WU =
+    OP_FP | (0b1101001 << kFunct7Shift) | (0b00001 << kRs2Shift);
 
 #ifdef V8_TARGET_ARCH_RISCV64
   // RV64D Standard Extension (in addition to RV32D)
-  RO_FCVT_L_D = OP_FP | (0b1100001 << kFunct7Shift) | (0b00010 << kRs2Shift),
-  RO_FCVT_LU_D = OP_FP | (0b1100001 << kFunct7Shift) | (0b00011 << kRs2Shift),
-  RO_FMV_X_D = OP_FP | (0b000 << kFunct3Shift) | (0b1110001 << kFunct7Shift) |
-               (0b00000 << kRs2Shift),
-  RO_FCVT_D_L = OP_FP | (0b1101001 << kFunct7Shift) | (0b00010 << kRs2Shift),
-  RO_FCVT_D_LU = OP_FP | (0b1101001 << kFunct7Shift) | (0b00011 << kRs2Shift),
-  RO_FMV_D_X = OP_FP | (0b000 << kFunct3Shift) | (0b1111001 << kFunct7Shift) |
-               (0b00000 << kRs2Shift),
+constexpr Opcode RO_FCVT_L_D =
+    OP_FP | (0b1100001 << kFunct7Shift) | (0b00010 << kRs2Shift);
+constexpr Opcode RO_FCVT_LU_D =
+    OP_FP | (0b1100001 << kFunct7Shift) | (0b00011 << kRs2Shift);
+constexpr Opcode RO_FMV_X_D = OP_FP | (0b000 << kFunct3Shift) |
+                              (0b1110001 << kFunct7Shift) |
+                              (0b00000 << kRs2Shift);
+constexpr Opcode RO_FCVT_D_L =
+    OP_FP | (0b1101001 << kFunct7Shift) | (0b00010 << kRs2Shift);
+constexpr Opcode RO_FCVT_D_LU =
+    OP_FP | (0b1101001 << kFunct7Shift) | (0b00011 << kRs2Shift);
+constexpr Opcode RO_FMV_D_X = OP_FP | (0b000 << kFunct3Shift) |
+                              (0b1111001 << kFunct7Shift) |
+                              (0b00000 << kRs2Shift);
 #endif
-};
+// clang-format on
 }  // namespace internal
 }  // namespace v8
 
diff --git a/src/codegen/riscv/constant-riscv-f.h b/src/codegen/riscv/constant-riscv-f.h
index fc742e7d574..c90dc70e200 100644
--- a/src/codegen/riscv/constant-riscv-f.h
+++ b/src/codegen/riscv/constant-riscv-f.h
@@ -7,44 +7,62 @@
 namespace v8 {
 namespace internal {
 
-enum OpcodeRISCVF : uint32_t {
-  // RV32F Standard Extension
-  RO_FLW = LOAD_FP | (0b010 << kFunct3Shift),
-  RO_FSW = STORE_FP | (0b010 << kFunct3Shift),
-  RO_FMADD_S = MADD | (0b00 << kFunct2Shift),
-  RO_FMSUB_S = MSUB | (0b00 << kFunct2Shift),
-  RO_FNMSUB_S = NMSUB | (0b00 << kFunct2Shift),
-  RO_FNMADD_S = NMADD | (0b00 << kFunct2Shift),
-  RO_FADD_S = OP_FP | (0b0000000 << kFunct7Shift),
-  RO_FSUB_S = OP_FP | (0b0000100 << kFunct7Shift),
-  RO_FMUL_S = OP_FP | (0b0001000 << kFunct7Shift),
-  RO_FDIV_S = OP_FP | (0b0001100 << kFunct7Shift),
-  RO_FSQRT_S = OP_FP | (0b0101100 << kFunct7Shift) | (0b00000 << kRs2Shift),
-  RO_FSGNJ_S = OP_FP | (0b000 << kFunct3Shift) | (0b0010000 << kFunct7Shift),
-  RO_FSGNJN_S = OP_FP | (0b001 << kFunct3Shift) | (0b0010000 << kFunct7Shift),
-  RO_FSQNJX_S = OP_FP | (0b010 << kFunct3Shift) | (0b0010000 << kFunct7Shift),
-  RO_FMIN_S = OP_FP | (0b000 << kFunct3Shift) | (0b0010100 << kFunct7Shift),
-  RO_FMAX_S = OP_FP | (0b001 << kFunct3Shift) | (0b0010100 << kFunct7Shift),
-  RO_FCVT_W_S = OP_FP | (0b1100000 << kFunct7Shift) | (0b00000 << kRs2Shift),
-  RO_FCVT_WU_S = OP_FP | (0b1100000 << kFunct7Shift) | (0b00001 << kRs2Shift),
-  RO_FMV = OP_FP | (0b1110000 << kFunct7Shift) | (0b000 << kFunct3Shift) |
-           (0b00000 << kRs2Shift),
-  RO_FEQ_S = OP_FP | (0b010 << kFunct3Shift) | (0b1010000 << kFunct7Shift),
-  RO_FLT_S = OP_FP | (0b001 << kFunct3Shift) | (0b1010000 << kFunct7Shift),
-  RO_FLE_S = OP_FP | (0b000 << kFunct3Shift) | (0b1010000 << kFunct7Shift),
-  RO_FCLASS_S = OP_FP | (0b001 << kFunct3Shift) | (0b1110000 << kFunct7Shift),
-  RO_FCVT_S_W = OP_FP | (0b1101000 << kFunct7Shift) | (0b00000 << kRs2Shift),
-  RO_FCVT_S_WU = OP_FP | (0b1101000 << kFunct7Shift) | (0b00001 << kRs2Shift),
-  RO_FMV_W_X = OP_FP | (0b000 << kFunct3Shift) | (0b1111000 << kFunct7Shift),
+// RV32F Standard Extension
+constexpr Opcode RO_FLW = LOAD_FP | (0b010 << kFunct3Shift);
+constexpr Opcode RO_FSW = STORE_FP | (0b010 << kFunct3Shift);
+constexpr Opcode RO_FMADD_S = MADD | (0b00 << kFunct2Shift);
+constexpr Opcode RO_FMSUB_S = MSUB | (0b00 << kFunct2Shift);
+constexpr Opcode RO_FNMSUB_S = NMSUB | (0b00 << kFunct2Shift);
+constexpr Opcode RO_FNMADD_S = NMADD | (0b00 << kFunct2Shift);
+constexpr Opcode RO_FADD_S = OP_FP | (0b0000000 << kFunct7Shift);
+constexpr Opcode RO_FSUB_S = OP_FP | (0b0000100 << kFunct7Shift);
+constexpr Opcode RO_FMUL_S = OP_FP | (0b0001000 << kFunct7Shift);
+constexpr Opcode RO_FDIV_S = OP_FP | (0b0001100 << kFunct7Shift);
+constexpr Opcode RO_FSQRT_S =
+    OP_FP | (0b0101100 << kFunct7Shift) | (0b00000 << kRs2Shift);
+constexpr Opcode RO_FSGNJ_S =
+    OP_FP | (0b000 << kFunct3Shift) | (0b0010000 << kFunct7Shift);
+constexpr Opcode RO_FSGNJN_S =
+    OP_FP | (0b001 << kFunct3Shift) | (0b0010000 << kFunct7Shift);
+constexpr Opcode RO_FSQNJX_S =
+    OP_FP | (0b010 << kFunct3Shift) | (0b0010000 << kFunct7Shift);
+constexpr Opcode RO_FMIN_S =
+    OP_FP | (0b000 << kFunct3Shift) | (0b0010100 << kFunct7Shift);
+constexpr Opcode RO_FMAX_S =
+    OP_FP | (0b001 << kFunct3Shift) | (0b0010100 << kFunct7Shift);
+constexpr Opcode RO_FCVT_W_S =
+    OP_FP | (0b1100000 << kFunct7Shift) | (0b00000 << kRs2Shift);
+constexpr Opcode RO_FCVT_WU_S =
+    OP_FP | (0b1100000 << kFunct7Shift) | (0b00001 << kRs2Shift);
+constexpr Opcode RO_FMV = OP_FP | (0b1110000 << kFunct7Shift) |
+                          (0b000 << kFunct3Shift) | (0b00000 << kRs2Shift);
+constexpr Opcode RO_FEQ_S =
+    OP_FP | (0b010 << kFunct3Shift) | (0b1010000 << kFunct7Shift);
+constexpr Opcode RO_FLT_S =
+    OP_FP | (0b001 << kFunct3Shift) | (0b1010000 << kFunct7Shift);
+constexpr Opcode RO_FLE_S =
+    OP_FP | (0b000 << kFunct3Shift) | (0b1010000 << kFunct7Shift);
+constexpr Opcode RO_FCLASS_S =
+    OP_FP | (0b001 << kFunct3Shift) | (0b1110000 << kFunct7Shift);
+constexpr Opcode RO_FCVT_S_W =
+    OP_FP | (0b1101000 << kFunct7Shift) | (0b00000 << kRs2Shift);
+constexpr Opcode RO_FCVT_S_WU =
+    OP_FP | (0b1101000 << kFunct7Shift) | (0b00001 << kRs2Shift);
+constexpr Opcode RO_FMV_W_X =
+    OP_FP | (0b000 << kFunct3Shift) | (0b1111000 << kFunct7Shift);
 
 #ifdef V8_TARGET_ARCH_RISCV64
   // RV64F Standard Extension (in addition to RV32F)
-  RO_FCVT_L_S = OP_FP | (0b1100000 << kFunct7Shift) | (0b00010 << kRs2Shift),
-  RO_FCVT_LU_S = OP_FP | (0b1100000 << kFunct7Shift) | (0b00011 << kRs2Shift),
-  RO_FCVT_S_L = OP_FP | (0b1101000 << kFunct7Shift) | (0b00010 << kRs2Shift),
-  RO_FCVT_S_LU = OP_FP | (0b1101000 << kFunct7Shift) | (0b00011 << kRs2Shift),
+constexpr Opcode RO_FCVT_L_S =
+    OP_FP | (0b1100000 << kFunct7Shift) | (0b00010 << kRs2Shift);
+constexpr Opcode RO_FCVT_LU_S =
+    OP_FP | (0b1100000 << kFunct7Shift) | (0b00011 << kRs2Shift);
+constexpr Opcode RO_FCVT_S_L =
+    OP_FP | (0b1101000 << kFunct7Shift) | (0b00010 << kRs2Shift);
+constexpr Opcode RO_FCVT_S_LU =
+    OP_FP | (0b1101000 << kFunct7Shift) | (0b00011 << kRs2Shift);
 #endif  // V8_TARGET_ARCH_RISCV64
-};
+// clang-format on
 }  // namespace internal
 }  // namespace v8
 
diff --git a/src/codegen/riscv/constant-riscv-i.h b/src/codegen/riscv/constant-riscv-i.h
index 75c6c44565b..d19010f933d 100644
--- a/src/codegen/riscv/constant-riscv-i.h
+++ b/src/codegen/riscv/constant-riscv-i.h
@@ -7,66 +7,80 @@
 namespace v8 {
 namespace internal {
 
-enum OpcodeRISCV32I : uint32_t {
-  // Note use RO (RiscV Opcode) prefix
-  // RV32I Base Instruction Set
-  RO_LUI = LUI,
-  RO_AUIPC = AUIPC,
-  RO_JAL = JAL,
-  RO_JALR = JALR | (0b000 << kFunct3Shift),
-  RO_BEQ = BRANCH | (0b000 << kFunct3Shift),
-  RO_BNE = BRANCH | (0b001 << kFunct3Shift),
-  RO_BLT = BRANCH | (0b100 << kFunct3Shift),
-  RO_BGE = BRANCH | (0b101 << kFunct3Shift),
-  RO_BLTU = BRANCH | (0b110 << kFunct3Shift),
-  RO_BGEU = BRANCH | (0b111 << kFunct3Shift),
-  RO_LB = LOAD | (0b000 << kFunct3Shift),
-  RO_LH = LOAD | (0b001 << kFunct3Shift),
-  RO_LW = LOAD | (0b010 << kFunct3Shift),
-  RO_LBU = LOAD | (0b100 << kFunct3Shift),
-  RO_LHU = LOAD | (0b101 << kFunct3Shift),
-  RO_SB = STORE | (0b000 << kFunct3Shift),
-  RO_SH = STORE | (0b001 << kFunct3Shift),
-  RO_SW = STORE | (0b010 << kFunct3Shift),
-  RO_ADDI = OP_IMM | (0b000 << kFunct3Shift),
-  RO_SLTI = OP_IMM | (0b010 << kFunct3Shift),
-  RO_SLTIU = OP_IMM | (0b011 << kFunct3Shift),
-  RO_XORI = OP_IMM | (0b100 << kFunct3Shift),
-  RO_ORI = OP_IMM | (0b110 << kFunct3Shift),
-  RO_ANDI = OP_IMM | (0b111 << kFunct3Shift),
-  RO_SLLI = OP_IMM | (0b001 << kFunct3Shift),
-  RO_SRLI = OP_IMM | (0b101 << kFunct3Shift),
-  // RO_SRAI = OP_IMM | (0b101 << kFunct3Shift), // Same as SRLI, use func7
-  RO_ADD = OP | (0b000 << kFunct3Shift) | (0b0000000 << kFunct7Shift),
-  RO_SUB = OP | (0b000 << kFunct3Shift) | (0b0100000 << kFunct7Shift),
-  RO_SLL = OP | (0b001 << kFunct3Shift) | (0b0000000 << kFunct7Shift),
-  RO_SLT = OP | (0b010 << kFunct3Shift) | (0b0000000 << kFunct7Shift),
-  RO_SLTU = OP | (0b011 << kFunct3Shift) | (0b0000000 << kFunct7Shift),
-  RO_XOR = OP | (0b100 << kFunct3Shift) | (0b0000000 << kFunct7Shift),
-  RO_SRL = OP | (0b101 << kFunct3Shift) | (0b0000000 << kFunct7Shift),
-  RO_SRA = OP | (0b101 << kFunct3Shift) | (0b0100000 << kFunct7Shift),
-  RO_OR = OP | (0b110 << kFunct3Shift) | (0b0000000 << kFunct7Shift),
-  RO_AND = OP | (0b111 << kFunct3Shift) | (0b0000000 << kFunct7Shift),
-  RO_FENCE = MISC_MEM | (0b000 << kFunct3Shift),
-  RO_ECALL = SYSTEM | (0b000 << kFunct3Shift),
+// Note use RO (RiscV Opcode) prefix
+// RV32I Base Instruction Set
+constexpr Opcode RO_LUI = LUI;
+constexpr Opcode RO_AUIPC = AUIPC;
+constexpr Opcode RO_JAL = JAL;
+constexpr Opcode RO_JALR = JALR | (0b000 << kFunct3Shift);
+constexpr Opcode RO_BEQ = BRANCH | (0b000 << kFunct3Shift);
+constexpr Opcode RO_BNE = BRANCH | (0b001 << kFunct3Shift);
+constexpr Opcode RO_BLT = BRANCH | (0b100 << kFunct3Shift);
+constexpr Opcode RO_BGE = BRANCH | (0b101 << kFunct3Shift);
+constexpr Opcode RO_BLTU = BRANCH | (0b110 << kFunct3Shift);
+constexpr Opcode RO_BGEU = BRANCH | (0b111 << kFunct3Shift);
+constexpr Opcode RO_LB = LOAD | (0b000 << kFunct3Shift);
+constexpr Opcode RO_LH = LOAD | (0b001 << kFunct3Shift);
+constexpr Opcode RO_LW = LOAD | (0b010 << kFunct3Shift);
+constexpr Opcode RO_LBU = LOAD | (0b100 << kFunct3Shift);
+constexpr Opcode RO_LHU = LOAD | (0b101 << kFunct3Shift);
+constexpr Opcode RO_SB = STORE | (0b000 << kFunct3Shift);
+constexpr Opcode RO_SH = STORE | (0b001 << kFunct3Shift);
+constexpr Opcode RO_SW = STORE | (0b010 << kFunct3Shift);
+constexpr Opcode RO_ADDI = OP_IMM | (0b000 << kFunct3Shift);
+constexpr Opcode RO_SLTI = OP_IMM | (0b010 << kFunct3Shift);
+constexpr Opcode RO_SLTIU = OP_IMM | (0b011 << kFunct3Shift);
+constexpr Opcode RO_XORI = OP_IMM | (0b100 << kFunct3Shift);
+constexpr Opcode RO_ORI = OP_IMM | (0b110 << kFunct3Shift);
+constexpr Opcode RO_ANDI = OP_IMM | (0b111 << kFunct3Shift);
+constexpr Opcode RO_SLLI = OP_IMM | (0b001 << kFunct3Shift);
+constexpr Opcode RO_SRLI = OP_IMM | (0b101 << kFunct3Shift);
+// RO_SRAI = OP_IMM | (0b101 << kFunct3Shift), // Same as SRLI, use func7
+constexpr Opcode RO_ADD =
+    OP | (0b000 << kFunct3Shift) | (0b0000000 << kFunct7Shift);
+constexpr Opcode RO_SUB =
+    OP | (0b000 << kFunct3Shift) | (0b0100000 << kFunct7Shift);
+constexpr Opcode RO_SLL =
+    OP | (0b001 << kFunct3Shift) | (0b0000000 << kFunct7Shift);
+constexpr Opcode RO_SLT =
+    OP | (0b010 << kFunct3Shift) | (0b0000000 << kFunct7Shift);
+constexpr Opcode RO_SLTU =
+    OP | (0b011 << kFunct3Shift) | (0b0000000 << kFunct7Shift);
+constexpr Opcode RO_XOR =
+    OP | (0b100 << kFunct3Shift) | (0b0000000 << kFunct7Shift);
+constexpr Opcode RO_SRL =
+    OP | (0b101 << kFunct3Shift) | (0b0000000 << kFunct7Shift);
+constexpr Opcode RO_SRA =
+    OP | (0b101 << kFunct3Shift) | (0b0100000 << kFunct7Shift);
+constexpr Opcode RO_OR =
+    OP | (0b110 << kFunct3Shift) | (0b0000000 << kFunct7Shift);
+constexpr Opcode RO_AND =
+    OP | (0b111 << kFunct3Shift) | (0b0000000 << kFunct7Shift);
+constexpr Opcode RO_FENCE = MISC_MEM | (0b000 << kFunct3Shift);
+constexpr Opcode RO_ECALL = SYSTEM | (0b000 << kFunct3Shift);
 // RO_EBREAK = SYSTEM | (0b000 << kFunct3Shift), // Same as ECALL, use imm12
 
 #if V8_TARGET_ARCH_RISCV64
   // RV64I Base Instruction Set (in addition to RV32I)
-  RO_LWU = LOAD | (0b110 << kFunct3Shift),
-  RO_LD = LOAD | (0b011 << kFunct3Shift),
-  RO_SD = STORE | (0b011 << kFunct3Shift),
-  RO_ADDIW = OP_IMM_32 | (0b000 << kFunct3Shift),
-  RO_SLLIW = OP_IMM_32 | (0b001 << kFunct3Shift),
-  RO_SRLIW = OP_IMM_32 | (0b101 << kFunct3Shift),
-  // RO_SRAIW = OP_IMM_32 | (0b101 << kFunct3Shift), // Same as SRLIW, use func7
-  RO_ADDW = OP_32 | (0b000 << kFunct3Shift) | (0b0000000 << kFunct7Shift),
-  RO_SUBW = OP_32 | (0b000 << kFunct3Shift) | (0b0100000 << kFunct7Shift),
-  RO_SLLW = OP_32 | (0b001 << kFunct3Shift) | (0b0000000 << kFunct7Shift),
-  RO_SRLW = OP_32 | (0b101 << kFunct3Shift) | (0b0000000 << kFunct7Shift),
-  RO_SRAW = OP_32 | (0b101 << kFunct3Shift) | (0b0100000 << kFunct7Shift),
+constexpr Opcode RO_LWU = LOAD | (0b110 << kFunct3Shift);
+constexpr Opcode RO_LD = LOAD | (0b011 << kFunct3Shift);
+constexpr Opcode RO_SD = STORE | (0b011 << kFunct3Shift);
+constexpr Opcode RO_ADDIW = OP_IMM_32 | (0b000 << kFunct3Shift);
+constexpr Opcode RO_SLLIW = OP_IMM_32 | (0b001 << kFunct3Shift);
+constexpr Opcode RO_SRLIW = OP_IMM_32 | (0b101 << kFunct3Shift);
+// RO_SRAIW = OP_IMM_32 | (0b101 << kFunct3Shift), // Same as SRLIW, use func7
+constexpr Opcode RO_ADDW =
+    OP_32 | (0b000 << kFunct3Shift) | (0b0000000 << kFunct7Shift);
+constexpr Opcode RO_SUBW =
+    OP_32 | (0b000 << kFunct3Shift) | (0b0100000 << kFunct7Shift);
+constexpr Opcode RO_SLLW =
+    OP_32 | (0b001 << kFunct3Shift) | (0b0000000 << kFunct7Shift);
+constexpr Opcode RO_SRLW =
+    OP_32 | (0b101 << kFunct3Shift) | (0b0000000 << kFunct7Shift);
+constexpr Opcode RO_SRAW =
+    OP_32 | (0b101 << kFunct3Shift) | (0b0100000 << kFunct7Shift);
 #endif
-};
+// clang-format on
 }  // namespace internal
 }  // namespace v8
 
diff --git a/src/codegen/riscv/constant-riscv-m.h b/src/codegen/riscv/constant-riscv-m.h
index 2ad1ffd1b57..a5c349f6d87 100644
--- a/src/codegen/riscv/constant-riscv-m.h
+++ b/src/codegen/riscv/constant-riscv-m.h
@@ -8,26 +8,38 @@
 namespace v8 {
 namespace internal {
 
-enum OpcodeRISCVM : uint32_t {
-  // RV32M Standard Extension
-  RO_MUL = OP | (0b000 << kFunct3Shift) | (0b0000001 << kFunct7Shift),
-  RO_MULH = OP | (0b001 << kFunct3Shift) | (0b0000001 << kFunct7Shift),
-  RO_MULHSU = OP | (0b010 << kFunct3Shift) | (0b0000001 << kFunct7Shift),
-  RO_MULHU = OP | (0b011 << kFunct3Shift) | (0b0000001 << kFunct7Shift),
-  RO_DIV = OP | (0b100 << kFunct3Shift) | (0b0000001 << kFunct7Shift),
-  RO_DIVU = OP | (0b101 << kFunct3Shift) | (0b0000001 << kFunct7Shift),
-  RO_REM = OP | (0b110 << kFunct3Shift) | (0b0000001 << kFunct7Shift),
-  RO_REMU = OP | (0b111 << kFunct3Shift) | (0b0000001 << kFunct7Shift),
+// RV32M Standard Extension
+constexpr Opcode RO_MUL =
+    OP | (0b000 << kFunct3Shift) | (0b0000001 << kFunct7Shift);
+constexpr Opcode RO_MULH =
+    OP | (0b001 << kFunct3Shift) | (0b0000001 << kFunct7Shift);
+constexpr Opcode RO_MULHSU =
+    OP | (0b010 << kFunct3Shift) | (0b0000001 << kFunct7Shift);
+constexpr Opcode RO_MULHU =
+    OP | (0b011 << kFunct3Shift) | (0b0000001 << kFunct7Shift);
+constexpr Opcode RO_DIV =
+    OP | (0b100 << kFunct3Shift) | (0b0000001 << kFunct7Shift);
+constexpr Opcode RO_DIVU =
+    OP | (0b101 << kFunct3Shift) | (0b0000001 << kFunct7Shift);
+constexpr Opcode RO_REM =
+    OP | (0b110 << kFunct3Shift) | (0b0000001 << kFunct7Shift);
+constexpr Opcode RO_REMU =
+    OP | (0b111 << kFunct3Shift) | (0b0000001 << kFunct7Shift);
 
 #ifdef V8_TARGET_ARCH_RISCV64
-  // RV64M Standard Extension (in addition to RV32M)
-  RO_MULW = OP_32 | (0b000 << kFunct3Shift) | (0b0000001 << kFunct7Shift),
-  RO_DIVW = OP_32 | (0b100 << kFunct3Shift) | (0b0000001 << kFunct7Shift),
-  RO_DIVUW = OP_32 | (0b101 << kFunct3Shift) | (0b0000001 << kFunct7Shift),
-  RO_REMW = OP_32 | (0b110 << kFunct3Shift) | (0b0000001 << kFunct7Shift),
-  RO_REMUW = OP_32 | (0b111 << kFunct3Shift) | (0b0000001 << kFunct7Shift),
+// RV64M Standard Extension (in addition to RV32M)
+constexpr Opcode RO_MULW =
+    OP_32 | (0b000 << kFunct3Shift) | (0b0000001 << kFunct7Shift);
+constexpr Opcode RO_DIVW =
+    OP_32 | (0b100 << kFunct3Shift) | (0b0000001 << kFunct7Shift);
+constexpr Opcode RO_DIVUW =
+    OP_32 | (0b101 << kFunct3Shift) | (0b0000001 << kFunct7Shift);
+constexpr Opcode RO_REMW =
+    OP_32 | (0b110 << kFunct3Shift) | (0b0000001 << kFunct7Shift);
+constexpr Opcode RO_REMUW =
+    OP_32 | (0b111 << kFunct3Shift) | (0b0000001 << kFunct7Shift);
 #endif
-};
+// clang-format on
 }  // namespace internal
 }  // namespace v8
 
diff --git a/src/codegen/riscv/constant-riscv-v.h b/src/codegen/riscv/constant-riscv-v.h
index 30ff0c1a244..b5dddcc6663 100644
--- a/src/codegen/riscv/constant-riscv-v.h
+++ b/src/codegen/riscv/constant-riscv-v.h
@@ -8,485 +8,554 @@
 namespace v8 {
 namespace internal {
 
-enum OpcodeRISCVV : uint32_t {
-  // RVV Extension
-  OP_IVV = OP_V | (0b000 << kFunct3Shift),
-  OP_FVV = OP_V | (0b001 << kFunct3Shift),
-  OP_MVV = OP_V | (0b010 << kFunct3Shift),
-  OP_IVI = OP_V | (0b011 << kFunct3Shift),
-  OP_IVX = OP_V | (0b100 << kFunct3Shift),
-  OP_FVF = OP_V | (0b101 << kFunct3Shift),
-  OP_MVX = OP_V | (0b110 << kFunct3Shift),
-
-  RO_V_VSETVLI = OP_V | (0b111 << kFunct3Shift) | 0b0 << 31,
-  RO_V_VSETIVLI = OP_V | (0b111 << kFunct3Shift) | 0b11 << 30,
-  RO_V_VSETVL = OP_V | (0b111 << kFunct3Shift) | 0b1 << 31,
-
-  // RVV LOAD/STORE
-  RO_V_VL = LOAD_FP | (0b00 << kRvvMopShift) | (0b000 << kRvvNfShift),
-  RO_V_VLS = LOAD_FP | (0b10 << kRvvMopShift) | (0b000 << kRvvNfShift),
-  RO_V_VLX = LOAD_FP | (0b11 << kRvvMopShift) | (0b000 << kRvvNfShift),
-
-  RO_V_VS = STORE_FP | (0b00 << kRvvMopShift) | (0b000 << kRvvNfShift),
-  RO_V_VSS = STORE_FP | (0b10 << kRvvMopShift) | (0b000 << kRvvNfShift),
-  RO_V_VSX = STORE_FP | (0b11 << kRvvMopShift) | (0b000 << kRvvNfShift),
-  RO_V_VSU = STORE_FP | (0b01 << kRvvMopShift) | (0b000 << kRvvNfShift),
-  // THE kFunct6Shift is mop
-  RO_V_VLSEG2 = LOAD_FP | (0b00 << kRvvMopShift) | (0b001 << kRvvNfShift),
-  RO_V_VLSEG3 = LOAD_FP | (0b00 << kRvvMopShift) | (0b010 << kRvvNfShift),
-  RO_V_VLSEG4 = LOAD_FP | (0b00 << kRvvMopShift) | (0b011 << kRvvNfShift),
-  RO_V_VLSEG5 = LOAD_FP | (0b00 << kRvvMopShift) | (0b100 << kRvvNfShift),
-  RO_V_VLSEG6 = LOAD_FP | (0b00 << kRvvMopShift) | (0b101 << kRvvNfShift),
-  RO_V_VLSEG7 = LOAD_FP | (0b00 << kRvvMopShift) | (0b110 << kRvvNfShift),
-  RO_V_VLSEG8 = LOAD_FP | (0b00 << kRvvMopShift) | (0b111 << kRvvNfShift),
-
-  RO_V_VSSEG2 = STORE_FP | (0b00 << kRvvMopShift) | (0b001 << kRvvNfShift),
-  RO_V_VSSEG3 = STORE_FP | (0b00 << kRvvMopShift) | (0b010 << kRvvNfShift),
-  RO_V_VSSEG4 = STORE_FP | (0b00 << kRvvMopShift) | (0b011 << kRvvNfShift),
-  RO_V_VSSEG5 = STORE_FP | (0b00 << kRvvMopShift) | (0b100 << kRvvNfShift),
-  RO_V_VSSEG6 = STORE_FP | (0b00 << kRvvMopShift) | (0b101 << kRvvNfShift),
-  RO_V_VSSEG7 = STORE_FP | (0b00 << kRvvMopShift) | (0b110 << kRvvNfShift),
-  RO_V_VSSEG8 = STORE_FP | (0b00 << kRvvMopShift) | (0b111 << kRvvNfShift),
-
-  RO_V_VLSSEG2 = LOAD_FP | (0b10 << kRvvMopShift) | (0b001 << kRvvNfShift),
-  RO_V_VLSSEG3 = LOAD_FP | (0b10 << kRvvMopShift) | (0b010 << kRvvNfShift),
-  RO_V_VLSSEG4 = LOAD_FP | (0b10 << kRvvMopShift) | (0b011 << kRvvNfShift),
-  RO_V_VLSSEG5 = LOAD_FP | (0b10 << kRvvMopShift) | (0b100 << kRvvNfShift),
-  RO_V_VLSSEG6 = LOAD_FP | (0b10 << kRvvMopShift) | (0b101 << kRvvNfShift),
-  RO_V_VLSSEG7 = LOAD_FP | (0b10 << kRvvMopShift) | (0b110 << kRvvNfShift),
-  RO_V_VLSSEG8 = LOAD_FP | (0b10 << kRvvMopShift) | (0b111 << kRvvNfShift),
-
-  RO_V_VSSSEG2 = STORE_FP | (0b10 << kRvvMopShift) | (0b001 << kRvvNfShift),
-  RO_V_VSSSEG3 = STORE_FP | (0b10 << kRvvMopShift) | (0b010 << kRvvNfShift),
-  RO_V_VSSSEG4 = STORE_FP | (0b10 << kRvvMopShift) | (0b011 << kRvvNfShift),
-  RO_V_VSSSEG5 = STORE_FP | (0b10 << kRvvMopShift) | (0b100 << kRvvNfShift),
-  RO_V_VSSSEG6 = STORE_FP | (0b10 << kRvvMopShift) | (0b101 << kRvvNfShift),
-  RO_V_VSSSEG7 = STORE_FP | (0b10 << kRvvMopShift) | (0b110 << kRvvNfShift),
-  RO_V_VSSSEG8 = STORE_FP | (0b10 << kRvvMopShift) | (0b111 << kRvvNfShift),
-
-  RO_V_VLXSEG2 = LOAD_FP | (0b11 << kRvvMopShift) | (0b001 << kRvvNfShift),
-  RO_V_VLXSEG3 = LOAD_FP | (0b11 << kRvvMopShift) | (0b010 << kRvvNfShift),
-  RO_V_VLXSEG4 = LOAD_FP | (0b11 << kRvvMopShift) | (0b011 << kRvvNfShift),
-  RO_V_VLXSEG5 = LOAD_FP | (0b11 << kRvvMopShift) | (0b100 << kRvvNfShift),
-  RO_V_VLXSEG6 = LOAD_FP | (0b11 << kRvvMopShift) | (0b101 << kRvvNfShift),
-  RO_V_VLXSEG7 = LOAD_FP | (0b11 << kRvvMopShift) | (0b110 << kRvvNfShift),
-  RO_V_VLXSEG8 = LOAD_FP | (0b11 << kRvvMopShift) | (0b111 << kRvvNfShift),
-
-  RO_V_VSXSEG2 = STORE_FP | (0b11 << kRvvMopShift) | (0b001 << kRvvNfShift),
-  RO_V_VSXSEG3 = STORE_FP | (0b11 << kRvvMopShift) | (0b010 << kRvvNfShift),
-  RO_V_VSXSEG4 = STORE_FP | (0b11 << kRvvMopShift) | (0b011 << kRvvNfShift),
-  RO_V_VSXSEG5 = STORE_FP | (0b11 << kRvvMopShift) | (0b100 << kRvvNfShift),
-  RO_V_VSXSEG6 = STORE_FP | (0b11 << kRvvMopShift) | (0b101 << kRvvNfShift),
-  RO_V_VSXSEG7 = STORE_FP | (0b11 << kRvvMopShift) | (0b110 << kRvvNfShift),
-  RO_V_VSXSEG8 = STORE_FP | (0b11 << kRvvMopShift) | (0b111 << kRvvNfShift),
-
-  // RVV Vector Arithmetic Instruction
-  VADD_FUNCT6 = 0b000000,
-  RO_V_VADD_VI = OP_IVI | (VADD_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VADD_VV = OP_IVV | (VADD_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VADD_VX = OP_IVX | (VADD_FUNCT6 << kRvvFunct6Shift),
-
-  VSUB_FUNCT6 = 0b000010,
-  RO_V_VSUB_VX = OP_IVX | (VSUB_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VSUB_VV = OP_IVV | (VSUB_FUNCT6 << kRvvFunct6Shift),
-
-  VDIVU_FUNCT6 = 0b100000,
-  RO_V_VDIVU_VX = OP_MVX | (VDIVU_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VDIVU_VV = OP_MVV | (VDIVU_FUNCT6 << kRvvFunct6Shift),
-
-  VDIV_FUNCT6 = 0b100001,
-  RO_V_VDIV_VX = OP_MVX | (VDIV_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VDIV_VV = OP_MVV | (VDIV_FUNCT6 << kRvvFunct6Shift),
-
-  VREMU_FUNCT6 = 0b100010,
-  RO_V_VREMU_VX = OP_MVX | (VREMU_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VREMU_VV = OP_MVV | (VREMU_FUNCT6 << kRvvFunct6Shift),
-
-  VREM_FUNCT6 = 0b100011,
-  RO_V_VREM_VX = OP_MVX | (VREM_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VREM_VV = OP_MVV | (VREM_FUNCT6 << kRvvFunct6Shift),
-
-  VMULHU_FUNCT6 = 0b100100,
-  RO_V_VMULHU_VX = OP_MVX | (VMULHU_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VMULHU_VV = OP_MVV | (VMULHU_FUNCT6 << kRvvFunct6Shift),
-
-  VMUL_FUNCT6 = 0b100101,
-  RO_V_VMUL_VX = OP_MVX | (VMUL_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VMUL_VV = OP_MVV | (VMUL_FUNCT6 << kRvvFunct6Shift),
-
-  VWMUL_FUNCT6 = 0b111011,
-  RO_V_VWMUL_VX = OP_MVX | (VWMUL_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VWMUL_VV = OP_MVV | (VWMUL_FUNCT6 << kRvvFunct6Shift),
-
-  VWMULU_FUNCT6 = 0b111000,
-  RO_V_VWMULU_VX = OP_MVX | (VWMULU_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VWMULU_VV = OP_MVV | (VWMULU_FUNCT6 << kRvvFunct6Shift),
-
-  VMULHSU_FUNCT6 = 0b100110,
-  RO_V_VMULHSU_VX = OP_MVX | (VMULHSU_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VMULHSU_VV = OP_MVV | (VMULHSU_FUNCT6 << kRvvFunct6Shift),
-
-  VMULH_FUNCT6 = 0b100111,
-  RO_V_VMULH_VX = OP_MVX | (VMULH_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VMULH_VV = OP_MVV | (VMULH_FUNCT6 << kRvvFunct6Shift),
-
-  VWADD_FUNCT6 = 0b110001,
-  RO_V_VWADD_VV = OP_MVV | (VWADD_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VWADD_VX = OP_MVX | (VWADD_FUNCT6 << kRvvFunct6Shift),
-
-  VWADDU_FUNCT6 = 0b110000,
-  RO_V_VWADDU_VV = OP_MVV | (VWADDU_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VWADDU_VX = OP_MVX | (VWADDU_FUNCT6 << kRvvFunct6Shift),
-
-  VWADDUW_FUNCT6 = 0b110101,
-  RO_V_VWADDUW_VX = OP_MVX | (VWADDUW_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VWADDUW_VV = OP_MVV | (VWADDUW_FUNCT6 << kRvvFunct6Shift),
-
-  VCOMPRESS_FUNCT6 = 0b010111,
-  RO_V_VCOMPRESS_VV = OP_MVV | (VCOMPRESS_FUNCT6 << kRvvFunct6Shift),
-
-  VSADDU_FUNCT6 = 0b100000,
-  RO_V_VSADDU_VI = OP_IVI | (VSADDU_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VSADDU_VV = OP_IVV | (VSADDU_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VSADDU_VX = OP_IVX | (VSADDU_FUNCT6 << kRvvFunct6Shift),
-
-  VSADD_FUNCT6 = 0b100001,
-  RO_V_VSADD_VI = OP_IVI | (VSADD_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VSADD_VV = OP_IVV | (VSADD_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VSADD_VX = OP_IVX | (VSADD_FUNCT6 << kRvvFunct6Shift),
-
-  VSSUB_FUNCT6 = 0b100011,
-  RO_V_VSSUB_VV = OP_IVV | (VSSUB_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VSSUB_VX = OP_IVX | (VSSUB_FUNCT6 << kRvvFunct6Shift),
-
-  VSSUBU_FUNCT6 = 0b100010,
-  RO_V_VSSUBU_VV = OP_IVV | (VSSUBU_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VSSUBU_VX = OP_IVX | (VSSUBU_FUNCT6 << kRvvFunct6Shift),
-
-  VRSUB_FUNCT6 = 0b000011,
-  RO_V_VRSUB_VX = OP_IVX | (VRSUB_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VRSUB_VI = OP_IVI | (VRSUB_FUNCT6 << kRvvFunct6Shift),
-
-  VMINU_FUNCT6 = 0b000100,
-  RO_V_VMINU_VX = OP_IVX | (VMINU_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VMINU_VV = OP_IVV | (VMINU_FUNCT6 << kRvvFunct6Shift),
-
-  VMIN_FUNCT6 = 0b000101,
-  RO_V_VMIN_VX = OP_IVX | (VMIN_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VMIN_VV = OP_IVV | (VMIN_FUNCT6 << kRvvFunct6Shift),
-
-  VMAXU_FUNCT6 = 0b000110,
-  RO_V_VMAXU_VX = OP_IVX | (VMAXU_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VMAXU_VV = OP_IVV | (VMAXU_FUNCT6 << kRvvFunct6Shift),
-
-  VMAX_FUNCT6 = 0b000111,
-  RO_V_VMAX_VX = OP_IVX | (VMAX_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VMAX_VV = OP_IVV | (VMAX_FUNCT6 << kRvvFunct6Shift),
-
-  VAND_FUNCT6 = 0b001001,
-  RO_V_VAND_VI = OP_IVI | (VAND_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VAND_VV = OP_IVV | (VAND_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VAND_VX = OP_IVX | (VAND_FUNCT6 << kRvvFunct6Shift),
-
-  VOR_FUNCT6 = 0b001010,
-  RO_V_VOR_VI = OP_IVI | (VOR_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VOR_VV = OP_IVV | (VOR_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VOR_VX = OP_IVX | (VOR_FUNCT6 << kRvvFunct6Shift),
-
-  VXOR_FUNCT6 = 0b001011,
-  RO_V_VXOR_VI = OP_IVI | (VXOR_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VXOR_VV = OP_IVV | (VXOR_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VXOR_VX = OP_IVX | (VXOR_FUNCT6 << kRvvFunct6Shift),
-
-  VRGATHER_FUNCT6 = 0b001100,
-  RO_V_VRGATHER_VI = OP_IVI | (VRGATHER_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VRGATHER_VV = OP_IVV | (VRGATHER_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VRGATHER_VX = OP_IVX | (VRGATHER_FUNCT6 << kRvvFunct6Shift),
-
-  VMV_FUNCT6 = 0b010111,
-  RO_V_VMV_VI = OP_IVI | (VMV_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VMV_VV = OP_IVV | (VMV_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VMV_VX = OP_IVX | (VMV_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VFMV_VF = OP_FVF | (VMV_FUNCT6 << kRvvFunct6Shift),
-
-  RO_V_VMERGE_VI = RO_V_VMV_VI,
-  RO_V_VMERGE_VV = RO_V_VMV_VV,
-  RO_V_VMERGE_VX = RO_V_VMV_VX,
-
-  VMSEQ_FUNCT6 = 0b011000,
-  RO_V_VMSEQ_VI = OP_IVI | (VMSEQ_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VMSEQ_VV = OP_IVV | (VMSEQ_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VMSEQ_VX = OP_IVX | (VMSEQ_FUNCT6 << kRvvFunct6Shift),
-
-  VMSNE_FUNCT6 = 0b011001,
-  RO_V_VMSNE_VI = OP_IVI | (VMSNE_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VMSNE_VV = OP_IVV | (VMSNE_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VMSNE_VX = OP_IVX | (VMSNE_FUNCT6 << kRvvFunct6Shift),
-
-  VMSLTU_FUNCT6 = 0b011010,
-  RO_V_VMSLTU_VV = OP_IVV | (VMSLTU_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VMSLTU_VX = OP_IVX | (VMSLTU_FUNCT6 << kRvvFunct6Shift),
-
-  VMSLT_FUNCT6 = 0b011011,
-  RO_V_VMSLT_VV = OP_IVV | (VMSLT_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VMSLT_VX = OP_IVX | (VMSLT_FUNCT6 << kRvvFunct6Shift),
-
-  VMSLE_FUNCT6 = 0b011101,
-  RO_V_VMSLE_VI = OP_IVI | (VMSLE_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VMSLE_VV = OP_IVV | (VMSLE_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VMSLE_VX = OP_IVX | (VMSLE_FUNCT6 << kRvvFunct6Shift),
-
-  VMSLEU_FUNCT6 = 0b011100,
-  RO_V_VMSLEU_VI = OP_IVI | (VMSLEU_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VMSLEU_VV = OP_IVV | (VMSLEU_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VMSLEU_VX = OP_IVX | (VMSLEU_FUNCT6 << kRvvFunct6Shift),
-
-  VMSGTU_FUNCT6 = 0b011110,
-  RO_V_VMSGTU_VI = OP_IVI | (VMSGTU_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VMSGTU_VX = OP_IVX | (VMSGTU_FUNCT6 << kRvvFunct6Shift),
-
-  VMSGT_FUNCT6 = 0b011111,
-  RO_V_VMSGT_VI = OP_IVI | (VMSGT_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VMSGT_VX = OP_IVX | (VMSGT_FUNCT6 << kRvvFunct6Shift),
-
-  VSLIDEUP_FUNCT6 = 0b001110,
-  RO_V_VSLIDEUP_VI = OP_IVI | (VSLIDEUP_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VSLIDEUP_VX = OP_IVX | (VSLIDEUP_FUNCT6 << kRvvFunct6Shift),
-
-  VSLIDEDOWN_FUNCT6 = 0b001111,
-  RO_V_VSLIDEDOWN_VI = OP_IVI | (VSLIDEDOWN_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VSLIDEDOWN_VX = OP_IVX | (VSLIDEDOWN_FUNCT6 << kRvvFunct6Shift),
-
-  VSRL_FUNCT6 = 0b101000,
-  RO_V_VSRL_VI = OP_IVI | (VSRL_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VSRL_VV = OP_IVV | (VSRL_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VSRL_VX = OP_IVX | (VSRL_FUNCT6 << kRvvFunct6Shift),
-
-  VSRA_FUNCT6 = 0b101001,
-  RO_V_VSRA_VI = OP_IVI | (VSRA_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VSRA_VV = OP_IVV | (VSRA_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VSRA_VX = OP_IVX | (VSRA_FUNCT6 << kRvvFunct6Shift),
-
-  VSLL_FUNCT6 = 0b100101,
-  RO_V_VSLL_VI = OP_IVI | (VSLL_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VSLL_VV = OP_IVV | (VSLL_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VSLL_VX = OP_IVX | (VSLL_FUNCT6 << kRvvFunct6Shift),
-
-  VSMUL_FUNCT6 = 0b100111,
-  RO_V_VSMUL_VV = OP_IVV | (VSMUL_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VSMUL_VX = OP_IVX | (VSMUL_FUNCT6 << kRvvFunct6Shift),
-
-  VADC_FUNCT6 = 0b010000,
-  RO_V_VADC_VI = OP_IVI | (VADC_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VADC_VV = OP_IVV | (VADC_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VADC_VX = OP_IVX | (VADC_FUNCT6 << kRvvFunct6Shift),
-
-  VMADC_FUNCT6 = 0b010001,
-  RO_V_VMADC_VI = OP_IVI | (VMADC_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VMADC_VV = OP_IVV | (VMADC_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VMADC_VX = OP_IVX | (VMADC_FUNCT6 << kRvvFunct6Shift),
-
-  VWXUNARY0_FUNCT6 = 0b010000,
-  VRXUNARY0_FUNCT6 = 0b010000,
-  VMUNARY0_FUNCT6 = 0b010100,
-
-  RO_V_VWXUNARY0 = OP_MVV | (VWXUNARY0_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VRXUNARY0 = OP_MVX | (VRXUNARY0_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VMUNARY0 = OP_MVV | (VMUNARY0_FUNCT6 << kRvvFunct6Shift),
-
-  VID_V = 0b10001,
-
-  VXUNARY0_FUNCT6 = 0b010010,
-  RO_V_VXUNARY0 = OP_MVV | (VXUNARY0_FUNCT6 << kRvvFunct6Shift),
-
-  VWFUNARY0_FUNCT6 = 0b010000,
-  RO_V_VFMV_FS = OP_FVV | (VWFUNARY0_FUNCT6 << kRvvFunct6Shift),
-
-  VRFUNARY0_FUNCT6 = 0b010000,
-  RO_V_VFMV_SF = OP_FVF | (VRFUNARY0_FUNCT6 << kRvvFunct6Shift),
-
-  VREDMAXU_FUNCT6 = 0b000110,
-  RO_V_VREDMAXU = OP_MVV | (VREDMAXU_FUNCT6 << kRvvFunct6Shift),
-  VREDMAX_FUNCT6 = 0b000111,
-  RO_V_VREDMAX = OP_MVV | (VREDMAX_FUNCT6 << kRvvFunct6Shift),
-
-  VREDMINU_FUNCT6 = 0b000100,
-  RO_V_VREDMINU = OP_MVV | (VREDMINU_FUNCT6 << kRvvFunct6Shift),
-  VREDMIN_FUNCT6 = 0b000101,
-  RO_V_VREDMIN = OP_MVV | (VREDMIN_FUNCT6 << kRvvFunct6Shift),
-
-  VFUNARY0_FUNCT6 = 0b010010,
-  RO_V_VFUNARY0 = OP_FVV | (VFUNARY0_FUNCT6 << kRvvFunct6Shift),
-  VFUNARY1_FUNCT6 = 0b010011,
-  RO_V_VFUNARY1 = OP_FVV | (VFUNARY1_FUNCT6 << kRvvFunct6Shift),
-
-  VFCVT_XU_F_V = 0b00000,
-  VFCVT_X_F_V = 0b00001,
-  VFCVT_F_XU_V = 0b00010,
-  VFCVT_F_X_V = 0b00011,
-  VFWCVT_XU_F_V = 0b01000,
-  VFWCVT_X_F_V = 0b01001,
-  VFWCVT_F_XU_V = 0b01010,
-  VFWCVT_F_X_V = 0b01011,
-  VFWCVT_F_F_V = 0b01100,
-  VFNCVT_F_F_W = 0b10100,
-  VFNCVT_X_F_W = 0b10001,
-  VFNCVT_XU_F_W = 0b10000,
-
-  VFCLASS_V = 0b10000,
-  VFSQRT_V = 0b00000,
-  VFRSQRT7_V = 0b00100,
-  VFREC7_V = 0b00101,
-
-  VFADD_FUNCT6 = 0b000000,
-  RO_V_VFADD_VV = OP_FVV | (VFADD_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VFADD_VF = OP_FVF | (VFADD_FUNCT6 << kRvvFunct6Shift),
-
-  VFSUB_FUNCT6 = 0b000010,
-  RO_V_VFSUB_VV = OP_FVV | (VFSUB_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VFSUB_VF = OP_FVF | (VFSUB_FUNCT6 << kRvvFunct6Shift),
-
-  VFDIV_FUNCT6 = 0b100000,
-  RO_V_VFDIV_VV = OP_FVV | (VFDIV_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VFDIV_VF = OP_FVF | (VFDIV_FUNCT6 << kRvvFunct6Shift),
-
-  VFMUL_FUNCT6 = 0b100100,
-  RO_V_VFMUL_VV = OP_FVV | (VFMUL_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VFMUL_VF = OP_FVF | (VFMUL_FUNCT6 << kRvvFunct6Shift),
-
-  // Vector Widening Floating-Point Add/Subtract Instructions
-  VFWADD_FUNCT6 = 0b110000,
-  RO_V_VFWADD_VV = OP_FVV | (VFWADD_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VFWADD_VF = OP_FVF | (VFWADD_FUNCT6 << kRvvFunct6Shift),
-
-  VFWSUB_FUNCT6 = 0b110010,
-  RO_V_VFWSUB_VV = OP_FVV | (VFWSUB_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VFWSUB_VF = OP_FVF | (VFWSUB_FUNCT6 << kRvvFunct6Shift),
-
-  VFWADD_W_FUNCT6 = 0b110100,
-  RO_V_VFWADD_W_VV = OP_FVV | (VFWADD_W_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VFWADD_W_VF = OP_FVF | (VFWADD_W_FUNCT6 << kRvvFunct6Shift),
-
-  VFWSUB_W_FUNCT6 = 0b110110,
-  RO_V_VFWSUB_W_VV = OP_FVV | (VFWSUB_W_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VFWSUB_W_VF = OP_FVF | (VFWSUB_W_FUNCT6 << kRvvFunct6Shift),
-
-  // Vector Widening Floating-Point Reduction Instructions
-  VFWREDUSUM_FUNCT6 = 0b110001,
-  RO_V_VFWREDUSUM_VV = OP_FVV | (VFWREDUSUM_FUNCT6 << kRvvFunct6Shift),
-
-  VFWREDOSUM_FUNCT6 = 0b110011,
-  RO_V_VFWREDOSUM_VV = OP_FVV | (VFWREDOSUM_FUNCT6 << kRvvFunct6Shift),
-
-  // Vector Widening Floating-Point Multiply
-  VFWMUL_FUNCT6 = 0b111000,
-  RO_V_VFWMUL_VV = OP_FVV | (VFWMUL_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VFWMUL_VF = OP_FVF | (VFWMUL_FUNCT6 << kRvvFunct6Shift),
-
-  VMFEQ_FUNCT6 = 0b011000,
-  RO_V_VMFEQ_VV = OP_FVV | (VMFEQ_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VMFEQ_VF = OP_FVF | (VMFEQ_FUNCT6 << kRvvFunct6Shift),
-
-  VMFNE_FUNCT6 = 0b011100,
-  RO_V_VMFNE_VV = OP_FVV | (VMFNE_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VMFNE_VF = OP_FVF | (VMFNE_FUNCT6 << kRvvFunct6Shift),
-
-  VMFLT_FUNCT6 = 0b011011,
-  RO_V_VMFLT_VV = OP_FVV | (VMFLT_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VMFLT_VF = OP_FVF | (VMFLT_FUNCT6 << kRvvFunct6Shift),
-
-  VMFLE_FUNCT6 = 0b011001,
-  RO_V_VMFLE_VV = OP_FVV | (VMFLE_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VMFLE_VF = OP_FVF | (VMFLE_FUNCT6 << kRvvFunct6Shift),
-
-  VMFGE_FUNCT6 = 0b011111,
-  RO_V_VMFGE_VF = OP_FVF | (VMFGE_FUNCT6 << kRvvFunct6Shift),
-
-  VMFGT_FUNCT6 = 0b011101,
-  RO_V_VMFGT_VF = OP_FVF | (VMFGT_FUNCT6 << kRvvFunct6Shift),
-
-  VFMAX_FUNCT6 = 0b000110,
-  RO_V_VFMAX_VV = OP_FVV | (VFMAX_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VFMAX_VF = OP_FVF | (VFMAX_FUNCT6 << kRvvFunct6Shift),
-
-  VFREDMAX_FUNCT6 = 0b0001111,
-  RO_V_VFREDMAX_VV = OP_FVV | (VFREDMAX_FUNCT6 << kRvvFunct6Shift),
-
-  VFMIN_FUNCT6 = 0b000100,
-  RO_V_VFMIN_VV = OP_FVV | (VFMIN_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VFMIN_VF = OP_FVF | (VFMIN_FUNCT6 << kRvvFunct6Shift),
-
-  VFSGNJ_FUNCT6 = 0b001000,
-  RO_V_VFSGNJ_VV = OP_FVV | (VFSGNJ_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VFSGNJ_VF = OP_FVF | (VFSGNJ_FUNCT6 << kRvvFunct6Shift),
-
-  VFSGNJN_FUNCT6 = 0b001001,
-  RO_V_VFSGNJN_VV = OP_FVV | (VFSGNJN_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VFSGNJN_VF = OP_FVF | (VFSGNJN_FUNCT6 << kRvvFunct6Shift),
-
-  VFSGNJX_FUNCT6 = 0b001010,
-  RO_V_VFSGNJX_VV = OP_FVV | (VFSGNJX_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VFSGNJX_VF = OP_FVF | (VFSGNJX_FUNCT6 << kRvvFunct6Shift),
-
-  VFMADD_FUNCT6 = 0b101000,
-  RO_V_VFMADD_VV = OP_FVV | (VFMADD_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VFMADD_VF = OP_FVF | (VFMADD_FUNCT6 << kRvvFunct6Shift),
-
-  VFNMADD_FUNCT6 = 0b101001,
-  RO_V_VFNMADD_VV = OP_FVV | (VFNMADD_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VFNMADD_VF = OP_FVF | (VFNMADD_FUNCT6 << kRvvFunct6Shift),
-
-  VFMSUB_FUNCT6 = 0b101010,
-  RO_V_VFMSUB_VV = OP_FVV | (VFMSUB_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VFMSUB_VF = OP_FVF | (VFMSUB_FUNCT6 << kRvvFunct6Shift),
-
-  VFNMSUB_FUNCT6 = 0b101011,
-  RO_V_VFNMSUB_VV = OP_FVV | (VFNMSUB_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VFNMSUB_VF = OP_FVF | (VFNMSUB_FUNCT6 << kRvvFunct6Shift),
-
-  VFMACC_FUNCT6 = 0b101100,
-  RO_V_VFMACC_VV = OP_FVV | (VFMACC_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VFMACC_VF = OP_FVF | (VFMACC_FUNCT6 << kRvvFunct6Shift),
-
-  VFNMACC_FUNCT6 = 0b101101,
-  RO_V_VFNMACC_VV = OP_FVV | (VFNMACC_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VFNMACC_VF = OP_FVF | (VFNMACC_FUNCT6 << kRvvFunct6Shift),
-
-  VFMSAC_FUNCT6 = 0b101110,
-  RO_V_VFMSAC_VV = OP_FVV | (VFMSAC_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VFMSAC_VF = OP_FVF | (VFMSAC_FUNCT6 << kRvvFunct6Shift),
-
-  VFNMSAC_FUNCT6 = 0b101111,
-  RO_V_VFNMSAC_VV = OP_FVV | (VFNMSAC_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VFNMSAC_VF = OP_FVF | (VFNMSAC_FUNCT6 << kRvvFunct6Shift),
-
-  // Vector Widening Floating-Point Fused Multiply-Add Instructions
-  VFWMACC_FUNCT6 = 0b111100,
-  RO_V_VFWMACC_VV = OP_FVV | (VFWMACC_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VFWMACC_VF = OP_FVF | (VFWMACC_FUNCT6 << kRvvFunct6Shift),
-
-  VFWNMACC_FUNCT6 = 0b111101,
-  RO_V_VFWNMACC_VV = OP_FVV | (VFWNMACC_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VFWNMACC_VF = OP_FVF | (VFWNMACC_FUNCT6 << kRvvFunct6Shift),
-
-  VFWMSAC_FUNCT6 = 0b111110,
-  RO_V_VFWMSAC_VV = OP_FVV | (VFWMSAC_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VFWMSAC_VF = OP_FVF | (VFWMSAC_FUNCT6 << kRvvFunct6Shift),
-
-  VFWNMSAC_FUNCT6 = 0b111111,
-  RO_V_VFWNMSAC_VV = OP_FVV | (VFWNMSAC_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VFWNMSAC_VF = OP_FVF | (VFWNMSAC_FUNCT6 << kRvvFunct6Shift),
-
-  VNCLIP_FUNCT6 = 0b101111,
-  RO_V_VNCLIP_WV = OP_IVV | (VNCLIP_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VNCLIP_WX = OP_IVX | (VNCLIP_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VNCLIP_WI = OP_IVI | (VNCLIP_FUNCT6 << kRvvFunct6Shift),
-
-  VNCLIPU_FUNCT6 = 0b101110,
-  RO_V_VNCLIPU_WV = OP_IVV | (VNCLIPU_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VNCLIPU_WX = OP_IVX | (VNCLIPU_FUNCT6 << kRvvFunct6Shift),
-  RO_V_VNCLIPU_WI = OP_IVI | (VNCLIPU_FUNCT6 << kRvvFunct6Shift),
-};
+// RVV Extension
+constexpr Opcode OP_IVV = OP_V | (0b000 << kFunct3Shift);
+constexpr Opcode OP_FVV = OP_V | (0b001 << kFunct3Shift);
+constexpr Opcode OP_MVV = OP_V | (0b010 << kFunct3Shift);
+constexpr Opcode OP_IVI = OP_V | (0b011 << kFunct3Shift);
+constexpr Opcode OP_IVX = OP_V | (0b100 << kFunct3Shift);
+constexpr Opcode OP_FVF = OP_V | (0b101 << kFunct3Shift);
+constexpr Opcode OP_MVX = OP_V | (0b110 << kFunct3Shift);
+
+constexpr Opcode RO_V_VSETVLI = OP_V | (0b111 << kFunct3Shift) | 0b0 << 31;
+constexpr Opcode RO_V_VSETIVLI = OP_V | (0b111 << kFunct3Shift) | 0b11 << 30;
+constexpr Opcode RO_V_VSETVL = OP_V | (0b111 << kFunct3Shift) | 0b1 << 31;
+
+// RVV LOAD/STORE
+constexpr Opcode RO_V_VL =
+    LOAD_FP | (0b00 << kRvvMopShift) | (0b000 << kRvvNfShift);
+constexpr Opcode RO_V_VLS =
+    LOAD_FP | (0b10 << kRvvMopShift) | (0b000 << kRvvNfShift);
+constexpr Opcode RO_V_VLX =
+    LOAD_FP | (0b11 << kRvvMopShift) | (0b000 << kRvvNfShift);
+
+constexpr Opcode RO_V_VS =
+    STORE_FP | (0b00 << kRvvMopShift) | (0b000 << kRvvNfShift);
+constexpr Opcode RO_V_VSS =
+    STORE_FP | (0b10 << kRvvMopShift) | (0b000 << kRvvNfShift);
+constexpr Opcode RO_V_VSX =
+    STORE_FP | (0b11 << kRvvMopShift) | (0b000 << kRvvNfShift);
+constexpr Opcode RO_V_VSU =
+    STORE_FP | (0b01 << kRvvMopShift) | (0b000 << kRvvNfShift);
+// THE kFunct6Shift is mop
+constexpr Opcode RO_V_VLSEG2 =
+    LOAD_FP | (0b00 << kRvvMopShift) | (0b001 << kRvvNfShift);
+constexpr Opcode RO_V_VLSEG3 =
+    LOAD_FP | (0b00 << kRvvMopShift) | (0b010 << kRvvNfShift);
+constexpr Opcode RO_V_VLSEG4 =
+    LOAD_FP | (0b00 << kRvvMopShift) | (0b011 << kRvvNfShift);
+constexpr Opcode RO_V_VLSEG5 =
+    LOAD_FP | (0b00 << kRvvMopShift) | (0b100 << kRvvNfShift);
+constexpr Opcode RO_V_VLSEG6 =
+    LOAD_FP | (0b00 << kRvvMopShift) | (0b101 << kRvvNfShift);
+constexpr Opcode RO_V_VLSEG7 =
+    LOAD_FP | (0b00 << kRvvMopShift) | (0b110 << kRvvNfShift);
+constexpr Opcode RO_V_VLSEG8 =
+    LOAD_FP | (0b00 << kRvvMopShift) | (0b111 << kRvvNfShift);
+
+constexpr Opcode RO_V_VSSEG2 =
+    STORE_FP | (0b00 << kRvvMopShift) | (0b001 << kRvvNfShift);
+constexpr Opcode RO_V_VSSEG3 =
+    STORE_FP | (0b00 << kRvvMopShift) | (0b010 << kRvvNfShift);
+constexpr Opcode RO_V_VSSEG4 =
+    STORE_FP | (0b00 << kRvvMopShift) | (0b011 << kRvvNfShift);
+constexpr Opcode RO_V_VSSEG5 =
+    STORE_FP | (0b00 << kRvvMopShift) | (0b100 << kRvvNfShift);
+constexpr Opcode RO_V_VSSEG6 =
+    STORE_FP | (0b00 << kRvvMopShift) | (0b101 << kRvvNfShift);
+constexpr Opcode RO_V_VSSEG7 =
+    STORE_FP | (0b00 << kRvvMopShift) | (0b110 << kRvvNfShift);
+constexpr Opcode RO_V_VSSEG8 =
+    STORE_FP | (0b00 << kRvvMopShift) | (0b111 << kRvvNfShift);
+
+constexpr Opcode RO_V_VLSSEG2 =
+    LOAD_FP | (0b10 << kRvvMopShift) | (0b001 << kRvvNfShift);
+constexpr Opcode RO_V_VLSSEG3 =
+    LOAD_FP | (0b10 << kRvvMopShift) | (0b010 << kRvvNfShift);
+constexpr Opcode RO_V_VLSSEG4 =
+    LOAD_FP | (0b10 << kRvvMopShift) | (0b011 << kRvvNfShift);
+constexpr Opcode RO_V_VLSSEG5 =
+    LOAD_FP | (0b10 << kRvvMopShift) | (0b100 << kRvvNfShift);
+constexpr Opcode RO_V_VLSSEG6 =
+    LOAD_FP | (0b10 << kRvvMopShift) | (0b101 << kRvvNfShift);
+constexpr Opcode RO_V_VLSSEG7 =
+    LOAD_FP | (0b10 << kRvvMopShift) | (0b110 << kRvvNfShift);
+constexpr Opcode RO_V_VLSSEG8 =
+    LOAD_FP | (0b10 << kRvvMopShift) | (0b111 << kRvvNfShift);
+
+constexpr Opcode RO_V_VSSSEG2 =
+    STORE_FP | (0b10 << kRvvMopShift) | (0b001 << kRvvNfShift);
+constexpr Opcode RO_V_VSSSEG3 =
+    STORE_FP | (0b10 << kRvvMopShift) | (0b010 << kRvvNfShift);
+constexpr Opcode RO_V_VSSSEG4 =
+    STORE_FP | (0b10 << kRvvMopShift) | (0b011 << kRvvNfShift);
+constexpr Opcode RO_V_VSSSEG5 =
+    STORE_FP | (0b10 << kRvvMopShift) | (0b100 << kRvvNfShift);
+constexpr Opcode RO_V_VSSSEG6 =
+    STORE_FP | (0b10 << kRvvMopShift) | (0b101 << kRvvNfShift);
+constexpr Opcode RO_V_VSSSEG7 =
+    STORE_FP | (0b10 << kRvvMopShift) | (0b110 << kRvvNfShift);
+constexpr Opcode RO_V_VSSSEG8 =
+    STORE_FP | (0b10 << kRvvMopShift) | (0b111 << kRvvNfShift);
+
+constexpr Opcode RO_V_VLXSEG2 =
+    LOAD_FP | (0b11 << kRvvMopShift) | (0b001 << kRvvNfShift);
+constexpr Opcode RO_V_VLXSEG3 =
+    LOAD_FP | (0b11 << kRvvMopShift) | (0b010 << kRvvNfShift);
+constexpr Opcode RO_V_VLXSEG4 =
+    LOAD_FP | (0b11 << kRvvMopShift) | (0b011 << kRvvNfShift);
+constexpr Opcode RO_V_VLXSEG5 =
+    LOAD_FP | (0b11 << kRvvMopShift) | (0b100 << kRvvNfShift);
+constexpr Opcode RO_V_VLXSEG6 =
+    LOAD_FP | (0b11 << kRvvMopShift) | (0b101 << kRvvNfShift);
+constexpr Opcode RO_V_VLXSEG7 =
+    LOAD_FP | (0b11 << kRvvMopShift) | (0b110 << kRvvNfShift);
+constexpr Opcode RO_V_VLXSEG8 =
+    LOAD_FP | (0b11 << kRvvMopShift) | (0b111 << kRvvNfShift);
+
+constexpr Opcode RO_V_VSXSEG2 =
+    STORE_FP | (0b11 << kRvvMopShift) | (0b001 << kRvvNfShift);
+constexpr Opcode RO_V_VSXSEG3 =
+    STORE_FP | (0b11 << kRvvMopShift) | (0b010 << kRvvNfShift);
+constexpr Opcode RO_V_VSXSEG4 =
+    STORE_FP | (0b11 << kRvvMopShift) | (0b011 << kRvvNfShift);
+constexpr Opcode RO_V_VSXSEG5 =
+    STORE_FP | (0b11 << kRvvMopShift) | (0b100 << kRvvNfShift);
+constexpr Opcode RO_V_VSXSEG6 =
+    STORE_FP | (0b11 << kRvvMopShift) | (0b101 << kRvvNfShift);
+constexpr Opcode RO_V_VSXSEG7 =
+    STORE_FP | (0b11 << kRvvMopShift) | (0b110 << kRvvNfShift);
+constexpr Opcode RO_V_VSXSEG8 =
+    STORE_FP | (0b11 << kRvvMopShift) | (0b111 << kRvvNfShift);
+
+// RVV Vector Arithmetic Instruction
+constexpr Opcode VADD_FUNCT6 = 0b000000;
+constexpr Opcode RO_V_VADD_VI = OP_IVI | (VADD_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VADD_VV = OP_IVV | (VADD_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VADD_VX = OP_IVX | (VADD_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VSUB_FUNCT6 = 0b000010;
+constexpr Opcode RO_V_VSUB_VX = OP_IVX | (VSUB_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VSUB_VV = OP_IVV | (VSUB_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VDIVU_FUNCT6 = 0b100000;
+constexpr Opcode RO_V_VDIVU_VX = OP_MVX | (VDIVU_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VDIVU_VV = OP_MVV | (VDIVU_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VDIV_FUNCT6 = 0b100001;
+constexpr Opcode RO_V_VDIV_VX = OP_MVX | (VDIV_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VDIV_VV = OP_MVV | (VDIV_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VREMU_FUNCT6 = 0b100010;
+constexpr Opcode RO_V_VREMU_VX = OP_MVX | (VREMU_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VREMU_VV = OP_MVV | (VREMU_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VREM_FUNCT6 = 0b100011;
+constexpr Opcode RO_V_VREM_VX = OP_MVX | (VREM_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VREM_VV = OP_MVV | (VREM_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VMULHU_FUNCT6 = 0b100100;
+constexpr Opcode RO_V_VMULHU_VX = OP_MVX | (VMULHU_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VMULHU_VV = OP_MVV | (VMULHU_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VMUL_FUNCT6 = 0b100101;
+constexpr Opcode RO_V_VMUL_VX = OP_MVX | (VMUL_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VMUL_VV = OP_MVV | (VMUL_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VWMUL_FUNCT6 = 0b111011;
+constexpr Opcode RO_V_VWMUL_VX = OP_MVX | (VWMUL_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VWMUL_VV = OP_MVV | (VWMUL_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VWMULU_FUNCT6 = 0b111000;
+constexpr Opcode RO_V_VWMULU_VX = OP_MVX | (VWMULU_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VWMULU_VV = OP_MVV | (VWMULU_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VMULHSU_FUNCT6 = 0b100110;
+constexpr Opcode RO_V_VMULHSU_VX = OP_MVX | (VMULHSU_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VMULHSU_VV = OP_MVV | (VMULHSU_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VMULH_FUNCT6 = 0b100111;
+constexpr Opcode RO_V_VMULH_VX = OP_MVX | (VMULH_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VMULH_VV = OP_MVV | (VMULH_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VWADD_FUNCT6 = 0b110001;
+constexpr Opcode RO_V_VWADD_VV = OP_MVV | (VWADD_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VWADD_VX = OP_MVX | (VWADD_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VWADDU_FUNCT6 = 0b110000;
+constexpr Opcode RO_V_VWADDU_VV = OP_MVV | (VWADDU_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VWADDU_VX = OP_MVX | (VWADDU_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VWADDUW_FUNCT6 = 0b110101;
+constexpr Opcode RO_V_VWADDUW_VX = OP_MVX | (VWADDUW_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VWADDUW_VV = OP_MVV | (VWADDUW_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VCOMPRESS_FUNCT6 = 0b010111;
+constexpr Opcode RO_V_VCOMPRESS_VV =
+    OP_MVV | (VCOMPRESS_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VSADDU_FUNCT6 = 0b100000;
+constexpr Opcode RO_V_VSADDU_VI = OP_IVI | (VSADDU_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VSADDU_VV = OP_IVV | (VSADDU_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VSADDU_VX = OP_IVX | (VSADDU_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VSADD_FUNCT6 = 0b100001;
+constexpr Opcode RO_V_VSADD_VI = OP_IVI | (VSADD_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VSADD_VV = OP_IVV | (VSADD_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VSADD_VX = OP_IVX | (VSADD_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VSSUB_FUNCT6 = 0b100011;
+constexpr Opcode RO_V_VSSUB_VV = OP_IVV | (VSSUB_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VSSUB_VX = OP_IVX | (VSSUB_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VSSUBU_FUNCT6 = 0b100010;
+constexpr Opcode RO_V_VSSUBU_VV = OP_IVV | (VSSUBU_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VSSUBU_VX = OP_IVX | (VSSUBU_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VRSUB_FUNCT6 = 0b000011;
+constexpr Opcode RO_V_VRSUB_VX = OP_IVX | (VRSUB_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VRSUB_VI = OP_IVI | (VRSUB_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VMINU_FUNCT6 = 0b000100;
+constexpr Opcode RO_V_VMINU_VX = OP_IVX | (VMINU_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VMINU_VV = OP_IVV | (VMINU_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VMIN_FUNCT6 = 0b000101;
+constexpr Opcode RO_V_VMIN_VX = OP_IVX | (VMIN_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VMIN_VV = OP_IVV | (VMIN_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VMAXU_FUNCT6 = 0b000110;
+constexpr Opcode RO_V_VMAXU_VX = OP_IVX | (VMAXU_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VMAXU_VV = OP_IVV | (VMAXU_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VMAX_FUNCT6 = 0b000111;
+constexpr Opcode RO_V_VMAX_VX = OP_IVX | (VMAX_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VMAX_VV = OP_IVV | (VMAX_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VAND_FUNCT6 = 0b001001;
+constexpr Opcode RO_V_VAND_VI = OP_IVI | (VAND_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VAND_VV = OP_IVV | (VAND_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VAND_VX = OP_IVX | (VAND_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VOR_FUNCT6 = 0b001010;
+constexpr Opcode RO_V_VOR_VI = OP_IVI | (VOR_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VOR_VV = OP_IVV | (VOR_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VOR_VX = OP_IVX | (VOR_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VXOR_FUNCT6 = 0b001011;
+constexpr Opcode RO_V_VXOR_VI = OP_IVI | (VXOR_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VXOR_VV = OP_IVV | (VXOR_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VXOR_VX = OP_IVX | (VXOR_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VRGATHER_FUNCT6 = 0b001100;
+constexpr Opcode RO_V_VRGATHER_VI =
+    OP_IVI | (VRGATHER_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VRGATHER_VV =
+    OP_IVV | (VRGATHER_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VRGATHER_VX =
+    OP_IVX | (VRGATHER_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VMV_FUNCT6 = 0b010111;
+constexpr Opcode RO_V_VMV_VI = OP_IVI | (VMV_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VMV_VV = OP_IVV | (VMV_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VMV_VX = OP_IVX | (VMV_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VFMV_VF = OP_FVF | (VMV_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode RO_V_VMERGE_VI = RO_V_VMV_VI;
+constexpr Opcode RO_V_VMERGE_VV = RO_V_VMV_VV;
+constexpr Opcode RO_V_VMERGE_VX = RO_V_VMV_VX;
+
+constexpr Opcode VMSEQ_FUNCT6 = 0b011000;
+constexpr Opcode RO_V_VMSEQ_VI = OP_IVI | (VMSEQ_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VMSEQ_VV = OP_IVV | (VMSEQ_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VMSEQ_VX = OP_IVX | (VMSEQ_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VMSNE_FUNCT6 = 0b011001;
+constexpr Opcode RO_V_VMSNE_VI = OP_IVI | (VMSNE_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VMSNE_VV = OP_IVV | (VMSNE_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VMSNE_VX = OP_IVX | (VMSNE_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VMSLTU_FUNCT6 = 0b011010;
+constexpr Opcode RO_V_VMSLTU_VV = OP_IVV | (VMSLTU_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VMSLTU_VX = OP_IVX | (VMSLTU_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VMSLT_FUNCT6 = 0b011011;
+constexpr Opcode RO_V_VMSLT_VV = OP_IVV | (VMSLT_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VMSLT_VX = OP_IVX | (VMSLT_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VMSLE_FUNCT6 = 0b011101;
+constexpr Opcode RO_V_VMSLE_VI = OP_IVI | (VMSLE_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VMSLE_VV = OP_IVV | (VMSLE_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VMSLE_VX = OP_IVX | (VMSLE_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VMSLEU_FUNCT6 = 0b011100;
+constexpr Opcode RO_V_VMSLEU_VI = OP_IVI | (VMSLEU_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VMSLEU_VV = OP_IVV | (VMSLEU_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VMSLEU_VX = OP_IVX | (VMSLEU_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VMSGTU_FUNCT6 = 0b011110;
+constexpr Opcode RO_V_VMSGTU_VI = OP_IVI | (VMSGTU_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VMSGTU_VX = OP_IVX | (VMSGTU_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VMSGT_FUNCT6 = 0b011111;
+constexpr Opcode RO_V_VMSGT_VI = OP_IVI | (VMSGT_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VMSGT_VX = OP_IVX | (VMSGT_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VSLIDEUP_FUNCT6 = 0b001110;
+constexpr Opcode RO_V_VSLIDEUP_VI =
+    OP_IVI | (VSLIDEUP_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VSLIDEUP_VX =
+    OP_IVX | (VSLIDEUP_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VSLIDEDOWN_FUNCT6 = 0b001111;
+constexpr Opcode RO_V_VSLIDEDOWN_VI =
+    OP_IVI | (VSLIDEDOWN_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VSLIDEDOWN_VX =
+    OP_IVX | (VSLIDEDOWN_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VSRL_FUNCT6 = 0b101000;
+constexpr Opcode RO_V_VSRL_VI = OP_IVI | (VSRL_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VSRL_VV = OP_IVV | (VSRL_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VSRL_VX = OP_IVX | (VSRL_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VSRA_FUNCT6 = 0b101001;
+constexpr Opcode RO_V_VSRA_VI = OP_IVI | (VSRA_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VSRA_VV = OP_IVV | (VSRA_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VSRA_VX = OP_IVX | (VSRA_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VSLL_FUNCT6 = 0b100101;
+constexpr Opcode RO_V_VSLL_VI = OP_IVI | (VSLL_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VSLL_VV = OP_IVV | (VSLL_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VSLL_VX = OP_IVX | (VSLL_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VSMUL_FUNCT6 = 0b100111;
+constexpr Opcode RO_V_VSMUL_VV = OP_IVV | (VSMUL_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VSMUL_VX = OP_IVX | (VSMUL_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VADC_FUNCT6 = 0b010000;
+constexpr Opcode RO_V_VADC_VI = OP_IVI | (VADC_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VADC_VV = OP_IVV | (VADC_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VADC_VX = OP_IVX | (VADC_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VMADC_FUNCT6 = 0b010001;
+constexpr Opcode RO_V_VMADC_VI = OP_IVI | (VMADC_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VMADC_VV = OP_IVV | (VMADC_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VMADC_VX = OP_IVX | (VMADC_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VWXUNARY0_FUNCT6 = 0b010000;
+constexpr Opcode VRXUNARY0_FUNCT6 = 0b010000;
+constexpr Opcode VMUNARY0_FUNCT6 = 0b010100;
+
+constexpr Opcode RO_V_VWXUNARY0 =
+    OP_MVV | (VWXUNARY0_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VRXUNARY0 =
+    OP_MVX | (VRXUNARY0_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VMUNARY0 = OP_MVV | (VMUNARY0_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VID_V = 0b10001;
+
+constexpr Opcode VXUNARY0_FUNCT6 = 0b010010;
+constexpr Opcode RO_V_VXUNARY0 = OP_MVV | (VXUNARY0_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VWFUNARY0_FUNCT6 = 0b010000;
+constexpr Opcode RO_V_VFMV_FS = OP_FVV | (VWFUNARY0_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VRFUNARY0_FUNCT6 = 0b010000;
+constexpr Opcode RO_V_VFMV_SF = OP_FVF | (VRFUNARY0_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VREDMAXU_FUNCT6 = 0b000110;
+constexpr Opcode RO_V_VREDMAXU = OP_MVV | (VREDMAXU_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode VREDMAX_FUNCT6 = 0b000111;
+constexpr Opcode RO_V_VREDMAX = OP_MVV | (VREDMAX_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VREDMINU_FUNCT6 = 0b000100;
+constexpr Opcode RO_V_VREDMINU = OP_MVV | (VREDMINU_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode VREDMIN_FUNCT6 = 0b000101;
+constexpr Opcode RO_V_VREDMIN = OP_MVV | (VREDMIN_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VFUNARY0_FUNCT6 = 0b010010;
+constexpr Opcode RO_V_VFUNARY0 = OP_FVV | (VFUNARY0_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode VFUNARY1_FUNCT6 = 0b010011;
+constexpr Opcode RO_V_VFUNARY1 = OP_FVV | (VFUNARY1_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VFCVT_XU_F_V = 0b00000;
+constexpr Opcode VFCVT_X_F_V = 0b00001;
+constexpr Opcode VFCVT_F_XU_V = 0b00010;
+constexpr Opcode VFCVT_F_X_V = 0b00011;
+constexpr Opcode VFWCVT_XU_F_V = 0b01000;
+constexpr Opcode VFWCVT_X_F_V = 0b01001;
+constexpr Opcode VFWCVT_F_XU_V = 0b01010;
+constexpr Opcode VFWCVT_F_X_V = 0b01011;
+constexpr Opcode VFWCVT_F_F_V = 0b01100;
+constexpr Opcode VFNCVT_F_F_W = 0b10100;
+constexpr Opcode VFNCVT_X_F_W = 0b10001;
+constexpr Opcode VFNCVT_XU_F_W = 0b10000;
+
+constexpr Opcode VFCLASS_V = 0b10000;
+constexpr Opcode VFSQRT_V = 0b00000;
+constexpr Opcode VFRSQRT7_V = 0b00100;
+constexpr Opcode VFREC7_V = 0b00101;
+
+constexpr Opcode VFADD_FUNCT6 = 0b000000;
+constexpr Opcode RO_V_VFADD_VV = OP_FVV | (VFADD_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VFADD_VF = OP_FVF | (VFADD_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VFSUB_FUNCT6 = 0b000010;
+constexpr Opcode RO_V_VFSUB_VV = OP_FVV | (VFSUB_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VFSUB_VF = OP_FVF | (VFSUB_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VFDIV_FUNCT6 = 0b100000;
+constexpr Opcode RO_V_VFDIV_VV = OP_FVV | (VFDIV_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VFDIV_VF = OP_FVF | (VFDIV_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VFMUL_FUNCT6 = 0b100100;
+constexpr Opcode RO_V_VFMUL_VV = OP_FVV | (VFMUL_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VFMUL_VF = OP_FVF | (VFMUL_FUNCT6 << kRvvFunct6Shift);
+
+// Vector Widening Floating-Point Add/Subtract Instructions
+constexpr Opcode VFWADD_FUNCT6 = 0b110000;
+constexpr Opcode RO_V_VFWADD_VV = OP_FVV | (VFWADD_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VFWADD_VF = OP_FVF | (VFWADD_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VFWSUB_FUNCT6 = 0b110010;
+constexpr Opcode RO_V_VFWSUB_VV = OP_FVV | (VFWSUB_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VFWSUB_VF = OP_FVF | (VFWSUB_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VFWADD_W_FUNCT6 = 0b110100;
+constexpr Opcode RO_V_VFWADD_W_VV =
+    OP_FVV | (VFWADD_W_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VFWADD_W_VF =
+    OP_FVF | (VFWADD_W_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VFWSUB_W_FUNCT6 = 0b110110;
+constexpr Opcode RO_V_VFWSUB_W_VV =
+    OP_FVV | (VFWSUB_W_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VFWSUB_W_VF =
+    OP_FVF | (VFWSUB_W_FUNCT6 << kRvvFunct6Shift);
+
+// Vector Widening Floating-Point Reduction Instructions
+constexpr Opcode VFWREDUSUM_FUNCT6 = 0b110001;
+constexpr Opcode RO_V_VFWREDUSUM_VV =
+    OP_FVV | (VFWREDUSUM_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VFWREDOSUM_FUNCT6 = 0b110011;
+constexpr Opcode RO_V_VFWREDOSUM_VV =
+    OP_FVV | (VFWREDOSUM_FUNCT6 << kRvvFunct6Shift);
+
+// Vector Widening Floating-Point Multiply
+constexpr Opcode VFWMUL_FUNCT6 = 0b111000;
+constexpr Opcode RO_V_VFWMUL_VV = OP_FVV | (VFWMUL_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VFWMUL_VF = OP_FVF | (VFWMUL_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VMFEQ_FUNCT6 = 0b011000;
+constexpr Opcode RO_V_VMFEQ_VV = OP_FVV | (VMFEQ_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VMFEQ_VF = OP_FVF | (VMFEQ_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VMFNE_FUNCT6 = 0b011100;
+constexpr Opcode RO_V_VMFNE_VV = OP_FVV | (VMFNE_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VMFNE_VF = OP_FVF | (VMFNE_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VMFLT_FUNCT6 = 0b011011;
+constexpr Opcode RO_V_VMFLT_VV = OP_FVV | (VMFLT_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VMFLT_VF = OP_FVF | (VMFLT_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VMFLE_FUNCT6 = 0b011001;
+constexpr Opcode RO_V_VMFLE_VV = OP_FVV | (VMFLE_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VMFLE_VF = OP_FVF | (VMFLE_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VMFGE_FUNCT6 = 0b011111;
+constexpr Opcode RO_V_VMFGE_VF = OP_FVF | (VMFGE_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VMFGT_FUNCT6 = 0b011101;
+constexpr Opcode RO_V_VMFGT_VF = OP_FVF | (VMFGT_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VFMAX_FUNCT6 = 0b000110;
+constexpr Opcode RO_V_VFMAX_VV = OP_FVV | (VFMAX_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VFMAX_VF = OP_FVF | (VFMAX_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VFREDMAX_FUNCT6 = 0b0001111;
+constexpr Opcode RO_V_VFREDMAX_VV =
+    OP_FVV | (VFREDMAX_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VFMIN_FUNCT6 = 0b000100;
+constexpr Opcode RO_V_VFMIN_VV = OP_FVV | (VFMIN_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VFMIN_VF = OP_FVF | (VFMIN_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VFSGNJ_FUNCT6 = 0b001000;
+constexpr Opcode RO_V_VFSGNJ_VV = OP_FVV | (VFSGNJ_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VFSGNJ_VF = OP_FVF | (VFSGNJ_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VFSGNJN_FUNCT6 = 0b001001;
+constexpr Opcode RO_V_VFSGNJN_VV = OP_FVV | (VFSGNJN_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VFSGNJN_VF = OP_FVF | (VFSGNJN_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VFSGNJX_FUNCT6 = 0b001010;
+constexpr Opcode RO_V_VFSGNJX_VV = OP_FVV | (VFSGNJX_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VFSGNJX_VF = OP_FVF | (VFSGNJX_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VFMADD_FUNCT6 = 0b101000;
+constexpr Opcode RO_V_VFMADD_VV = OP_FVV | (VFMADD_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VFMADD_VF = OP_FVF | (VFMADD_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VFNMADD_FUNCT6 = 0b101001;
+constexpr Opcode RO_V_VFNMADD_VV = OP_FVV | (VFNMADD_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VFNMADD_VF = OP_FVF | (VFNMADD_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VFMSUB_FUNCT6 = 0b101010;
+constexpr Opcode RO_V_VFMSUB_VV = OP_FVV | (VFMSUB_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VFMSUB_VF = OP_FVF | (VFMSUB_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VFNMSUB_FUNCT6 = 0b101011;
+constexpr Opcode RO_V_VFNMSUB_VV = OP_FVV | (VFNMSUB_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VFNMSUB_VF = OP_FVF | (VFNMSUB_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VFMACC_FUNCT6 = 0b101100;
+constexpr Opcode RO_V_VFMACC_VV = OP_FVV | (VFMACC_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VFMACC_VF = OP_FVF | (VFMACC_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VFNMACC_FUNCT6 = 0b101101;
+constexpr Opcode RO_V_VFNMACC_VV = OP_FVV | (VFNMACC_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VFNMACC_VF = OP_FVF | (VFNMACC_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VFMSAC_FUNCT6 = 0b101110;
+constexpr Opcode RO_V_VFMSAC_VV = OP_FVV | (VFMSAC_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VFMSAC_VF = OP_FVF | (VFMSAC_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VFNMSAC_FUNCT6 = 0b101111;
+constexpr Opcode RO_V_VFNMSAC_VV = OP_FVV | (VFNMSAC_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VFNMSAC_VF = OP_FVF | (VFNMSAC_FUNCT6 << kRvvFunct6Shift);
+
+// Vector Widening Floating-Point Fused Multiply-Add Instructions
+constexpr Opcode VFWMACC_FUNCT6 = 0b111100;
+constexpr Opcode RO_V_VFWMACC_VV = OP_FVV | (VFWMACC_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VFWMACC_VF = OP_FVF | (VFWMACC_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VFWNMACC_FUNCT6 = 0b111101;
+constexpr Opcode RO_V_VFWNMACC_VV =
+    OP_FVV | (VFWNMACC_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VFWNMACC_VF =
+    OP_FVF | (VFWNMACC_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VFWMSAC_FUNCT6 = 0b111110;
+constexpr Opcode RO_V_VFWMSAC_VV = OP_FVV | (VFWMSAC_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VFWMSAC_VF = OP_FVF | (VFWMSAC_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VFWNMSAC_FUNCT6 = 0b111111;
+constexpr Opcode RO_V_VFWNMSAC_VV =
+    OP_FVV | (VFWNMSAC_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VFWNMSAC_VF =
+    OP_FVF | (VFWNMSAC_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VNCLIP_FUNCT6 = 0b101111;
+constexpr Opcode RO_V_VNCLIP_WV = OP_IVV | (VNCLIP_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VNCLIP_WX = OP_IVX | (VNCLIP_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VNCLIP_WI = OP_IVI | (VNCLIP_FUNCT6 << kRvvFunct6Shift);
+
+constexpr Opcode VNCLIPU_FUNCT6 = 0b101110;
+constexpr Opcode RO_V_VNCLIPU_WV = OP_IVV | (VNCLIPU_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VNCLIPU_WX = OP_IVX | (VNCLIPU_FUNCT6 << kRvvFunct6Shift);
+constexpr Opcode RO_V_VNCLIPU_WI = OP_IVI | (VNCLIPU_FUNCT6 << kRvvFunct6Shift);
+// clang-format on
 }  // namespace internal
 }  // namespace v8
 
diff --git a/src/codegen/riscv/constant-riscv-zicsr.h b/src/codegen/riscv/constant-riscv-zicsr.h
index d6171859eeb..0b3d2545416 100644
--- a/src/codegen/riscv/constant-riscv-zicsr.h
+++ b/src/codegen/riscv/constant-riscv-zicsr.h
@@ -16,15 +16,13 @@ const uint32_t kFcsrFrmMask = ((1 << kFcsrFrmBits) - 1) << kFcsrFrmShift;
 const int kFcsrBits = kFcsrFlagsBits + kFcsrFrmBits;
 const uint32_t kFcsrMask = kFcsrFlagsMask | kFcsrFrmMask;
 
-enum OpcodeRISCVZICSR : uint32_t {
-  // RV32/RV64 Zicsr Standard Extension
-  RO_CSRRW = SYSTEM | (0b001 << kFunct3Shift),
-  RO_CSRRS = SYSTEM | (0b010 << kFunct3Shift),
-  RO_CSRRC = SYSTEM | (0b011 << kFunct3Shift),
-  RO_CSRRWI = SYSTEM | (0b101 << kFunct3Shift),
-  RO_CSRRSI = SYSTEM | (0b110 << kFunct3Shift),
-  RO_CSRRCI = SYSTEM | (0b111 << kFunct3Shift),
-};
+// RV32/RV64 Zicsr Standard Extension
+constexpr Opcode RO_CSRRW = SYSTEM | (0b001 << kFunct3Shift);
+constexpr Opcode RO_CSRRS = SYSTEM | (0b010 << kFunct3Shift);
+constexpr Opcode RO_CSRRC = SYSTEM | (0b011 << kFunct3Shift);
+constexpr Opcode RO_CSRRWI = SYSTEM | (0b101 << kFunct3Shift);
+constexpr Opcode RO_CSRRSI = SYSTEM | (0b110 << kFunct3Shift);
+constexpr Opcode RO_CSRRCI = SYSTEM | (0b111 << kFunct3Shift);
 }  // namespace internal
 }  // namespace v8
 #endif  // V8_CODEGEN_RISCV_CONSTANT_RISCV_ZICSR_H_
diff --git a/src/codegen/riscv/constant-riscv-zifencei.h b/src/codegen/riscv/constant-riscv-zifencei.h
index 49105017cbe..e3869fa879f 100644
--- a/src/codegen/riscv/constant-riscv-zifencei.h
+++ b/src/codegen/riscv/constant-riscv-zifencei.h
@@ -7,9 +7,7 @@
 #include "src/codegen/riscv/base-constants-riscv.h"
 namespace v8 {
 namespace internal {
-enum OpcodeRISCVIFENCEI : uint32_t {
-  RO_FENCE_I = MISC_MEM | (0b001 << kFunct3Shift),
-};
+constexpr Opcode RO_FENCE_I = MISC_MEM | (0b001 << kFunct3Shift);
 }
 }  // namespace v8
 #endif  // V8_CODEGEN_RISCV_CONSTANT_RISCV_ZIFENCEI_H_
diff --git a/src/codegen/riscv/extension-riscv-v.cc b/src/codegen/riscv/extension-riscv-v.cc
index c5be03a1819..06c92d884c5 100644
--- a/src/codegen/riscv/extension-riscv-v.cc
+++ b/src/codegen/riscv/extension-riscv-v.cc
@@ -160,7 +160,7 @@ void AssemblerRISCVV::vid_v(VRegister vd, MaskType mask) {
     GenInstrV(funct6, OP_MVV, vd, vs1, vs2, mask);                            \
   }
 
-// void GenInstrV(uint8_t funct6, OpcodeRISCVV opcode, VRegister vd, Register
+// void GenInstrV(uint8_t funct6, Opcode opcode, VRegister vd, Register
 // rs1,
 //                  VRegister vs2, MaskType mask = NoMask);
 #define DEFINE_OPMVX(name, funct6)                                           \
@@ -455,9 +455,8 @@ uint8_t vsew_switch(VSew vsew) {
 }
 
 // OPIVV OPFVV OPMVV
-void AssemblerRISCVV::GenInstrV(uint8_t funct6, OpcodeRISCVV opcode,
-                                VRegister vd, VRegister vs1, VRegister vs2,
-                                MaskType mask) {
+void AssemblerRISCVV::GenInstrV(uint8_t funct6, Opcode opcode, VRegister vd,
+                                VRegister vs1, VRegister vs2, MaskType mask) {
   DCHECK(opcode == OP_MVV || opcode == OP_FVV || opcode == OP_IVV);
   Instr instr = (funct6 << kRvvFunct6Shift) | opcode | (mask << kRvvVmShift) |
                 ((vd.code() & 0x1F) << kRvvVdShift) |
@@ -466,9 +465,8 @@ void AssemblerRISCVV::GenInstrV(uint8_t funct6, OpcodeRISCVV opcode,
   emit(instr);
 }
 
-void AssemblerRISCVV::GenInstrV(uint8_t funct6, OpcodeRISCVV opcode,
-                                VRegister vd, int8_t vs1, VRegister vs2,
-                                MaskType mask) {
+void AssemblerRISCVV::GenInstrV(uint8_t funct6, Opcode opcode, VRegister vd,
+                                int8_t vs1, VRegister vs2, MaskType mask) {
   DCHECK(opcode == OP_MVV || opcode == OP_FVV || opcode == OP_IVV);
   Instr instr = (funct6 << kRvvFunct6Shift) | opcode | (mask << kRvvVmShift) |
                 ((vd.code() & 0x1F) << kRvvVdShift) |
@@ -477,9 +475,8 @@ void AssemblerRISCVV::GenInstrV(uint8_t funct6, OpcodeRISCVV opcode,
   emit(instr);
 }
 // OPMVV OPFVV
-void AssemblerRISCVV::GenInstrV(uint8_t funct6, OpcodeRISCVV opcode,
-                                Register rd, VRegister vs1, VRegister vs2,
-                                MaskType mask) {
+void AssemblerRISCVV::GenInstrV(uint8_t funct6, Opcode opcode, Register rd,
+                                VRegister vs1, VRegister vs2, MaskType mask) {
   DCHECK(opcode == OP_MVV || opcode == OP_FVV);
   Instr instr = (funct6 << kRvvFunct6Shift) | opcode | (mask << kRvvVmShift) |
                 ((rd.code() & 0x1F) << kRvvVdShift) |
@@ -489,9 +486,8 @@ void AssemblerRISCVV::GenInstrV(uint8_t funct6, OpcodeRISCVV opcode,
 }
 
 // OPFVV
-void AssemblerRISCVV::GenInstrV(uint8_t funct6, OpcodeRISCVV opcode,
-                                FPURegister fd, VRegister vs1, VRegister vs2,
-                                MaskType mask) {
+void AssemblerRISCVV::GenInstrV(uint8_t funct6, Opcode opcode, FPURegister fd,
+                                VRegister vs1, VRegister vs2, MaskType mask) {
   DCHECK(opcode == OP_FVV);
   Instr instr = (funct6 << kRvvFunct6Shift) | opcode | (mask << kRvvVmShift) |
                 ((fd.code() & 0x1F) << kRvvVdShift) |
@@ -501,9 +497,8 @@ void AssemblerRISCVV::GenInstrV(uint8_t funct6, OpcodeRISCVV opcode,
 }
 
 // OPIVX OPMVX
-void AssemblerRISCVV::GenInstrV(uint8_t funct6, OpcodeRISCVV opcode,
-                                VRegister vd, Register rs1, VRegister vs2,
-                                MaskType mask) {
+void AssemblerRISCVV::GenInstrV(uint8_t funct6, Opcode opcode, VRegister vd,
+                                Register rs1, VRegister vs2, MaskType mask) {
   DCHECK(opcode == OP_IVX || opcode == OP_MVX);
   Instr instr = (funct6 << kRvvFunct6Shift) | opcode | (mask << kRvvVmShift) |
                 ((vd.code() & 0x1F) << kRvvVdShift) |
@@ -513,9 +508,8 @@ void AssemblerRISCVV::GenInstrV(uint8_t funct6, OpcodeRISCVV opcode,
 }
 
 // OPFVF
-void AssemblerRISCVV::GenInstrV(uint8_t funct6, OpcodeRISCVV opcode,
-                                VRegister vd, FPURegister fs1, VRegister vs2,
-                                MaskType mask) {
+void AssemblerRISCVV::GenInstrV(uint8_t funct6, Opcode opcode, VRegister vd,
+                                FPURegister fs1, VRegister vs2, MaskType mask) {
   DCHECK(opcode == OP_FVF);
   Instr instr = (funct6 << kRvvFunct6Shift) | opcode | (mask << kRvvVmShift) |
                 ((vd.code() & 0x1F) << kRvvVdShift) |
@@ -589,9 +583,8 @@ void AssemblerRISCVV::GenInstrV(BaseOpcode opcode, uint8_t width, VRegister vd,
   emit(instr);
 }
 // vmv_xs vcpop_m vfirst_m
-void AssemblerRISCVV::GenInstrV(uint8_t funct6, OpcodeRISCVV opcode,
-                                Register rd, uint8_t vs1, VRegister vs2,
-                                MaskType mask) {
+void AssemblerRISCVV::GenInstrV(uint8_t funct6, Opcode opcode, Register rd,
+                                uint8_t vs1, VRegister vs2, MaskType mask) {
   DCHECK(opcode == OP_MVV);
   Instr instr = (funct6 << kRvvFunct6Shift) | opcode | (mask << kRvvVmShift) |
                 ((rd.code() & 0x1F) << kRvvVdShift) |
diff --git a/src/codegen/riscv/extension-riscv-v.h b/src/codegen/riscv/extension-riscv-v.h
index 2682f6c0452..576d349eb45 100644
--- a/src/codegen/riscv/extension-riscv-v.h
+++ b/src/codegen/riscv/extension-riscv-v.h
@@ -425,25 +425,25 @@ class AssemblerRISCVV : public AssemblerRiscvBase {
   // vsetvli
   void GenInstrV(Register rd, Register rs1, uint32_t zimm);
   // OPIVV OPFVV OPMVV
-  void GenInstrV(uint8_t funct6, OpcodeRISCVV opcode, VRegister vd,
-                 VRegister vs1, VRegister vs2, MaskType mask = NoMask);
-  void GenInstrV(uint8_t funct6, OpcodeRISCVV opcode, VRegister vd, int8_t vs1,
+  void GenInstrV(uint8_t funct6, Opcode opcode, VRegister vd, VRegister vs1,
                  VRegister vs2, MaskType mask = NoMask);
-  void GenInstrV(uint8_t funct6, OpcodeRISCVV opcode, VRegister vd,
+  void GenInstrV(uint8_t funct6, Opcode opcode, VRegister vd, int8_t vs1,
                  VRegister vs2, MaskType mask = NoMask);
+  void GenInstrV(uint8_t funct6, Opcode opcode, VRegister vd, VRegister vs2,
+                 MaskType mask = NoMask);
   // OPMVV OPFVV
-  void GenInstrV(uint8_t funct6, OpcodeRISCVV opcode, Register rd,
-                 VRegister vs1, VRegister vs2, MaskType mask = NoMask);
+  void GenInstrV(uint8_t funct6, Opcode opcode, Register rd, VRegister vs1,
+                 VRegister vs2, MaskType mask = NoMask);
   // OPFVV
-  void GenInstrV(uint8_t funct6, OpcodeRISCVV opcode, FPURegister fd,
-                 VRegister vs1, VRegister vs2, MaskType mask = NoMask);
+  void GenInstrV(uint8_t funct6, Opcode opcode, FPURegister fd, VRegister vs1,
+                 VRegister vs2, MaskType mask = NoMask);
 
   // OPIVX OPMVX
-  void GenInstrV(uint8_t funct6, OpcodeRISCVV opcode, VRegister vd,
-                 Register rs1, VRegister vs2, MaskType mask = NoMask);
+  void GenInstrV(uint8_t funct6, Opcode opcode, VRegister vd, Register rs1,
+                 VRegister vs2, MaskType mask = NoMask);
   // OPFVF
-  void GenInstrV(uint8_t funct6, OpcodeRISCVV opcode, VRegister vd,
-                 FPURegister fs1, VRegister vs2, MaskType mask = NoMask);
+  void GenInstrV(uint8_t funct6, Opcode opcode, VRegister vd, FPURegister fs1,
+                 VRegister vs2, MaskType mask = NoMask);
   // OPMVX
   void GenInstrV(uint8_t funct6, Register rd, Register rs1, VRegister vs2,
                  MaskType mask = NoMask);
@@ -464,7 +464,7 @@ class AssemblerRISCVV : public AssemblerRiscvBase {
                  VRegister vs2, MaskType mask, uint8_t IsMop, bool IsMew,
                  uint8_t Nf);
   // vmv_xs vcpop_m vfirst_m
-  void GenInstrV(uint8_t funct6, OpcodeRISCVV opcode, Register rd, uint8_t vs1,
+  void GenInstrV(uint8_t funct6, Opcode opcode, Register rd, uint8_t vs1,
                  VRegister vs2, MaskType mask);
 };
 
-- 
2.35.1

