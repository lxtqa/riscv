From d371c44f54f58830fd4b69d60b25bcd7eff2a229 Mon Sep 17 00:00:00 2001
From: Andreas Haas <ahaas@chromium.org>
Date: Wed, 20 Sep 2023 11:38:03 +0200
Subject: [PATCH] [wasm] Use Builtin ids instead of RuntimeStubId ids for calls

Builtin ids get mapped to far jumptable indices by a constexpr array,
so in terms of wasm compile time it should not cause measurable
overhead. The advantage is that Builtin are already available
everywhere and easy to understand.

Bug: v8:14108
Change-Id: I4d497f7ecad279082aac7f6c38a550c7aef848d9
Reviewed-on: https://chromium-review.googlesource.com/c/v8/v8/+/4866128
Reviewed-by: Matthias Liedtke <mliedtke@chromium.org>
Reviewed-by: Clemens Backes <clemensb@chromium.org>
Commit-Queue: Andreas Haas <ahaas@chromium.org>
Cr-Commit-Position: refs/heads/main@{#90058}
---
 BUILD.bazel                                   |   1 +
 BUILD.gn                                      |   1 +
 src/codegen/arm/macro-assembler-arm.cc        |   9 +-
 src/codegen/arm64/macro-assembler-arm64.cc    |   9 +-
 src/codegen/ia32/macro-assembler-ia32.cc      |   3 +-
 .../loong64/macro-assembler-loong64.cc        |   3 +-
 src/codegen/mips64/macro-assembler-mips64.cc  |   3 +-
 src/codegen/ppc/macro-assembler-ppc.cc        |   3 +-
 src/codegen/riscv/macro-assembler-riscv.cc    |   3 +-
 src/codegen/s390/macro-assembler-s390.cc      |   3 +-
 src/codegen/x64/assembler-x64.h               |   1 +
 src/codegen/x64/macro-assembler-x64.cc        |   9 +-
 .../backend/arm/code-generator-arm.cc         |   4 +-
 .../backend/arm64/code-generator-arm64.cc     |   4 +-
 .../backend/ia32/code-generator-ia32.cc       |  12 +-
 src/compiler/backend/instruction-selector.cc  |   6 +
 .../backend/loong64/code-generator-loong64.cc |   7 +-
 .../backend/mips64/code-generator-mips64.cc   |   7 +-
 .../backend/ppc/code-generator-ppc.cc         |   4 +-
 .../backend/riscv/code-generator-riscv.cc     |   4 +-
 .../backend/s390/code-generator-s390.cc       |   4 +-
 .../backend/x64/code-generator-x64.cc         |  12 +-
 src/compiler/common-operator.cc               |   8 +
 src/compiler/common-operator.h                |  13 +-
 src/compiler/loop-analysis.cc                 |  33 +-
 src/compiler/machine-graph.cc                 |   5 +
 src/compiler/machine-graph.h                  |   1 +
 src/compiler/machine-operator-reducer.cc      |   4 +
 src/compiler/turboshaft/assembler.h           |  17 +-
 .../turboshaft/branch-elimination-reducer.h   |   2 +
 .../debug-feature-lowering-reducer.h          |   8 +-
 src/compiler/turboshaft/graph-builder.cc      |   2 +
 .../turboshaft/machine-optimization-reducer.h |   2 +
 src/compiler/turboshaft/operations.h          |   6 +-
 src/compiler/turboshaft/optimization-phase.h  |   4 +
 src/compiler/turboshaft/recreate-schedule.cc  |   4 +
 src/compiler/turboshaft/reduce-args-helper.h  |   2 +
 .../turboshaft/type-inference-analysis.h      |   2 +-
 .../turboshaft/wasm-js-lowering-reducer.h     |   3 +-
 .../turboshaft/wasm-lowering-reducer.h        |   6 +-
 src/compiler/wasm-compiler.cc                 | 153 ++--
 src/compiler/wasm-compiler.h                  |   2 +-
 src/compiler/wasm-graph-assembler.h           |  15 +-
 src/compiler/wasm-js-lowering.cc              |   4 +-
 src/diagnostics/disassembler.cc               |   4 +-
 src/objects/instruction-stream.cc             |   6 +-
 src/wasm/baseline/arm/liftoff-assembler-arm.h |  13 +-
 .../baseline/arm64/liftoff-assembler-arm64.h  |  13 +-
 .../baseline/ia32/liftoff-assembler-ia32.h    |  13 +-
 src/wasm/baseline/liftoff-assembler.h         |   3 +-
 src/wasm/baseline/liftoff-compiler.cc         | 727 +++++++++---------
 .../loong64/liftoff-assembler-loong64.h       |  13 +-
 .../mips64/liftoff-assembler-mips64.h         |  13 +-
 src/wasm/baseline/ppc/liftoff-assembler-ppc.h |  11 +-
 .../baseline/riscv/liftoff-assembler-riscv.h  |  13 +-
 .../baseline/s390/liftoff-assembler-s390.h    |  11 +-
 src/wasm/baseline/x64/liftoff-assembler-x64.h |  15 +-
 src/wasm/turboshaft-graph-interface.cc        | 268 ++++---
 src/wasm/wasm-builtin-list.h                  | 189 +++++
 src/wasm/wasm-code-manager.cc                 |  94 +--
 src/wasm/wasm-code-manager.h                  | 192 +----
 src/wasm/wasm-serialization.cc                |   9 +-
 62 files changed, 1033 insertions(+), 982 deletions(-)
 create mode 100644 src/wasm/wasm-builtin-list.h

diff --git a/BUILD.bazel b/BUILD.bazel
index baf0d32fcc3..fe75d55e186 100644
--- a/BUILD.bazel
+++ b/BUILD.bazel
@@ -2660,6 +2660,7 @@ filegroup(
             "src/wasm/value-type.cc",
             "src/wasm/value-type.h",
             "src/wasm/wasm-arguments.h",
+            "src/wasm/wasm-builtin-list.h",
             "src/wasm/wasm-code-manager.cc",
             "src/wasm/wasm-code-manager.h",
             "src/wasm/wasm-debug.cc",
diff --git a/BUILD.gn b/BUILD.gn
index 142e250073b..4dd6c325e0c 100644
--- a/BUILD.gn
+++ b/BUILD.gn
@@ -4137,6 +4137,7 @@ v8_header_set("v8_internal_headers") {
       "src/wasm/turboshaft-graph-interface.h",
       "src/wasm/value-type.h",
       "src/wasm/wasm-arguments.h",
+      "src/wasm/wasm-builtin-list.h",
       "src/wasm/wasm-code-manager.h",
       "src/wasm/wasm-debug.h",
       "src/wasm/wasm-disassembler-impl.h",
diff --git a/src/codegen/arm/macro-assembler-arm.cc b/src/codegen/arm/macro-assembler-arm.cc
index 6ab47b8f629..c1654d48cbe 100644
--- a/src/codegen/arm/macro-assembler-arm.cc
+++ b/src/codegen/arm/macro-assembler-arm.cc
@@ -28,10 +28,6 @@
 #include "src/runtime/runtime.h"
 #include "src/snapshot/snapshot.h"
 
-#if V8_ENABLE_WEBASSEMBLY
-#include "src/wasm/wasm-code-manager.h"
-#endif  // V8_ENABLE_WEBASSEMBLY
-
 // Satisfy cpplint check, but don't include platform-specific header. It is
 // included recursively via macro-assembler.h.
 #if 0
@@ -742,7 +738,8 @@ void MacroAssembler::CallRecordWriteStub(Register object, Register slot_address,
   DCHECK_EQ(WriteBarrierDescriptor::SlotAddressRegister(), slot_address);
 #if V8_ENABLE_WEBASSEMBLY
   if (mode == StubCallMode::kCallWasmRuntimeStub) {
-    auto wasm_target = wasm::WasmCode::GetRecordWriteStub(fp_mode);
+    auto wasm_target =
+        static_cast<Address>(wasm::WasmCode::GetRecordWriteBuiltin(fp_mode));
     Call(wasm_target, RelocInfo::WASM_STUB_CALL);
 #else
   if (false) {
@@ -1894,7 +1891,7 @@ void MacroAssembler::TruncateDoubleToI(Isolate* isolate, Zone* zone,
 
 #if V8_ENABLE_WEBASSEMBLY
   if (stub_mode == StubCallMode::kCallWasmRuntimeStub) {
-    Call(wasm::WasmCode::kDoubleToI, RelocInfo::WASM_STUB_CALL);
+    Call(static_cast<Address>(Builtin::kDoubleToI), RelocInfo::WASM_STUB_CALL);
 #else
   // For balance.
   if (false) {
diff --git a/src/codegen/arm64/macro-assembler-arm64.cc b/src/codegen/arm64/macro-assembler-arm64.cc
index f4214cf5d79..1a29adc591d 100644
--- a/src/codegen/arm64/macro-assembler-arm64.cc
+++ b/src/codegen/arm64/macro-assembler-arm64.cc
@@ -24,10 +24,6 @@
 #include "src/runtime/runtime.h"
 #include "src/snapshot/snapshot.h"
 
-#if V8_ENABLE_WEBASSEMBLY
-#include "src/wasm/wasm-code-manager.h"
-#endif  // V8_ENABLE_WEBASSEMBLY
-
 // Satisfy cpplint check, but don't include platform-specific header. It is
 // included recursively via macro-assembler.h.
 #if 0
@@ -2924,7 +2920,7 @@ void MacroAssembler::TruncateDoubleToI(Isolate* isolate, Zone* zone,
   // DoubleToI preserves any registers it needs to clobber.
 #if V8_ENABLE_WEBASSEMBLY
   if (stub_mode == StubCallMode::kCallWasmRuntimeStub) {
-    Call(wasm::WasmCode::kDoubleToI, RelocInfo::WASM_STUB_CALL);
+    Call(static_cast<Address>(Builtin::kDoubleToI), RelocInfo::WASM_STUB_CALL);
 #else
   // For balance.
   if (false) {
@@ -3646,7 +3642,8 @@ void MacroAssembler::CallRecordWriteStub(Register object, Register slot_address,
     DCHECK_EQ(WriteBarrierDescriptor::SlotAddressRegister(), slot_address);
 #if V8_ENABLE_WEBASSEMBLY
   if (mode == StubCallMode::kCallWasmRuntimeStub) {
-    auto wasm_target = wasm::WasmCode::GetRecordWriteStub(fp_mode);
+    auto wasm_target =
+        static_cast<Address>(wasm::WasmCode::GetRecordWriteBuiltin(fp_mode));
     Call(wasm_target, RelocInfo::WASM_STUB_CALL);
 #else
   if (false) {
diff --git a/src/codegen/ia32/macro-assembler-ia32.cc b/src/codegen/ia32/macro-assembler-ia32.cc
index 20f16ac2014..babe10e5b7f 100644
--- a/src/codegen/ia32/macro-assembler-ia32.cc
+++ b/src/codegen/ia32/macro-assembler-ia32.cc
@@ -484,7 +484,8 @@ void MacroAssembler::CallRecordWriteStub(Register object, Register slot_address,
 #if V8_ENABLE_WEBASSEMBLY
   if (mode == StubCallMode::kCallWasmRuntimeStub) {
     // Use {wasm_call} for direct Wasm call within a module.
-    auto wasm_target = wasm::WasmCode::GetRecordWriteStub(fp_mode);
+    auto wasm_target =
+        static_cast<Address>(wasm::WasmCode::GetRecordWriteBuiltin(fp_mode));
     wasm_call(wasm_target, RelocInfo::WASM_STUB_CALL);
 #else
   if (false) {
diff --git a/src/codegen/loong64/macro-assembler-loong64.cc b/src/codegen/loong64/macro-assembler-loong64.cc
index 576446ca640..973573a8bbf 100644
--- a/src/codegen/loong64/macro-assembler-loong64.cc
+++ b/src/codegen/loong64/macro-assembler-loong64.cc
@@ -301,7 +301,8 @@ void MacroAssembler::CallRecordWriteStub(Register object, Register slot_address,
   DCHECK_EQ(WriteBarrierDescriptor::SlotAddressRegister(), slot_address);
 #if V8_ENABLE_WEBASSEMBLY
   if (mode == StubCallMode::kCallWasmRuntimeStub) {
-    auto wasm_target = wasm::WasmCode::GetRecordWriteStub(fp_mode);
+    auto wasm_target =
+        static_cast<Address>(wasm::WasmCode::GetRecordWriteBuiltin(fp_mode));
     Call(wasm_target, RelocInfo::WASM_STUB_CALL);
 #else
   if (false) {
diff --git a/src/codegen/mips64/macro-assembler-mips64.cc b/src/codegen/mips64/macro-assembler-mips64.cc
index 3d0ea54397a..4bdaa5d2a8a 100644
--- a/src/codegen/mips64/macro-assembler-mips64.cc
+++ b/src/codegen/mips64/macro-assembler-mips64.cc
@@ -242,7 +242,8 @@ void MacroAssembler::CallRecordWriteStub(Register object, Register slot_address,
   DCHECK_EQ(WriteBarrierDescriptor::SlotAddressRegister(), slot_address);
 #if V8_ENABLE_WEBASSEMBLY
   if (mode == StubCallMode::kCallWasmRuntimeStub) {
-    auto wasm_target = wasm::WasmCode::GetRecordWriteStub(fp_mode);
+    auto wasm_target =
+        static_cast<Address>(wasm::WasmCode::GetRecordWriteBuiltin(fp_mode));
     Call(wasm_target, RelocInfo::WASM_STUB_CALL);
 #else
   if (false) {
diff --git a/src/codegen/ppc/macro-assembler-ppc.cc b/src/codegen/ppc/macro-assembler-ppc.cc
index 3ba34b05f7a..844fb44a93c 100644
--- a/src/codegen/ppc/macro-assembler-ppc.cc
+++ b/src/codegen/ppc/macro-assembler-ppc.cc
@@ -814,7 +814,8 @@ void MacroAssembler::CallRecordWriteStub(Register object, Register slot_address,
 #if V8_ENABLE_WEBASSEMBLY
   if (mode == StubCallMode::kCallWasmRuntimeStub) {
     // Use {near_call} for direct Wasm call within a module.
-    auto wasm_target = wasm::WasmCode::GetRecordWriteStub(fp_mode);
+    auto wasm_target =
+        static_cast<Address>(wasm::WasmCode::GetRecordWriteBuiltin(fp_mode));
     Call(wasm_target, RelocInfo::WASM_STUB_CALL);
 #else
   if (false) {
diff --git a/src/codegen/riscv/macro-assembler-riscv.cc b/src/codegen/riscv/macro-assembler-riscv.cc
index a2c7338d2e6..51c996824dd 100644
--- a/src/codegen/riscv/macro-assembler-riscv.cc
+++ b/src/codegen/riscv/macro-assembler-riscv.cc
@@ -430,7 +430,8 @@ void MacroAssembler::CallRecordWriteStub(Register object, Register slot_address,
   DCHECK_EQ(WriteBarrierDescriptor::ObjectRegister(), object);
   DCHECK_EQ(WriteBarrierDescriptor::SlotAddressRegister(), slot_address);
   if (mode == StubCallMode::kCallWasmRuntimeStub) {
-    auto wasm_target = wasm::WasmCode::GetRecordWriteStub(fp_mode);
+    auto wasm_target =
+        static_cast<Address>(wasm::WasmCode::GetRecordWriteBuiltin(fp_mode));
     Call(wasm_target, RelocInfo::WASM_STUB_CALL);
   } else {
     auto builtin = Builtins::GetRecordWriteStub(fp_mode);
diff --git a/src/codegen/s390/macro-assembler-s390.cc b/src/codegen/s390/macro-assembler-s390.cc
index fc6ad1be84d..93899b2c83e 100644
--- a/src/codegen/s390/macro-assembler-s390.cc
+++ b/src/codegen/s390/macro-assembler-s390.cc
@@ -1053,7 +1053,8 @@ void MacroAssembler::CallRecordWriteStub(Register object, Register slot_address,
   DCHECK_EQ(WriteBarrierDescriptor::SlotAddressRegister(), slot_address);
 #if V8_ENABLE_WEBASSEMBLY
   if (mode == StubCallMode::kCallWasmRuntimeStub) {
-    auto wasm_target = wasm::WasmCode::GetRecordWriteStub(fp_mode);
+    auto wasm_target =
+        static_cast<Address>(wasm::WasmCode::GetRecordWriteBuiltin(fp_mode));
     Call(wasm_target, RelocInfo::WASM_STUB_CALL);
 #else
   if (false) {
diff --git a/src/codegen/x64/assembler-x64.h b/src/codegen/x64/assembler-x64.h
index 6c65ea6303a..be6634b277c 100644
--- a/src/codegen/x64/assembler-x64.h
+++ b/src/codegen/x64/assembler-x64.h
@@ -900,6 +900,7 @@ class V8_EXPORT_PRIVATE Assembler : public AssemblerBase {
   // the next instructions (which starts at {pc_offset() + kNearJmpInstrSize}).
   static constexpr int kNearJmpInstrSize = 5;
   void near_call(intptr_t disp, RelocInfo::Mode rmode);
+  void near_call(Builtin buitin, RelocInfo::Mode rmode);
   void near_jmp(intptr_t disp, RelocInfo::Mode rmode);
   void near_j(Condition cc, intptr_t disp, RelocInfo::Mode rmode);
 
diff --git a/src/codegen/x64/macro-assembler-x64.cc b/src/codegen/x64/macro-assembler-x64.cc
index eea2fec44db..b35624ca53f 100644
--- a/src/codegen/x64/macro-assembler-x64.cc
+++ b/src/codegen/x64/macro-assembler-x64.cc
@@ -579,7 +579,8 @@ void MacroAssembler::CallRecordWriteStub(Register object, Register slot_address,
   if (mode == StubCallMode::kCallWasmRuntimeStub) {
     DCHECK_EQ(type, PointerType::kDirect);
     // Use {near_call} for direct Wasm call within a module.
-    auto wasm_target = wasm::WasmCode::GetRecordWriteStub(fp_mode);
+    intptr_t wasm_target =
+        static_cast<intptr_t>(wasm::WasmCode::GetRecordWriteBuiltin(fp_mode));
     near_call(wasm_target, RelocInfo::WASM_STUB_CALL);
 #else
   if (false) {
@@ -629,7 +630,8 @@ void MacroAssembler::CallTSANStoreStub(Register address, Register value,
   else {
     DCHECK_EQ(mode, StubCallMode::kCallWasmRuntimeStub);
     // Use {near_call} for direct Wasm call within a module.
-    auto wasm_target = wasm::WasmCode::GetTSANStoreStub(fp_mode, size, order);
+    auto wasm_target = static_cast<intptr_t>(
+        wasm::WasmCode::GetTSANStoreBuiltin(fp_mode, size, order));
     near_call(wasm_target, RelocInfo::WASM_STUB_CALL);
   }
 #endif  // V8_ENABLE_WEBASSEMBLY
@@ -670,7 +672,8 @@ void MacroAssembler::CallTSANRelaxedLoadStub(Register address,
   else {
     DCHECK_EQ(mode, StubCallMode::kCallWasmRuntimeStub);
     // Use {near_call} for direct Wasm call within a module.
-    auto wasm_target = wasm::WasmCode::GetTSANRelaxedLoadStub(fp_mode, size);
+    auto wasm_target = static_cast<intptr_t>(
+        wasm::WasmCode::GetTSANRelaxedLoadBuiltin(fp_mode, size));
     near_call(wasm_target, RelocInfo::WASM_STUB_CALL);
   }
 #endif  // V8_ENABLE_WEBASSEMBLY
diff --git a/src/compiler/backend/arm/code-generator-arm.cc b/src/compiler/backend/arm/code-generator-arm.cc
index 721a441cc40..6f5cc04d2be 100644
--- a/src/compiler/backend/arm/code-generator-arm.cc
+++ b/src/compiler/backend/arm/code-generator-arm.cc
@@ -21,7 +21,6 @@
 #include "src/utils/boxed-float.h"
 
 #if V8_ENABLE_WEBASSEMBLY
-#include "src/wasm/wasm-code-manager.h"
 #include "src/wasm/wasm-objects.h"
 #endif  // V8_ENABLE_WEBASSEMBLY
 
@@ -3800,7 +3799,8 @@ void CodeGenerator::AssembleConstructFrame() {
         __ b(cs, &done);
       }
 
-      __ Call(wasm::WasmCode::kWasmStackOverflow, RelocInfo::WASM_STUB_CALL);
+      __ Call(static_cast<intptr_t>(Builtin::kWasmStackOverflow),
+              RelocInfo::WASM_STUB_CALL);
       // The call does not return, hence we can ignore any references and just
       // define an empty safepoint.
       ReferenceMap* reference_map = zone()->New<ReferenceMap>(zone());
diff --git a/src/compiler/backend/arm64/code-generator-arm64.cc b/src/compiler/backend/arm64/code-generator-arm64.cc
index 1c82874dc1f..cbcbdd64603 100644
--- a/src/compiler/backend/arm64/code-generator-arm64.cc
+++ b/src/compiler/backend/arm64/code-generator-arm64.cc
@@ -17,7 +17,6 @@
 #include "src/heap/memory-chunk.h"
 
 #if V8_ENABLE_WEBASSEMBLY
-#include "src/wasm/wasm-code-manager.h"
 #include "src/wasm/wasm-objects.h"
 #endif  // V8_ENABLE_WEBASSEMBLY
 
@@ -3319,7 +3318,8 @@ void CodeGenerator::AssembleConstructFrame() {
         __ Push(scratch, kWasmInstanceRegister);
       }
 
-      __ Call(wasm::WasmCode::kWasmStackOverflow, RelocInfo::WASM_STUB_CALL);
+      __ Call(static_cast<intptr_t>(Builtin::kWasmStackOverflow),
+              RelocInfo::WASM_STUB_CALL);
       // The call does not return, hence we can ignore any references and just
       // define an empty safepoint.
       ReferenceMap* reference_map = zone()->New<ReferenceMap>(zone());
diff --git a/src/compiler/backend/ia32/code-generator-ia32.cc b/src/compiler/backend/ia32/code-generator-ia32.cc
index 6b565d43d12..1bb7418d4a5 100644
--- a/src/compiler/backend/ia32/code-generator-ia32.cc
+++ b/src/compiler/backend/ia32/code-generator-ia32.cc
@@ -21,7 +21,6 @@
 #include "src/objects/smi.h"
 
 #if V8_ENABLE_WEBASSEMBLY
-#include "src/wasm/wasm-code-manager.h"
 #include "src/wasm/wasm-objects.h"
 #endif  // V8_ENABLE_WEBASSEMBLY
 
@@ -272,10 +271,11 @@ class OutOfLineTruncateDoubleToI final : public OutOfLineCode {
     __ Movsd(MemOperand(esp, 0), input_);
 #if V8_ENABLE_WEBASSEMBLY
     if (stub_mode_ == StubCallMode::kCallWasmRuntimeStub) {
-      // A direct call to a wasm runtime stub defined in this module.
-      // Just encode the stub index. This will be patched when the code
-      // is added to the native module and copied into wasm code space.
-      __ wasm_call(wasm::WasmCode::kDoubleToI, RelocInfo::WASM_STUB_CALL);
+      // A direct call to a builtin. Just encode the builtin index. This will be
+      // patched when the code is added to the native module and copied into
+      // wasm code space.
+      __ wasm_call(static_cast<Address>(Builtin::kDoubleToI),
+                   RelocInfo::WASM_STUB_CALL);
 #else
     // For balance.
     if (false) {
@@ -4084,7 +4084,7 @@ void CodeGenerator::AssembleConstructFrame() {
         __ j(above_equal, &done, Label::kNear);
       }
 
-      __ wasm_call(wasm::WasmCode::kWasmStackOverflow,
+      __ wasm_call(static_cast<Address>(Builtin::kWasmStackOverflow),
                    RelocInfo::WASM_STUB_CALL);
       // The call does not return, hence we can ignore any references and just
       // define an empty safepoint.
diff --git a/src/compiler/backend/instruction-selector.cc b/src/compiler/backend/instruction-selector.cc
index 395b5e9c5b2..eb1485aa939 100644
--- a/src/compiler/backend/instruction-selector.cc
+++ b/src/compiler/backend/instruction-selector.cc
@@ -1554,7 +1554,9 @@ bool InstructionSelectorT<Adapter>::IsSourcePositionUsed(node_t node) {
     if (const StoreOp* store = operation.TryCast<StoreOp>()) {
       return store->kind.with_trap_handler;
     }
+#if V8_ENABLE_WEBASSEMBLY
     if (operation.Is<TrapIfOp>()) return true;
+#endif
     return false;
   } else {
     switch (node->opcode()) {
@@ -2964,10 +2966,12 @@ void InstructionSelectorT<TurbofanAdapter>::VisitNode(Node* node) {
       return VisitDeoptimizeIf(node);
     case IrOpcode::kDeoptimizeUnless:
       return VisitDeoptimizeUnless(node);
+#if V8_ENABLE_WEBASSEMBLY
     case IrOpcode::kTrapIf:
       return VisitTrapIf(node, TrapIdOf(node->op()));
     case IrOpcode::kTrapUnless:
       return VisitTrapUnless(node, TrapIdOf(node->op()));
+#endif
     case IrOpcode::kFrameState:
     case IrOpcode::kStateValues:
     case IrOpcode::kObjectState:
@@ -4894,6 +4898,7 @@ void InstructionSelectorT<TurboshaftAdapter>::VisitNode(
         return VisitDeoptimizeUnless(node);
       }
       return VisitDeoptimizeIf(node);
+#if V8_ENABLE_WEBASSEMBLY
     case Opcode::kTrapIf: {
       const TrapIfOp& trap_if = op.Cast<TrapIfOp>();
       if (trap_if.negated) {
@@ -4901,6 +4906,7 @@ void InstructionSelectorT<TurboshaftAdapter>::VisitNode(
       }
       return VisitTrapIf(node, trap_if.trap_id);
     }
+#endif
     case Opcode::kCatchBlockBegin:
       MarkAsTagged(node);
       return VisitIfException(node);
diff --git a/src/compiler/backend/loong64/code-generator-loong64.cc b/src/compiler/backend/loong64/code-generator-loong64.cc
index 61ee6bc4681..1b05a97e3ae 100644
--- a/src/compiler/backend/loong64/code-generator-loong64.cc
+++ b/src/compiler/backend/loong64/code-generator-loong64.cc
@@ -15,10 +15,6 @@
 #include "src/compiler/osr.h"
 #include "src/heap/memory-chunk.h"
 
-#if V8_ENABLE_WEBASSEMBLY
-#include "src/wasm/wasm-code-manager.h"
-#endif  // V8_ENABLE_WEBASSEMBLY
-
 namespace v8 {
 namespace internal {
 namespace compiler {
@@ -2330,7 +2326,8 @@ void CodeGenerator::AssembleConstructFrame() {
         __ Branch(&done, uge, sp, Operand(scratch));
       }
 
-      __ Call(wasm::WasmCode::kWasmStackOverflow, RelocInfo::WASM_STUB_CALL);
+      __ Call(static_cast<intptr_t>(Builtin::kWasmStackOverflow),
+              RelocInfo::WASM_STUB_CALL);
       // The call does not return, hence we can ignore any references and just
       // define an empty safepoint.
       ReferenceMap* reference_map = zone()->New<ReferenceMap>(zone());
diff --git a/src/compiler/backend/mips64/code-generator-mips64.cc b/src/compiler/backend/mips64/code-generator-mips64.cc
index 648d633548f..222c44653e0 100644
--- a/src/compiler/backend/mips64/code-generator-mips64.cc
+++ b/src/compiler/backend/mips64/code-generator-mips64.cc
@@ -15,10 +15,6 @@
 #include "src/compiler/osr.h"
 #include "src/heap/memory-chunk.h"
 
-#if V8_ENABLE_WEBASSEMBLY
-#include "src/wasm/wasm-code-manager.h"
-#endif  // V8_ENABLE_WEBASSEMBLY
-
 namespace v8 {
 namespace internal {
 namespace compiler {
@@ -4177,7 +4173,8 @@ void CodeGenerator::AssembleConstructFrame() {
         __ Branch(&done, uge, sp, Operand(kScratchReg));
       }
 
-      __ Call(wasm::WasmCode::kWasmStackOverflow, RelocInfo::WASM_STUB_CALL);
+      __ Call(static_cast<intptr_t>(Builtin::kWasmStackOverflow),
+              RelocInfo::WASM_STUB_CALL);
       // The call does not return, hence we can ignore any references and just
       // define an empty safepoint.
       ReferenceMap* reference_map = zone()->New<ReferenceMap>(zone());
diff --git a/src/compiler/backend/ppc/code-generator-ppc.cc b/src/compiler/backend/ppc/code-generator-ppc.cc
index a91e03303d8..ec9c9fa42fd 100644
--- a/src/compiler/backend/ppc/code-generator-ppc.cc
+++ b/src/compiler/backend/ppc/code-generator-ppc.cc
@@ -15,7 +15,6 @@
 #include "src/heap/memory-chunk.h"
 
 #if V8_ENABLE_WEBASSEMBLY
-#include "src/wasm/wasm-code-manager.h"
 #include "src/wasm/wasm-objects.h"
 #endif  // V8_ENABLE_WEBASSEMBLY
 
@@ -3169,7 +3168,8 @@ void CodeGenerator::AssembleConstructFrame() {
         __ bge(&done);
       }
 
-      __ Call(wasm::WasmCode::kWasmStackOverflow, RelocInfo::WASM_STUB_CALL);
+      __ Call(static_cast<intptr_t>(Builtin::kWasmStackOverflow),
+              RelocInfo::WASM_STUB_CALL);
       // The call does not return, hence we can ignore any references and just
       // define an empty safepoint.
       ReferenceMap* reference_map = zone()->New<ReferenceMap>(zone());
diff --git a/src/compiler/backend/riscv/code-generator-riscv.cc b/src/compiler/backend/riscv/code-generator-riscv.cc
index fd782062d29..8ce6f850ac3 100644
--- a/src/compiler/backend/riscv/code-generator-riscv.cc
+++ b/src/compiler/backend/riscv/code-generator-riscv.cc
@@ -13,7 +13,6 @@
 #include "src/compiler/node-matchers.h"
 #include "src/compiler/osr.h"
 #include "src/heap/memory-chunk.h"
-#include "src/wasm/wasm-code-manager.h"
 
 namespace v8 {
 namespace internal {
@@ -4135,7 +4134,8 @@ void CodeGenerator::AssembleConstructFrame() {
         __ BranchShort(&done, uge, sp, Operand(kScratchReg));
       }
 
-      __ Call(wasm::WasmCode::kWasmStackOverflow, RelocInfo::WASM_STUB_CALL);
+      __ Call(static_cast<intptr_t>(Builtin::kWasmStackOverflow),
+              RelocInfo::WASM_STUB_CALL);
       // We come from WebAssembly, there are no references for the GC.
       ReferenceMap* reference_map = zone()->New<ReferenceMap>(zone());
       RecordSafepoint(reference_map);
diff --git a/src/compiler/backend/s390/code-generator-s390.cc b/src/compiler/backend/s390/code-generator-s390.cc
index 4e196f828af..a3e02f1ca26 100644
--- a/src/compiler/backend/s390/code-generator-s390.cc
+++ b/src/compiler/backend/s390/code-generator-s390.cc
@@ -14,7 +14,6 @@
 #include "src/heap/memory-chunk.h"
 
 #if V8_ENABLE_WEBASSEMBLY
-#include "src/wasm/wasm-code-manager.h"
 #include "src/wasm/wasm-objects.h"
 #endif  // V8_ENABLE_WEBASSEMBLY
 
@@ -3464,7 +3463,8 @@ void CodeGenerator::AssembleConstructFrame() {
         __ bge(&done);
       }
 
-      __ Call(wasm::WasmCode::kWasmStackOverflow, RelocInfo::WASM_STUB_CALL);
+      __ Call(static_cast<intptr_t>(Builtin::kWasmStackOverflow),
+              RelocInfo::WASM_STUB_CALL);
       // The call does not return, hence we can ignore any references and just
       // define an empty safepoint.
       ReferenceMap* reference_map = zone()->New<ReferenceMap>(zone());
diff --git a/src/compiler/backend/x64/code-generator-x64.cc b/src/compiler/backend/x64/code-generator-x64.cc
index 45d7aa0e585..0982d1ad57a 100644
--- a/src/compiler/backend/x64/code-generator-x64.cc
+++ b/src/compiler/backend/x64/code-generator-x64.cc
@@ -29,7 +29,6 @@
 #include "src/objects/smi.h"
 
 #if V8_ENABLE_WEBASSEMBLY
-#include "src/wasm/wasm-code-manager.h"
 #include "src/wasm/wasm-objects.h"
 #endif  // V8_ENABLE_WEBASSEMBLY
 
@@ -254,10 +253,11 @@ class OutOfLineTruncateDoubleToI final : public OutOfLineCode {
     __ Movsd(MemOperand(rsp, 0), input_);
 #if V8_ENABLE_WEBASSEMBLY
     if (stub_mode_ == StubCallMode::kCallWasmRuntimeStub) {
-      // A direct call to a wasm runtime stub defined in this module.
-      // Just encode the stub index. This will be patched when the code
-      // is added to the native module and copied into wasm code space.
-      __ near_call(wasm::WasmCode::kDoubleToI, RelocInfo::WASM_STUB_CALL);
+      // A direct call to a builtin. Just encode the builtin index. This will be
+      // patched when the code is added to the native module and copied into
+      // wasm code space.
+      __ near_call(static_cast<intptr_t>(Builtin::kDoubleToI),
+                   RelocInfo::WASM_STUB_CALL);
 #else
     // For balance.
     if (false) {
@@ -6990,7 +6990,7 @@ void CodeGenerator::AssembleConstructFrame() {
         __ j(above_equal, &done, Label::kNear);
       }
 
-      __ near_call(wasm::WasmCode::kWasmStackOverflow,
+      __ near_call(static_cast<intptr_t>(Builtin::kWasmStackOverflow),
                    RelocInfo::WASM_STUB_CALL);
       // The call does not return, hence we can ignore any references and just
       // define an empty safepoint.
diff --git a/src/compiler/common-operator.cc b/src/compiler/common-operator.cc
index 2207d56cf2d..636b9e5b137 100644
--- a/src/compiler/common-operator.cc
+++ b/src/compiler/common-operator.cc
@@ -41,6 +41,7 @@ std::ostream& operator<<(std::ostream& os, BranchSemantics semantics) {
   UNREACHABLE();
 }
 
+#if V8_ENABLE_WEBASSEMBLY
 std::ostream& operator<<(std::ostream& os, TrapId trap_id) {
   switch (trap_id) {
 #define TRAP_CASE(Name) \
@@ -57,6 +58,7 @@ TrapId TrapIdOf(const Operator* const op) {
          op->opcode() == IrOpcode::kTrapUnless);
   return OpParameter<TrapId>(op);
 }
+#endif  // V8_ENABLE_WEBASSEMBLY
 
 bool operator==(const BranchParameters& lhs, const BranchParameters& rhs) {
   return lhs.semantics() == rhs.semantics() && lhs.hint() == rhs.hint();
@@ -812,6 +814,7 @@ struct CommonOperatorGlobalCache final {
   CACHED_DEOPTIMIZE_UNLESS_LIST(CACHED_DEOPTIMIZE_UNLESS)
 #undef CACHED_DEOPTIMIZE_UNLESS
 
+#if V8_ENABLE_WEBASSEMBLY
   template <TrapId trap_id, bool has_frame_state>
   struct TrapIfOperator final : public Operator1<TrapId> {
     TrapIfOperator()
@@ -855,6 +858,8 @@ struct CommonOperatorGlobalCache final {
   CACHED_TRAP_UNLESS_LIST(CACHED_TRAP_UNLESS)
 #undef CACHED_TRAP_UNLESS
 
+#endif  // V8_ENABLE_WEBASSEMBLY
+
   template <MachineRepresentation kRep, int kInputCount>
   struct PhiOperator final : public Operator1<MachineRepresentation> {
     PhiOperator()
@@ -1061,6 +1066,7 @@ const Operator* CommonOperatorBuilder::DeoptimizeUnless(
       parameter);                                       // parameter
 }
 
+#if V8_ENABLE_WEBASSEMBLY
 const Operator* CommonOperatorBuilder::TrapIf(TrapId trap_id,
                                               bool has_frame_state) {
   switch (trap_id) {
@@ -1107,6 +1113,8 @@ const Operator* CommonOperatorBuilder::TrapUnless(TrapId trap_id,
       trap_id);                                  // parameter
 }
 
+#endif  // V8_ENABLE_WEBASSEMBLY
+
 const Operator* CommonOperatorBuilder::Switch(size_t control_output_count) {
   return zone()->New<Operator>(               // --
       IrOpcode::kSwitch, Operator::kKontrol,  // opcode
diff --git a/src/compiler/common-operator.h b/src/compiler/common-operator.h
index d7cda403c7e..b8b245b15fa 100644
--- a/src/compiler/common-operator.h
+++ b/src/compiler/common-operator.h
@@ -54,17 +54,23 @@ inline BranchHint NegateBranchHint(BranchHint hint) {
   UNREACHABLE();
 }
 
-enum class TrapId : uint32_t {
-#define DEF_ENUM(Name, ...) k##Name,
+#if V8_ENABLE_WEBASSEMBLY
+enum class TrapId : int32_t {
+#define DEF_ENUM(Name, ...) \
+  k##Name = static_cast<uint32_t>(Builtin::kThrowWasm##Name),
   FOREACH_WASM_TRAPREASON(DEF_ENUM)
 #undef DEF_ENUM
 };
 
+static_assert(std::is_same_v<std::underlying_type_t<Builtin>,
+                             std::underlying_type_t<TrapId>>);
+
 inline size_t hash_value(TrapId id) { return static_cast<uint32_t>(id); }
 
 std::ostream& operator<<(std::ostream&, TrapId trap_id);
 
 TrapId TrapIdOf(const Operator* const op);
+#endif
 
 class BranchParameters final {
  public:
@@ -550,8 +556,11 @@ class V8_EXPORT_PRIVATE CommonOperatorBuilder final
                                FeedbackSource const& feedback);
   const Operator* DeoptimizeUnless(DeoptimizeReason reason,
                                    FeedbackSource const& feedback);
+
+#if V8_ENABLE_WEBASSEMBLY
   const Operator* TrapIf(TrapId trap_id, bool has_frame_state);
   const Operator* TrapUnless(TrapId trap_id, bool has_frame_state);
+#endif
   const Operator* Return(int value_input_count = 1);
   const Operator* Terminate();
 
diff --git a/src/compiler/loop-analysis.cc b/src/compiler/loop-analysis.cc
index b0f7b5fd993..e6638fc52b8 100644
--- a/src/compiler/loop-analysis.cc
+++ b/src/compiler/loop-analysis.cc
@@ -14,10 +14,6 @@
 #include "src/compiler/node.h"
 #include "src/zone/zone.h"
 
-#if V8_ENABLE_WEBASSEMBLY
-#include "src/wasm/wasm-code-manager.h"
-#endif
-
 namespace v8 {
 namespace internal {
 
@@ -619,29 +615,28 @@ ZoneUnorderedSet<Node*>* LoopFinder::FindSmallInnermostLoopFromHeader(
             callee->opcode() != IrOpcode::kRelocatableInt64Constant) {
           return nullptr;
         }
-        intptr_t info =
-            OpParameter<RelocatablePtrConstantInfo>(callee->op()).value();
-        using WasmCode = v8::internal::wasm::WasmCode;
-        constexpr intptr_t unrollable_builtins[] = {
+        Builtin builtin = static_cast<Builtin>(
+            OpParameter<RelocatablePtrConstantInfo>(callee->op()).value());
+        constexpr Builtin unrollable_builtins[] = {
             // Exists in every stack check.
-            WasmCode::kWasmStackGuard,
+            Builtin::kWasmStackGuard,
             // Fast table operations.
-            WasmCode::kWasmTableGet, WasmCode::kWasmTableSet,
-            WasmCode::kWasmTableGetFuncRef, WasmCode::kWasmTableSetFuncRef,
-            WasmCode::kWasmTableGrow,
+            Builtin::kWasmTableGet, Builtin::kWasmTableSet,
+            Builtin::kWasmTableGetFuncRef, Builtin::kWasmTableSetFuncRef,
+            Builtin::kWasmTableGrow,
             // Atomics.
-            WasmCode::kWasmAtomicNotify, WasmCode::kWasmI32AtomicWait,
-            WasmCode::kWasmI64AtomicWait,
+            Builtin::kWasmAtomicNotify, Builtin::kWasmI32AtomicWait,
+            Builtin::kWasmI64AtomicWait,
             // Exceptions.
-            WasmCode::kWasmAllocateFixedArray, WasmCode::kWasmThrow,
-            WasmCode::kWasmRethrow, WasmCode::kWasmRethrowExplicitContext,
+            Builtin::kWasmAllocateFixedArray, Builtin::kWasmThrow,
+            Builtin::kWasmRethrow, Builtin::kWasmRethrowExplicitContext,
             // Fast wasm-gc operations.
-            WasmCode::kWasmRefFunc,
+            Builtin::kWasmRefFunc,
             // While a built-in call, this is the slow path, so it should not
             // prevent loop unrolling for stringview_wtf16.get_codeunit.
-            WasmCode::kWasmStringViewWtf16GetCodeUnit};
+            Builtin::kWasmStringViewWtf16GetCodeUnit};
         if (std::count(std::begin(unrollable_builtins),
-                       std::end(unrollable_builtins), info) == 0) {
+                       std::end(unrollable_builtins), builtin) == 0) {
           return nullptr;
         }
         ENQUEUE_USES(use, true)
diff --git a/src/compiler/machine-graph.cc b/src/compiler/machine-graph.cc
index be3c08a7871..e5d60e6ffc3 100644
--- a/src/compiler/machine-graph.cc
+++ b/src/compiler/machine-graph.cc
@@ -85,6 +85,11 @@ Node* MachineGraph::RelocatableIntPtrConstant(intptr_t value,
              : RelocatableInt32Constant(static_cast<int>(value), rmode);
 }
 
+Node* MachineGraph::RelocatableWasmBuiltinCallTarget(Builtin builtin) {
+  return RelocatableIntPtrConstant(static_cast<intptr_t>(builtin),
+                                   RelocInfo::WASM_STUB_CALL);
+}
+
 Node* MachineGraph::Float32Constant(float value) {
   Node** loc = cache_.FindFloat32Constant(value);
   if (*loc == nullptr) {
diff --git a/src/compiler/machine-graph.h b/src/compiler/machine-graph.h
index 8c930303f70..76dcc49fa7d 100644
--- a/src/compiler/machine-graph.h
+++ b/src/compiler/machine-graph.h
@@ -63,6 +63,7 @@ class V8_EXPORT_PRIVATE MachineGraph : public NON_EXPORTED_BASE(ZoneObject) {
   Node* RelocatableInt32Constant(int32_t value, RelocInfo::Mode rmode);
   Node* RelocatableInt64Constant(int64_t value, RelocInfo::Mode rmode);
   Node* RelocatableIntPtrConstant(intptr_t value, RelocInfo::Mode rmode);
+  Node* RelocatableWasmBuiltinCallTarget(Builtin builtin);
 
   // Creates a Float32Constant node, usually canonicalized.
   Node* Float32Constant(float value);
diff --git a/src/compiler/machine-operator-reducer.cc b/src/compiler/machine-operator-reducer.cc
index e5290f40fb6..15b28eae069 100644
--- a/src/compiler/machine-operator-reducer.cc
+++ b/src/compiler/machine-operator-reducer.cc
@@ -987,8 +987,10 @@ Reduction MachineOperatorReducer::Reduce(Node* node) {
     case IrOpcode::kBranch:
     case IrOpcode::kDeoptimizeIf:
     case IrOpcode::kDeoptimizeUnless:
+#if V8_ENABLE_WEBASSEMBLY
     case IrOpcode::kTrapIf:
     case IrOpcode::kTrapUnless:
+#endif
       return ReduceConditional(node);
     case IrOpcode::kInt64LessThan: {
       Int64BinopMatcher m(node);
@@ -2887,6 +2889,7 @@ Reduction MachineOperatorReducer::SimplifyBranch(Node* node) {
         case IrOpcode::kBranch:
           SwapBranches(node);
           break;
+#if V8_ENABLE_WEBASSEMBLY
         case IrOpcode::kTrapIf: {
           const bool has_frame_state = node->op()->ValueInputCount() > 1;
           NodeProperties::ChangeOp(
@@ -2900,6 +2903,7 @@ Reduction MachineOperatorReducer::SimplifyBranch(Node* node) {
               node, common()->TrapIf(TrapIdOf(node->op()), has_frame_state));
           break;
         }
+#endif  // V8_ENABLE_WEBASSEMBLY
         case IrOpcode::kDeoptimizeIf: {
           DeoptimizeParameters p = DeoptimizeParametersOf(node->op());
           NodeProperties::ChangeOp(
diff --git a/src/compiler/turboshaft/assembler.h b/src/compiler/turboshaft/assembler.h
index 7ecf0692290..559809d6c99 100644
--- a/src/compiler/turboshaft/assembler.h
+++ b/src/compiler/turboshaft/assembler.h
@@ -1342,6 +1342,12 @@ class AssemblerOpInterface {
             : ConstantOp::Kind::kRelocatableWasmStubCall,
         static_cast<uint64_t>(value));
   }
+
+  V<WordPtr> RelocatableWasmBuiltinCallTarget(Builtin builtin) {
+    return RelocatableConstant(static_cast<int64_t>(builtin),
+                               RelocInfo::WASM_STUB_CALL);
+  }
+
   V<Context> NoContextConstant() {
     return V<Context>::Cast(TagSmi(Context::kNoContext));
   }
@@ -2290,6 +2296,7 @@ class AssemblerOpInterface {
     Deoptimize(frame_state, params);
   }
 
+#if V8_ENABLE_WEBASSEMBLY
   void TrapIf(V<Word32> condition, OpIndex frame_state, TrapId trap_id) {
     if (V8_UNLIKELY(Asm().generating_unreachable_operations())) {
       return;
@@ -2310,6 +2317,7 @@ class AssemblerOpInterface {
       Asm().SetGeneratingUnreachableOperations();
     }
   }
+#endif  // V8_ENABLE_WEBASSEMBLY
 
   void StaticAssert(OpIndex condition, const char* source) {
     CHECK(v8_flags.turboshaft_enable_debug_features);
@@ -2865,12 +2873,10 @@ class AssemblerOpInterface {
     return ReduceIfReachableSimd128Shuffle(left, right, shuffle);
   }
 
-  OpIndex CallBuiltin(wasm::WasmCode::RuntimeStubId stub_id,
-                      std::initializer_list<OpIndex> args,
+  OpIndex CallBuiltin(Builtin builtin, std::initializer_list<OpIndex> args,
                       Operator::Properties properties) {
-    Builtin builtin_name = RuntimeStubIdToBuiltinName(stub_id);
     CallInterfaceDescriptor interface_descriptor =
-        Builtins::CallInterfaceDescriptorFor(builtin_name);
+        Builtins::CallInterfaceDescriptorFor(builtin);
     const CallDescriptor* call_descriptor =
         compiler::Linkage::GetStubCallDescriptor(
             Asm().output_graph().graph_zone(), interface_descriptor,
@@ -2880,8 +2886,7 @@ class AssemblerOpInterface {
     const TSCallDescriptor* ts_call_descriptor =
         TSCallDescriptor::Create(call_descriptor, compiler::CanThrow::kYes,
                                  Asm().output_graph().graph_zone());
-    V<WordPtr> call_target =
-        RelocatableConstant(stub_id, RelocInfo::WASM_STUB_CALL);
+    V<WordPtr> call_target = RelocatableWasmBuiltinCallTarget(builtin);
     return Call(call_target, OpIndex::Invalid(), base::VectorOf(args),
                 ts_call_descriptor);
   }
diff --git a/src/compiler/turboshaft/branch-elimination-reducer.h b/src/compiler/turboshaft/branch-elimination-reducer.h
index 6904a31308e..2e726df49f6 100644
--- a/src/compiler/turboshaft/branch-elimination-reducer.h
+++ b/src/compiler/turboshaft/branch-elimination-reducer.h
@@ -375,6 +375,7 @@ class BranchEliminationReducer : public Next {
     }
   }
 
+#if V8_ENABLE_WEBASSEMBLY
   OpIndex REDUCE(TrapIf)(OpIndex condition, OpIndex frame_state, bool negated,
                          const TrapId trap_id) {
     LABEL_BLOCK(no_change) {
@@ -400,6 +401,7 @@ class BranchEliminationReducer : public Next {
     }
     return OpIndex::Invalid();
   }
+#endif  // V8_ENABLE_WEBASSEMBLY
 
  private:
   // Resets {known_conditions_} and {dominator_path_} up to the 1st dominator of
diff --git a/src/compiler/turboshaft/debug-feature-lowering-reducer.h b/src/compiler/turboshaft/debug-feature-lowering-reducer.h
index 058141cbd72..807dbde30ec 100644
--- a/src/compiler/turboshaft/debug-feature-lowering-reducer.h
+++ b/src/compiler/turboshaft/debug-feature-lowering-reducer.h
@@ -45,12 +45,12 @@ class DebugFeatureLoweringReducer : public Next {
                   WasmInstanceObject::kNativeContextOffset);
       switch (rep.value()) {
         case RegisterRepresentation::Float64():
-          __ CallBuiltin(wasm::WasmCode::kDebugPrintFloat64,
-                         {input, native_context}, Operator::kNoProperties);
+          __ CallBuiltin(Builtin::kDebugPrintFloat64, {input, native_context},
+                         Operator::kNoProperties);
           break;
         case RegisterRepresentation::PointerSized():
-          __ CallBuiltin(wasm::WasmCode::kDebugPrintWordPtr,
-                         {input, native_context}, Operator::kNoProperties);
+          __ CallBuiltin(Builtin::kDebugPrintWordPtr, {input, native_context},
+                         Operator::kNoProperties);
           break;
         default:
           // TODO(mliedtke): Support other representations.
diff --git a/src/compiler/turboshaft/graph-builder.cc b/src/compiler/turboshaft/graph-builder.cc
index 3297c024c82..053fa16c338 100644
--- a/src/compiler/turboshaft/graph-builder.cc
+++ b/src/compiler/turboshaft/graph-builder.cc
@@ -1290,6 +1290,7 @@ OpIndex GraphBuilder::Process(
                          &DeoptimizeParametersOf(op));
       return OpIndex::Invalid();
 
+#if V8_ENABLE_WEBASSEMBLY
     case IrOpcode::kTrapIf:
       // For wasm the dominating_frame_state is invalid and will not be used.
       // For traps inlined into JS the dominating_frame_state is valid and is
@@ -1303,6 +1304,7 @@ OpIndex GraphBuilder::Process(
       // needed for the trap.
       __ TrapIfNot(Map(node->InputAt(0)), dominating_frame_state, TrapIdOf(op));
       return OpIndex::Invalid();
+#endif  // V8_ENABLE_WEBASSEMBLY
 
     case IrOpcode::kDeoptimize: {
       OpIndex frame_state = Map(node->InputAt(0));
diff --git a/src/compiler/turboshaft/machine-optimization-reducer.h b/src/compiler/turboshaft/machine-optimization-reducer.h
index c94f23dd9aa..547113fa035 100644
--- a/src/compiler/turboshaft/machine-optimization-reducer.h
+++ b/src/compiler/turboshaft/machine-optimization-reducer.h
@@ -1565,6 +1565,7 @@ class MachineOptimizationReducer : public Next {
     }
   }
 
+#if V8_ENABLE_WEBASSEMBLY
   OpIndex REDUCE(TrapIf)(OpIndex condition, OpIndex frame_state, bool negated,
                          TrapId trap_id) {
     LABEL_BLOCK(no_change) {
@@ -1587,6 +1588,7 @@ class MachineOptimizationReducer : public Next {
       goto no_change;
     }
   }
+#endif  // V8_ENABLE_WEBASSEMBLY
 
   OpIndex REDUCE(Select)(OpIndex cond, OpIndex vtrue, OpIndex vfalse,
                          RegisterRepresentation rep, BranchHint hint,
diff --git a/src/compiler/turboshaft/operations.h b/src/compiler/turboshaft/operations.h
index 8155b689ad9..418b0373995 100644
--- a/src/compiler/turboshaft/operations.h
+++ b/src/compiler/turboshaft/operations.h
@@ -48,7 +48,7 @@ class CallDescriptor;
 class DeoptimizeParameters;
 class FrameStateInfo;
 class Node;
-enum class TrapId : uint32_t;
+enum class TrapId : int32_t;
 }  // namespace v8::internal::compiler
 namespace v8::internal::compiler::turboshaft {
 class Block;
@@ -232,7 +232,7 @@ using Variable = SnapshotTable<OpIndex, VariableData>::Key;
   V(StackSlot)                               \
   V(FrameConstant)                           \
   V(DeoptimizeIf)                            \
-  V(TrapIf)                                  \
+  IF_WASM(V, TrapIf)                         \
   V(Phi)                                     \
   V(FrameState)                              \
   V(Call)                                    \
@@ -3210,6 +3210,7 @@ struct DeoptimizeIfOp : FixedArityOperationT<2, DeoptimizeIfOp> {
   auto options() const { return std::tuple{negated, parameters}; }
 };
 
+#if V8_ENABLE_WEBASSEMBLY
 struct TrapIfOp : OperationT<TrapIfOp> {
   bool negated;
   const TrapId trap_id;
@@ -3254,6 +3255,7 @@ struct TrapIfOp : OperationT<TrapIfOp> {
   }
   auto options() const { return std::tuple{negated, trap_id}; }
 };
+#endif  // V8_ENABLE_WEBASSEMBLY
 
 struct StaticAssertOp : FixedArityOperationT<1, StaticAssertOp> {
   const char* source;
diff --git a/src/compiler/turboshaft/optimization-phase.h b/src/compiler/turboshaft/optimization-phase.h
index e34700255ed..fb1e91089b3 100644
--- a/src/compiler/turboshaft/optimization-phase.h
+++ b/src/compiler/turboshaft/optimization-phase.h
@@ -892,11 +892,15 @@ class GraphVisitor {
                                           MapToNewGraph(op.frame_state()),
                                           op.negated, op.parameters);
   }
+
+#if V8_ENABLE_WEBASSEMBLY
   OpIndex AssembleOutputGraphTrapIf(const TrapIfOp& op) {
     return assembler().ReduceTrapIf(MapToNewGraph(op.condition()),
                                     MapToNewGraphIfValid(op.frame_state()),
                                     op.negated, op.trap_id);
   }
+#endif  // V8_ENABLE_WEBASSEMBLY
+
   OpIndex AssembleOutputGraphTuple(const TupleOp& op) {
     return assembler().ReduceTuple(
         base::VectorOf(MapToNewGraph<4>(op.inputs())));
diff --git a/src/compiler/turboshaft/recreate-schedule.cc b/src/compiler/turboshaft/recreate-schedule.cc
index fcd2d80d960..ee9eb3e3d9f 100644
--- a/src/compiler/turboshaft/recreate-schedule.cc
+++ b/src/compiler/turboshaft/recreate-schedule.cc
@@ -1213,6 +1213,8 @@ Node* ScheduleBuilder::ProcessOperation(const DeoptimizeIfOp& op) {
                                                 op.parameters->feedback());
   return AddNode(o, {condition, frame_state});
 }
+
+#if V8_ENABLE_WEBASSEMBLY
 Node* ScheduleBuilder::ProcessOperation(const TrapIfOp& op) {
   Node* condition = GetNode(op.condition());
   bool has_frame_state = op.frame_state().valid();
@@ -1223,6 +1225,8 @@ Node* ScheduleBuilder::ProcessOperation(const TrapIfOp& op) {
   return has_frame_state ? AddNode(o, {condition, frame_state})
                          : AddNode(o, {condition});
 }
+#endif  // V8_ENABLE_WEBASSEMBLY
+
 Node* ScheduleBuilder::ProcessOperation(const DeoptimizeOp& op) {
   Node* frame_state = GetNode(op.frame_state());
   const Operator* o =
diff --git a/src/compiler/turboshaft/reduce-args-helper.h b/src/compiler/turboshaft/reduce-args-helper.h
index 97561bc18d1..79d4f4cb48d 100644
--- a/src/compiler/turboshaft/reduce-args-helper.h
+++ b/src/compiler/turboshaft/reduce-args-helper.h
@@ -208,9 +208,11 @@ class CallWithReduceArgsHelper {
                      op.parameters);
   }
 
+#if V8_ENABLE_WEBASSEMBLY
   OpIndex operator()(const TrapIfOp& op) {
     return callback_(op.condition(), op.frame_state(), op.negated, op.trap_id);
   }
+#endif
 
   OpIndex operator()(const ProjectionOp& op) {
     return callback_(op.input(), op.index, op.rep);
diff --git a/src/compiler/turboshaft/type-inference-analysis.h b/src/compiler/turboshaft/type-inference-analysis.h
index eeeda45d005..918f8574450 100644
--- a/src/compiler/turboshaft/type-inference-analysis.h
+++ b/src/compiler/turboshaft/type-inference-analysis.h
@@ -156,7 +156,6 @@ class TypeInferenceAnalysis {
         case Opcode::kReturn:
         case Opcode::kStore:
         case Opcode::kRetain:
-        case Opcode::kTrapIf:
         case Opcode::kUnreachable:
         case Opcode::kSwitch:
         case Opcode::kTuple:
@@ -165,6 +164,7 @@ class TypeInferenceAnalysis {
         case Opcode::kDebugPrint:
 #if V8_ENABLE_WEBASSEMBLY
         case Opcode::kGlobalSet:
+        case Opcode::kTrapIf:
 #endif
         case Opcode::kCheckException:
           // These operations do not produce any output that needs to be typed.
diff --git a/src/compiler/turboshaft/wasm-js-lowering-reducer.h b/src/compiler/turboshaft/wasm-js-lowering-reducer.h
index 5c39937c8b8..8544d9dee28 100644
--- a/src/compiler/turboshaft/wasm-js-lowering-reducer.h
+++ b/src/compiler/turboshaft/wasm-js-lowering-reducer.h
@@ -31,8 +31,7 @@ class WasmJSLoweringReducer : public Next {
                          TrapId trap_id) {
     // All TrapIf nodes in JS need to have a FrameState.
     DCHECK(frame_state.valid());
-    Builtin trap = wasm::RuntimeStubIdToBuiltinName(
-        static_cast<wasm::WasmCode::RuntimeStubId>(trap_id));
+    Builtin trap = static_cast<Builtin>(trap_id);
     // The call is not marked as Operator::kNoDeopt. While it cannot actually
     // deopt, deopt info based on the provided FrameState is required for stack
     // trace creation of the wasm trap.
diff --git a/src/compiler/turboshaft/wasm-lowering-reducer.h b/src/compiler/turboshaft/wasm-lowering-reducer.h
index d53e6d8f6cb..b4f8a33eb1c 100644
--- a/src/compiler/turboshaft/wasm-lowering-reducer.h
+++ b/src/compiler/turboshaft/wasm-lowering-reducer.h
@@ -144,8 +144,8 @@ class WasmLoweringReducer : public Next {
       GOTO(end_label, object);
 
       BIND(convert_to_heap_number_label);
-      V<Tagged> heap_number = __ CallBuiltin(
-          wasm::WasmCode::kWasmInt32ToHeapNumber, {int_value}, Operator::kPure);
+      V<Tagged> heap_number = __ CallBuiltin(Builtin::kWasmInt32ToHeapNumber,
+                                             {int_value}, Operator::kPure);
       GOTO(end_label, heap_number);
     }
 
@@ -286,7 +286,7 @@ class WasmLoweringReducer : public Next {
     V<Word32> string_representation = __ Word32BitwiseAnd(
         instance_type, __ Word32Constant(kStringRepresentationMask));
     GOTO_IF(__ Word32Equal(string_representation, kSeqStringTag), done, string);
-    GOTO(done, __ CallBuiltin(wasm::WasmCode::kWasmStringAsWtf16, {string},
+    GOTO(done, __ CallBuiltin(Builtin::kWasmStringAsWtf16, {string},
                               Operator::kPure));
     BIND(done, result);
     return result;
diff --git a/src/compiler/wasm-compiler.cc b/src/compiler/wasm-compiler.cc
index 2b206726f3a..d063f7e278b 100644
--- a/src/compiler/wasm-compiler.cc
+++ b/src/compiler/wasm-compiler.cc
@@ -379,9 +379,9 @@ Node* WasmGraphBuilder::RefFunc(uint32_t function_index) {
   gasm_->Goto(&done, maybe_function);
 
   gasm_->Bind(&create_funcref);
-  Node* function_from_builtin =
-      gasm_->CallRuntimeStub(wasm::WasmCode::kWasmRefFunc, Operator::kNoThrow,
-                             gasm_->Uint32Constant(function_index));
+  Node* function_from_builtin = gasm_->CallBuiltinThroughJumptable(
+      Builtin::kWasmRefFunc, Operator::kNoThrow,
+      gasm_->Uint32Constant(function_index));
   gasm_->Goto(&done, function_from_builtin);
 
   gasm_->Bind(&done);
@@ -446,8 +446,8 @@ void WasmGraphBuilder::StackCheck(
 
     // A direct call to a wasm runtime stub defined in this module.
     // Just encode the stub index. This will be patched at relocation.
-    stack_check_code_node_.set(mcgraph()->RelocatableIntPtrConstant(
-        wasm::WasmCode::kWasmStackGuard, RelocInfo::WASM_STUB_CALL));
+    stack_check_code_node_.set(
+        mcgraph()->RelocatableWasmBuiltinCallTarget(Builtin::kWasmStackGuard));
 
     constexpr Operator::Properties properties =
         Operator::kNoThrow | Operator::kNoWrite;
@@ -1178,13 +1178,14 @@ Node* WasmGraphBuilder::Select(Node *cond, Node* true_node,
   return Phi(type, 2, inputs);
 }
 
+// TODO(ahaas): Merge TrapId with TrapReason.
 TrapId WasmGraphBuilder::GetTrapIdForTrap(wasm::TrapReason reason) {
   switch (reason) {
-#define TRAPREASON_TO_TRAPID(name)                                             \
-  case wasm::k##name:                                                          \
-    static_assert(                                                             \
-        static_cast<int>(TrapId::k##name) == wasm::WasmCode::kThrowWasm##name, \
-        "trap id mismatch");                                                   \
+#define TRAPREASON_TO_TRAPID(name)                                 \
+  case wasm::k##name:                                              \
+    static_assert(static_cast<int>(TrapId::k##name) ==             \
+                      static_cast<int>(Builtin::kThrowWasm##name), \
+                  "trap id mismatch");                             \
     return TrapId::k##name;
     FOREACH_WASM_TRAPREASON(TRAPREASON_TO_TRAPID)
 #undef TRAPREASON_TO_TRAPID
@@ -2164,9 +2165,9 @@ Node* WasmGraphBuilder::MemoryGrow(const wasm::WasmMemory* memory,
   needs_stack_check_ = true;
   if (!memory->is_memory64) {
     // For 32-bit memories, just call the builtin.
-    return gasm_->CallRuntimeStub(wasm::WasmCode::kWasmMemoryGrow,
-                                  Operator::kNoThrow,
-                                  gasm_->Int32Constant(memory->index), input);
+    return gasm_->CallBuiltinThroughJumptable(
+        Builtin::kWasmMemoryGrow, Operator::kNoThrow,
+        gasm_->Int32Constant(memory->index), input);
   }
 
   // If the input is not a positive int32, growing will always fail
@@ -2179,9 +2180,11 @@ Node* WasmGraphBuilder::MemoryGrow(const wasm::WasmMemory* memory,
 
   SetControl(is_32_bit.if_true);
 
-  Node* grow_result = gasm_->ChangeInt32ToInt64(gasm_->CallRuntimeStub(
-      wasm::WasmCode::kWasmMemoryGrow, Operator::kNoThrow,
-      gasm_->Int32Constant(memory->index), gasm_->TruncateInt64ToInt32(input)));
+  Node* grow_result =
+      gasm_->ChangeInt32ToInt64(gasm_->CallBuiltinThroughJumptable(
+          Builtin::kWasmMemoryGrow, Operator::kNoThrow,
+          gasm_->Int32Constant(memory->index),
+          gasm_->TruncateInt64ToInt32(input)));
 
   Node* diamond_result = is_32_bit.Phi(MachineRepresentation::kWord64,
                                        grow_result, gasm_->Int64Constant(-1));
@@ -2195,8 +2198,8 @@ Node* WasmGraphBuilder::Throw(uint32_t tag_index, const wasm::WasmTag* tag,
   needs_stack_check_ = true;
   uint32_t encoded_size = WasmExceptionPackage::GetEncodedSize(tag);
 
-  Node* values_array = gasm_->CallRuntimeStub(
-      wasm::WasmCode::kWasmAllocateFixedArray, Operator::kNoThrow,
+  Node* values_array = gasm_->CallBuiltinThroughJumptable(
+      Builtin::kWasmAllocateFixedArray, Operator::kNoThrow,
       gasm_->IntPtrConstant(encoded_size));
   SetSourcePosition(values_array, position);
 
@@ -2254,9 +2257,9 @@ Node* WasmGraphBuilder::Throw(uint32_t tag_index, const wasm::WasmTag* tag,
 
   Node* exception_tag = LoadTagFromTable(tag_index);
 
-  Node* throw_call = gasm_->CallRuntimeStub(wasm::WasmCode::kWasmThrow,
-                                            Operator::kNoProperties,
-                                            exception_tag, values_array);
+  Node* throw_call = gasm_->CallBuiltinThroughJumptable(
+      Builtin::kWasmThrow, Operator::kNoProperties, exception_tag,
+      values_array);
   SetSourcePosition(throw_call, position);
   return throw_call;
 }
@@ -2302,8 +2305,8 @@ Node* WasmGraphBuilder::Rethrow(Node* except_obj) {
   // TODO(v8:8091): Currently the message of the original exception is not being
   // preserved when rethrown to the console. The pending message will need to be
   // saved when caught and restored here while being rethrown.
-  return gasm_->CallRuntimeStub(wasm::WasmCode::kWasmRethrow,
-                                Operator::kNoProperties, except_obj);
+  return gasm_->CallBuiltinThroughJumptable(
+      Builtin::kWasmRethrow, Operator::kNoProperties, except_obj);
 }
 
 Node* WasmGraphBuilder::IsExceptionTagUndefined(Node* tag) {
@@ -3520,22 +3523,22 @@ Node* WasmGraphBuilder::TableGet(uint32_t table_index, Node* index,
                                  wasm::WasmCodePosition position) {
   const wasm::WasmTable& table = env_->module->tables[table_index];
   bool is_funcref = IsSubtypeOf(table.type, wasm::kWasmFuncRef, env_->module);
-  auto stub = is_funcref ? wasm::WasmCode::kWasmTableGetFuncRef
-                         : wasm::WasmCode::kWasmTableGet;
+  auto stub =
+      is_funcref ? Builtin::kWasmTableGetFuncRef : Builtin::kWasmTableGet;
 
-  return gasm_->CallRuntimeStub(stub, Operator::kNoThrow,
-                                gasm_->IntPtrConstant(table_index), index);
+  return gasm_->CallBuiltinThroughJumptable(
+      stub, Operator::kNoThrow, gasm_->IntPtrConstant(table_index), index);
 }
 
 void WasmGraphBuilder::TableSet(uint32_t table_index, Node* index, Node* val,
                                 wasm::WasmCodePosition position) {
   const wasm::WasmTable& table = env_->module->tables[table_index];
   bool is_funcref = IsSubtypeOf(table.type, wasm::kWasmFuncRef, env_->module);
-  auto stub = is_funcref ? wasm::WasmCode::kWasmTableSetFuncRef
-                         : wasm::WasmCode::kWasmTableSet;
+  auto stub =
+      is_funcref ? Builtin::kWasmTableSetFuncRef : Builtin::kWasmTableSet;
 
-  gasm_->CallRuntimeStub(stub, Operator::kNoThrow,
-                         gasm_->IntPtrConstant(table_index), index, val);
+  gasm_->CallBuiltinThroughJumptable(
+      stub, Operator::kNoThrow, gasm_->IntPtrConstant(table_index), index, val);
 }
 
 std::pair<Node*, BoundsCheckResult> WasmGraphBuilder::CheckBoundsAndAlignment(
@@ -5145,18 +5148,17 @@ Node* WasmGraphBuilder::AtomicOp(const wasm::WasmMemory* memory,
 
   switch (opcode) {
     case wasm::kExprAtomicNotify:
-      return gasm_->CallRuntimeStub(wasm::WasmCode::kWasmAtomicNotify,
-                                    Operator::kNoThrow, memory_index,
-                                    effective_offset, inputs[1]);
+      return gasm_->CallBuiltinThroughJumptable(
+          Builtin::kWasmAtomicNotify, Operator::kNoThrow, memory_index,
+          effective_offset, inputs[1]);
 
     case wasm::kExprI32AtomicWait: {
       constexpr StubCallMode kStubMode = StubCallMode::kCallWasmRuntimeStub;
       auto* call_descriptor = GetBuiltinCallDescriptor(
           Builtin::kWasmI32AtomicWait, zone_, kStubMode);
 
-      intptr_t target = wasm::WasmCode::kWasmI32AtomicWait;
-      Node* call_target = mcgraph()->RelocatableIntPtrConstant(
-          target, RelocInfo::WASM_STUB_CALL);
+      Builtin target = Builtin::kWasmI32AtomicWait;
+      Node* call_target = mcgraph()->RelocatableWasmBuiltinCallTarget(target);
 
       return gasm_->Call(call_descriptor, call_target, memory_index,
                          effective_offset, inputs[1],
@@ -5168,9 +5170,8 @@ Node* WasmGraphBuilder::AtomicOp(const wasm::WasmMemory* memory,
       auto* call_descriptor = GetBuiltinCallDescriptor(
           Builtin::kWasmI64AtomicWait, zone_, kStubMode);
 
-      intptr_t target = wasm::WasmCode::kWasmI64AtomicWait;
-      Node* call_target = mcgraph()->RelocatableIntPtrConstant(
-          target, RelocInfo::WASM_STUB_CALL);
+      Builtin target = Builtin::kWasmI64AtomicWait;
+      Node* call_target = mcgraph()->RelocatableWasmBuiltinCallTarget(target);
 
       return gasm_->Call(call_descriptor, call_target, memory_index,
                          effective_offset,
@@ -5327,9 +5328,10 @@ void WasmGraphBuilder::TableInit(uint32_t table_index,
                                  uint32_t elem_segment_index, Node* dst,
                                  Node* src, Node* size,
                                  wasm::WasmCodePosition position) {
-  gasm_->CallRuntimeStub(wasm::WasmCode::kWasmTableInit, Operator::kNoThrow,
-                         dst, src, size, gasm_->NumberConstant(table_index),
-                         gasm_->NumberConstant(elem_segment_index));
+  gasm_->CallBuiltinThroughJumptable(Builtin::kWasmTableInit,
+                                     Operator::kNoThrow, dst, src, size,
+                                     gasm_->NumberConstant(table_index),
+                                     gasm_->NumberConstant(elem_segment_index));
 }
 
 void WasmGraphBuilder::ElemDrop(uint32_t elem_segment_index,
@@ -5349,16 +5351,17 @@ void WasmGraphBuilder::ElemDrop(uint32_t elem_segment_index,
 void WasmGraphBuilder::TableCopy(uint32_t table_dst_index,
                                  uint32_t table_src_index, Node* dst, Node* src,
                                  Node* size, wasm::WasmCodePosition position) {
-  gasm_->CallRuntimeStub(wasm::WasmCode::kWasmTableCopy, Operator::kNoThrow,
-                         dst, src, size, gasm_->NumberConstant(table_dst_index),
-                         gasm_->NumberConstant(table_src_index));
+  gasm_->CallBuiltinThroughJumptable(Builtin::kWasmTableCopy,
+                                     Operator::kNoThrow, dst, src, size,
+                                     gasm_->NumberConstant(table_dst_index),
+                                     gasm_->NumberConstant(table_src_index));
 }
 
 Node* WasmGraphBuilder::TableGrow(uint32_t table_index, Node* value,
                                   Node* delta) {
-  return gasm_->BuildChangeSmiToInt32(
-      gasm_->CallRuntimeStub(wasm::WasmCode::kWasmTableGrow, Operator::kNoThrow,
-                             gasm_->NumberConstant(table_index), delta, value));
+  return gasm_->BuildChangeSmiToInt32(gasm_->CallBuiltinThroughJumptable(
+      Builtin::kWasmTableGrow, Operator::kNoThrow,
+      gasm_->NumberConstant(table_index), delta, value));
 }
 
 Node* WasmGraphBuilder::TableSize(uint32_t table_index) {
@@ -5376,9 +5379,9 @@ Node* WasmGraphBuilder::TableSize(uint32_t table_index) {
 
 void WasmGraphBuilder::TableFill(uint32_t table_index, Node* start, Node* value,
                                  Node* count) {
-  gasm_->CallRuntimeStub(wasm::WasmCode::kWasmTableFill, Operator::kNoThrow,
-                         gasm_->NumberConstant(table_index), start, count,
-                         value);
+  gasm_->CallBuiltinThroughJumptable(
+      Builtin::kWasmTableFill, Operator::kNoThrow,
+      gasm_->NumberConstant(table_index), start, count, value);
 }
 
 Node* WasmGraphBuilder::DefaultValue(wasm::ValueType type) {
@@ -6387,8 +6390,8 @@ Node* WasmGraphBuilder::StringViewWtf16GetCodeUnit(
   gasm_->Goto(&done, result);
 
   gasm_->Bind(&bailout);
-  gasm_->Goto(&done, gasm_->CallRuntimeStub(
-                         wasm::WasmCode::kWasmStringViewWtf16GetCodeUnit,
+  gasm_->Goto(&done, gasm_->CallBuiltinThroughJumptable(
+                         Builtin::kWasmStringViewWtf16GetCodeUnit,
                          Operator::kPure, string, offset));
 
   gasm_->Bind(&done);
@@ -6461,9 +6464,9 @@ Node* WasmGraphBuilder::StringCodePointAt(Node* string, CheckForNull null_check,
   gasm_->Goto(&done, result);
 
   gasm_->Bind(&bailout);
-  gasm_->Goto(&done,
-              gasm_->CallRuntimeStub(wasm::WasmCode::kWasmStringCodePointAt,
-                                     Operator::kPure, string, offset));
+  gasm_->Goto(&done, gasm_->CallBuiltinThroughJumptable(
+                         Builtin::kWasmStringCodePointAt, Operator::kPure,
+                         string, offset));
 
   gasm_->Bind(&done);
   // Make sure the original string is kept alive as long as we're operating
@@ -6923,11 +6926,9 @@ class WasmWrapperGraphBuilder : public WasmGraphBuilder {
         stub_mode_, needs_frame_state);
   }
 
-  Node* GetTargetForBuiltinCall(wasm::WasmCode::RuntimeStubId wasm_stub,
-                                Builtin builtin) {
+  Node* GetTargetForBuiltinCall(Builtin builtin) {
     return (stub_mode_ == StubCallMode::kCallWasmRuntimeStub)
-               ? mcgraph()->RelocatableIntPtrConstant(wasm_stub,
-                                                      RelocInfo::WASM_STUB_CALL)
+               ? mcgraph()->RelocatableWasmBuiltinCallTarget(builtin)
                : gasm_->GetBuiltinPointerTarget(builtin);
   }
 
@@ -6955,9 +6956,7 @@ class WasmWrapperGraphBuilder : public WasmGraphBuilder {
     // Otherwise, call builtin, to convert to a HeapNumber.
     gasm_->Bind(&builtin);
     CommonOperatorBuilder* common = mcgraph()->common();
-    Node* target =
-        GetTargetForBuiltinCall(wasm::WasmCode::kWasmInt32ToHeapNumber,
-                                Builtin::kWasmInt32ToHeapNumber);
+    Node* target = GetTargetForBuiltinCall(Builtin::kWasmInt32ToHeapNumber);
     if (!int32_to_heapnumber_operator_.is_set()) {
       auto call_descriptor = Linkage::GetStubCallDescriptor(
           mcgraph()->zone(), WasmInt32ToHeapNumberDescriptor(), 0,
@@ -6987,9 +6986,7 @@ class WasmWrapperGraphBuilder : public WasmGraphBuilder {
     // Otherwise, call builtin which changes non-Smi to Int32.
     gasm_->Bind(&builtin);
     CommonOperatorBuilder* common = mcgraph()->common();
-    Node* target =
-        GetTargetForBuiltinCall(wasm::WasmCode::kWasmTaggedNonSmiToInt32,
-                                Builtin::kWasmTaggedNonSmiToInt32);
+    Node* target = GetTargetForBuiltinCall(Builtin::kWasmTaggedNonSmiToInt32);
     if (!tagged_non_smi_to_int32_operator_.is_set()) {
       auto call_descriptor = Linkage::GetStubCallDescriptor(
           mcgraph()->zone(), WasmTaggedNonSmiToInt32Descriptor(), 0,
@@ -7013,8 +7010,7 @@ class WasmWrapperGraphBuilder : public WasmGraphBuilder {
 
   Node* BuildChangeFloat32ToNumber(Node* value) {
     CommonOperatorBuilder* common = mcgraph()->common();
-    Node* target = GetTargetForBuiltinCall(wasm::WasmCode::kWasmFloat32ToNumber,
-                                           Builtin::kWasmFloat32ToNumber);
+    Node* target = GetTargetForBuiltinCall(Builtin::kWasmFloat32ToNumber);
     if (!float32_to_number_operator_.is_set()) {
       auto call_descriptor = Linkage::GetStubCallDescriptor(
           mcgraph()->zone(), WasmFloat32ToNumberDescriptor(), 0,
@@ -7026,8 +7022,7 @@ class WasmWrapperGraphBuilder : public WasmGraphBuilder {
 
   Node* BuildChangeFloat64ToNumber(Node* value) {
     CommonOperatorBuilder* common = mcgraph()->common();
-    Node* target = GetTargetForBuiltinCall(wasm::WasmCode::kWasmFloat64ToNumber,
-                                           Builtin::kWasmFloat64ToNumber);
+    Node* target = GetTargetForBuiltinCall(Builtin::kWasmFloat64ToNumber);
     if (!float64_to_number_operator_.is_set()) {
       auto call_descriptor = Linkage::GetStubCallDescriptor(
           mcgraph()->zone(), WasmFloat64ToTaggedDescriptor(), 0,
@@ -7040,8 +7035,7 @@ class WasmWrapperGraphBuilder : public WasmGraphBuilder {
   Node* BuildChangeTaggedToFloat64(Node* value, Node* context,
                                    Node* frame_state) {
     CommonOperatorBuilder* common = mcgraph()->common();
-    Node* target = GetTargetForBuiltinCall(wasm::WasmCode::kWasmTaggedToFloat64,
-                                           Builtin::kWasmTaggedToFloat64);
+    Node* target = GetTargetForBuiltinCall(Builtin::kWasmTaggedToFloat64);
     bool needs_frame_state = frame_state != nullptr;
     if (!tagged_to_float64_operator_.is_set()) {
       auto call_descriptor = Linkage::GetStubCallDescriptor(
@@ -7195,15 +7189,13 @@ class WasmWrapperGraphBuilder : public WasmGraphBuilder {
                                  Node* frame_state) {
     Node* target;
     if (mcgraph()->machine()->Is64()) {
-      target = GetTargetForBuiltinCall(wasm::WasmCode::kBigIntToI64,
-                                       Builtin::kBigIntToI64);
+      target = GetTargetForBuiltinCall(Builtin::kBigIntToI64);
     } else {
       DCHECK(mcgraph()->machine()->Is32());
       // On 32-bit platforms we already set the target to the
       // BigIntToI32Pair builtin here, so that we don't have to replace the
       // target in the int64-lowering.
-      target = GetTargetForBuiltinCall(wasm::WasmCode::kBigIntToI32Pair,
-                                       Builtin::kBigIntToI32Pair);
+      target = GetTargetForBuiltinCall(Builtin::kBigIntToI32Pair);
     }
 
     return frame_state ? gasm_->Call(GetBigIntToI64CallDescriptor(true), target,
@@ -7699,8 +7691,7 @@ class WasmWrapperGraphBuilder : public WasmGraphBuilder {
 
     auto* call_descriptor =
         GetBuiltinCallDescriptor(Builtin::kWasmSuspend, zone_, stub_mode_);
-    Node* call_target = GetTargetForBuiltinCall(wasm::WasmCode::kWasmSuspend,
-                                                Builtin::kWasmSuspend);
+    Node* call_target = GetTargetForBuiltinCall(Builtin::kWasmSuspend);
     // Trap if there is any JS frame on the stack. Trap before decrementing the
     // wasm-to-js counter, since it will already be decremented by the stack
     // unwinder.
@@ -8051,8 +8042,8 @@ class WasmWrapperGraphBuilder : public WasmGraphBuilder {
         mcgraph()->zone(), interface_descriptor,
         interface_descriptor.GetStackParameterCount(), CallDescriptor::kNoFlags,
         Operator::kNoProperties, StubCallMode::kCallWasmRuntimeStub);
-    Node* call_target = mcgraph()->RelocatableIntPtrConstant(
-        wasm::WasmCode::kWasmRethrowExplicitContext, RelocInfo::WASM_STUB_CALL);
+    Node* call_target = mcgraph()->RelocatableWasmBuiltinCallTarget(
+        Builtin::kWasmRethrowExplicitContext);
     Node* context = gasm_->Load(
         MachineType::TaggedPointer(), Param(0),
         wasm::ObjectAccess::ToTagged(WasmApiFunctionRef::kNativeContextOffset));
diff --git a/src/compiler/wasm-compiler.h b/src/compiler/wasm-compiler.h
index 5f8c986c68a..e6f1dc31245 100644
--- a/src/compiler/wasm-compiler.h
+++ b/src/compiler/wasm-compiler.h
@@ -47,7 +47,7 @@ class SourcePositionTable;
 struct WasmCompilationData;
 class WasmDecorator;
 class WasmGraphAssembler;
-enum class TrapId : uint32_t;
+enum class TrapId : int32_t;
 struct Int64LoweringSpecialCase;
 template <size_t VarCount>
 class GraphAssemblerLabel;
diff --git a/src/compiler/wasm-graph-assembler.h b/src/compiler/wasm-graph-assembler.h
index b996365f309..74cc1a744ea 100644
--- a/src/compiler/wasm-graph-assembler.h
+++ b/src/compiler/wasm-graph-assembler.h
@@ -29,22 +29,21 @@ class WasmGraphAssembler : public GraphAssembler {
       : GraphAssembler(mcgraph, zone, BranchSemantics::kMachine),
         simplified_(zone) {}
 
-  // Calls the builtin specified via the stub_id.
   // While CallBuiltin() translates to a direct call to the address of the
-  // builtin, CallRuntimeStub instead jumps to the stub_id's slot in a jump
+  // builtin, CallBuiltinThroughJumptable instead jumps to a slot in a jump
   // table that then calls the builtin. As the jump table is "close" to the
   // generated code, this is encoded as a near call resulting in the instruction
   // being shorter than a direct call to the builtin.
   template <typename... Args>
-  Node* CallRuntimeStub(wasm::WasmCode::RuntimeStubId stub_id,
-                        Operator::Properties properties, Args... args) {
+  Node* CallBuiltinThroughJumptable(Builtin builtin,
+                                    Operator::Properties properties,
+                                    Args... args) {
     auto* call_descriptor = GetBuiltinCallDescriptor(
-        RuntimeStubIdToBuiltinName(stub_id), temp_zone(),
-        StubCallMode::kCallWasmRuntimeStub, false, properties);
+        builtin, temp_zone(), StubCallMode::kCallWasmRuntimeStub, false,
+        properties);
     // A direct call to a wasm runtime stub defined in this module.
     // Just encode the stub index. This will be patched at relocation.
-    Node* call_target = mcgraph()->RelocatableIntPtrConstant(
-        stub_id, RelocInfo::WASM_STUB_CALL);
+    Node* call_target = mcgraph()->RelocatableWasmBuiltinCallTarget(builtin);
     return Call(call_descriptor, call_target, args...);
   }
 
diff --git a/src/compiler/wasm-js-lowering.cc b/src/compiler/wasm-js-lowering.cc
index 5bfea5b6182..972edf0943d 100644
--- a/src/compiler/wasm-js-lowering.cc
+++ b/src/compiler/wasm-js-lowering.cc
@@ -9,7 +9,6 @@
 #include "src/compiler/node-properties.h"
 #include "src/compiler/opcodes.h"
 #include "src/compiler/operator.h"
-#include "src/wasm/wasm-code-manager.h"
 
 namespace v8::internal::compiler {
 
@@ -43,8 +42,7 @@ Reduction WasmJSLowering::Reduce(Node* node) {
       gasm_.InitializeEffectControl(nullptr, nullptr);
       gasm_.Bind(&ool_trap);
       TrapId trap_id = TrapIdOf(node->op());
-      Builtin trap = wasm::RuntimeStubIdToBuiltinName(
-          static_cast<wasm::WasmCode::RuntimeStubId>(trap_id));
+      Builtin trap = static_cast<Builtin>(trap_id);
 
       // Create new FrameState with the correct source position (the position
       // of the trap location).
diff --git a/src/diagnostics/disassembler.cc b/src/diagnostics/disassembler.cc
index 6656cf4fc5f..f112bd07c5a 100644
--- a/src/diagnostics/disassembler.cc
+++ b/src/diagnostics/disassembler.cc
@@ -268,8 +268,8 @@ static void PrintRelocInfo(std::ostringstream& out, Isolate* isolate,
 #if V8_ENABLE_WEBASSEMBLY
   } else if (RelocInfo::IsWasmStubCall(rmode) && host.is_wasm_code()) {
     // Host is isolate-independent, try wasm native module instead.
-    const char* runtime_stub_name = GetRuntimeStubName(
-        host.as_wasm_code()->native_module()->GetRuntimeStubId(
+    const char* runtime_stub_name = Builtins::name(
+        host.as_wasm_code()->native_module()->GetBuiltinInJumptableSlot(
             relocinfo->wasm_stub_call_address()));
     out << "    ;; wasm stub: " << runtime_stub_name;
 #endif  // V8_ENABLE_WEBASSEMBLY
diff --git a/src/objects/instruction-stream.cc b/src/objects/instruction-stream.cc
index adc9856618d..a7c1849ba60 100644
--- a/src/objects/instruction-stream.cc
+++ b/src/objects/instruction-stream.cc
@@ -75,9 +75,9 @@ InstructionStream::WriteBarrierPromise InstructionStream::RelocateFromDesc(
 #if V8_ENABLE_WEBASSEMBLY
       // Map wasm stub id to builtin.
       uint32_t stub_call_tag = it.rinfo()->wasm_call_tag();
-      DCHECK_LT(stub_call_tag, wasm::WasmCode::kRuntimeStubCount);
-      Builtin builtin = wasm::RuntimeStubIdToBuiltinName(
-          static_cast<wasm::WasmCode::RuntimeStubId>(stub_call_tag));
+      DCHECK_LT(stub_call_tag,
+                static_cast<uint32_t>(Builtin::kFirstBytecodeHandler));
+      Builtin builtin = static_cast<Builtin>(stub_call_tag);
       // Store the builtin address in relocation info.
       Address entry =
           heap->isolate()->builtin_entry_table()[Builtins::ToInt(builtin)];
diff --git a/src/wasm/baseline/arm/liftoff-assembler-arm.h b/src/wasm/baseline/arm/liftoff-assembler-arm.h
index 7451c4a62b8..5f3a6400290 100644
--- a/src/wasm/baseline/arm/liftoff-assembler-arm.h
+++ b/src/wasm/baseline/arm/liftoff-assembler-arm.h
@@ -488,7 +488,7 @@ void LiftoffAssembler::CallFrameSetupStub(int declared_function_index) {
   PushCommonFrame(scratch);
   LoadConstant(LiftoffRegister(kLiftoffFrameSetupFunctionReg),
                WasmValue(declared_function_index));
-  CallRuntimeStub(WasmCode::kWasmLiftoffFrameSetup);
+  CallBuiltin(Builtin::kWasmLiftoffFrameSetup);
 }
 
 void LiftoffAssembler::PrepareTailCall(int num_callee_stack_params,
@@ -575,7 +575,8 @@ void LiftoffAssembler::PatchPrepareStackFrame(
     b(cs /* higher or same */, &continuation);
   }
 
-  Call(wasm::WasmCode::kWasmStackOverflow, RelocInfo::WASM_STUB_CALL);
+  Call(static_cast<Address>(Builtin::kWasmStackOverflow),
+       RelocInfo::WASM_STUB_CALL);
   // The call will not return; just define an empty safepoint.
   safepoint_table_builder->DefineSafepoint(this);
   if (v8_flags.debug_code) stop();
@@ -4492,10 +4493,10 @@ void LiftoffAssembler::TailCallIndirect(Register target) {
   Jump(target);
 }
 
-void LiftoffAssembler::CallRuntimeStub(WasmCode::RuntimeStubId sid) {
-  // A direct call to a wasm runtime stub defined in this module.
-  // Just encode the stub index. This will be patched at relocation.
-  Call(static_cast<Address>(sid), RelocInfo::WASM_STUB_CALL);
+void LiftoffAssembler::CallBuiltin(Builtin builtin) {
+  // A direct call to a builtin. Just encode the builtin index. This will be
+  // patched at relocation.
+  Call(static_cast<Address>(builtin), RelocInfo::WASM_STUB_CALL);
 }
 
 void LiftoffAssembler::AllocateStackSlot(Register addr, uint32_t size) {
diff --git a/src/wasm/baseline/arm64/liftoff-assembler-arm64.h b/src/wasm/baseline/arm64/liftoff-assembler-arm64.h
index 0bea95c3ecc..dbd06c8661a 100644
--- a/src/wasm/baseline/arm64/liftoff-assembler-arm64.h
+++ b/src/wasm/baseline/arm64/liftoff-assembler-arm64.h
@@ -232,7 +232,7 @@ void LiftoffAssembler::CallFrameSetupStub(int declared_function_index) {
   EnterFrame(StackFrame::WASM);
   LoadConstant(LiftoffRegister(kLiftoffFrameSetupFunctionReg),
                WasmValue(declared_function_index));
-  CallRuntimeStub(WasmCode::kWasmLiftoffFrameSetup);
+  CallBuiltin(Builtin::kWasmLiftoffFrameSetup);
 }
 
 void LiftoffAssembler::PrepareTailCall(int num_callee_stack_params,
@@ -351,7 +351,8 @@ void LiftoffAssembler::PatchPrepareStackFrame(
     B(hs /* higher or same */, &continuation);
   }
 
-  Call(wasm::WasmCode::kWasmStackOverflow, RelocInfo::WASM_STUB_CALL);
+  Call(static_cast<Address>(Builtin::kWasmStackOverflow),
+       RelocInfo::WASM_STUB_CALL);
   // The call will not return; just define an empty safepoint.
   safepoint_table_builder->DefineSafepoint(this);
   if (v8_flags.debug_code) Brk(0);
@@ -3569,10 +3570,10 @@ void LiftoffAssembler::TailCallIndirect(Register target) {
   Jump(x17);
 }
 
-void LiftoffAssembler::CallRuntimeStub(WasmCode::RuntimeStubId sid) {
-  // A direct call to a wasm runtime stub defined in this module.
-  // Just encode the stub index. This will be patched at relocation.
-  Call(static_cast<Address>(sid), RelocInfo::WASM_STUB_CALL);
+void LiftoffAssembler::CallBuiltin(Builtin builtin) {
+  // A direct call to a builtin. Just encode the builtin index. This will be
+  // patched at relocation.
+  Call(static_cast<Address>(builtin), RelocInfo::WASM_STUB_CALL);
 }
 
 void LiftoffAssembler::AllocateStackSlot(Register addr, uint32_t size) {
diff --git a/src/wasm/baseline/ia32/liftoff-assembler-ia32.h b/src/wasm/baseline/ia32/liftoff-assembler-ia32.h
index f1b0b7de99d..adb6474f5e1 100644
--- a/src/wasm/baseline/ia32/liftoff-assembler-ia32.h
+++ b/src/wasm/baseline/ia32/liftoff-assembler-ia32.h
@@ -224,7 +224,7 @@ void LiftoffAssembler::CallFrameSetupStub(int declared_function_index) {
 
   LoadConstant(LiftoffRegister(kLiftoffFrameSetupFunctionReg),
                WasmValue(declared_function_index));
-  CallRuntimeStub(WasmCode::kWasmLiftoffFrameSetup);
+  CallBuiltin(Builtin::kWasmLiftoffFrameSetup);
 }
 
 void LiftoffAssembler::PrepareTailCall(int num_callee_stack_params,
@@ -316,7 +316,8 @@ void LiftoffAssembler::PatchPrepareStackFrame(
     j(above_equal, &continuation, Label::kNear);
   }
 
-  wasm_call(wasm::WasmCode::kWasmStackOverflow, RelocInfo::WASM_STUB_CALL);
+  wasm_call(static_cast<intptr_t>(Builtin::kWasmStackOverflow),
+            RelocInfo::WASM_STUB_CALL);
   // The call will not return; just define an empty safepoint.
   safepoint_table_builder->DefineSafepoint(this);
   AssertUnreachable(AbortReason::kUnexpectedReturnFromWasmTrap);
@@ -4813,10 +4814,10 @@ void LiftoffAssembler::TailCallIndirect(Register target) {
   jmp(target);
 }
 
-void LiftoffAssembler::CallRuntimeStub(WasmCode::RuntimeStubId sid) {
-  // A direct call to a wasm runtime stub defined in this module.
-  // Just encode the stub index. This will be patched at relocation.
-  wasm_call(static_cast<Address>(sid), RelocInfo::WASM_STUB_CALL);
+void LiftoffAssembler::CallBuiltin(Builtin builtin) {
+  // A direct call to a builtin. Just encode the builtin index. This will be
+  // patched at relocation.
+  wasm_call(static_cast<Address>(builtin), RelocInfo::WASM_STUB_CALL);
 }
 
 void LiftoffAssembler::AllocateStackSlot(Register addr, uint32_t size) {
diff --git a/src/wasm/baseline/liftoff-assembler.h b/src/wasm/baseline/liftoff-assembler.h
index 297f397c052..4c157c63776 100644
--- a/src/wasm/baseline/liftoff-assembler.h
+++ b/src/wasm/baseline/liftoff-assembler.h
@@ -14,7 +14,6 @@
 #include "src/wasm/baseline/liftoff-compiler.h"
 #include "src/wasm/baseline/liftoff-register.h"
 #include "src/wasm/function-body-decoder.h"
-#include "src/wasm/wasm-code-manager.h"
 #include "src/wasm/wasm-module.h"
 #include "src/wasm/wasm-opcodes.h"
 #include "src/wasm/wasm-value.h"
@@ -1624,7 +1623,7 @@ class LiftoffAssembler : public MacroAssembler {
                            compiler::CallDescriptor* call_descriptor,
                            Register target);
   inline void TailCallIndirect(Register target);
-  inline void CallRuntimeStub(WasmCode::RuntimeStubId sid);
+  inline void CallBuiltin(Builtin builtin);
 
   // Reserve space in the current frame, store address to space in {addr}.
   inline void AllocateStackSlot(Register addr, uint32_t size);
diff --git a/src/wasm/baseline/liftoff-compiler.cc b/src/wasm/baseline/liftoff-compiler.cc
index 233b51a1443..b5723a7a80d 100644
--- a/src/wasm/baseline/liftoff-compiler.cc
+++ b/src/wasm/baseline/liftoff-compiler.cc
@@ -420,7 +420,7 @@ class LiftoffCompiler {
   struct OutOfLineCode {
     MovableLabel label;
     MovableLabel continuation;
-    WasmCode::RuntimeStubId stub;
+    Builtin builtin;
     WasmCodePosition position;
     LiftoffRegList regs_to_save;
     Register cached_instance;
@@ -432,7 +432,7 @@ class LiftoffCompiler {
 
     // Named constructors:
     static OutOfLineCode Trap(
-        Zone* zone, WasmCode::RuntimeStubId s, WasmCodePosition pos,
+        Zone* zone, Builtin builtin, WasmCodePosition pos,
         SpilledRegistersForInspection* spilled_registers,
         OutOfLineSafepointInfo* safepoint_info, uint32_t pc,
         DebugSideTableBuilder::EntryBuilder* debug_sidetable_entry_builder) {
@@ -440,7 +440,7 @@ class LiftoffCompiler {
       return {
           MovableLabel{zone},            // label
           MovableLabel{zone},            // continuation
-          s,                             // stub
+          builtin,                       // builtin
           pos,                           // position
           {},                            // regs_to_save
           no_reg,                        // cached_instance
@@ -458,7 +458,7 @@ class LiftoffCompiler {
       return {
           MovableLabel{zone},            // label
           MovableLabel{zone},            // continuation
-          WasmCode::kWasmStackGuard,     // stub
+          Builtin::kWasmStackGuard,      // builtin
           pos,                           // position
           regs_to_save,                  // regs_to_save
           cached_instance,               // cached_instance
@@ -476,7 +476,7 @@ class LiftoffCompiler {
       return {
           MovableLabel{zone},            // label
           MovableLabel{zone},            // continuation,
-          WasmCode::kWasmTriggerTierUp,  // stub
+          Builtin::kWasmTriggerTierUp,   // builtin
           pos,                           // position
           regs_to_save,                  // regs_to_save
           cached_instance,               // cached_instance
@@ -830,7 +830,7 @@ class LiftoffCompiler {
     __ SpillAllRegisters();
     source_position_table_builder_.AddPosition(
         __ pc_offset(), SourcePosition(decoder->position()), false);
-    __ CallRuntimeStub(WasmCode::kWasmTraceEnter);
+    __ CallBuiltin(Builtin::kWasmTraceEnter);
     DefineSafepoint();
   }
 
@@ -952,7 +952,7 @@ class LiftoffCompiler {
         // need safepoint information (which would be difficult to compute if
         // the OOL code is shared).
         out_of_line_code_.push_back(OutOfLineCode::Trap(
-            zone_, WasmCode::kThrowWasmTrapUnreachable, decoder->position(),
+            zone_, Builtin::kThrowWasmTrapUnreachable, decoder->position(),
             nullptr, nullptr, 0, nullptr));
 
         // Subtract 16 steps for the function call itself (including the
@@ -973,16 +973,15 @@ class LiftoffCompiler {
   }
 
   void GenerateOutOfLineCode(OutOfLineCode* ool) {
-    CODE_COMMENT(
-        (std::string("OOL: ") + GetRuntimeStubName(ool->stub)).c_str());
+    CODE_COMMENT((std::string("OOL: ") + Builtins::name(ool->builtin)).c_str());
     __ bind(ool->label.get());
-    const bool is_stack_check = ool->stub == WasmCode::kWasmStackGuard;
-    const bool is_tierup = ool->stub == WasmCode::kWasmTriggerTierUp;
+    const bool is_stack_check = ool->builtin == Builtin::kWasmStackGuard;
+    const bool is_tierup = ool->builtin == Builtin::kWasmTriggerTierUp;
 
     // Only memory OOB traps need a {pc}, but not unconditionally. Static OOB
     // accesses do not need protected instruction information, hence they also
     // do not set {pc}.
-    DCHECK_IMPLIES(ool->stub != WasmCode::kThrowWasmTrapMemOutOfBounds,
+    DCHECK_IMPLIES(ool->builtin != Builtin::kThrowWasmTrapMemOutOfBounds,
                    ool->trapping_pc == 0);
 
     if (ool->trapping_pc != 0) {
@@ -1005,7 +1004,7 @@ class LiftoffCompiler {
 
     source_position_table_builder_.AddPosition(
         __ pc_offset(), SourcePosition(ool->position), true);
-    __ CallRuntimeStub(ool->stub);
+    __ CallBuiltin(ool->builtin);
     auto safepoint = safepoint_table_builder_.DefineSafepoint(&asm_);
 
     if (ool->safepoint_info) {
@@ -1123,8 +1122,8 @@ class LiftoffCompiler {
       __ Store(max_steps_addr.gp(), no_reg, 0, max_steps, StoreType::kI32Store,
                pinned);
       // Abort if max steps have been executed.
-      DCHECK_EQ(WasmCode::kThrowWasmTrapUnreachable,
-                out_of_line_code_.front().stub);
+      DCHECK_EQ(Builtin::kThrowWasmTrapUnreachable,
+                out_of_line_code_.front().builtin);
       Label* trap_label = out_of_line_code_.front().label.get();
       __ emit_i32_cond_jumpi(kLessThan, trap_label, max_steps.gp(), 0, frozen);
     }
@@ -1229,7 +1228,7 @@ class LiftoffCompiler {
     DCHECK(for_debugging_);
     source_position_table_builder_.AddPosition(
         __ pc_offset(), SourcePosition(decoder->position()), true);
-    __ CallRuntimeStub(WasmCode::kWasmDebugBreak);
+    __ CallBuiltin(Builtin::kWasmDebugBreak);
     DefineSafepointWithCalleeSavedRegisters();
     RegisterDebugSideTableEntry(decoder,
                                 DebugSideTableBuilder::kAllowRegisters);
@@ -1292,9 +1291,9 @@ class LiftoffCompiler {
     VarState tag_symbol{kRef, tag_symbol_reg, 0};
     VarState context{kRef, context_reg, 0};
 
-    CallRuntimeStub(WasmCode::kWasmGetOwnProperty,
-                    MakeSig::Returns(kRef).Params(kRef, kRef, kRef),
-                    {exception, tag_symbol, context}, kNoSourcePosition);
+    CallBuiltin(Builtin::kWasmGetOwnProperty,
+                MakeSig::Returns(kRef).Params(kRef, kRef, kRef),
+                {exception, tag_symbol, context}, kNoSourcePosition);
 
     return LiftoffRegister(kReturnRegister0);
   }
@@ -1432,8 +1431,8 @@ class LiftoffCompiler {
   }
 
   void Rethrow(FullDecoder* decoder, const VarState& exception) {
-    CallRuntimeStub(WasmCode::kWasmRethrow, MakeSig::Params(kRef), {exception},
-                    decoder->position());
+    CallBuiltin(Builtin::kWasmRethrow, MakeSig::Params(kRef), {exception},
+                decoder->position());
   }
 
   void Delegate(FullDecoder* decoder, uint32_t depth, Control* block) {
@@ -1761,8 +1760,8 @@ class LiftoffCompiler {
                               ? __ GetUnusedRegister(dst_rc, {src}, {})
                               : __ GetUnusedRegister(dst_rc, {});
     Label* trap =
-        can_trap ? AddOutOfLineTrap(
-                       decoder, WasmCode::kThrowWasmTrapFloatUnrepresentable)
+        can_trap ? AddOutOfLineTrap(decoder,
+                                    Builtin::kThrowWasmTrapFloatUnrepresentable)
                  : nullptr;
     if (!__ emit_type_conversion(opcode, dst, src, trap)) {
       DCHECK_NOT_NULL(fallback_fn);
@@ -1935,9 +1934,9 @@ class LiftoffCompiler {
         return EmitIsNull(opcode, value.type);
       case kExprExternInternalize: {
         VarState input_state = __ cache_state()->stack_state.back();
-        CallRuntimeStub(WasmCode::kWasmExternInternalize,
-                        MakeSig::Returns(kRefNull).Params(kRefNull),
-                        {input_state}, decoder->position());
+        CallBuiltin(Builtin::kWasmExternInternalize,
+                    MakeSig::Returns(kRefNull).Params(kRefNull), {input_state},
+                    decoder->position());
         __ DropValues(1);
         __ PushRegister(kRef, LiftoffRegister(kReturnRegister0));
         return;
@@ -2257,10 +2256,10 @@ class LiftoffCompiler {
         return EmitBinOp<kI32, kI32>([this, decoder](LiftoffRegister dst,
                                                      LiftoffRegister lhs,
                                                      LiftoffRegister rhs) {
-          AddOutOfLineTrap(decoder, WasmCode::kThrowWasmTrapDivByZero);
+          AddOutOfLineTrap(decoder, Builtin::kThrowWasmTrapDivByZero);
           // Adding the second trap might invalidate the pointer returned for
           // the first one, thus get both pointers afterwards.
-          AddOutOfLineTrap(decoder, WasmCode::kThrowWasmTrapDivUnrepresentable);
+          AddOutOfLineTrap(decoder, Builtin::kThrowWasmTrapDivUnrepresentable);
           Label* div_by_zero = out_of_line_code_.end()[-2].label.get();
           Label* div_unrepresentable = out_of_line_code_.end()[-1].label.get();
           __ emit_i32_divs(dst.gp(), lhs.gp(), rhs.gp(), div_by_zero,
@@ -2271,7 +2270,7 @@ class LiftoffCompiler {
                                                      LiftoffRegister lhs,
                                                      LiftoffRegister rhs) {
           Label* div_by_zero =
-              AddOutOfLineTrap(decoder, WasmCode::kThrowWasmTrapDivByZero);
+              AddOutOfLineTrap(decoder, Builtin::kThrowWasmTrapDivByZero);
           __ emit_i32_divu(dst.gp(), lhs.gp(), rhs.gp(), div_by_zero);
         });
       case kExprI32RemS:
@@ -2279,7 +2278,7 @@ class LiftoffCompiler {
                                                      LiftoffRegister lhs,
                                                      LiftoffRegister rhs) {
           Label* rem_by_zero =
-              AddOutOfLineTrap(decoder, WasmCode::kThrowWasmTrapRemByZero);
+              AddOutOfLineTrap(decoder, Builtin::kThrowWasmTrapRemByZero);
           __ emit_i32_rems(dst.gp(), lhs.gp(), rhs.gp(), rem_by_zero);
         });
       case kExprI32RemU:
@@ -2287,17 +2286,17 @@ class LiftoffCompiler {
                                                      LiftoffRegister lhs,
                                                      LiftoffRegister rhs) {
           Label* rem_by_zero =
-              AddOutOfLineTrap(decoder, WasmCode::kThrowWasmTrapRemByZero);
+              AddOutOfLineTrap(decoder, Builtin::kThrowWasmTrapRemByZero);
           __ emit_i32_remu(dst.gp(), lhs.gp(), rhs.gp(), rem_by_zero);
         });
       case kExprI64DivS:
         return EmitBinOp<kI64, kI64>([this, decoder](LiftoffRegister dst,
                                                      LiftoffRegister lhs,
                                                      LiftoffRegister rhs) {
-          AddOutOfLineTrap(decoder, WasmCode::kThrowWasmTrapDivByZero);
+          AddOutOfLineTrap(decoder, Builtin::kThrowWasmTrapDivByZero);
           // Adding the second trap might invalidate the pointer returned for
           // the first one, thus get both pointers afterwards.
-          AddOutOfLineTrap(decoder, WasmCode::kThrowWasmTrapDivUnrepresentable);
+          AddOutOfLineTrap(decoder, Builtin::kThrowWasmTrapDivUnrepresentable);
           Label* div_by_zero = out_of_line_code_.end()[-2].label.get();
           Label* div_unrepresentable = out_of_line_code_.end()[-1].label.get();
           if (!__ emit_i64_divs(dst, lhs, rhs, div_by_zero,
@@ -2312,7 +2311,7 @@ class LiftoffCompiler {
                                                      LiftoffRegister lhs,
                                                      LiftoffRegister rhs) {
           Label* div_by_zero =
-              AddOutOfLineTrap(decoder, WasmCode::kThrowWasmTrapDivByZero);
+              AddOutOfLineTrap(decoder, Builtin::kThrowWasmTrapDivByZero);
           if (!__ emit_i64_divu(dst, lhs, rhs, div_by_zero)) {
             ExternalReference ext_ref = ExternalReference::wasm_uint64_div();
             EmitDivOrRem64CCall(dst, lhs, rhs, ext_ref, div_by_zero);
@@ -2323,7 +2322,7 @@ class LiftoffCompiler {
                                                      LiftoffRegister lhs,
                                                      LiftoffRegister rhs) {
           Label* rem_by_zero =
-              AddOutOfLineTrap(decoder, WasmCode::kThrowWasmTrapRemByZero);
+              AddOutOfLineTrap(decoder, Builtin::kThrowWasmTrapRemByZero);
           if (!__ emit_i64_rems(dst, lhs, rhs, rem_by_zero)) {
             ExternalReference ext_ref = ExternalReference::wasm_int64_mod();
             EmitDivOrRem64CCall(dst, lhs, rhs, ext_ref, rem_by_zero);
@@ -2334,7 +2333,7 @@ class LiftoffCompiler {
                                                      LiftoffRegister lhs,
                                                      LiftoffRegister rhs) {
           Label* rem_by_zero =
-              AddOutOfLineTrap(decoder, WasmCode::kThrowWasmTrapRemByZero);
+              AddOutOfLineTrap(decoder, Builtin::kThrowWasmTrapRemByZero);
           if (!__ emit_i64_remu(dst, lhs, rhs, rem_by_zero)) {
             ExternalReference ext_ref = ExternalReference::wasm_uint64_mod();
             EmitDivOrRem64CCall(dst, lhs, rhs, ext_ref, rem_by_zero);
@@ -2401,9 +2400,9 @@ class LiftoffCompiler {
   }
 
   void RefFunc(FullDecoder* decoder, uint32_t function_index, Value* result) {
-    CallRuntimeStub(WasmCode::kWasmRefFunc, MakeSig::Returns(kRef).Params(kI32),
-                    {VarState{kI32, static_cast<int>(function_index), 0}},
-                    decoder->position());
+    CallBuiltin(Builtin::kWasmRefFunc, MakeSig::Returns(kRef).Params(kI32),
+                {VarState{kI32, static_cast<int>(function_index), 0}},
+                decoder->position());
     __ PushRegister(kRef, LiftoffRegister(kReturnRegister0));
   }
 
@@ -2443,7 +2442,7 @@ class LiftoffCompiler {
 
     source_position_table_builder_.AddPosition(
         __ pc_offset(), SourcePosition(decoder->position()), false);
-    __ CallRuntimeStub(WasmCode::kWasmTraceExit);
+    __ CallBuiltin(Builtin::kWasmTraceExit);
     DefineSafepoint();
   }
 
@@ -2683,10 +2682,10 @@ class LiftoffCompiler {
     ValueType type = env_->module->tables[imm.index].type;
     bool is_funcref = IsSubtypeOf(type, kWasmFuncRef, env_->module);
     auto stub =
-        is_funcref ? WasmCode::kWasmTableGetFuncRef : WasmCode::kWasmTableGet;
+        is_funcref ? Builtin::kWasmTableGetFuncRef : Builtin::kWasmTableGet;
 
-    CallRuntimeStub(stub, MakeSig::Returns(type.kind()).Params(kI32, kI32),
-                    {table_index, index}, decoder->position());
+    CallBuiltin(stub, MakeSig::Returns(type.kind()).Params(kI32, kI32),
+                {table_index, index}, decoder->position());
 
     RegisterDebugSideTableEntry(decoder, DebugSideTableBuilder::kDidSpill);
 
@@ -2703,19 +2702,19 @@ class LiftoffCompiler {
     ValueType type = env_->module->tables[imm.index].type;
     bool is_funcref = IsSubtypeOf(type, kWasmFuncRef, env_->module);
     auto stub =
-        is_funcref ? WasmCode::kWasmTableSetFuncRef : WasmCode::kWasmTableSet;
+        is_funcref ? Builtin::kWasmTableSetFuncRef : Builtin::kWasmTableSet;
 
-    CallRuntimeStub(stub, MakeSig::Params(kI32, kI32, kRefNull),
-                    {table_index, index, value}, decoder->position());
+    CallBuiltin(stub, MakeSig::Params(kI32, kI32, kRefNull),
+                {table_index, index, value}, decoder->position());
 
     RegisterDebugSideTableEntry(decoder, DebugSideTableBuilder::kDidSpill);
   }
 
-  WasmCode::RuntimeStubId GetRuntimeStubIdForTrapReason(TrapReason reason) {
+  Builtin GetBuiltinForTrapReason(TrapReason reason) {
     switch (reason) {
 #define RUNTIME_STUB_FOR_TRAP(trap_reason) \
   case k##trap_reason:                     \
-    return WasmCode::kThrowWasm##trap_reason;
+    return Builtin::kThrowWasm##trap_reason;
 
       FOREACH_WASM_TRAPREASON(RUNTIME_STUB_FOR_TRAP)
 #undef RUNTIME_STUB_FOR_TRAP
@@ -2726,7 +2725,7 @@ class LiftoffCompiler {
 
   void Trap(FullDecoder* decoder, TrapReason reason) {
     Label* trap_label =
-        AddOutOfLineTrap(decoder, GetRuntimeStubIdForTrapReason(reason));
+        AddOutOfLineTrap(decoder, GetBuiltinForTrapReason(reason));
     __ emit_jump(trap_label);
     __ AssertUnreachable(AbortReason::kUnexpectedReturnFromWasmTrap);
   }
@@ -2736,7 +2735,7 @@ class LiftoffCompiler {
     LiftoffRegList pinned;
     LiftoffRegister obj = pinned.set(__ PopToRegister(pinned));
     Label* trap_label =
-        AddOutOfLineTrap(decoder, WasmCode::kThrowWasmTrapIllegalCast);
+        AddOutOfLineTrap(decoder, Builtin::kThrowWasmTrapIllegalCast);
     LiftoffRegister null = __ GetUnusedRegister(kGpReg, pinned);
     LoadNullValueForCompare(null.gp(), pinned, arg.type);
     {
@@ -2965,10 +2964,10 @@ class LiftoffCompiler {
     return spilled;
   }
 
-  Label* AddOutOfLineTrap(FullDecoder* decoder, WasmCode::RuntimeStubId stub,
+  Label* AddOutOfLineTrap(FullDecoder* decoder, Builtin builtin,
                           uint32_t trapping_pc = 0) {
     // Only memory OOB traps need a {pc}.
-    DCHECK_IMPLIES(stub != WasmCode::kThrowWasmTrapMemOutOfBounds,
+    DCHECK_IMPLIES(builtin != Builtin::kThrowWasmTrapMemOutOfBounds,
                    trapping_pc == 0);
     DCHECK(v8_flags.wasm_bounds_checks);
     OutOfLineSafepointInfo* safepoint_info = nullptr;
@@ -2983,7 +2982,7 @@ class LiftoffCompiler {
           LiftoffAssembler::CacheState::SpillLocation::kStackSlots);
     }
     out_of_line_code_.push_back(OutOfLineCode::Trap(
-        zone_, stub, decoder->position(),
+        zone_, builtin, decoder->position(),
         V8_UNLIKELY(for_debugging_) ? GetSpilledRegistersForInspection()
                                     : nullptr,
         safepoint_info, trapping_pc, RegisterOOLDebugSideTableEntry(decoder)));
@@ -3029,7 +3028,7 @@ class LiftoffCompiler {
     // Set {pc} of the OOL code to {0} to avoid generation of protected
     // instruction information (see {GenerateOutOfLineCode}.
     Label* trap_label =
-        AddOutOfLineTrap(decoder, WasmCode::kThrowWasmTrapMemOutOfBounds, 0);
+        AddOutOfLineTrap(decoder, Builtin::kThrowWasmTrapMemOutOfBounds, 0);
 
     // Convert the index to ptrsize, bounds-checking the high word on 32-bit
     // systems for memory64.
@@ -3087,7 +3086,7 @@ class LiftoffCompiler {
                          LiftoffRegList pinned) {
     CODE_COMMENT("alignment check");
     Label* trap_label =
-        AddOutOfLineTrap(decoder, WasmCode::kThrowWasmTrapUnalignedAccess, 0);
+        AddOutOfLineTrap(decoder, Builtin::kThrowWasmTrapUnalignedAccess, 0);
     Register address = __ GetUnusedRegister(kGpReg, pinned).gp();
 
     FREEZE_STATE(trapping);
@@ -3176,7 +3175,7 @@ class LiftoffCompiler {
 
     source_position_table_builder_.AddPosition(__ pc_offset(),
                                                SourcePosition(position), false);
-    __ CallRuntimeStub(WasmCode::kWasmTraceMemory);
+    __ CallBuiltin(Builtin::kWasmTraceMemory);
     DefineSafepoint();
 
     __ DeallocateStackSlot(sizeof(MemoryTracingInfo));
@@ -3276,7 +3275,7 @@ class LiftoffCompiler {
       __ Load(value, mem, index, offset, type, &protected_load_pc, true,
               i64_offset);
       if (imm.memory->bounds_checks == kTrapHandler) {
-        AddOutOfLineTrap(decoder, WasmCode::kThrowWasmTrapMemOutOfBounds,
+        AddOutOfLineTrap(decoder, Builtin::kThrowWasmTrapMemOutOfBounds,
                          protected_load_pc);
       }
       __ PushRegister(kind, value);
@@ -3320,7 +3319,7 @@ class LiftoffCompiler {
                      &protected_load_pc);
 
     if (imm.memory->bounds_checks == kTrapHandler) {
-      AddOutOfLineTrap(decoder, WasmCode::kThrowWasmTrapMemOutOfBounds,
+      AddOutOfLineTrap(decoder, Builtin::kThrowWasmTrapMemOutOfBounds,
                        protected_load_pc);
     }
     __ PushRegister(kS128, value);
@@ -3364,7 +3363,7 @@ class LiftoffCompiler {
     __ LoadLane(result, value, addr, index, offset, type, laneidx,
                 &protected_load_pc, i64_offset);
     if (imm.memory->bounds_checks == kTrapHandler) {
-      AddOutOfLineTrap(decoder, WasmCode::kThrowWasmTrapMemOutOfBounds,
+      AddOutOfLineTrap(decoder, Builtin::kThrowWasmTrapMemOutOfBounds,
                        protected_load_pc);
     }
 
@@ -3419,7 +3418,7 @@ class LiftoffCompiler {
       __ Store(mem, index, offset, value, type, outer_pinned,
                &protected_store_pc, true, i64_offset);
       if (imm.memory->bounds_checks == kTrapHandler) {
-        AddOutOfLineTrap(decoder, WasmCode::kThrowWasmTrapMemOutOfBounds,
+        AddOutOfLineTrap(decoder, Builtin::kThrowWasmTrapMemOutOfBounds,
                          protected_store_pc);
       }
     }
@@ -3456,7 +3455,7 @@ class LiftoffCompiler {
     __ StoreLane(addr, index, offset, value, type, lane, &protected_store_pc,
                  i64_offset);
     if (imm.memory->bounds_checks == kTrapHandler) {
-      AddOutOfLineTrap(decoder, WasmCode::kThrowWasmTrapMemOutOfBounds,
+      AddOutOfLineTrap(decoder, Builtin::kThrowWasmTrapMemOutOfBounds,
                        protected_store_pc);
     }
     if (V8_UNLIKELY(v8_flags.trace_wasm_memory)) {
@@ -3540,7 +3539,7 @@ class LiftoffCompiler {
     __ LoadConstant(LiftoffRegister{mem_index_param_reg},
                     WasmValue(imm.memory->index));
 
-    __ CallRuntimeStub(WasmCode::kWasmMemoryGrow);
+    __ CallBuiltin(Builtin::kWasmMemoryGrow);
     DefineSafepoint();
     RegisterDebugSideTableEntry(decoder, DebugSideTableBuilder::kDidSpill);
 
@@ -4837,11 +4836,10 @@ class LiftoffCompiler {
     __ LoadConstant(encoded_size_reg, WasmValue::ForUintPtr(encoded_size));
 
     // Call the WasmAllocateFixedArray builtin to create the values array.
-    CallRuntimeStub(
-        WasmCode::kWasmAllocateFixedArray,
-        MakeSig::Returns(kIntPtrKind).Params(kIntPtrKind),
-        {VarState{kIntPtrKind, LiftoffRegister{encoded_size_reg}, 0}},
-        decoder->position());
+    CallBuiltin(Builtin::kWasmAllocateFixedArray,
+                MakeSig::Returns(kIntPtrKind).Params(kIntPtrKind),
+                {VarState{kIntPtrKind, LiftoffRegister{encoded_size_reg}, 0}},
+                decoder->position());
     MaybeOSR();
 
     // The FixedArray for the exception values is now in the first gp return
@@ -4871,11 +4869,10 @@ class LiftoffCompiler {
         wasm::ObjectAccess::ElementOffsetInTaggedFixedArray(imm.index));
 
     // Finally, call WasmThrow.
-    CallRuntimeStub(WasmCode::kWasmThrow,
-                    MakeSig::Params(kIntPtrKind, kIntPtrKind),
-                    {VarState{kIntPtrKind, exception_tag, 0},
-                     VarState{kIntPtrKind, values_array, 0}},
-                    decoder->position());
+    CallBuiltin(Builtin::kWasmThrow, MakeSig::Params(kIntPtrKind, kIntPtrKind),
+                {VarState{kIntPtrKind, exception_tag, 0},
+                 VarState{kIntPtrKind, values_array, 0}},
+                decoder->position());
 
     RegisterDebugSideTableEntry(decoder, DebugSideTableBuilder::kDidSpill);
 
@@ -5057,12 +5054,10 @@ class LiftoffCompiler {
 #endif
   }
 
-  void CallRuntimeStub(WasmCode::RuntimeStubId stub_id, const ValueKindSig& sig,
-                       std::initializer_list<VarState> params, int position) {
-    CODE_COMMENT(
-        (std::string{"call builtin: "} + GetRuntimeStubName(stub_id)).c_str());
-    auto interface_descriptor = Builtins::CallInterfaceDescriptorFor(
-        RuntimeStubIdToBuiltinName(stub_id));
+  void CallBuiltin(Builtin builtin, const ValueKindSig& sig,
+                   std::initializer_list<VarState> params, int position) {
+    CODE_COMMENT((std::string{"call builtin: "} + Builtins::name(builtin)));
+    auto interface_descriptor = Builtins::CallInterfaceDescriptorFor(builtin);
     auto* call_descriptor = compiler::Linkage::GetStubCallDescriptor(
         zone_,                                          // zone
         interface_descriptor,                           // descriptor
@@ -5076,7 +5071,7 @@ class LiftoffCompiler {
       source_position_table_builder_.AddPosition(
           __ pc_offset(), SourcePosition(position), true);
     }
-    __ CallRuntimeStub(stub_id);
+    __ CallBuiltin(builtin);
     DefineSafepoint();
   }
 
@@ -5129,8 +5124,8 @@ class LiftoffCompiler {
       // Convert the top value of the stack (the timeout) from I64 to a BigInt,
       // which we can then pass to the atomic.wait builtin.
       VarState i64_timeout = __ cache_state()->stack_state.back();
-      CallRuntimeStub(
-          kNeedI64RegPair ? WasmCode::kI32PairToBigInt : WasmCode::kI64ToBigInt,
+      CallBuiltin(
+          kNeedI64RegPair ? Builtin::kI32PairToBigInt : Builtin::kI64ToBigInt,
           MakeSig::Returns(kRef).Params(kI64), {i64_timeout},
           decoder->position());
       __ DropValues(1);
@@ -5144,8 +5139,8 @@ class LiftoffCompiler {
       expected = __ PeekToRegister(1, {}).gp();
     } else {
       VarState i64_expected = __ cache_state()->stack_state.end()[-2];
-      CallRuntimeStub(
-          kNeedI64RegPair ? WasmCode::kI32PairToBigInt : WasmCode::kI64ToBigInt,
+      CallBuiltin(
+          kNeedI64RegPair ? Builtin::kI32PairToBigInt : Builtin::kI64ToBigInt,
           MakeSig::Returns(kRef).Params(kI64), {i64_expected},
           decoder->position());
       expected = kReturnRegister0;
@@ -5155,19 +5150,18 @@ class LiftoffCompiler {
     VarState timeout = __ cache_state()->stack_state.end()[-1];
     VarState index = __ cache_state()->stack_state.end()[-3];
 
-    auto target = kind == kI32 ? WasmCode::kWasmI32AtomicWait
-                               : WasmCode::kWasmI64AtomicWait;
+    auto target = kind == kI32 ? Builtin::kWasmI32AtomicWait
+                               : Builtin::kWasmI64AtomicWait;
 
     // The type of {index} can either by i32 or intptr, depending on whether
     // memory32 or memory64 is used. This is okay because both values get passed
     // by register.
-    CallRuntimeStub(target,
-                    MakeSig::Params(kI32, index_kind, expected_kind, kRef),
-                    {{kI32, static_cast<int32_t>(imm.memory->index), 0},
-                     index,
-                     {expected_kind, LiftoffRegister{expected}, 0},
-                     timeout},
-                    decoder->position());
+    CallBuiltin(target, MakeSig::Params(kI32, index_kind, expected_kind, kRef),
+                {{kI32, static_cast<int32_t>(imm.memory->index), 0},
+                 index,
+                 {expected_kind, LiftoffRegister{expected}, 0},
+                 timeout},
+                decoder->position());
     // Pop parameters from the value stack.
     __ DropValues(3);
 
@@ -5196,12 +5190,12 @@ class LiftoffCompiler {
 
     VarState count = __ cache_state()->stack_state.end()[-1];
 
-    CallRuntimeStub(WasmCode::kWasmAtomicNotify,
-                    MakeSig::Returns(kI32).Params(kI32, kIntPtrKind, kI32),
-                    {{kI32, static_cast<int32_t>(imm.memory->index), 0},
-                     {kIntPtrKind, LiftoffRegister{index_plus_offset}, 0},
-                     count},
-                    decoder->position());
+    CallBuiltin(Builtin::kWasmAtomicNotify,
+                MakeSig::Returns(kI32).Params(kI32, kIntPtrKind, kI32),
+                {{kI32, static_cast<int32_t>(imm.memory->index), 0},
+                 {kIntPtrKind, LiftoffRegister{index_plus_offset}, 0},
+                 count},
+                decoder->position());
     // Pop parameters from the value stack.
     __ DropValues(2);
 
@@ -5422,7 +5416,7 @@ class LiftoffCompiler {
     // Only allocate the OOB code now, so the state of the stack is reflected
     // correctly.
     Label* trap_label =
-        AddOutOfLineTrap(decoder, WasmCode::kThrowWasmTrapMemOutOfBounds);
+        AddOutOfLineTrap(decoder, Builtin::kThrowWasmTrapMemOutOfBounds);
     if (mem_offsets_high_word != no_reg) {
       // If any high word has bits set, jump to the OOB trap.
       FREEZE_STATE(trapping);
@@ -5491,7 +5485,7 @@ class LiftoffCompiler {
     // Only allocate the OOB code now, so the state of the stack is reflected
     // correctly.
     Label* trap_label =
-        AddOutOfLineTrap(decoder, WasmCode::kThrowWasmTrapMemOutOfBounds);
+        AddOutOfLineTrap(decoder, Builtin::kThrowWasmTrapMemOutOfBounds);
     if (mem_offsets_high_word != no_reg) {
       // If any high word has bits set, jump to the OOB trap.
       FREEZE_STATE(trapping);
@@ -5535,7 +5529,7 @@ class LiftoffCompiler {
     // Only allocate the OOB code now, so the state of the stack is reflected
     // correctly.
     Label* trap_label =
-        AddOutOfLineTrap(decoder, WasmCode::kThrowWasmTrapMemOutOfBounds);
+        AddOutOfLineTrap(decoder, Builtin::kThrowWasmTrapMemOutOfBounds);
     if (mem_offsets_high_word != no_reg) {
       // If any high word has bits set, jump to the OOB trap.
       FREEZE_STATE(trapping);
@@ -5581,10 +5575,10 @@ class LiftoffCompiler {
     VarState src = __ PopVarState();
     VarState dst = __ PopVarState();
 
-    CallRuntimeStub(WasmCode::kWasmTableInit,
-                    MakeSig::Params(kI32, kI32, kI32, kSmiKind, kSmiKind),
-                    {dst, src, size, table_index, segment_index},
-                    decoder->position());
+    CallBuiltin(Builtin::kWasmTableInit,
+                MakeSig::Params(kI32, kI32, kI32, kSmiKind, kSmiKind),
+                {dst, src, size, table_index, segment_index},
+                decoder->position());
 
     RegisterDebugSideTableEntry(decoder, DebugSideTableBuilder::kDidSpill);
   }
@@ -5631,10 +5625,10 @@ class LiftoffCompiler {
     VarState src = __ PopVarState();
     VarState dst = __ PopVarState();
 
-    CallRuntimeStub(WasmCode::kWasmTableCopy,
-                    MakeSig::Params(kI32, kI32, kI32, kSmiKind, kSmiKind),
-                    {dst, src, size, table_dst_index, table_src_index},
-                    decoder->position());
+    CallBuiltin(Builtin::kWasmTableCopy,
+                MakeSig::Params(kI32, kI32, kI32, kSmiKind, kSmiKind),
+                {dst, src, size, table_dst_index, table_src_index},
+                decoder->position());
 
     RegisterDebugSideTableEntry(decoder, DebugSideTableBuilder::kDidSpill);
   }
@@ -5651,9 +5645,9 @@ class LiftoffCompiler {
     VarState delta = __ PopVarState();
     VarState value = __ PopVarState();
 
-    CallRuntimeStub(WasmCode::kWasmTableGrow,
-                    MakeSig::Returns(kSmiKind).Params(kSmiKind, kI32, kRefNull),
-                    {table_index, delta, value}, decoder->position());
+    CallBuiltin(Builtin::kWasmTableGrow,
+                MakeSig::Returns(kSmiKind).Params(kSmiKind, kI32, kRefNull),
+                {table_index, delta, value}, decoder->position());
 
     RegisterDebugSideTableEntry(decoder, DebugSideTableBuilder::kDidSpill);
     __ SmiToInt32(kReturnRegister0);
@@ -5698,9 +5692,9 @@ class LiftoffCompiler {
     VarState value = __ PopVarState();
     VarState start = __ PopVarState();
 
-    CallRuntimeStub(WasmCode::kWasmTableFill,
-                    MakeSig::Params(kSmiKind, kI32, kI32, kRefNull),
-                    {table_index, start, count, value}, decoder->position());
+    CallBuiltin(Builtin::kWasmTableFill,
+                MakeSig::Params(kSmiKind, kI32, kI32, kRefNull),
+                {table_index, start, count, value}, decoder->position());
 
     RegisterDebugSideTableEntry(decoder, DebugSideTableBuilder::kDidSpill);
   }
@@ -5709,11 +5703,11 @@ class LiftoffCompiler {
                  bool initial_values_on_stack) {
     LiftoffRegister rtt = RttCanon(imm.index, {});
 
-    CallRuntimeStub(WasmCode::kWasmAllocateStructWithRtt,
-                    MakeSig::Returns(kRef).Params(kRtt, kI32),
-                    {VarState{kRtt, rtt, 0},
-                     VarState{kI32, WasmStruct::Size(imm.struct_type), 0}},
-                    decoder->position());
+    CallBuiltin(Builtin::kWasmAllocateStructWithRtt,
+                MakeSig::Returns(kRef).Params(kRtt, kI32),
+                {VarState{kRtt, rtt, 0},
+                 VarState{kI32, WasmStruct::Size(imm.struct_type), 0}},
+                decoder->position());
 
     LiftoffRegister obj(kReturnRegister0);
     LiftoffRegList pinned{obj};
@@ -5792,7 +5786,7 @@ class LiftoffCompiler {
       LiftoffRegister length =
           __ LoadToRegister(__ cache_state()->stack_state.end()[-1], {});
       Label* trap_label =
-          AddOutOfLineTrap(decoder, WasmCode::kThrowWasmTrapArrayTooLarge);
+          AddOutOfLineTrap(decoder, Builtin::kThrowWasmTrapArrayTooLarge);
       FREEZE_STATE(trapping);
       __ emit_i32_cond_jumpi(kUnsignedGreaterThan, trap_label, length.gp(),
                              WasmArray::MaxLength(imm.array_type), trapping);
@@ -5803,12 +5797,12 @@ class LiftoffCompiler {
     // Allocate the array.
     {
       LiftoffRegister rtt = RttCanon(imm.index, {});
-      CallRuntimeStub(WasmCode::kWasmAllocateArray_Uninitialized,
-                      MakeSig::Returns(kRef).Params(kRtt, kI32, kI32),
-                      {VarState{kRtt, rtt, 0},
-                       __ cache_state()->stack_state.end()[-1],  // length
-                       VarState{kI32, elem_size, 0}},
-                      decoder->position());
+      CallBuiltin(Builtin::kWasmAllocateArray_Uninitialized,
+                  MakeSig::Returns(kRef).Params(kRtt, kI32, kI32),
+                  {VarState{kRtt, rtt, 0},
+                   __ cache_state()->stack_state.end()[-1],  // length
+                   VarState{kI32, elem_size, 0}},
+                  decoder->position());
     }
 
     LiftoffRegister obj(kReturnRegister0);
@@ -5858,7 +5852,7 @@ class LiftoffCompiler {
 
       // Bounds checks.
       Label* trap_label =
-          AddOutOfLineTrap(decoder, WasmCode::kThrowWasmTrapArrayOutOfBounds);
+          AddOutOfLineTrap(decoder, Builtin::kThrowWasmTrapArrayOutOfBounds);
       LiftoffRegister array_length =
           pinned.set(__ GetUnusedRegister(kGpReg, pinned));
       LoadObjectField(array_length, array_reg.gp(), no_reg,
@@ -5947,18 +5941,18 @@ class LiftoffCompiler {
                  const ArrayIndexImmediate& src_imm, const Value& length) {
     // TODO(14034): Unify implementation with TF: Implement this with
     // GenerateCCall. Remove runtime function and builtin in wasm.tq.
-    CallRuntimeStub(v8_flags.experimental_wasm_skip_bounds_checks
-                        ? WasmCode::kWasmArrayCopy
-                        : WasmCode::kWasmArrayCopyWithChecks,
-                    MakeSig::Params(kI32, kI32, kI32, kRefNull, kRefNull),
-                    // Builtin parameter order:
-                    // [dst_index, src_index, length, dst, src].
-                    {__ cache_state()->stack_state.end()[-4],
-                     __ cache_state()->stack_state.end()[-2],
-                     __ cache_state()->stack_state.end()[-1],
-                     __ cache_state()->stack_state.end()[-5],
-                     __ cache_state()->stack_state.end()[-3]},
-                    decoder->position());
+    CallBuiltin(v8_flags.experimental_wasm_skip_bounds_checks
+                    ? Builtin::kWasmArrayCopy
+                    : Builtin::kWasmArrayCopyWithChecks,
+                MakeSig::Params(kI32, kI32, kI32, kRefNull, kRefNull),
+                // Builtin parameter order:
+                // [dst_index, src_index, length, dst, src].
+                {__ cache_state()->stack_state.end()[-4],
+                 __ cache_state()->stack_state.end()[-2],
+                 __ cache_state()->stack_state.end()[-1],
+                 __ cache_state()->stack_state.end()[-5],
+                 __ cache_state()->stack_state.end()[-3]},
+                decoder->position());
     __ DropValues(5);
   }
 
@@ -5969,11 +5963,11 @@ class LiftoffCompiler {
     ValueKind elem_kind = array_imm.array_type->element_type().kind();
     int32_t elem_count = length_imm.index;
     // Allocate the array.
-    CallRuntimeStub(WasmCode::kWasmAllocateArray_Uninitialized,
-                    MakeSig::Returns(kRef).Params(kRtt, kI32, kI32),
-                    {VarState{kRtt, rtt, 0}, VarState{kI32, elem_count, 0},
-                     VarState{kI32, value_kind_size(elem_kind), 0}},
-                    decoder->position());
+    CallBuiltin(Builtin::kWasmAllocateArray_Uninitialized,
+                MakeSig::Returns(kRef).Params(kRtt, kI32, kI32),
+                {VarState{kRtt, rtt, 0}, VarState{kI32, elem_count, 0},
+                 VarState{kI32, value_kind_size(elem_kind), 0}},
+                decoder->position());
 
     // Initialize the array with stack arguments.
     LiftoffRegister array(kReturnRegister0);
@@ -6006,8 +6000,8 @@ class LiftoffCompiler {
     LoadSmi(is_element_reg,
             array_imm.array_type->element_type().is_reference());
 
-    CallRuntimeStub(
-        WasmCode::kWasmArrayNewSegment,
+    CallBuiltin(
+        Builtin::kWasmArrayNewSegment,
         MakeSig::Returns(kRef).Params(kI32, kI32, kI32, kSmiKind, kRtt),
         {
             VarState{kI32, static_cast<int>(segment_imm.index), 0},  // segment
@@ -6042,16 +6036,15 @@ class LiftoffCompiler {
 
     // Builtin parameter order: array_index, segment_offset, length,
     //                          segment_index, array.
-    CallRuntimeStub(
-        WasmCode::kWasmArrayInitSegment,
-        MakeSig::Params(kI32, kI32, kI32, kSmiKind, kSmiKind, kRefNull),
-        {__ cache_state()->stack_state.end()[-3],
-         __ cache_state()->stack_state.end()[-2],
-         __ cache_state()->stack_state.end()[-1],
-         VarState{kSmiKind, segment_index_reg, 0},
-         VarState{kSmiKind, is_element_reg, 0},
-         __ cache_state()->stack_state.end()[-4]},
-        decoder->position());
+    CallBuiltin(Builtin::kWasmArrayInitSegment,
+                MakeSig::Params(kI32, kI32, kI32, kSmiKind, kSmiKind, kRefNull),
+                {__ cache_state()->stack_state.end()[-3],
+                 __ cache_state()->stack_state.end()[-2],
+                 __ cache_state()->stack_state.end()[-1],
+                 VarState{kSmiKind, segment_index_reg, 0},
+                 VarState{kSmiKind, is_element_reg, 0},
+                 __ cache_state()->stack_state.end()[-4]},
+                decoder->position());
     __ DropValues(4);
   }
 
@@ -6264,7 +6257,7 @@ class LiftoffCompiler {
     if (v8_flags.experimental_wasm_assume_ref_cast_succeeds) return;
 
     Label* trap_label =
-        AddOutOfLineTrap(decoder, WasmCode::kThrowWasmTrapIllegalCast);
+        AddOutOfLineTrap(decoder, Builtin::kThrowWasmTrapIllegalCast);
     LiftoffRegList pinned;
     LiftoffRegister rtt_reg = pinned.set(RttCanon(ref_index, pinned));
     LiftoffRegister obj_reg = pinned.set(__ PopToRegister(pinned));
@@ -6583,7 +6576,7 @@ class LiftoffCompiler {
                         ValueKind result_kind, bool null_succeeds = false) {
     Label match;
     Label* trap_label =
-        AddOutOfLineTrap(decoder, WasmCode::kThrowWasmTrapIllegalCast);
+        AddOutOfLineTrap(decoder, Builtin::kThrowWasmTrapIllegalCast);
     TypeCheck check(object.type, trap_label, null_succeeds);
     Initialize(check, kPeek, object.type);
     FREEZE_STATE(frozen);
@@ -6763,8 +6756,8 @@ class LiftoffCompiler {
     LoadSmi(variant_reg, static_cast<int32_t>(variant));
     VarState variant_var(kSmiKind, variant_reg, 0);
 
-    CallRuntimeStub(
-        WasmCode::kWasmStringNewWtf8,
+    CallBuiltin(
+        Builtin::kWasmStringNewWtf8,
         MakeSig::Returns(kRefNull).Params(kI32, kI32, kSmiKind, kSmiKind),
         {
             __ cache_state()->stack_state.end()[-2],  // offset
@@ -6796,16 +6789,15 @@ class LiftoffCompiler {
     LoadSmi(variant_reg, static_cast<int32_t>(variant));
     VarState variant_var(kSmiKind, variant_reg, 0);
 
-    CallRuntimeStub(
-        WasmCode::kWasmStringNewWtf8Array,
-        MakeSig::Returns(kRefNull).Params(kI32, kI32, kRef, kSmiKind),
-        {
-            __ cache_state()->stack_state.end()[-2],  // start
-            __ cache_state()->stack_state.end()[-1],  // end
-            array_var,
-            variant_var,
-        },
-        decoder->position());
+    CallBuiltin(Builtin::kWasmStringNewWtf8Array,
+                MakeSig::Returns(kRefNull).Params(kI32, kI32, kRef, kSmiKind),
+                {
+                    __ cache_state()->stack_state.end()[-2],  // start
+                    __ cache_state()->stack_state.end()[-1],  // end
+                    array_var,
+                    variant_var,
+                },
+                decoder->position());
     __ cache_state()->stack_state.pop_back(3);
     RegisterDebugSideTableEntry(decoder, DebugSideTableBuilder::kDidSpill);
 
@@ -6817,14 +6809,14 @@ class LiftoffCompiler {
                       const Value& offset, const Value& size, Value* result) {
     VarState memory_var{kI32, static_cast<int32_t>(imm.index), 0};
 
-    CallRuntimeStub(WasmCode::kWasmStringNewWtf16,
-                    MakeSig::Returns(kRef).Params(kI32, kI32, kI32),
-                    {
-                        memory_var,
-                        __ cache_state()->stack_state.end()[-2],  // offset
-                        __ cache_state()->stack_state.end()[-1]   // size
-                    },
-                    decoder->position());
+    CallBuiltin(Builtin::kWasmStringNewWtf16,
+                MakeSig::Returns(kRef).Params(kI32, kI32, kI32),
+                {
+                    memory_var,
+                    __ cache_state()->stack_state.end()[-2],  // offset
+                    __ cache_state()->stack_state.end()[-1]   // size
+                },
+                decoder->position());
     __ cache_state()->stack_state.pop_back(2);
     RegisterDebugSideTableEntry(decoder, DebugSideTableBuilder::kDidSpill);
 
@@ -6842,14 +6834,14 @@ class LiftoffCompiler {
     MaybeEmitNullCheck(decoder, array_reg.gp(), pinned, array.type);
     VarState array_var(kRef, array_reg, 0);
 
-    CallRuntimeStub(WasmCode::kWasmStringNewWtf16Array,
-                    MakeSig::Returns(kRef).Params(kRef, kI32, kI32),
-                    {
-                        array_var,
-                        __ cache_state()->stack_state.end()[-2],  // start
-                        __ cache_state()->stack_state.end()[-1],  // end
-                    },
-                    decoder->position());
+    CallBuiltin(Builtin::kWasmStringNewWtf16Array,
+                MakeSig::Returns(kRef).Params(kRef, kI32, kI32),
+                {
+                    array_var,
+                    __ cache_state()->stack_state.end()[-2],  // start
+                    __ cache_state()->stack_state.end()[-1],  // end
+                },
+                decoder->position());
     __ cache_state()->stack_state.pop_back(3);
     RegisterDebugSideTableEntry(decoder, DebugSideTableBuilder::kDidSpill);
 
@@ -6861,9 +6853,8 @@ class LiftoffCompiler {
                    Value* result) {
     VarState index_var{kI32, static_cast<int32_t>(imm.index), 0};
 
-    CallRuntimeStub(WasmCode::kWasmStringConst,
-                    MakeSig::Returns(kRef).Params(kI32), {index_var},
-                    decoder->position());
+    CallBuiltin(Builtin::kWasmStringConst, MakeSig::Returns(kRef).Params(kI32),
+                {index_var}, decoder->position());
     RegisterDebugSideTableEntry(decoder, DebugSideTableBuilder::kDidSpill);
 
     LiftoffRegister result_reg(kReturnRegister0);
@@ -6878,23 +6869,23 @@ class LiftoffCompiler {
     MaybeEmitNullCheck(decoder, string_reg.gp(), pinned, str.type);
     VarState string_var(kRef, string_reg, 0);
 
-    WasmCode::RuntimeStubId stub_id;
+    Builtin builtin;
     switch (variant) {
       case unibrow::Utf8Variant::kUtf8:
-        stub_id = WasmCode::kWasmStringMeasureUtf8;
+        builtin = Builtin::kWasmStringMeasureUtf8;
         break;
       case unibrow::Utf8Variant::kLossyUtf8:
       case unibrow::Utf8Variant::kWtf8:
-        stub_id = WasmCode::kWasmStringMeasureWtf8;
+        builtin = Builtin::kWasmStringMeasureWtf8;
         break;
       case unibrow::Utf8Variant::kUtf8NoTrap:
         UNREACHABLE();
     }
-    CallRuntimeStub(stub_id, MakeSig::Returns(kI32).Params(kRef),
-                    {
-                        string_var,
-                    },
-                    decoder->position());
+    CallBuiltin(builtin, MakeSig::Returns(kI32).Params(kRef),
+                {
+                    string_var,
+                },
+                decoder->position());
     RegisterDebugSideTableEntry(decoder, DebugSideTableBuilder::kDidSpill);
 
     LiftoffRegister result_reg(kReturnRegister0);
@@ -6935,16 +6926,15 @@ class LiftoffCompiler {
     LoadSmi(variant_reg, static_cast<int32_t>(variant));
     VarState variant_var(kSmiKind, variant_reg, 0);
 
-    CallRuntimeStub(
-        WasmCode::kWasmStringEncodeWtf8,
-        MakeSig::Returns(kI32).Params(kRef, kI32, kSmiKind, kSmiKind),
-        {
-            string_var,
-            offset_var,
-            memory_var,
-            variant_var,
-        },
-        decoder->position());
+    CallBuiltin(Builtin::kWasmStringEncodeWtf8,
+                MakeSig::Returns(kI32).Params(kRef, kI32, kSmiKind, kSmiKind),
+                {
+                    string_var,
+                    offset_var,
+                    memory_var,
+                    variant_var,
+                },
+                decoder->position());
     __ DropValues(2);
     RegisterDebugSideTableEntry(decoder, DebugSideTableBuilder::kDidSpill);
 
@@ -6975,15 +6965,15 @@ class LiftoffCompiler {
     LoadSmi(variant_reg, static_cast<int32_t>(variant));
     VarState variant_var(kSmiKind, variant_reg, 0);
 
-    CallRuntimeStub(WasmCode::kWasmStringEncodeWtf8Array,
-                    MakeSig::Returns(kI32).Params(kRef, kRef, kI32, kSmiKind),
-                    {
-                        string_var,
-                        array_var,
-                        start_var,
-                        variant_var,
-                    },
-                    decoder->position());
+    CallBuiltin(Builtin::kWasmStringEncodeWtf8Array,
+                MakeSig::Returns(kI32).Params(kRef, kRef, kI32, kSmiKind),
+                {
+                    string_var,
+                    array_var,
+                    start_var,
+                    variant_var,
+                },
+                decoder->position());
     __ DropValues(3);
     RegisterDebugSideTableEntry(decoder, DebugSideTableBuilder::kDidSpill);
 
@@ -7007,14 +6997,14 @@ class LiftoffCompiler {
     LoadSmi(memory_reg, imm.index);
     VarState memory_var(kSmiKind, memory_reg, 0);
 
-    CallRuntimeStub(WasmCode::kWasmStringEncodeWtf16,
-                    MakeSig::Returns(kI32).Params(kRef, kI32, kSmiKind),
-                    {
-                        string_var,
-                        offset_var,
-                        memory_var,
-                    },
-                    decoder->position());
+    CallBuiltin(Builtin::kWasmStringEncodeWtf16,
+                MakeSig::Returns(kI32).Params(kRef, kI32, kSmiKind),
+                {
+                    string_var,
+                    offset_var,
+                    memory_var,
+                },
+                decoder->position());
     __ DropValues(2);
     RegisterDebugSideTableEntry(decoder, DebugSideTableBuilder::kDidSpill);
 
@@ -7039,14 +7029,14 @@ class LiftoffCompiler {
 
     VarState& start_var = __ cache_state()->stack_state.end()[-1];
 
-    CallRuntimeStub(WasmCode::kWasmStringEncodeWtf16Array,
-                    MakeSig::Returns(kI32).Params(kRef, kRef, kI32),
-                    {
-                        string_var,
-                        array_var,
-                        start_var,
-                    },
-                    decoder->position());
+    CallBuiltin(Builtin::kWasmStringEncodeWtf16Array,
+                MakeSig::Returns(kI32).Params(kRef, kRef, kI32),
+                {
+                    string_var,
+                    array_var,
+                    start_var,
+                },
+                decoder->position());
     __ DropValues(3);
     RegisterDebugSideTableEntry(decoder, DebugSideTableBuilder::kDidSpill);
 
@@ -7066,13 +7056,13 @@ class LiftoffCompiler {
     MaybeEmitNullCheck(decoder, head_reg.gp(), pinned, head.type);
     VarState head_var(kRef, head_reg, 0);
 
-    CallRuntimeStub(WasmCode::kWasmStringConcat,
-                    MakeSig::Returns(kRef).Params(kRef, kRef),
-                    {
-                        head_var,
-                        tail_var,
-                    },
-                    decoder->position());
+    CallBuiltin(Builtin::kWasmStringConcat,
+                MakeSig::Returns(kRef).Params(kRef, kRef),
+                {
+                    head_var,
+                    tail_var,
+                },
+                decoder->position());
     RegisterDebugSideTableEntry(decoder, DebugSideTableBuilder::kDidSpill);
 
     LiftoffRegister result_reg(kReturnRegister0);
@@ -7126,13 +7116,13 @@ class LiftoffCompiler {
     // runtime.
     VarState a_var(kRef, a_reg, 0);
     VarState b_var(kRef, b_reg, 0);
-    CallRuntimeStub(WasmCode::kWasmStringEqual,
-                    MakeSig::Returns(kI32).Params(kRef, kRef),
-                    {
-                        a_var,
-                        b_var,
-                    },
-                    decoder->position());
+    CallBuiltin(Builtin::kWasmStringEqual,
+                MakeSig::Returns(kI32).Params(kRef, kRef),
+                {
+                    a_var,
+                    b_var,
+                },
+                decoder->position());
     RegisterDebugSideTableEntry(decoder, DebugSideTableBuilder::kDidSpill);
 
     __ bind(&done);
@@ -7148,12 +7138,12 @@ class LiftoffCompiler {
     MaybeEmitNullCheck(decoder, str_reg.gp(), pinned, str.type);
     VarState str_var(kRef, str_reg, 0);
 
-    CallRuntimeStub(WasmCode::kWasmStringIsUSVSequence,
-                    MakeSig::Returns(kI32).Params(kRef),
-                    {
-                        str_var,
-                    },
-                    decoder->position());
+    CallBuiltin(Builtin::kWasmStringIsUSVSequence,
+                MakeSig::Returns(kI32).Params(kRef),
+                {
+                    str_var,
+                },
+                decoder->position());
     RegisterDebugSideTableEntry(decoder, DebugSideTableBuilder::kDidSpill);
 
     LiftoffRegister result_reg(kReturnRegister0);
@@ -7167,12 +7157,11 @@ class LiftoffCompiler {
     MaybeEmitNullCheck(decoder, str_reg.gp(), pinned, str.type);
     VarState str_var(kRef, str_reg, 0);
 
-    CallRuntimeStub(WasmCode::kWasmStringAsWtf8,
-                    MakeSig::Returns(kRef).Params(kRef),
-                    {
-                        str_var,
-                    },
-                    decoder->position());
+    CallBuiltin(Builtin::kWasmStringAsWtf8, MakeSig::Returns(kRef).Params(kRef),
+                {
+                    str_var,
+                },
+                decoder->position());
     RegisterDebugSideTableEntry(decoder, DebugSideTableBuilder::kDidSpill);
 
     LiftoffRegister result_reg(kReturnRegister0);
@@ -7192,14 +7181,14 @@ class LiftoffCompiler {
     MaybeEmitNullCheck(decoder, view_reg.gp(), pinned, view.type);
     VarState view_var(kRef, view_reg, 0);
 
-    CallRuntimeStub(WasmCode::kWasmStringViewWtf8Advance,
-                    MakeSig::Returns(kI32).Params(kRef, kI32, kI32),
-                    {
-                        view_var,
-                        pos_var,
-                        bytes_var,
-                    },
-                    decoder->position());
+    CallBuiltin(Builtin::kWasmStringViewWtf8Advance,
+                MakeSig::Returns(kI32).Params(kRef, kI32, kI32),
+                {
+                    view_var,
+                    pos_var,
+                    bytes_var,
+                },
+                decoder->position());
     __ DropValues(3);
     RegisterDebugSideTableEntry(decoder, DebugSideTableBuilder::kDidSpill);
 
@@ -7234,18 +7223,18 @@ class LiftoffCompiler {
     LoadSmi(variant_reg, static_cast<int32_t>(variant));
     VarState variant_var(kSmiKind, variant_reg, 0);
 
-    CallRuntimeStub(WasmCode::kWasmStringViewWtf8Encode,
-                    MakeSig::Returns(kI32, kI32)
-                        .Params(kI32, kI32, kI32, kRef, kSmiKind, kSmiKind),
-                    {
-                        addr_var,
-                        pos_var,
-                        bytes_var,
-                        view_var,
-                        memory_var,
-                        variant_var,
-                    },
-                    decoder->position());
+    CallBuiltin(Builtin::kWasmStringViewWtf8Encode,
+                MakeSig::Returns(kI32, kI32)
+                    .Params(kI32, kI32, kI32, kRef, kSmiKind, kSmiKind),
+                {
+                    addr_var,
+                    pos_var,
+                    bytes_var,
+                    view_var,
+                    memory_var,
+                    variant_var,
+                },
+                decoder->position());
     __ DropValues(4);
     RegisterDebugSideTableEntry(decoder, DebugSideTableBuilder::kDidSpill);
 
@@ -7268,14 +7257,14 @@ class LiftoffCompiler {
     MaybeEmitNullCheck(decoder, view_reg.gp(), pinned, view.type);
     VarState view_var(kRef, view_reg, 0);
 
-    CallRuntimeStub(WasmCode::kWasmStringViewWtf8Slice,
-                    MakeSig::Returns(kRef).Params(kRef, kI32, kI32),
-                    {
-                        view_var,
-                        start_var,
-                        end_var,
-                    },
-                    decoder->position());
+    CallBuiltin(Builtin::kWasmStringViewWtf8Slice,
+                MakeSig::Returns(kRef).Params(kRef, kI32, kI32),
+                {
+                    view_var,
+                    start_var,
+                    end_var,
+                },
+                decoder->position());
     __ DropValues(3);
     RegisterDebugSideTableEntry(decoder, DebugSideTableBuilder::kDidSpill);
 
@@ -7290,12 +7279,12 @@ class LiftoffCompiler {
     MaybeEmitNullCheck(decoder, str_reg.gp(), pinned, str.type);
     VarState str_var(kRef, str_reg, 0);
 
-    CallRuntimeStub(WasmCode::kWasmStringAsWtf16,
-                    MakeSig::Returns(kRef).Params(kRef),
-                    {
-                        str_var,
-                    },
-                    decoder->position());
+    CallBuiltin(Builtin::kWasmStringAsWtf16,
+                MakeSig::Returns(kRef).Params(kRef),
+                {
+                    str_var,
+                },
+                decoder->position());
     RegisterDebugSideTableEntry(decoder, DebugSideTableBuilder::kDidSpill);
 
     LiftoffRegister result_reg(kReturnRegister0);
@@ -7311,13 +7300,13 @@ class LiftoffCompiler {
     VarState view_var(kRef, view_reg, 0);
     VarState pos_var(kI32, pos_reg, 0);
 
-    CallRuntimeStub(WasmCode::kWasmStringViewWtf16GetCodeUnit,
-                    MakeSig::Returns(kI32).Params(kRef, kI32),
-                    {
-                        view_var,
-                        pos_var,
-                    },
-                    decoder->position());
+    CallBuiltin(Builtin::kWasmStringViewWtf16GetCodeUnit,
+                MakeSig::Returns(kI32).Params(kRef, kI32),
+                {
+                    view_var,
+                    pos_var,
+                },
+                decoder->position());
     RegisterDebugSideTableEntry(decoder, DebugSideTableBuilder::kDidSpill);
 
     LiftoffRegister result_reg(kReturnRegister0);
@@ -7344,17 +7333,16 @@ class LiftoffCompiler {
     LoadSmi(memory_reg, imm.index);
     VarState memory_var(kSmiKind, memory_reg, 0);
 
-    CallRuntimeStub(
-        WasmCode::kWasmStringViewWtf16Encode,
-        MakeSig::Returns(kI32).Params(kI32, kI32, kI32, kRef, kSmiKind),
-        {
-            offset_var,
-            pos_var,
-            codeunits_var,
-            view_var,
-            memory_var,
-        },
-        decoder->position());
+    CallBuiltin(Builtin::kWasmStringViewWtf16Encode,
+                MakeSig::Returns(kI32).Params(kI32, kI32, kI32, kRef, kSmiKind),
+                {
+                    offset_var,
+                    pos_var,
+                    codeunits_var,
+                    view_var,
+                    memory_var,
+                },
+                decoder->position());
     __ DropValues(4);
     RegisterDebugSideTableEntry(decoder, DebugSideTableBuilder::kDidSpill);
 
@@ -7374,14 +7362,14 @@ class LiftoffCompiler {
     VarState start_var(kI32, start_reg, 0);
     VarState end_var(kI32, end_reg, 0);
 
-    CallRuntimeStub(WasmCode::kWasmStringViewWtf16Slice,
-                    MakeSig::Returns(kRef).Params(kRef, kI32, kI32),
-                    {
-                        view_var,
-                        start_var,
-                        end_var,
-                    },
-                    decoder->position());
+    CallBuiltin(Builtin::kWasmStringViewWtf16Slice,
+                MakeSig::Returns(kRef).Params(kRef, kI32, kI32),
+                {
+                    view_var,
+                    start_var,
+                    end_var,
+                },
+                decoder->position());
     RegisterDebugSideTableEntry(decoder, DebugSideTableBuilder::kDidSpill);
 
     LiftoffRegister result_reg(kReturnRegister0);
@@ -7395,12 +7383,11 @@ class LiftoffCompiler {
     MaybeEmitNullCheck(decoder, str_reg.gp(), pinned, str.type);
     VarState str_var(kRef, str_reg, 0);
 
-    CallRuntimeStub(WasmCode::kWasmStringAsIter,
-                    MakeSig::Returns(kRef).Params(kRef),
-                    {
-                        str_var,
-                    },
-                    decoder->position());
+    CallBuiltin(Builtin::kWasmStringAsIter, MakeSig::Returns(kRef).Params(kRef),
+                {
+                    str_var,
+                },
+                decoder->position());
     RegisterDebugSideTableEntry(decoder, DebugSideTableBuilder::kDidSpill);
 
     LiftoffRegister result_reg(kReturnRegister0);
@@ -7415,12 +7402,12 @@ class LiftoffCompiler {
     MaybeEmitNullCheck(decoder, view_reg.gp(), pinned, view.type);
     VarState view_var(kRef, view_reg, 0);
 
-    CallRuntimeStub(WasmCode::kWasmStringViewIterNext,
-                    MakeSig::Returns(kI32).Params(kRef),
-                    {
-                        view_var,
-                    },
-                    decoder->position());
+    CallBuiltin(Builtin::kWasmStringViewIterNext,
+                MakeSig::Returns(kI32).Params(kRef),
+                {
+                    view_var,
+                },
+                decoder->position());
     RegisterDebugSideTableEntry(decoder, DebugSideTableBuilder::kDidSpill);
 
     LiftoffRegister result_reg(kReturnRegister0);
@@ -7438,13 +7425,13 @@ class LiftoffCompiler {
     MaybeEmitNullCheck(decoder, view_reg.gp(), pinned, view.type);
     VarState view_var(kRef, view_reg, 0);
 
-    CallRuntimeStub(WasmCode::kWasmStringViewIterAdvance,
-                    MakeSig::Returns(kI32).Params(kRef, kI32),
-                    {
-                        view_var,
-                        codepoints_var,
-                    },
-                    decoder->position());
+    CallBuiltin(Builtin::kWasmStringViewIterAdvance,
+                MakeSig::Returns(kI32).Params(kRef, kI32),
+                {
+                    view_var,
+                    codepoints_var,
+                },
+                decoder->position());
     RegisterDebugSideTableEntry(decoder, DebugSideTableBuilder::kDidSpill);
 
     LiftoffRegister result_reg(kReturnRegister0);
@@ -7463,13 +7450,13 @@ class LiftoffCompiler {
     MaybeEmitNullCheck(decoder, view_reg.gp(), pinned, view.type);
     VarState view_var(kRef, view_reg, 0);
 
-    CallRuntimeStub(WasmCode::kWasmStringViewIterRewind,
-                    MakeSig::Returns(kI32).Params(kRef, kI32),
-                    {
-                        view_var,
-                        codepoints_var,
-                    },
-                    decoder->position());
+    CallBuiltin(Builtin::kWasmStringViewIterRewind,
+                MakeSig::Returns(kI32).Params(kRef, kI32),
+                {
+                    view_var,
+                    codepoints_var,
+                },
+                decoder->position());
     RegisterDebugSideTableEntry(decoder, DebugSideTableBuilder::kDidSpill);
 
     LiftoffRegister result_reg(kReturnRegister0);
@@ -7488,13 +7475,13 @@ class LiftoffCompiler {
     MaybeEmitNullCheck(decoder, view_reg.gp(), pinned, view.type);
     VarState view_var(kRef, view_reg, 0);
 
-    CallRuntimeStub(WasmCode::kWasmStringViewIterSlice,
-                    MakeSig::Returns(kRef).Params(kRef, kI32),
-                    {
-                        view_var,
-                        codepoints_var,
-                    },
-                    decoder->position());
+    CallBuiltin(Builtin::kWasmStringViewIterSlice,
+                MakeSig::Returns(kRef).Params(kRef, kI32),
+                {
+                    view_var,
+                    codepoints_var,
+                },
+                decoder->position());
     RegisterDebugSideTableEntry(decoder, DebugSideTableBuilder::kDidSpill);
 
     LiftoffRegister result_reg(kReturnRegister0);
@@ -7515,9 +7502,9 @@ class LiftoffCompiler {
     MaybeEmitNullCheck(decoder, lhs_reg.gp(), pinned, lhs.type);
     VarState lhs_var(kRef, lhs_reg, 0);
 
-    CallRuntimeStub(WasmCode::kStringCompare,
-                    MakeSig::Returns(kSmiKind).Params(kRef, kRef),
-                    {lhs_var, rhs_var}, decoder->position());
+    CallBuiltin(Builtin::kStringCompare,
+                MakeSig::Returns(kSmiKind).Params(kRef, kRef),
+                {lhs_var, rhs_var}, decoder->position());
     RegisterDebugSideTableEntry(decoder, DebugSideTableBuilder::kDidSpill);
 
     LiftoffRegister result_reg(kReturnRegister0);
@@ -7530,9 +7517,9 @@ class LiftoffCompiler {
                            Value* result) {
     VarState& codepoint_var = __ cache_state()->stack_state.end()[-1];
 
-    CallRuntimeStub(WasmCode::kWasmStringFromCodePoint,
-                    MakeSig::Returns(kRef).Params(kI32), {codepoint_var},
-                    decoder->position());
+    CallBuiltin(Builtin::kWasmStringFromCodePoint,
+                MakeSig::Returns(kRef).Params(kI32), {codepoint_var},
+                decoder->position());
     RegisterDebugSideTableEntry(decoder, DebugSideTableBuilder::kDidSpill);
 
     LiftoffRegister result_reg(kReturnRegister0);
@@ -7547,9 +7534,8 @@ class LiftoffCompiler {
     MaybeEmitNullCheck(decoder, string_reg.gp(), pinned, string.type);
     VarState string_var(kRef, string_reg, 0);
 
-    CallRuntimeStub(WasmCode::kWasmStringHash,
-                    MakeSig::Returns(kI32).Params(kRef), {string_var},
-                    decoder->position());
+    CallBuiltin(Builtin::kWasmStringHash, MakeSig::Returns(kI32).Params(kRef),
+                {string_var}, decoder->position());
 
     LiftoffRegister result_reg(kReturnRegister0);
     __ DropValues(1);
@@ -7687,7 +7673,7 @@ class LiftoffCompiler {
       // Bounds check against the table size: Compare against table size stored
       // in {instance->indirect_function_table_size}.
       Label* out_of_bounds_label =
-          AddOutOfLineTrap(decoder, WasmCode::kThrowWasmTrapTableOutOfBounds);
+          AddOutOfLineTrap(decoder, Builtin::kThrowWasmTrapTableOutOfBounds);
       {
         FREEZE_STATE(trapping);
         __ emit_cond_jump(kUnsignedGreaterThanEqual, out_of_bounds_label, kI32,
@@ -7730,7 +7716,7 @@ class LiftoffCompiler {
               imm.sig_imm.index * kInt32Size, LoadType::kI32Load);
 
       Label* sig_mismatch_label =
-          AddOutOfLineTrap(decoder, WasmCode::kThrowWasmTrapFuncSigMismatch);
+          AddOutOfLineTrap(decoder, Builtin::kThrowWasmTrapFuncSigMismatch);
       __ DropValues(1);
 
       if (decoder->enabled_.has_gc() &&
@@ -7815,7 +7801,7 @@ class LiftoffCompiler {
               LoadType::kI32Load, nullptr, false, false, true);
 
       Label* sig_mismatch_label =
-          AddOutOfLineTrap(decoder, WasmCode::kThrowWasmTrapFuncSigMismatch);
+          AddOutOfLineTrap(decoder, Builtin::kThrowWasmTrapFuncSigMismatch);
       __ DropValues(1);
 
       FREEZE_STATE(frozen);
@@ -7908,11 +7894,10 @@ class LiftoffCompiler {
 
       // CallRefIC(vector: FixedArray, index: intptr,
       //           funcref: WasmInternalFunction)
-      CallRuntimeStub(WasmCode::kCallRefIC,
-                      MakeSig::Returns(kIntPtrKind, kIntPtrKind)
-                          .Params(kRef, kIntPtrKind, kRef),
-                      {vector_var, index_var, func_ref_var},
-                      decoder->position());
+      CallBuiltin(Builtin::kCallRefIC,
+                  MakeSig::Returns(kIntPtrKind, kIntPtrKind)
+                      .Params(kRef, kIntPtrKind, kRef),
+                  {vector_var, index_var, func_ref_var}, decoder->position());
 
       target_reg = LiftoffRegister(kReturnRegister0).gp();
       instance_reg = LiftoffRegister(kReturnRegister1).gp();
@@ -8023,7 +8008,7 @@ class LiftoffCompiler {
       return;
     }
     Label* trap_label =
-        AddOutOfLineTrap(decoder, WasmCode::kThrowWasmTrapNullDereference);
+        AddOutOfLineTrap(decoder, Builtin::kThrowWasmTrapNullDereference);
     LiftoffRegister null = __ GetUnusedRegister(kGpReg, pinned);
     LoadNullValueForCompare(null.gp(), pinned, type);
     FREEZE_STATE(trapping);
@@ -8035,7 +8020,7 @@ class LiftoffCompiler {
                         LiftoffRegister index, LiftoffRegList pinned) {
     if (V8_UNLIKELY(v8_flags.experimental_wasm_skip_bounds_checks)) return;
     Label* trap_label =
-        AddOutOfLineTrap(decoder, WasmCode::kThrowWasmTrapArrayOutOfBounds);
+        AddOutOfLineTrap(decoder, Builtin::kThrowWasmTrapArrayOutOfBounds);
     LiftoffRegister length = __ GetUnusedRegister(kGpReg, pinned);
     constexpr int kLengthOffset =
         wasm::ObjectAccess::ToTagged(WasmArray::kLengthOffset);
diff --git a/src/wasm/baseline/loong64/liftoff-assembler-loong64.h b/src/wasm/baseline/loong64/liftoff-assembler-loong64.h
index 974d5863def..4f7f4bb3105 100644
--- a/src/wasm/baseline/loong64/liftoff-assembler-loong64.h
+++ b/src/wasm/baseline/loong64/liftoff-assembler-loong64.h
@@ -181,7 +181,7 @@ void LiftoffAssembler::CallFrameSetupStub(int declared_function_index) {
   EnterFrame(StackFrame::WASM);
   LoadConstant(LiftoffRegister(kLiftoffFrameSetupFunctionReg),
                WasmValue(declared_function_index));
-  CallRuntimeStub(WasmCode::kWasmLiftoffFrameSetup);
+  CallBuiltin(Builtin::kWasmLiftoffFrameSetup);
 }
 
 void LiftoffAssembler::PrepareTailCall(int num_callee_stack_params,
@@ -269,7 +269,8 @@ void LiftoffAssembler::PatchPrepareStackFrame(
     Branch(&continuation, uge, sp, Operand(stack_limit));
   }
 
-  Call(wasm::WasmCode::kWasmStackOverflow, RelocInfo::WASM_STUB_CALL);
+  Call(static_cast<Address>(Builtin::kWasmStackOverflow),
+       RelocInfo::WASM_STUB_CALL);
   // The call will not return; just define an empty safepoint.
   safepoint_table_builder->DefineSafepoint(this);
   if (v8_flags.debug_code) stop();
@@ -3232,10 +3233,10 @@ void LiftoffAssembler::TailCallIndirect(Register target) {
   }
 }
 
-void LiftoffAssembler::CallRuntimeStub(WasmCode::RuntimeStubId sid) {
-  // A direct call to a wasm runtime stub defined in this module.
-  // Just encode the stub index. This will be patched at relocation.
-  Call(static_cast<Address>(sid), RelocInfo::WASM_STUB_CALL);
+void LiftoffAssembler::CallBuiltin(Builtin builtin) {
+  // A direct call to a builtin. Just encode the builtin index. This will be
+  // patched at relocation.
+  Call(static_cast<Address>(builtin), RelocInfo::WASM_STUB_CALL);
 }
 
 void LiftoffAssembler::AllocateStackSlot(Register addr, uint32_t size) {
diff --git a/src/wasm/baseline/mips64/liftoff-assembler-mips64.h b/src/wasm/baseline/mips64/liftoff-assembler-mips64.h
index 9e47cecf852..aebd90debf3 100644
--- a/src/wasm/baseline/mips64/liftoff-assembler-mips64.h
+++ b/src/wasm/baseline/mips64/liftoff-assembler-mips64.h
@@ -299,7 +299,7 @@ void LiftoffAssembler::CallFrameSetupStub(int declared_function_index) {
   EnterFrame(StackFrame::WASM);
   LoadConstant(LiftoffRegister(kLiftoffFrameSetupFunctionReg),
                WasmValue(declared_function_index));
-  CallRuntimeStub(WasmCode::kWasmLiftoffFrameSetup);
+  CallBuiltin(Builtin::kWasmLiftoffFrameSetup);
 }
 
 void LiftoffAssembler::PrepareTailCall(int num_callee_stack_params,
@@ -386,7 +386,8 @@ void LiftoffAssembler::PatchPrepareStackFrame(
     Branch(&continuation, uge, sp, Operand(stack_limit));
   }
 
-  Call(wasm::WasmCode::kWasmStackOverflow, RelocInfo::WASM_STUB_CALL);
+  Call(static_cast<Address>(Builtin::kWasmStackOverflow),
+       RelocInfo::WASM_STUB_CALL);
   // The call will not return; just define an empty safepoint.
   safepoint_table_builder->DefineSafepoint(this);
   if (v8_flags.debug_code) stop();
@@ -3768,10 +3769,10 @@ void LiftoffAssembler::TailCallIndirect(Register target) {
   }
 }
 
-void LiftoffAssembler::CallRuntimeStub(WasmCode::RuntimeStubId sid) {
-  // A direct call to a wasm runtime stub defined in this module.
-  // Just encode the stub index. This will be patched at relocation.
-  Call(static_cast<Address>(sid), RelocInfo::WASM_STUB_CALL);
+void LiftoffAssembler::CallBuiltin(Builtin builtin) {
+  // A direct call to a builtin. Just encode the builtin index. This will be
+  // patched at relocation.
+  Call(static_cast<Address>(builtin), RelocInfo::WASM_STUB_CALL);
 }
 
 void LiftoffAssembler::AllocateStackSlot(Register addr, uint32_t size) {
diff --git a/src/wasm/baseline/ppc/liftoff-assembler-ppc.h b/src/wasm/baseline/ppc/liftoff-assembler-ppc.h
index 98620733d6f..ff948d6ca1f 100644
--- a/src/wasm/baseline/ppc/liftoff-assembler-ppc.h
+++ b/src/wasm/baseline/ppc/liftoff-assembler-ppc.h
@@ -82,7 +82,7 @@ void LiftoffAssembler::CallFrameSetupStub(int declared_function_index) {
   PushCommonFrame(scratch);
   LoadConstant(LiftoffRegister(kLiftoffFrameSetupFunctionReg),
                WasmValue(declared_function_index));
-  CallRuntimeStub(WasmCode::kWasmLiftoffFrameSetup);
+  CallBuiltin(Builtin::kWasmLiftoffFrameSetup);
 }
 
 void LiftoffAssembler::PrepareTailCall(int num_callee_stack_params,
@@ -171,7 +171,8 @@ void LiftoffAssembler::PatchPrepareStackFrame(
     bge(&continuation);
   }
 
-  Call(wasm::WasmCode::kWasmStackOverflow, RelocInfo::WASM_STUB_CALL);
+  Call(static_cast<Address>(wasm::kWasmStackOverflow),
+       RelocInfo::WASM_STUB_CALL);
   // The call will not return; just define an empty safepoint.
   safepoint_table_builder->DefineSafepoint(this);
   if (v8_flags.debug_code) stop();
@@ -2683,8 +2684,10 @@ void LiftoffAssembler::TailCallIndirect(Register target) {
   Jump(target);
 }
 
-void LiftoffAssembler::CallRuntimeStub(WasmCode::RuntimeStubId sid) {
-  Call(static_cast<Address>(sid), RelocInfo::WASM_STUB_CALL);
+void LiftoffAssembler::CallBuiltin(Builtin builtin) {
+  // A direct call to a builtin. Just encode the builtin index. This will be
+  // patched at relocation.
+  Call(static_cast<Address>(builtin), RelocInfo::WASM_STUB_CALL);
 }
 
 void LiftoffAssembler::AllocateStackSlot(Register addr, uint32_t size) {
diff --git a/src/wasm/baseline/riscv/liftoff-assembler-riscv.h b/src/wasm/baseline/riscv/liftoff-assembler-riscv.h
index 5f22f66f1f3..a56e493b9b7 100644
--- a/src/wasm/baseline/riscv/liftoff-assembler-riscv.h
+++ b/src/wasm/baseline/riscv/liftoff-assembler-riscv.h
@@ -146,7 +146,8 @@ void LiftoffAssembler::PatchPrepareStackFrame(
     Branch(&continuation, uge, sp, Operand(stack_limit));
   }
 
-  Call(wasm::WasmCode::kWasmStackOverflow, RelocInfo::WASM_STUB_CALL);
+  Call(static_cast<Address>(wasm::kWasmStackOverflow),
+       RelocInfo::WASM_STUB_CALL);
   // The call will not return; just define an empty safepoint.
   safepoint_table_builder->DefineSafepoint(this);
   if (v8_flags.debug_code) stop();
@@ -2314,10 +2315,10 @@ void LiftoffAssembler::TailCallIndirect(Register target) {
   }
 }
 
-void LiftoffAssembler::CallRuntimeStub(WasmCode::RuntimeStubId sid) {
-  // A direct call to a wasm runtime stub defined in this module.
-  // Just encode the stub index. This will be patched at relocation.
-  Call(static_cast<Address>(sid), RelocInfo::WASM_STUB_CALL);
+void LiftoffAssembler::CallBuiltin(Builtin builtin) {
+  // A direct call to a builtin. Just encode the builtin index. This will be
+  // patched at relocation.
+  Call(static_cast<Address>(builtin), RelocInfo::WASM_STUB_CALL);
 }
 
 void LiftoffAssembler::AllocateStackSlot(Register addr, uint32_t size) {
@@ -2359,7 +2360,7 @@ void LiftoffAssembler::CallFrameSetupStub(int declared_function_index) {
   EnterFrame(StackFrame::WASM);
   LoadConstant(LiftoffRegister(kLiftoffFrameSetupFunctionReg),
                WasmValue(declared_function_index));
-  CallRuntimeStub(WasmCode::kWasmLiftoffFrameSetup);
+  CallBuiltin(Builtin::kWasmLiftoffFrameSetup);
 }
 
 }  // namespace wasm
diff --git a/src/wasm/baseline/s390/liftoff-assembler-s390.h b/src/wasm/baseline/s390/liftoff-assembler-s390.h
index b3a482a751b..75087719e6e 100644
--- a/src/wasm/baseline/s390/liftoff-assembler-s390.h
+++ b/src/wasm/baseline/s390/liftoff-assembler-s390.h
@@ -73,7 +73,7 @@ void LiftoffAssembler::CallFrameSetupStub(int declared_function_index) {
   PushCommonFrame(scratch);
   LoadConstant(LiftoffRegister(kLiftoffFrameSetupFunctionReg),
                WasmValue(declared_function_index));
-  CallRuntimeStub(WasmCode::kWasmLiftoffFrameSetup);
+  CallBuiltin(Builtin::kWasmLiftoffFrameSetup);
 }
 
 void LiftoffAssembler::PrepareTailCall(int num_callee_stack_params,
@@ -156,7 +156,8 @@ void LiftoffAssembler::PatchPrepareStackFrame(
     bge(&continuation);
   }
 
-  Call(wasm::WasmCode::kWasmStackOverflow, RelocInfo::WASM_STUB_CALL);
+  Call(static_cast<Address>(wasm::kWasmStackOverflow),
+       RelocInfo::WASM_STUB_CALL);
   // The call will not return; just define an empty safepoint.
   safepoint_table_builder->DefineSafepoint(this);
   if (v8_flags.debug_code) stop();
@@ -3109,8 +3110,10 @@ void LiftoffAssembler::TailCallIndirect(Register target) {
   Jump(target);
 }
 
-void LiftoffAssembler::CallRuntimeStub(WasmCode::RuntimeStubId sid) {
-  Call(static_cast<Address>(sid), RelocInfo::WASM_STUB_CALL);
+void LiftoffAssembler::CallBuiltin(Builtin builtin) {
+  // A direct call to a builtin. Just encode the builtin index. This will be
+  // patched at relocation.
+  Call(static_cast<Address>(builtin), RelocInfo::WASM_STUB_CALL);
 }
 
 void LiftoffAssembler::AllocateStackSlot(Register addr, uint32_t size) {
diff --git a/src/wasm/baseline/x64/liftoff-assembler-x64.h b/src/wasm/baseline/x64/liftoff-assembler-x64.h
index 485cade4edb..0461f77efd0 100644
--- a/src/wasm/baseline/x64/liftoff-assembler-x64.h
+++ b/src/wasm/baseline/x64/liftoff-assembler-x64.h
@@ -177,7 +177,7 @@ void LiftoffAssembler::CallFrameSetupStub(int declared_function_index) {
 
   LoadConstant(LiftoffRegister(kLiftoffFrameSetupFunctionReg),
                WasmValue(declared_function_index));
-  CallRuntimeStub(WasmCode::kWasmLiftoffFrameSetup);
+  CallBuiltin(Builtin::kWasmLiftoffFrameSetup);
 }
 
 void LiftoffAssembler::PrepareTailCall(int num_callee_stack_params,
@@ -264,7 +264,8 @@ void LiftoffAssembler::PatchPrepareStackFrame(
     j(above_equal, &continuation, Label::kNear);
   }
 
-  near_call(wasm::WasmCode::kWasmStackOverflow, RelocInfo::WASM_STUB_CALL);
+  near_call(static_cast<intptr_t>(Builtin::kWasmStackOverflow),
+            RelocInfo::WASM_STUB_CALL);
   // The call will not return; just define an empty safepoint.
   safepoint_table_builder->DefineSafepoint(this);
   AssertUnreachable(AbortReason::kUnexpectedReturnFromWasmTrap);
@@ -4327,10 +4328,10 @@ void LiftoffAssembler::TailCallIndirect(Register target) {
   jmp(target);
 }
 
-void LiftoffAssembler::CallRuntimeStub(WasmCode::RuntimeStubId sid) {
-  // A direct call to a wasm runtime stub defined in this module.
-  // Just encode the stub index. This will be patched at relocation.
-  near_call(static_cast<Address>(sid), RelocInfo::WASM_STUB_CALL);
+void LiftoffAssembler::CallBuiltin(Builtin builtin) {
+  // A direct call to a builtin. Just encode the builtin index. This will be
+  // patched at relocation.
+  near_call(static_cast<Address>(builtin), RelocInfo::WASM_STUB_CALL);
 }
 
 void LiftoffAssembler::AllocateStackSlot(Register addr, uint32_t size) {
@@ -4344,7 +4345,7 @@ void LiftoffAssembler::DeallocateStackSlot(uint32_t size) {
 
 void LiftoffAssembler::MaybeOSR() {
   cmpq(liftoff::kOSRTargetSlot, Immediate(0));
-  j(not_equal, static_cast<Address>(WasmCode::kWasmOnStackReplace),
+  j(not_equal, static_cast<Address>(Builtin::kWasmOnStackReplace),
     RelocInfo::WASM_STUB_CALL);
 }
 
diff --git a/src/wasm/turboshaft-graph-interface.cc b/src/wasm/turboshaft-graph-interface.cc
index cf5f2d403cf..23a77887b4f 100644
--- a/src/wasm/turboshaft-graph-interface.cc
+++ b/src/wasm/turboshaft-graph-interface.cc
@@ -487,8 +487,8 @@ class TurboshaftGraphBuildingInterface {
     Label<WasmInternalFunction> done(&asm_);
     IF (UNLIKELY(__ IsSmi(maybe_function))) {
       V<Word32> function_index_constant = __ Word32Constant(function_index);
-      V<WasmInternalFunction> from_builtin = CallBuiltinFromRuntimeStub(
-          decoder, wasm::WasmCode::kWasmRefFunc, {function_index_constant});
+      V<WasmInternalFunction> from_builtin = CallBuiltinThroughJumptable(
+          decoder, Builtin::kWasmRefFunc, {function_index_constant});
       GOTO(done, from_builtin);
     }
     ELSE {
@@ -856,15 +856,15 @@ class TurboshaftGraphBuildingInterface {
                   const Value& value, Value* result) {
     if (!imm.memory->is_memory64) {
       result->op =
-          CallBuiltinFromRuntimeStub(decoder, WasmCode::kWasmMemoryGrow,
-                                     {__ Word32Constant(imm.index), value.op});
+          CallBuiltinThroughJumptable(decoder, Builtin::kWasmMemoryGrow,
+                                      {__ Word32Constant(imm.index), value.op});
     } else {
       Label<Word64> done(&asm_);
 
       IF (LIKELY(__ Uint64LessThanOrEqual(
               value.op, __ Word64Constant(static_cast<int64_t>(kMaxInt))))) {
-        GOTO(done, __ ChangeInt32ToInt64(CallBuiltinFromRuntimeStub(
-                       decoder, WasmCode::kWasmMemoryGrow,
+        GOTO(done, __ ChangeInt32ToInt64(CallBuiltinThroughJumptable(
+                       decoder, Builtin::kWasmMemoryGrow,
                        {__ Word32Constant(imm.index),
                         __ TruncateWord64ToWord32(value.op)})));
       }
@@ -1177,8 +1177,8 @@ class TurboshaftGraphBuildingInterface {
     uint32_t encoded_size = WasmExceptionPackage::GetEncodedSize(imm.tag);
 
     V<FixedArray> values_array =
-        CallBuiltinFromRuntimeStub(decoder, WasmCode::kWasmAllocateFixedArray,
-                                   {__ IntPtrConstant(encoded_size)});
+        CallBuiltinThroughJumptable(decoder, Builtin::kWasmAllocateFixedArray,
+                                    {__ IntPtrConstant(encoded_size)});
 
     uint32_t index = 0;
     const wasm::WasmTagSig* sig = imm.tag->sig;
@@ -1248,16 +1248,16 @@ class TurboshaftGraphBuildingInterface {
     auto tag =
         V<WasmTagObject>::Cast(LoadFixedArrayElement(instance_tags, imm.index));
 
-    CallBuiltinFromRuntimeStub(decoder, WasmCode::kWasmThrow,
-                               {tag, values_array}, Operator::kNoProperties,
-                               CheckForException::kYes);
+    CallBuiltinThroughJumptable(decoder, Builtin::kWasmThrow,
+                                {tag, values_array}, Operator::kNoProperties,
+                                CheckForException::kYes);
     __ Unreachable();
   }
 
   void Rethrow(FullDecoder* decoder, Control* block) {
-    CallBuiltinFromRuntimeStub(decoder, WasmCode::kWasmRethrow,
-                               {block->exception}, Operator::kNoProperties,
-                               CheckForException::kYes);
+    CallBuiltinThroughJumptable(decoder, Builtin::kWasmRethrow,
+                                {block->exception}, Operator::kNoProperties,
+                                CheckForException::kYes);
     __ Unreachable();
   }
 
@@ -1268,8 +1268,8 @@ class TurboshaftGraphBuildingInterface {
                              nullptr, &block->exception);
     V<NativeContext> native_context = LOAD_IMMUTABLE_INSTANCE_FIELD(
         NativeContext, MemoryRepresentation::TaggedPointer());
-    V<WasmTagObject> caught_tag = CallBuiltinFromRuntimeStub(
-        decoder, WasmCode::kWasmGetOwnProperty,
+    V<WasmTagObject> caught_tag = CallBuiltinThroughJumptable(
+        decoder, Builtin::kWasmGetOwnProperty,
         {block->exception, LOAD_IMMUTABLE_ROOT(wasm_exception_tag_symbol),
          native_context});
     V<FixedArray> instance_tags = LOAD_IMMUTABLE_INSTANCE_FIELD(
@@ -1341,8 +1341,8 @@ class TurboshaftGraphBuildingInterface {
     if (depth == decoder->control_depth() - 1) {
       // We just throw to the caller, no need to handle the exception in this
       // frame.
-      CallBuiltinFromRuntimeStub(decoder, WasmCode::kWasmRethrow,
-                                 {block->exception});
+      CallBuiltinThroughJumptable(decoder, Builtin::kWasmRethrow,
+                                  {block->exception});
       __ Unreachable();
     } else {
       DCHECK(decoder->control_at(depth)->is_try());
@@ -1361,15 +1361,11 @@ class TurboshaftGraphBuildingInterface {
   }
 
   V<BigInt> BuildChangeInt64ToBigInt(V<Word64> input) {
-    V<WordPtr> builtin =
-        Is64() ? __ RelocatableConstant(WasmCode::kI64ToBigInt,
-                                        RelocInfo::WASM_STUB_CALL)
-               : __ RelocatableConstant(WasmCode::kI32PairToBigInt,
-                                        RelocInfo::WASM_STUB_CALL);
+    Builtin builtin =
+        Is64() ? Builtin::kI64ToBigInt : Builtin::kI32PairToBigInt;
+    V<WordPtr> target = __ RelocatableWasmBuiltinCallTarget(builtin);
     CallInterfaceDescriptor interface_descriptor =
-        Is64()
-            ? Builtins::CallInterfaceDescriptorFor(Builtin::kI64ToBigInt)
-            : Builtins::CallInterfaceDescriptorFor(Builtin::kI32PairToBigInt);
+        Builtins::CallInterfaceDescriptorFor(builtin);
     const CallDescriptor* call_descriptor =
         compiler::Linkage::GetStubCallDescriptor(
             __ graph_zone(),  // zone
@@ -1381,12 +1377,12 @@ class TurboshaftGraphBuildingInterface {
     const TSCallDescriptor* ts_call_descriptor = TSCallDescriptor::Create(
         call_descriptor, compiler::CanThrow::kNo, __ graph_zone());
     if constexpr (Is64()) {
-      return __ Call(builtin, {input}, ts_call_descriptor);
+      return __ Call(target, {input}, ts_call_descriptor);
     }
     V<Word32> low_word = __ TruncateWord64ToWord32(input);
     V<Word32> high_word = __ TruncateWord64ToWord32(__ ShiftRightLogical(
         input, __ Word32Constant(32), WordRepresentation::Word64()));
-    return __ Call(builtin, {low_word, high_word}, ts_call_descriptor);
+    return __ Call(target, {low_word, high_word}, ts_call_descriptor);
   }
 
   void AtomicNotify(FullDecoder* decoder, const MemoryAccessImmediate& imm,
@@ -1399,8 +1395,8 @@ class TurboshaftGraphBuildingInterface {
 
     OpIndex effective_offset = __ WordPtrAdd(converted_index, imm.offset);
 
-    result->op = CallBuiltinFromRuntimeStub(
-        decoder, WasmCode::kWasmAtomicNotify,
+    result->op = CallBuiltinThroughJumptable(
+        decoder, Builtin::kWasmAtomicNotify,
         {__ Word32Constant(imm.memory->index), effective_offset, value});
   }
 
@@ -1420,16 +1416,16 @@ class TurboshaftGraphBuildingInterface {
     V<BigInt> bigint_timeout = BuildChangeInt64ToBigInt(timeout);
 
     if (opcode == kExprI32AtomicWait) {
-      result->op = CallBuiltinFromRuntimeStub(
-          decoder, WasmCode::kWasmI32AtomicWait,
+      result->op = CallBuiltinThroughJumptable(
+          decoder, Builtin::kWasmI32AtomicWait,
           {__ Word32Constant(imm.memory->index), effective_offset, expected,
            bigint_timeout});
       return;
     }
     DCHECK_EQ(opcode, kExprI64AtomicWait);
     V<BigInt> bigint_expected = BuildChangeInt64ToBigInt(expected);
-    result->op = CallBuiltinFromRuntimeStub(
-        decoder, WasmCode::kWasmI64AtomicWait,
+    result->op = CallBuiltinThroughJumptable(
+        decoder, Builtin::kWasmI64AtomicWait,
         {__ Word32Constant(imm.memory->index), effective_offset,
          bigint_expected, bigint_timeout});
   }
@@ -1686,9 +1682,9 @@ class TurboshaftGraphBuildingInterface {
                 const IndexImmediate& imm) {
     ValueType table_type = decoder->module_->tables[imm.index].type;
     auto stub = IsSubtypeOf(table_type, kWasmFuncRef, decoder->module_)
-                    ? WasmCode::kWasmTableGetFuncRef
-                    : WasmCode::kWasmTableGet;
-    result->op = CallBuiltinFromRuntimeStub(
+                    ? Builtin::kWasmTableGetFuncRef
+                    : Builtin::kWasmTableGet;
+    result->op = CallBuiltinThroughJumptable(
         decoder, stub, {__ IntPtrConstant(imm.index), index.op});
   }
 
@@ -1696,9 +1692,9 @@ class TurboshaftGraphBuildingInterface {
                 const IndexImmediate& imm) {
     ValueType table_type = decoder->module_->tables[imm.index].type;
     auto stub = IsSubtypeOf(table_type, kWasmFuncRef, decoder->module_)
-                    ? WasmCode::kWasmTableSetFuncRef
-                    : WasmCode::kWasmTableSet;
-    CallBuiltinFromRuntimeStub(
+                    ? Builtin::kWasmTableSetFuncRef
+                    : Builtin::kWasmTableSet;
+    CallBuiltinThroughJumptable(
         decoder, stub, {__ IntPtrConstant(imm.index), index.op, value.op});
   }
 
@@ -1707,8 +1703,8 @@ class TurboshaftGraphBuildingInterface {
     V<Word32> dst = args[0].op;
     V<Word32> src = args[1].op;
     V<Word32> size = args[2].op;
-    CallBuiltinFromRuntimeStub(
-        decoder, WasmCode::kWasmTableInit,
+    CallBuiltinThroughJumptable(
+        decoder, Builtin::kWasmTableInit,
         {dst, src, size, __ NumberConstant(imm.table.index),
          __ NumberConstant(imm.element_segment.index)});
   }
@@ -1718,24 +1714,24 @@ class TurboshaftGraphBuildingInterface {
     V<Word32> dst = args[0].op;
     V<Word32> src = args[1].op;
     V<Word32> size = args[2].op;
-    CallBuiltinFromRuntimeStub(
-        decoder, WasmCode::kWasmTableCopy,
+    CallBuiltinThroughJumptable(
+        decoder, Builtin::kWasmTableCopy,
         {dst, src, size, __ NumberConstant(imm.table_dst.index),
          __ NumberConstant(imm.table_src.index)});
   }
 
   void TableGrow(FullDecoder* decoder, const IndexImmediate& imm,
                  const Value& value, const Value& delta, Value* result) {
-    V<Smi> result_smi = CallBuiltinFromRuntimeStub(
-        decoder, WasmCode::kWasmTableGrow,
+    V<Smi> result_smi = CallBuiltinThroughJumptable(
+        decoder, Builtin::kWasmTableGrow,
         {__ NumberConstant(imm.index), delta.op, value.op});
     result->op = __ UntagSmi(result_smi);
   }
 
   void TableFill(FullDecoder* decoder, const IndexImmediate& imm,
                  const Value& start, const Value& value, const Value& count) {
-    CallBuiltinFromRuntimeStub(
-        decoder, WasmCode::kWasmTableFill,
+    CallBuiltinThroughJumptable(
+        decoder, Builtin::kWasmTableFill,
         {__ NumberConstant(imm.index), start.op, count.op, value.op});
   }
 
@@ -1991,8 +1987,8 @@ class TurboshaftGraphBuildingInterface {
                        const IndexImmediate& segment_imm, const Value& offset,
                        const Value& length, Value* result) {
     bool is_element = array_imm.array_type->element_type().is_reference();
-    result->op = CallBuiltinFromRuntimeStub(
-        decoder, WasmCode::kWasmArrayNewSegment,
+    result->op = CallBuiltinThroughJumptable(
+        decoder, Builtin::kWasmArrayNewSegment,
         {__ Word32Constant(segment_imm.index), offset.op, length.op,
          __ SmiConstant(Smi::FromInt(is_element ? 1 : 0)),
          __ RttCanon(instance_node_, array_imm.index)});
@@ -2004,8 +2000,8 @@ class TurboshaftGraphBuildingInterface {
                         const Value& array_index, const Value& segment_offset,
                         const Value& length) {
     bool is_element = array_imm.array_type->element_type().is_reference();
-    CallBuiltinFromRuntimeStub(
-        decoder, WasmCode::kWasmArrayInitSegment,
+    CallBuiltinThroughJumptable(
+        decoder, Builtin::kWasmArrayInitSegment,
         {array_index.op, segment_offset.op, length.op,
          __ SmiConstant(Smi::FromInt(segment_imm.index)),
          __ SmiConstant(Smi::FromInt(is_element ? 1 : 0)), array.op});
@@ -2158,8 +2154,8 @@ class TurboshaftGraphBuildingInterface {
     V<Object> memory_smi = __ SmiConstant(Smi::FromInt(memory.index));
     V<Object> variant_smi =
         __ SmiConstant(Smi::FromInt(static_cast<int>(variant)));
-    result->op = CallBuiltinFromRuntimeStub(
-        decoder, WasmCode::kWasmStringNewWtf8,
+    result->op = CallBuiltinThroughJumptable(
+        decoder, Builtin::kWasmStringNewWtf8,
         {offset.op, size.op, memory_smi, variant_smi},
         Operator::kNoDeopt | Operator::kNoThrow);
   }
@@ -2174,8 +2170,8 @@ class TurboshaftGraphBuildingInterface {
              .MatchWasmStubCallConstant(call->callee(), &stub_id)) {
       return false;
     }
-    DCHECK_LT(stub_id, WasmCode::kRuntimeStubCount);
-    return stub_id == WasmCode::kWasmArrayNewSegment;
+    DCHECK_LT(stub_id, static_cast<int64_t>(Builtin::kFirstBytecodeHandler));
+    return stub_id == static_cast<int64_t>(Builtin::kWasmArrayNewSegment);
   }
 
   void StringNewWtf8Array(FullDecoder* decoder,
@@ -2201,16 +2197,16 @@ class TurboshaftGraphBuildingInterface {
           OpIndex::Invalid(), TrapId::kTrapDataSegmentOutOfBounds);
       V<Object> offset_smi = __ TagSmi(segment_offset);
       OpIndex segment_length = array_new.input(3);
-      result->op = CallBuiltinFromRuntimeStub(
-          decoder, WasmCode::kWasmStringFromDataSegment,
+      result->op = CallBuiltinThroughJumptable(
+          decoder, Builtin::kWasmStringFromDataSegment,
           {segment_length, start.op, end.op, index_smi, offset_smi},
           Operator::kNoDeopt | Operator::kNoThrow);
       return;
     }
 
     // Regular path if the shortcut wasn't taken.
-    result->op = CallBuiltinFromRuntimeStub(
-        decoder, WasmCode::kWasmStringNewWtf8Array,
+    result->op = CallBuiltinThroughJumptable(
+        decoder, Builtin::kWasmStringNewWtf8Array,
         {start.op, end.op, NullCheck(array),
          __ SmiConstant(Smi::FromInt(static_cast<int32_t>(variant)))},
         Operator::kNoDeopt | Operator::kNoThrow);
@@ -2218,8 +2214,8 @@ class TurboshaftGraphBuildingInterface {
 
   void StringNewWtf16(FullDecoder* decoder, const MemoryIndexImmediate& imm,
                       const Value& offset, const Value& size, Value* result) {
-    result->op = CallBuiltinFromRuntimeStub(
-        decoder, WasmCode::kWasmStringNewWtf16,
+    result->op = CallBuiltinThroughJumptable(
+        decoder, Builtin::kWasmStringNewWtf16,
         {__ Word32Constant(imm.index), offset.op, size.op},
         Operator::kNoDeopt | Operator::kNoThrow);
   }
@@ -2228,35 +2224,35 @@ class TurboshaftGraphBuildingInterface {
                            const Value& start, const Value& end,
                            Value* result) {
     result->op =
-        CallBuiltinFromRuntimeStub(decoder, WasmCode::kWasmStringNewWtf16Array,
-                                   {NullCheck(array), start.op, end.op},
-                                   Operator::kNoDeopt | Operator::kNoThrow);
+        CallBuiltinThroughJumptable(decoder, Builtin::kWasmStringNewWtf16Array,
+                                    {NullCheck(array), start.op, end.op},
+                                    Operator::kNoDeopt | Operator::kNoThrow);
   }
 
   void StringConst(FullDecoder* decoder, const StringConstImmediate& imm,
                    Value* result) {
-    result->op = CallBuiltinFromRuntimeStub(
-        decoder, WasmCode::kWasmStringConst, {__ Word32Constant(imm.index)},
+    result->op = CallBuiltinThroughJumptable(
+        decoder, Builtin::kWasmStringConst, {__ Word32Constant(imm.index)},
         Operator::kNoDeopt | Operator::kNoThrow);
   }
 
   void StringMeasureWtf8(FullDecoder* decoder,
                          const unibrow::Utf8Variant variant, const Value& str,
                          Value* result) {
-    WasmCode::RuntimeStubId builtin;
+    Builtin builtin;
     switch (variant) {
       case unibrow::Utf8Variant::kUtf8:
-        builtin = WasmCode::kWasmStringMeasureUtf8;
+        builtin = Builtin::kWasmStringMeasureUtf8;
         break;
       case unibrow::Utf8Variant::kLossyUtf8:
       case unibrow::Utf8Variant::kWtf8:
-        builtin = WasmCode::kWasmStringMeasureWtf8;
+        builtin = Builtin::kWasmStringMeasureWtf8;
         break;
       case unibrow::Utf8Variant::kUtf8NoTrap:
         UNREACHABLE();
     }
-    result->op = CallBuiltinFromRuntimeStub(decoder, builtin, {NullCheck(str)},
-                                            Operator::kEliminatable);
+    result->op = CallBuiltinThroughJumptable(decoder, builtin, {NullCheck(str)},
+                                             Operator::kEliminatable);
   }
 
   void StringMeasureWtf16(FullDecoder* decoder, const Value& str,
@@ -2269,8 +2265,8 @@ class TurboshaftGraphBuildingInterface {
                         const MemoryIndexImmediate& memory,
                         const unibrow::Utf8Variant variant, const Value& str,
                         const Value& offset, Value* result) {
-    result->op = CallBuiltinFromRuntimeStub(
-        decoder, WasmCode::kWasmStringEncodeWtf8,
+    result->op = CallBuiltinThroughJumptable(
+        decoder, Builtin::kWasmStringEncodeWtf8,
         {NullCheck(str), offset.op, __ SmiConstant(Smi::FromInt(memory.index)),
          __ SmiConstant(Smi::FromInt(static_cast<int32_t>(variant)))},
         Operator::kNoDeopt | Operator::kNoThrow);
@@ -2280,8 +2276,8 @@ class TurboshaftGraphBuildingInterface {
                              const unibrow::Utf8Variant variant,
                              const Value& str, const Value& array,
                              const Value& start, Value* result) {
-    result->op = CallBuiltinFromRuntimeStub(
-        decoder, WasmCode::kWasmStringEncodeWtf8Array,
+    result->op = CallBuiltinThroughJumptable(
+        decoder, Builtin::kWasmStringEncodeWtf8Array,
         {NullCheck(str), NullCheck(array), start.op,
          __ SmiConstant(Smi::FromInt(static_cast<int32_t>(variant)))},
         Operator::kNoDeopt | Operator::kNoThrow);
@@ -2289,8 +2285,8 @@ class TurboshaftGraphBuildingInterface {
 
   void StringEncodeWtf16(FullDecoder* decoder, const MemoryIndexImmediate& imm,
                          const Value& str, const Value& offset, Value* result) {
-    result->op = CallBuiltinFromRuntimeStub(
-        decoder, WasmCode::kWasmStringEncodeWtf16,
+    result->op = CallBuiltinThroughJumptable(
+        decoder, Builtin::kWasmStringEncodeWtf16,
         {NullCheck(str), offset.op,
          __ SmiConstant(Smi::FromInt(static_cast<int32_t>(imm.index)))},
         Operator::kNoDeopt | Operator::kNoThrow);
@@ -2299,8 +2295,8 @@ class TurboshaftGraphBuildingInterface {
   void StringEncodeWtf16Array(FullDecoder* decoder, const Value& str,
                               const Value& array, const Value& start,
                               Value* result) {
-    result->op = CallBuiltinFromRuntimeStub(
-        decoder, WasmCode::kWasmStringEncodeWtf16Array,
+    result->op = CallBuiltinThroughJumptable(
+        decoder, Builtin::kWasmStringEncodeWtf16Array,
         {NullCheck(str), NullCheck(array), start.op},
         Operator::kNoDeopt | Operator::kNoThrow);
   }
@@ -2309,8 +2305,8 @@ class TurboshaftGraphBuildingInterface {
                     Value* result) {
     V<HeapObject> native_context = LOAD_IMMUTABLE_INSTANCE_FIELD(
         NativeContext, MemoryRepresentation::TaggedPointer());
-    result->op = CallBuiltinFromRuntimeStub(
-        decoder, WasmCode::kStringAdd_CheckNone,
+    result->op = CallBuiltinThroughJumptable(
+        decoder, Builtin::kStringAdd_CheckNone,
         {NullCheck(head), NullCheck(tail), native_context},
         Operator::kNoDeopt | Operator::kNoThrow);
   }
@@ -2328,8 +2324,8 @@ class TurboshaftGraphBuildingInterface {
     }
     // TODO(jkummerow): Call Builtin::kStringEqual directly.
     GOTO(done,
-         CallBuiltinFromRuntimeStub(decoder, WasmCode::kWasmStringEqual,
-                                    {a.op, b.op}, Operator::kEliminatable));
+         CallBuiltinThroughJumptable(decoder, Builtin::kWasmStringEqual,
+                                     {a.op, b.op}, Operator::kEliminatable));
     BIND(done, eq_result);
     result->op = eq_result;
   }
@@ -2337,21 +2333,21 @@ class TurboshaftGraphBuildingInterface {
   void StringIsUSVSequence(FullDecoder* decoder, const Value& str,
                            Value* result) {
     result->op =
-        CallBuiltinFromRuntimeStub(decoder, WasmCode::kWasmStringIsUSVSequence,
-                                   {NullCheck(str)}, Operator::kEliminatable);
+        CallBuiltinThroughJumptable(decoder, Builtin::kWasmStringIsUSVSequence,
+                                    {NullCheck(str)}, Operator::kEliminatable);
   }
 
   void StringAsWtf8(FullDecoder* decoder, const Value& str, Value* result) {
     result->op =
-        CallBuiltinFromRuntimeStub(decoder, WasmCode::kWasmStringAsWtf8,
-                                   {NullCheck(str)}, Operator::kEliminatable);
+        CallBuiltinThroughJumptable(decoder, Builtin::kWasmStringAsWtf8,
+                                    {NullCheck(str)}, Operator::kEliminatable);
   }
 
   void StringViewWtf8Advance(FullDecoder* decoder, const Value& view,
                              const Value& pos, const Value& bytes,
                              Value* result) {
-    result->op = CallBuiltinFromRuntimeStub(
-        decoder, WasmCode::kWasmStringViewWtf8Advance,
+    result->op = CallBuiltinThroughJumptable(
+        decoder, Builtin::kWasmStringViewWtf8Advance,
         {NullCheck(view), pos.op, bytes.op}, Operator::kEliminatable);
   }
 
@@ -2361,8 +2357,8 @@ class TurboshaftGraphBuildingInterface {
                             const Value& view, const Value& addr,
                             const Value& pos, const Value& bytes,
                             Value* next_pos, Value* bytes_written) {
-    OpIndex result = CallBuiltinFromRuntimeStub(
-        decoder, WasmCode::kWasmStringViewWtf8Encode,
+    OpIndex result = CallBuiltinThroughJumptable(
+        decoder, Builtin::kWasmStringViewWtf8Encode,
         {addr.op, pos.op, bytes.op, NullCheck(view),
          __ SmiConstant(Smi::FromInt(memory.index)),
          __ SmiConstant(Smi::FromInt(static_cast<int32_t>(variant)))},
@@ -2375,8 +2371,8 @@ class TurboshaftGraphBuildingInterface {
   void StringViewWtf8Slice(FullDecoder* decoder, const Value& view,
                            const Value& start, const Value& end,
                            Value* result) {
-    result->op = CallBuiltinFromRuntimeStub(
-        decoder, WasmCode::kWasmStringViewWtf8Slice,
+    result->op = CallBuiltinThroughJumptable(
+        decoder, Builtin::kWasmStringViewWtf8Slice,
         {NullCheck(view), start.op, end.op}, Operator::kEliminatable);
   }
 
@@ -2435,8 +2431,8 @@ class TurboshaftGraphBuildingInterface {
     GOTO(done, result_value);
 
     BIND(bailout);
-    GOTO(done, CallBuiltinFromRuntimeStub(
-                   decoder, WasmCode::kWasmStringViewWtf16GetCodeUnit,
+    GOTO(done, CallBuiltinThroughJumptable(
+                   decoder, Builtin::kWasmStringViewWtf16GetCodeUnit,
                    {string, pos.op}, Operator::kPure));
 
     BIND(done, final_result);
@@ -2452,8 +2448,8 @@ class TurboshaftGraphBuildingInterface {
                              const Value& offset, const Value& pos,
                              const Value& codeunits, Value* result) {
     V<Tagged> string = NullCheck(view);
-    result->op = CallBuiltinFromRuntimeStub(
-        decoder, WasmCode::kWasmStringViewWtf16Encode,
+    result->op = CallBuiltinThroughJumptable(
+        decoder, Builtin::kWasmStringViewWtf16Encode,
         {offset.op, pos.op, codeunits.op, string,
          __ SmiConstant(Smi::FromInt(imm.index))},
         Operator::kNoDeopt | Operator::kNoThrow);
@@ -2463,47 +2459,46 @@ class TurboshaftGraphBuildingInterface {
                             const Value& start, const Value& end,
                             Value* result) {
     V<Tagged> string = NullCheck(view);
-    result->op = CallBuiltinFromRuntimeStub(
-        decoder, WasmCode::kWasmStringViewWtf16Slice,
-        {string, start.op, end.op}, Operator::kEliminatable);
+    result->op = CallBuiltinThroughJumptable(
+        decoder, Builtin::kWasmStringViewWtf16Slice, {string, start.op, end.op},
+        Operator::kEliminatable);
   }
 
   void StringAsIter(FullDecoder* decoder, const Value& str, Value* result) {
     V<Tagged> string = NullCheck(str);
-    result->op =
-        CallBuiltinFromRuntimeStub(decoder, WasmCode::kWasmStringAsIter,
-                                   {string}, Operator::kEliminatable);
+    result->op = CallBuiltinThroughJumptable(
+        decoder, Builtin::kWasmStringAsIter, {string}, Operator::kEliminatable);
   }
 
   void StringViewIterNext(FullDecoder* decoder, const Value& view,
                           Value* result) {
     V<Tagged> string = NullCheck(view);
     result->op =
-        CallBuiltinFromRuntimeStub(decoder, WasmCode::kWasmStringViewIterNext,
-                                   {string}, Operator::kEliminatable);
+        CallBuiltinThroughJumptable(decoder, Builtin::kWasmStringViewIterNext,
+                                    {string}, Operator::kEliminatable);
   }
 
   void StringViewIterAdvance(FullDecoder* decoder, const Value& view,
                              const Value& codepoints, Value* result) {
     V<Tagged> string = NullCheck(view);
-    result->op = CallBuiltinFromRuntimeStub(
-        decoder, WasmCode::kWasmStringViewIterAdvance, {string, codepoints.op},
+    result->op = CallBuiltinThroughJumptable(
+        decoder, Builtin::kWasmStringViewIterAdvance, {string, codepoints.op},
         Operator::kEliminatable);
   }
 
   void StringViewIterRewind(FullDecoder* decoder, const Value& view,
                             const Value& codepoints, Value* result) {
     V<Tagged> string = NullCheck(view);
-    result->op = CallBuiltinFromRuntimeStub(
-        decoder, WasmCode::kWasmStringViewIterRewind, {string, codepoints.op},
+    result->op = CallBuiltinThroughJumptable(
+        decoder, Builtin::kWasmStringViewIterRewind, {string, codepoints.op},
         Operator::kEliminatable);
   }
 
   void StringViewIterSlice(FullDecoder* decoder, const Value& view,
                            const Value& codepoints, Value* result) {
     V<Tagged> string = NullCheck(view);
-    result->op = CallBuiltinFromRuntimeStub(
-        decoder, WasmCode::kWasmStringViewIterSlice, {string, codepoints.op},
+    result->op = CallBuiltinThroughJumptable(
+        decoder, Builtin::kWasmStringViewIterSlice, {string, codepoints.op},
         Operator::kEliminatable);
   }
 
@@ -2511,16 +2506,16 @@ class TurboshaftGraphBuildingInterface {
                      Value* result) {
     V<Tagged> lhs_val = NullCheck(lhs);
     V<Tagged> rhs_val = NullCheck(rhs);
-    result->op = __ UntagSmi(CallBuiltinFromRuntimeStub(
-        decoder, WasmCode::kStringCompare, {lhs_val, rhs_val},
+    result->op = __ UntagSmi(CallBuiltinThroughJumptable(
+        decoder, Builtin::kStringCompare, {lhs_val, rhs_val},
         Operator::kEliminatable));
   }
 
   void StringFromCodePoint(FullDecoder* decoder, const Value& code_point,
                            Value* result) {
     result->op =
-        CallBuiltinFromRuntimeStub(decoder, WasmCode::kWasmStringFromCodePoint,
-                                   {code_point.op}, Operator::kEliminatable);
+        CallBuiltinThroughJumptable(decoder, Builtin::kWasmStringFromCodePoint,
+                                    {code_point.op}, Operator::kEliminatable);
   }
 
   void StringHash(FullDecoder* decoder, const Value& string, Value* result) {
@@ -2547,8 +2542,8 @@ class TurboshaftGraphBuildingInterface {
 
     BIND(runtime_label);
     V<Word32> hash_runtime =
-        CallBuiltinFromRuntimeStub(decoder, WasmCode::kWasmStringHash,
-                                   {string_val}, Operator::kEliminatable);
+        CallBuiltinThroughJumptable(decoder, Builtin::kWasmStringHash,
+                                    {string_val}, Operator::kEliminatable);
     GOTO(end_label, hash_runtime);
 
     BIND(end_label, hash_val);
@@ -3966,8 +3961,8 @@ class TurboshaftGraphBuildingInterface {
 
     // TODO(14108): Cache descriptor.
     __ Bind(call_builtin);
-    V<WordPtr> builtin = __ RelocatableConstant(WasmCode::kWasmStackGuard,
-                                                RelocInfo::WASM_STUB_CALL);
+    V<WordPtr> builtin =
+        __ RelocatableWasmBuiltinCallTarget(Builtin::kWasmStackGuard);
     const CallDescriptor* call_descriptor =
         compiler::Linkage::GetStubCallDescriptor(
             __ graph_zone(),                      // zone
@@ -4260,14 +4255,12 @@ class TurboshaftGraphBuildingInterface {
     __ TailCall(callee, base::VectorOf(arg_indices), descriptor);
   }
 
-  OpIndex CallBuiltinFromRuntimeStub(
-      FullDecoder* decoder, WasmCode::RuntimeStubId stub_id,
-      base::Vector<const OpIndex> args,
+  OpIndex CallBuiltinThroughJumptable(
+      FullDecoder* decoder, Builtin builtin, base::Vector<const OpIndex> args,
       Operator::Properties properties = Operator::kNoProperties,
       CheckForException check_for_exception = CheckForException::kNo) {
-    Builtin builtin_name = RuntimeStubIdToBuiltinName(stub_id);
     CallInterfaceDescriptor interface_descriptor =
-        Builtins::CallInterfaceDescriptorFor(builtin_name);
+        Builtins::CallInterfaceDescriptorFor(builtin);
     // TODO(14108): We should set properties like `Operator::kEliminatable`
     // where applicable.
     const CallDescriptor* call_descriptor =
@@ -4278,8 +4271,7 @@ class TurboshaftGraphBuildingInterface {
             StubCallMode::kCallWasmRuntimeStub);
     const TSCallDescriptor* ts_call_descriptor = TSCallDescriptor::Create(
         call_descriptor, compiler::CanThrow::kYes, __ graph_zone());
-    V<WordPtr> call_target =
-        __ RelocatableConstant(stub_id, RelocInfo::WASM_STUB_CALL);
+    V<WordPtr> call_target = __ RelocatableWasmBuiltinCallTarget(builtin);
     return check_for_exception == CheckForException::kYes
                ? CallAndMaybeCatchException(decoder, call_target, args,
                                             ts_call_descriptor)
@@ -4287,13 +4279,13 @@ class TurboshaftGraphBuildingInterface {
                          ts_call_descriptor);
   }
 
-  OpIndex CallBuiltinFromRuntimeStub(
-      FullDecoder* decoder, WasmCode::RuntimeStubId stub_id,
+  OpIndex CallBuiltinThroughJumptable(
+      FullDecoder* decoder, Builtin builtin,
       std::initializer_list<OpIndex> args,
       Operator::Properties properties = Operator::kNoProperties,
       CheckForException check_for_exception = CheckForException::kNo) {
-    return CallBuiltinFromRuntimeStub(decoder, stub_id, base::VectorOf(args),
-                                      properties, check_for_exception);
+    return CallBuiltinThroughJumptable(decoder, builtin, base::VectorOf(args),
+                                       properties, check_for_exception);
   }
 
   OpIndex CallAndMaybeCatchException(FullDecoder* decoder, V<WordPtr> callee,
@@ -4526,8 +4518,8 @@ class TurboshaftGraphBuildingInterface {
 
   void UnpackWasmException(FullDecoder* decoder, V<Tagged> exception,
                            base::Vector<Value> values) {
-    V<FixedArray> exception_values_array = CallBuiltinFromRuntimeStub(
-        decoder, WasmCode::kWasmGetOwnProperty,
+    V<FixedArray> exception_values_array = CallBuiltinThroughJumptable(
+        decoder, Builtin::kWasmGetOwnProperty,
         {exception, LOAD_IMMUTABLE_ROOT(wasm_exception_values_symbol),
          LOAD_IMMUTABLE_INSTANCE_FIELD(NativeContext,
                                        MemoryRepresentation::TaggedPointer())});
@@ -4891,11 +4883,11 @@ class TurboshaftGraphBuildingInterface {
 
   TrapId GetTrapIdForTrap(wasm::TrapReason reason) {
     switch (reason) {
-#define TRAPREASON_TO_TRAPID(name)                                             \
-  case wasm::k##name:                                                          \
-    static_assert(                                                             \
-        static_cast<int>(TrapId::k##name) == wasm::WasmCode::kThrowWasm##name, \
-        "trap id mismatch");                                                   \
+#define TRAPREASON_TO_TRAPID(name)                                 \
+  case wasm::k##name:                                              \
+    static_assert(static_cast<int>(TrapId::k##name) ==             \
+                      static_cast<int>(Builtin::kThrowWasm##name), \
+                  "trap id mismatch");                             \
     return TrapId::k##name;
       FOREACH_WASM_TRAPREASON(TRAPREASON_TO_TRAPID)
 #undef TRAPREASON_TO_TRAPID
diff --git a/src/wasm/wasm-builtin-list.h b/src/wasm/wasm-builtin-list.h
new file mode 100644
index 00000000000..613b891e723
--- /dev/null
+++ b/src/wasm/wasm-builtin-list.h
@@ -0,0 +1,189 @@
+// Copyright 2023 the V8 project authors. All rights reserved.
+// Use of this source code is governed by a BSD-style license that can be
+// found in the LICENSE file.
+
+#ifndef V8_WASM_WASM_BUILTIN_LIST_H_
+#define V8_WASM_WASM_BUILTIN_LIST_H_
+
+#include "src/base/macros.h"
+#include "src/builtins/builtins.h"
+#include "src/common/globals.h"
+
+#if !V8_ENABLE_WEBASSEMBLY
+#error This header should only be included if WebAssembly is enabled.
+#endif  // !V8_ENABLE_WEBASSEMBLY
+
+namespace v8::internal::wasm {
+// Convenience macro listing all builtins called from wasm. Note that the first
+// few elements of the list coincide with {compiler::TrapId}, order matters.
+#define WASM_BUILTIN_LIST(V, VTRAP)      \
+  FOREACH_WASM_TRAPREASON(VTRAP)         \
+  V(WasmCompileLazy)                     \
+  V(WasmTriggerTierUp)                   \
+  V(WasmLiftoffFrameSetup)               \
+  V(WasmDebugBreak)                      \
+  V(WasmInt32ToHeapNumber)               \
+  V(WasmTaggedNonSmiToInt32)             \
+  V(WasmFloat32ToNumber)                 \
+  V(WasmFloat64ToNumber)                 \
+  V(WasmTaggedToFloat64)                 \
+  V(WasmAllocateJSArray)                 \
+  V(WasmAtomicNotify)                    \
+  V(WasmI32AtomicWait)                   \
+  V(WasmI64AtomicWait)                   \
+  V(WasmGetOwnProperty)                  \
+  V(WasmRefFunc)                         \
+  V(WasmInternalFunctionCreateExternal)  \
+  V(WasmMemoryGrow)                      \
+  V(WasmTableInit)                       \
+  V(WasmTableCopy)                       \
+  V(WasmTableFill)                       \
+  V(WasmTableGrow)                       \
+  V(WasmTableGet)                        \
+  V(WasmTableSet)                        \
+  V(WasmTableGetFuncRef)                 \
+  V(WasmTableSetFuncRef)                 \
+  V(WasmStackGuard)                      \
+  V(WasmStackOverflow)                   \
+  V(WasmAllocateFixedArray)              \
+  V(WasmThrow)                           \
+  V(WasmRethrow)                         \
+  V(WasmRethrowExplicitContext)          \
+  V(WasmTraceEnter)                      \
+  V(WasmTraceExit)                       \
+  V(WasmTraceMemory)                     \
+  V(BigIntToI32Pair)                     \
+  V(BigIntToI64)                         \
+  V(CallRefIC)                           \
+  V(DoubleToI)                           \
+  V(I32PairToBigInt)                     \
+  V(I64ToBigInt)                         \
+  V(RecordWriteSaveFP)                   \
+  V(RecordWriteIgnoreFP)                 \
+  V(ToNumber)                            \
+  IF_TSAN(V, TSANRelaxedStore8IgnoreFP)  \
+  IF_TSAN(V, TSANRelaxedStore8SaveFP)    \
+  IF_TSAN(V, TSANRelaxedStore16IgnoreFP) \
+  IF_TSAN(V, TSANRelaxedStore16SaveFP)   \
+  IF_TSAN(V, TSANRelaxedStore32IgnoreFP) \
+  IF_TSAN(V, TSANRelaxedStore32SaveFP)   \
+  IF_TSAN(V, TSANRelaxedStore64IgnoreFP) \
+  IF_TSAN(V, TSANRelaxedStore64SaveFP)   \
+  IF_TSAN(V, TSANSeqCstStore8IgnoreFP)   \
+  IF_TSAN(V, TSANSeqCstStore8SaveFP)     \
+  IF_TSAN(V, TSANSeqCstStore16IgnoreFP)  \
+  IF_TSAN(V, TSANSeqCstStore16SaveFP)    \
+  IF_TSAN(V, TSANSeqCstStore32IgnoreFP)  \
+  IF_TSAN(V, TSANSeqCstStore32SaveFP)    \
+  IF_TSAN(V, TSANSeqCstStore64IgnoreFP)  \
+  IF_TSAN(V, TSANSeqCstStore64SaveFP)    \
+  IF_TSAN(V, TSANRelaxedLoad32IgnoreFP)  \
+  IF_TSAN(V, TSANRelaxedLoad32SaveFP)    \
+  IF_TSAN(V, TSANRelaxedLoad64IgnoreFP)  \
+  IF_TSAN(V, TSANRelaxedLoad64SaveFP)    \
+  V(WasmAllocateArray_Uninitialized)     \
+  V(WasmArrayCopy)                       \
+  V(WasmArrayCopyWithChecks)             \
+  V(WasmArrayNewSegment)                 \
+  V(WasmArrayInitSegment)                \
+  V(WasmAllocateStructWithRtt)           \
+  V(WasmOnStackReplace)                  \
+  V(WasmSuspend)                         \
+  V(WasmStringNewWtf8)                   \
+  V(WasmStringNewWtf16)                  \
+  V(WasmStringConst)                     \
+  V(WasmStringMeasureUtf8)               \
+  V(WasmStringMeasureWtf8)               \
+  V(WasmStringEncodeWtf8)                \
+  V(WasmStringEncodeWtf16)               \
+  V(WasmStringConcat)                    \
+  V(WasmStringEqual)                     \
+  V(WasmStringIsUSVSequence)             \
+  V(WasmStringAsWtf16)                   \
+  V(WasmStringViewWtf16GetCodeUnit)      \
+  V(WasmStringCodePointAt)               \
+  V(WasmStringViewWtf16Encode)           \
+  V(WasmStringViewWtf16Slice)            \
+  V(WasmStringNewWtf8Array)              \
+  V(WasmStringNewWtf16Array)             \
+  V(WasmStringEncodeWtf8Array)           \
+  V(WasmStringEncodeWtf16Array)          \
+  V(WasmStringAsWtf8)                    \
+  V(WasmStringViewWtf8Advance)           \
+  V(WasmStringViewWtf8Encode)            \
+  V(WasmStringViewWtf8Slice)             \
+  V(WasmStringAsIter)                    \
+  V(WasmStringViewIterNext)              \
+  V(WasmStringViewIterAdvance)           \
+  V(WasmStringViewIterRewind)            \
+  V(WasmStringViewIterSlice)             \
+  V(StringCompare)                       \
+  V(WasmStringFromCodePoint)             \
+  V(WasmStringHash)                      \
+  V(WasmExternInternalize)               \
+  V(WasmStringFromDataSegment)           \
+  V(StringAdd_CheckNone)                 \
+  V(DebugPrintFloat64)                   \
+  V(DebugPrintWordPtr)
+
+namespace detail {
+constexpr std::array<uint8_t, static_cast<int>(Builtin::kFirstBytecodeHandler)>
+InitBuiltinToFarJumpTableIndex() {
+  std::array<uint8_t, static_cast<int>(Builtin::kFirstBytecodeHandler)>
+      result{};
+  uint8_t next_index = 0;
+#define DEF_INIT_LOOKUP(NAME) \
+  result[static_cast<int>(Builtin::k##NAME)] = next_index++;
+#define DEF_INIT_LOOKUP_TRAP(NAME) DEF_INIT_LOOKUP(ThrowWasm##NAME)
+  WASM_BUILTIN_LIST(DEF_INIT_LOOKUP, DEF_INIT_LOOKUP_TRAP)
+#undef DEF_INIT_LOOKUP_TRAP
+#undef DEF_INIT_LOOKUP
+  return result;
+}
+}  // namespace detail
+class BuiltinLookup {
+ public:
+  static constexpr int JumptableIndexForBuiltin(Builtin builtin) {
+    int result = kBuiltinToFarJumpTableIndex[static_cast<int>(builtin)];
+    DCHECK_EQ(builtin, kFarJumpTableIndexToBuiltin[result]);
+    return result;
+  }
+
+  static constexpr Builtin BuiltinForJumptableIndex(int index) {
+    Builtin result = kFarJumpTableIndexToBuiltin[index];
+    DCHECK_EQ(index, kBuiltinToFarJumpTableIndex[static_cast<int>(result)]);
+    return result;
+  }
+
+  static constexpr int BuiltinCount() { return kBuiltinCount; }
+
+ private:
+#define BUILTIN_COUNTER(NAME) +1
+  static constexpr int kBuiltinCount =
+      0 WASM_BUILTIN_LIST(BUILTIN_COUNTER, BUILTIN_COUNTER);
+#undef BUILTIN_COUNTER
+
+  static constexpr auto kFarJumpTableIndexToBuiltin =
+      base::make_array<static_cast<int>(kBuiltinCount)>([](size_t index) {
+        size_t next_index = 0;
+#define DEF_INIT_LOOKUP(NAME) \
+  if (index == next_index) {  \
+    return Builtin::k##NAME;  \
+  }                           \
+  ++next_index;
+#define DEF_INIT_LOOKUP_TRAP(NAME) DEF_INIT_LOOKUP(ThrowWasm##NAME)
+        WASM_BUILTIN_LIST(DEF_INIT_LOOKUP, DEF_INIT_LOOKUP_TRAP)
+#undef DEF_INIT_LOOKUP_TRAP
+#undef DEF_INIT_LOOKUP
+        return Builtin::kNoBuiltinId;
+      });
+
+  static constexpr auto kBuiltinToFarJumpTableIndex =
+      detail::InitBuiltinToFarJumpTableIndex();
+};
+
+}  // namespace v8::internal::wasm
+
+#undef WASM_BUILTIN_LIST
+
+#endif  // V8_WASM_WASM_BUILTIN_LIST_H_
diff --git a/src/wasm/wasm-code-manager.cc b/src/wasm/wasm-code-manager.cc
index 3fed39a53e9..a523ff85cd4 100644
--- a/src/wasm/wasm-code-manager.cc
+++ b/src/wasm/wasm-code-manager.cc
@@ -36,6 +36,7 @@
 #include "src/wasm/names-provider.h"
 #include "src/wasm/pgo.h"
 #include "src/wasm/std-object-sizes.h"
+#include "src/wasm/wasm-builtin-list.h"
 #include "src/wasm/wasm-debug.h"
 #include "src/wasm/wasm-engine.h"
 #include "src/wasm/wasm-import-wrapper-cache.h"
@@ -616,7 +617,7 @@ size_t OverheadPerCodeSpace(uint32_t num_declared_functions) {
   // Overhead for the far jump table.
   overhead +=
       RoundUp<kCodeAlignment>(JumpTableAssembler::SizeForNumberOfFarJumpSlots(
-          WasmCode::kRuntimeStubCount,
+          BuiltinLookup::BuiltinCount(),
           NumWasmFunctionsInFarJumpTable(num_declared_functions)));
 
   return overhead;
@@ -865,7 +866,7 @@ void NativeModule::ReserveCodeTableForTesting(uint32_t max_functions) {
       single_code_space_region.contains(main_jump_table_->instruction_start()));
   main_far_jump_table_ = CreateEmptyJumpTableInRegionLocked(
       JumpTableAssembler::SizeForNumberOfFarJumpSlots(
-          WasmCode::kRuntimeStubCount,
+          BuiltinLookup::BuiltinCount(),
           NumWasmFunctionsInFarJumpTable(max_functions)),
       single_code_space_region, JumpTableType::kFarJumpTable);
   CHECK(single_code_space_region.contains(
@@ -962,10 +963,10 @@ WasmCode* NativeModule::AddCodeForTesting(Handle<Code> code) {
       RelocInfo::Mode mode = it.rinfo()->rmode();
       if (RelocInfo::IsWasmStubCall(mode)) {
         uint32_t stub_call_tag = orig_it.rinfo()->wasm_call_tag();
-        DCHECK_LT(stub_call_tag, WasmCode::kRuntimeStubCount);
-        Address entry = GetNearRuntimeStubEntry(
-            static_cast<WasmCode::RuntimeStubId>(stub_call_tag),
-            jump_tables_ref);
+        DCHECK_LT(stub_call_tag,
+                  static_cast<uint32_t>(Builtin::kFirstBytecodeHandler));
+        Builtin builtin = static_cast<Builtin>(stub_call_tag);
+        Address entry = GetJumpTableEntryForBuiltin(builtin, jump_tables_ref);
         it.rinfo()->set_wasm_stub_call_address(entry, SKIP_ICACHE_FLUSH);
       } else {
         it.rinfo()->apply(delta);
@@ -1017,7 +1018,8 @@ void NativeModule::InitializeJumpTableForLazyCompilation(
 
   Address compile_lazy_address =
       code_space_data.far_jump_table->instruction_start() +
-      JumpTableAssembler::FarJumpSlotIndexToOffset(WasmCode::kWasmCompileLazy);
+      JumpTableAssembler::FarJumpSlotIndexToOffset(
+          BuiltinLookup::JumptableIndexForBuiltin(Builtin::kWasmCompileLazy));
 
   JumpTableAssembler::GenerateLazyCompileTable(
       lazy_compile_table_->instruction_start(), num_wasm_functions,
@@ -1123,9 +1125,10 @@ std::unique_ptr<WasmCode> NativeModule::AddCodeWithCodeSpace(
         it.rinfo()->set_wasm_call_address(target, SKIP_ICACHE_FLUSH);
       } else if (RelocInfo::IsWasmStubCall(mode)) {
         uint32_t stub_call_tag = it.rinfo()->wasm_call_tag();
-        DCHECK_LT(stub_call_tag, WasmCode::kRuntimeStubCount);
-        Address entry = GetNearRuntimeStubEntry(
-            static_cast<WasmCode::RuntimeStubId>(stub_call_tag), jump_tables);
+        DCHECK_LT(stub_call_tag,
+                  static_cast<uint32_t>(Builtin::kFirstBytecodeHandler));
+        Builtin builtin = static_cast<Builtin>(stub_call_tag);
+        Address entry = GetJumpTableEntryForBuiltin(builtin, jump_tables);
         it.rinfo()->set_wasm_stub_call_address(entry, SKIP_ICACHE_FLUSH);
       } else {
         it.rinfo()->apply(delta);
@@ -1490,7 +1493,7 @@ void NativeModule::PatchJumpTableLocked(const CodeSpaceData& code_space_data,
       code_space_data.jump_table->instruction_start() +
       JumpTableAssembler::JumpSlotIndexToOffset(slot_index);
   uint32_t far_jump_table_offset = JumpTableAssembler::FarJumpSlotIndexToOffset(
-      WasmCode::kRuntimeStubCount + slot_index);
+      BuiltinLookup::BuiltinCount() + slot_index);
   // Only pass the far jump table start if the far jump table actually has a
   // slot for this function index (i.e. does not only contain runtime stubs).
   bool has_far_jump_slot =
@@ -1560,30 +1563,24 @@ void NativeModule::AddCodeSpaceLocked(base::AddressRegion region) {
     int far_jump_table_size =
         is_first_code_space
             ? JumpTableAssembler::SizeForNumberOfFarJumpSlots(
-                  WasmCode::kRuntimeStubCount, num_function_slots)
+                  BuiltinLookup::BuiltinCount(), num_function_slots)
             : main_far_jump_table_->instructions_size_;
     far_jump_table = CreateEmptyJumpTableInRegionLocked(
         far_jump_table_size, region, JumpTableType::kFarJumpTable);
     CHECK(region.contains(far_jump_table->instruction_start()));
     EmbeddedData embedded_data = EmbeddedData::FromBlob();
-#define RUNTIME_STUB(Name) Builtin::k##Name,
-#define RUNTIME_STUB_TRAP(Name) RUNTIME_STUB(ThrowWasm##Name)
-    Builtin stub_names[WasmCode::kRuntimeStubCount] = {
-        WASM_RUNTIME_STUB_LIST(RUNTIME_STUB, RUNTIME_STUB_TRAP)};
-#undef RUNTIME_STUB
-#undef RUNTIME_STUB_TRAP
     static_assert(Builtins::kAllBuiltinsAreIsolateIndependent);
-    Address builtin_addresses[WasmCode::kRuntimeStubCount];
-    for (int i = 0; i < WasmCode::kRuntimeStubCount; ++i) {
-      Builtin builtin = stub_names[i];
-      builtin_addresses[i] = embedded_data.InstructionStartOf(builtin);
+    Address builtin_addresses[BuiltinLookup::BuiltinCount()];
+    for (int i = 0; i < BuiltinLookup::BuiltinCount(); ++i) {
+      builtin_addresses[i] = embedded_data.InstructionStartOf(
+          BuiltinLookup::BuiltinForJumptableIndex(i));
     }
     WritableJitAllocation jit_allocation = ThreadIsolation::LookupJitAllocation(
         far_jump_table->instruction_start(), far_jump_table->instructions_size_,
         ThreadIsolation::JitAllocationType::kWasmFarJumpTable);
     JumpTableAssembler::GenerateFarJumpTable(
         far_jump_table->instruction_start(), builtin_addresses,
-        WasmCode::kRuntimeStubCount, num_function_slots);
+        BuiltinLookup::BuiltinCount(), num_function_slots);
   }
 
   if (is_first_code_space) {
@@ -1780,9 +1777,11 @@ Address NativeModule::GetNearCallTargetForFunction(
   return jump_tables.jump_table_start + slot_offset;
 }
 
-Address NativeModule::GetNearRuntimeStubEntry(
-    WasmCode::RuntimeStubId index, const JumpTablesRef& jump_tables) const {
+Address NativeModule::GetJumpTableEntryForBuiltin(
+    Builtin builtin, const JumpTablesRef& jump_tables) const {
   DCHECK(jump_tables.is_valid());
+  int index = BuiltinLookup::JumptableIndexForBuiltin(builtin);
+
   auto offset = JumpTableAssembler::FarJumpSlotIndexToOffset(index);
   return jump_tables.far_jump_table_start + offset;
 }
@@ -1803,7 +1802,7 @@ uint32_t NativeModule::GetFunctionIndexFromJumpTableSlot(
   return module_->num_imported_functions + slot_idx;
 }
 
-WasmCode::RuntimeStubId NativeModule::GetRuntimeStubId(Address target) const {
+Builtin NativeModule::GetBuiltinInJumptableSlot(Address target) const {
   base::RecursiveMutexGuard guard(&allocation_mutex_);
 
   for (auto& code_space_data : code_space_data_) {
@@ -1812,16 +1811,16 @@ WasmCode::RuntimeStubId NativeModule::GetRuntimeStubId(Address target) const {
       uint32_t offset = static_cast<uint32_t>(
           target - code_space_data.far_jump_table->instruction_start());
       uint32_t index = JumpTableAssembler::FarJumpSlotOffsetToIndex(offset);
-      if (index >= WasmCode::kRuntimeStubCount) continue;
+      if (index >= BuiltinLookup::BuiltinCount()) continue;
       if (JumpTableAssembler::FarJumpSlotIndexToOffset(index) != offset) {
         continue;
       }
-      return static_cast<WasmCode::RuntimeStubId>(index);
+      return BuiltinLookup::BuiltinForJumptableIndex(index);
     }
   }
 
   // Invalid address.
-  return WasmCode::kRuntimeStubCount;
+  return Builtin::kNoBuiltinId;
 }
 
 NativeModule::~NativeModule() {
@@ -2109,7 +2108,7 @@ size_t WasmCodeManager::EstimateNativeModuleMetaDataSize(
       JumpTableAssembler::SizeForNumberOfSlots(num_wasm_functions));
   size_t far_jump_table_size =
       RoundUp<kCodeAlignment>(JumpTableAssembler::SizeForNumberOfFarJumpSlots(
-          WasmCode::kRuntimeStubCount,
+          BuiltinLookup::BuiltinCount(),
           NumWasmFunctionsInFarJumpTable(num_wasm_functions)));
 
   return wasm_module_estimate + native_module_estimate + jump_table_size +
@@ -2524,41 +2523,6 @@ void WasmCodeRefScope::AddRef(WasmCode* code) {
   current_scope->code_ptrs_.push_back(code);
   code->IncRef();
 }
-
-Builtin RuntimeStubIdToBuiltinName(WasmCode::RuntimeStubId stub_id) {
-#define RUNTIME_STUB_NAME(Name) Builtin::k##Name,
-#define RUNTIME_STUB_NAME_TRAP(Name) Builtin::kThrowWasm##Name,
-  constexpr Builtin builtin_names[] = {
-      WASM_RUNTIME_STUB_LIST(RUNTIME_STUB_NAME, RUNTIME_STUB_NAME_TRAP)};
-#undef RUNTIME_STUB_NAME
-#undef RUNTIME_STUB_NAME_TRAP
-  static_assert(arraysize(builtin_names) == WasmCode::kRuntimeStubCount);
-
-#define RUNTIME_STUB_NAME(Name) \
-  static_assert(Builtin::k##Name == builtin_names[wasm::WasmCode::k##Name]);
-#define RUNTIME_STUB_NAME_TRAP(Name) RUNTIME_STUB_NAME(ThrowWasm##Name)
-  WASM_RUNTIME_STUB_LIST(RUNTIME_STUB_NAME, RUNTIME_STUB_NAME_TRAP);
-#undef RUNTIME_STUB_NAME
-#undef RUNTIME_STUB_NAME_TRAP
-
-  DCHECK_GT(arraysize(builtin_names), stub_id);
-  return builtin_names[stub_id];
-}
-
-const char* GetRuntimeStubName(WasmCode::RuntimeStubId stub_id) {
-#define RUNTIME_STUB_NAME(Name) #Name,
-#define RUNTIME_STUB_NAME_TRAP(Name) "ThrowWasm" #Name,
-  constexpr const char* runtime_stub_names[] = {WASM_RUNTIME_STUB_LIST(
-      RUNTIME_STUB_NAME, RUNTIME_STUB_NAME_TRAP) "<unknown>"};
-#undef RUNTIME_STUB_NAME
-#undef RUNTIME_STUB_NAME_TRAP
-  static_assert(arraysize(runtime_stub_names) ==
-                WasmCode::kRuntimeStubCount + 1);
-
-  DCHECK_GT(arraysize(runtime_stub_names), stub_id);
-  return runtime_stub_names[stub_id];
-}
-
 }  // namespace wasm
 }  // namespace internal
 }  // namespace v8
diff --git a/src/wasm/wasm-code-manager.h b/src/wasm/wasm-code-manager.h
index 7835ed4a636..18071c5e730 100644
--- a/src/wasm/wasm-code-manager.h
+++ b/src/wasm/wasm-code-manager.h
@@ -50,118 +50,6 @@ class WasmImportWrapperCache;
 struct WasmModule;
 enum class WellKnownImport : uint8_t;
 
-// Convenience macro listing all wasm runtime stubs. Note that the first few
-// elements of the list coincide with {compiler::TrapId}, order matters.
-#define WASM_RUNTIME_STUB_LIST(V, VTRAP) \
-  FOREACH_WASM_TRAPREASON(VTRAP)         \
-  V(WasmCompileLazy)                     \
-  V(WasmTriggerTierUp)                   \
-  V(WasmLiftoffFrameSetup)               \
-  V(WasmDebugBreak)                      \
-  V(WasmInt32ToHeapNumber)               \
-  V(WasmTaggedNonSmiToInt32)             \
-  V(WasmFloat32ToNumber)                 \
-  V(WasmFloat64ToNumber)                 \
-  V(WasmTaggedToFloat64)                 \
-  V(WasmAllocateJSArray)                 \
-  V(WasmAtomicNotify)                    \
-  V(WasmI32AtomicWait)                   \
-  V(WasmI64AtomicWait)                   \
-  V(WasmGetOwnProperty)                  \
-  V(WasmRefFunc)                         \
-  V(WasmInternalFunctionCreateExternal)  \
-  V(WasmMemoryGrow)                      \
-  V(WasmTableInit)                       \
-  V(WasmTableCopy)                       \
-  V(WasmTableFill)                       \
-  V(WasmTableGrow)                       \
-  V(WasmTableGet)                        \
-  V(WasmTableSet)                        \
-  V(WasmTableGetFuncRef)                 \
-  V(WasmTableSetFuncRef)                 \
-  V(WasmStackGuard)                      \
-  V(WasmStackOverflow)                   \
-  V(WasmAllocateFixedArray)              \
-  V(WasmThrow)                           \
-  V(WasmRethrow)                         \
-  V(WasmRethrowExplicitContext)          \
-  V(WasmTraceEnter)                      \
-  V(WasmTraceExit)                       \
-  V(WasmTraceMemory)                     \
-  V(BigIntToI32Pair)                     \
-  V(BigIntToI64)                         \
-  V(CallRefIC)                           \
-  V(DoubleToI)                           \
-  V(I32PairToBigInt)                     \
-  V(I64ToBigInt)                         \
-  V(RecordWriteSaveFP)                   \
-  V(RecordWriteIgnoreFP)                 \
-  V(ToNumber)                            \
-  IF_TSAN(V, TSANRelaxedStore8IgnoreFP)  \
-  IF_TSAN(V, TSANRelaxedStore8SaveFP)    \
-  IF_TSAN(V, TSANRelaxedStore16IgnoreFP) \
-  IF_TSAN(V, TSANRelaxedStore16SaveFP)   \
-  IF_TSAN(V, TSANRelaxedStore32IgnoreFP) \
-  IF_TSAN(V, TSANRelaxedStore32SaveFP)   \
-  IF_TSAN(V, TSANRelaxedStore64IgnoreFP) \
-  IF_TSAN(V, TSANRelaxedStore64SaveFP)   \
-  IF_TSAN(V, TSANSeqCstStore8IgnoreFP)   \
-  IF_TSAN(V, TSANSeqCstStore8SaveFP)     \
-  IF_TSAN(V, TSANSeqCstStore16IgnoreFP)  \
-  IF_TSAN(V, TSANSeqCstStore16SaveFP)    \
-  IF_TSAN(V, TSANSeqCstStore32IgnoreFP)  \
-  IF_TSAN(V, TSANSeqCstStore32SaveFP)    \
-  IF_TSAN(V, TSANSeqCstStore64IgnoreFP)  \
-  IF_TSAN(V, TSANSeqCstStore64SaveFP)    \
-  IF_TSAN(V, TSANRelaxedLoad32IgnoreFP)  \
-  IF_TSAN(V, TSANRelaxedLoad32SaveFP)    \
-  IF_TSAN(V, TSANRelaxedLoad64IgnoreFP)  \
-  IF_TSAN(V, TSANRelaxedLoad64SaveFP)    \
-  V(WasmAllocateArray_Uninitialized)     \
-  V(WasmArrayCopy)                       \
-  V(WasmArrayCopyWithChecks)             \
-  V(WasmArrayNewSegment)                 \
-  V(WasmArrayInitSegment)                \
-  V(WasmAllocateStructWithRtt)           \
-  V(WasmOnStackReplace)                  \
-  V(WasmSuspend)                         \
-  V(WasmStringNewWtf8)                   \
-  V(WasmStringNewWtf16)                  \
-  V(WasmStringConst)                     \
-  V(WasmStringMeasureUtf8)               \
-  V(WasmStringMeasureWtf8)               \
-  V(WasmStringEncodeWtf8)                \
-  V(WasmStringEncodeWtf16)               \
-  V(WasmStringConcat)                    \
-  V(WasmStringEqual)                     \
-  V(WasmStringIsUSVSequence)             \
-  V(WasmStringAsWtf16)                   \
-  V(WasmStringViewWtf16GetCodeUnit)      \
-  V(WasmStringCodePointAt)               \
-  V(WasmStringViewWtf16Encode)           \
-  V(WasmStringViewWtf16Slice)            \
-  V(WasmStringNewWtf8Array)              \
-  V(WasmStringNewWtf16Array)             \
-  V(WasmStringEncodeWtf8Array)           \
-  V(WasmStringEncodeWtf16Array)          \
-  V(WasmStringAsWtf8)                    \
-  V(WasmStringViewWtf8Advance)           \
-  V(WasmStringViewWtf8Encode)            \
-  V(WasmStringViewWtf8Slice)             \
-  V(WasmStringAsIter)                    \
-  V(WasmStringViewIterNext)              \
-  V(WasmStringViewIterAdvance)           \
-  V(WasmStringViewIterRewind)            \
-  V(WasmStringViewIterSlice)             \
-  V(StringCompare)                       \
-  V(WasmStringFromCodePoint)             \
-  V(WasmStringHash)                      \
-  V(WasmExternInternalize)               \
-  V(WasmStringFromDataSegment)           \
-  V(StringAdd_CheckNone)                 \
-  V(DebugPrintFloat64)                   \
-  V(DebugPrintWordPtr)
-
 // Sorted, disjoint and non-overlapping memory regions. A region is of the
 // form [start, end). So there's no [start, end), [end, other_end),
 // because that should have been reduced to [start, other_end).
@@ -196,82 +84,70 @@ class V8_EXPORT_PRIVATE WasmCode final {
  public:
   enum Kind { kWasmFunction, kWasmToCapiWrapper, kWasmToJsWrapper, kJumpTable };
 
-  // Each runtime stub is identified by an id. This id is used to reference the
-  // stub via {RelocInfo::WASM_STUB_CALL} and gets resolved during relocation.
-  enum RuntimeStubId {
-#define DEF_ENUM(Name) k##Name,
-#define DEF_ENUM_TRAP(Name) kThrowWasm##Name,
-    WASM_RUNTIME_STUB_LIST(DEF_ENUM, DEF_ENUM_TRAP)
-#undef DEF_ENUM_TRAP
-#undef DEF_ENUM
-        kRuntimeStubCount
-  };
-
-  static constexpr RuntimeStubId GetRecordWriteStub(SaveFPRegsMode fp_mode) {
+  static constexpr Builtin GetRecordWriteBuiltin(SaveFPRegsMode fp_mode) {
     switch (fp_mode) {
       case SaveFPRegsMode::kIgnore:
-        return RuntimeStubId::kRecordWriteIgnoreFP;
+        return Builtin::kRecordWriteIgnoreFP;
       case SaveFPRegsMode::kSave:
-        return RuntimeStubId::kRecordWriteSaveFP;
+        return Builtin::kRecordWriteSaveFP;
     }
   }
 
 #ifdef V8_IS_TSAN
-  static RuntimeStubId GetTSANStoreStub(SaveFPRegsMode fp_mode, int size,
-                                        std::memory_order order) {
+  static Builtin GetTSANStoreBuiltin(SaveFPRegsMode fp_mode, int size,
+                                     std::memory_order order) {
     if (order == std::memory_order_relaxed) {
       if (size == kInt8Size) {
         return fp_mode == SaveFPRegsMode::kIgnore
-                   ? RuntimeStubId::kTSANRelaxedStore8IgnoreFP
-                   : RuntimeStubId::kTSANRelaxedStore8SaveFP;
+                   ? Builtin::kTSANRelaxedStore8IgnoreFP
+                   : Builtin::kTSANRelaxedStore8SaveFP;
       } else if (size == kInt16Size) {
         return fp_mode == SaveFPRegsMode::kIgnore
-                   ? RuntimeStubId::kTSANRelaxedStore16IgnoreFP
-                   : RuntimeStubId::kTSANRelaxedStore16SaveFP;
+                   ? Builtin::kTSANRelaxedStore16IgnoreFP
+                   : Builtin::kTSANRelaxedStore16SaveFP;
       } else if (size == kInt32Size) {
         return fp_mode == SaveFPRegsMode::kIgnore
-                   ? RuntimeStubId::kTSANRelaxedStore32IgnoreFP
-                   : RuntimeStubId::kTSANRelaxedStore32SaveFP;
+                   ? Builtin::kTSANRelaxedStore32IgnoreFP
+                   : Builtin::kTSANRelaxedStore32SaveFP;
       } else {
         CHECK_EQ(size, kInt64Size);
         return fp_mode == SaveFPRegsMode::kIgnore
-                   ? RuntimeStubId::kTSANRelaxedStore64IgnoreFP
-                   : RuntimeStubId::kTSANRelaxedStore64SaveFP;
+                   ? Builtin::kTSANRelaxedStore64IgnoreFP
+                   : Builtin::kTSANRelaxedStore64SaveFP;
       }
     } else {
       DCHECK_EQ(order, std::memory_order_seq_cst);
       if (size == kInt8Size) {
         return fp_mode == SaveFPRegsMode::kIgnore
-                   ? RuntimeStubId::kTSANSeqCstStore8IgnoreFP
-                   : RuntimeStubId::kTSANSeqCstStore8SaveFP;
+                   ? Builtin::kTSANSeqCstStore8IgnoreFP
+                   : Builtin::kTSANSeqCstStore8SaveFP;
       } else if (size == kInt16Size) {
         return fp_mode == SaveFPRegsMode::kIgnore
-                   ? RuntimeStubId::kTSANSeqCstStore16IgnoreFP
-                   : RuntimeStubId::kTSANSeqCstStore16SaveFP;
+                   ? Builtin::kTSANSeqCstStore16IgnoreFP
+                   : Builtin::kTSANSeqCstStore16SaveFP;
       } else if (size == kInt32Size) {
         return fp_mode == SaveFPRegsMode::kIgnore
-                   ? RuntimeStubId::kTSANSeqCstStore32IgnoreFP
-                   : RuntimeStubId::kTSANSeqCstStore32SaveFP;
+                   ? Builtin::kTSANSeqCstStore32IgnoreFP
+                   : Builtin::kTSANSeqCstStore32SaveFP;
       } else {
         CHECK_EQ(size, kInt64Size);
         return fp_mode == SaveFPRegsMode::kIgnore
-                   ? RuntimeStubId::kTSANSeqCstStore64IgnoreFP
-                   : RuntimeStubId::kTSANSeqCstStore64SaveFP;
+                   ? Builtin::kTSANSeqCstStore64IgnoreFP
+                   : Builtin::kTSANSeqCstStore64SaveFP;
       }
     }
   }
 
-  static RuntimeStubId GetTSANRelaxedLoadStub(SaveFPRegsMode fp_mode,
-                                              int size) {
+  static Builtin GetTSANRelaxedLoadBuiltin(SaveFPRegsMode fp_mode, int size) {
     if (size == kInt32Size) {
       return fp_mode == SaveFPRegsMode::kIgnore
-                 ? RuntimeStubId::kTSANRelaxedLoad32IgnoreFP
-                 : RuntimeStubId::kTSANRelaxedLoad32SaveFP;
+                 ? Builtin::kTSANRelaxedLoad32IgnoreFP
+                 : Builtin::kTSANRelaxedLoad32SaveFP;
     } else {
       CHECK_EQ(size, kInt64Size);
       return fp_mode == SaveFPRegsMode::kIgnore
-                 ? RuntimeStubId::kTSANRelaxedLoad64IgnoreFP
-                 : RuntimeStubId::kTSANRelaxedLoad64SaveFP;
+                 ? Builtin::kTSANRelaxedLoad64IgnoreFP
+                 : Builtin::kTSANRelaxedLoad64SaveFP;
     }
   }
 #endif  // V8_IS_TSAN
@@ -703,10 +579,9 @@ class V8_EXPORT_PRIVATE NativeModule final {
   Address GetNearCallTargetForFunction(uint32_t func_index,
                                        const JumpTablesRef&) const;
 
-  // Get a runtime stub entry (which is a far jump table slot) in the jump table
-  // previously looked up via {FindJumpTablesForRegionLocked}.
-  Address GetNearRuntimeStubEntry(WasmCode::RuntimeStubId index,
-                                  const JumpTablesRef&) const;
+  // Get the slot offset in the far jump table that jumps to the given builtin.
+  Address GetJumpTableEntryForBuiltin(Builtin builtin,
+                                      const JumpTablesRef&) const;
 
   // Reverse lookup from a given call target (which must be a jump table slot)
   // to a function index.
@@ -809,9 +684,9 @@ class V8_EXPORT_PRIVATE NativeModule final {
 
   WasmFeatures enabled_features() const { return enabled_features_; }
 
-  // Returns the runtime stub id that corresponds to the given address (which
-  // must be a far jump table slot). Returns {kRuntimeStubCount} on failure.
-  WasmCode::RuntimeStubId GetRuntimeStubId(Address runtime_stub_target) const;
+  // Returns the builtin that corresponds to the given address (which
+  // must be a far jump table slot). Returns {kNoBuiltinId} on failure.
+  Builtin GetBuiltinInJumptableSlot(Address target) const;
 
   // Sample the current code size of this modules to the given counters.
   void SampleCodeSize(Counters*) const;
@@ -1200,9 +1075,6 @@ class GlobalWasmCodeRef {
   const std::shared_ptr<NativeModule> native_module_;
 };
 
-Builtin RuntimeStubIdToBuiltinName(WasmCode::RuntimeStubId);
-const char* GetRuntimeStubName(WasmCode::RuntimeStubId);
-
 }  // namespace wasm
 }  // namespace internal
 }  // namespace v8
diff --git a/src/wasm/wasm-serialization.cc b/src/wasm/wasm-serialization.cc
index bf7635110bc..c8d46fbefb0 100644
--- a/src/wasm/wasm-serialization.cc
+++ b/src/wasm/wasm-serialization.cc
@@ -460,8 +460,8 @@ void NativeModuleSerializer::WriteCode(const WasmCode* code, Writer* writer) {
       } break;
       case RelocInfo::WASM_STUB_CALL: {
         Address target = orig_iter.rinfo()->wasm_stub_call_address();
-        uint32_t tag = native_module_->GetRuntimeStubId(target);
-        DCHECK_GT(WasmCode::kRuntimeStubCount, tag);
+        uint32_t tag = static_cast<uint32_t>(
+            native_module_->GetBuiltinInJumptableSlot(target));
         SetWasmCalleeTag(iter.rinfo(), tag);
       } break;
       case RelocInfo::EXTERNAL_REFERENCE: {
@@ -862,9 +862,8 @@ void NativeModuleDeserializer::CopyAndRelocate(
       }
       case RelocInfo::WASM_STUB_CALL: {
         uint32_t tag = GetWasmCalleeTag(iter.rinfo());
-        DCHECK_LT(tag, WasmCode::kRuntimeStubCount);
-        Address target = native_module_->GetNearRuntimeStubEntry(
-            static_cast<WasmCode::RuntimeStubId>(tag), unit.jump_tables);
+        Address target = native_module_->GetJumpTableEntryForBuiltin(
+            static_cast<Builtin>(tag), unit.jump_tables);
         iter.rinfo()->set_wasm_stub_call_address(target, SKIP_ICACHE_FLUSH);
         break;
       }
-- 
2.35.1

