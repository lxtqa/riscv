From a7f4ca5fd0f6d701ad44f55adae590e1b39999b3 Mon Sep 17 00:00:00 2001
From: Peter Kasting <pkasting@chromium.org>
Date: Thu, 5 May 2022 06:37:00 -0700
Subject: [PATCH] Place bit_cast<>() in the v8::base:: namespace.

This prevents ambiguity errors in C++20 due to ADL when casting types in
std::, which gains std::bit_cast<>().

Bug: chromium:1284275
Change-Id: I25046d1952a9304852e481ad8b84049c6769c289
Reviewed-on: https://chromium-review.googlesource.com/c/v8/v8/+/3625838
Auto-Submit: Peter Kasting <pkasting@chromium.org>
Reviewed-by: Adam Klein <adamk@chromium.org>
Reviewed-by: Michael Lippautz <mlippautz@chromium.org>
Commit-Queue: Adam Klein <adamk@chromium.org>
Cr-Commit-Position: refs/heads/main@{#80378}
---
 src/base/bits.cc                              |   8 +-
 src/base/bits.h                               |   8 +-
 src/base/functional.h                         |  38 +--
 src/base/ieee754.cc                           |  56 ++--
 src/base/macros.h                             |   2 +
 src/base/numbers/double.h                     |   8 +-
 src/base/utils/random-number-generator.cc     |   4 +-
 src/base/utils/random-number-generator.h      |   2 +-
 src/builtins/ia32/builtins-ia32.cc            |   2 +-
 src/codegen/arm64/assembler-arm64.cc          |   6 +-
 .../arm64/instructions-arm64-constants.cc     |  26 +-
 src/codegen/arm64/instructions-arm64.h        |   4 +-
 src/codegen/arm64/macro-assembler-arm64-inl.h |   4 +-
 src/codegen/arm64/macro-assembler-arm64.cc    |   2 +-
 src/codegen/arm64/utils-arm64.cc              |  16 +-
 src/codegen/arm64/utils-arm64.h               |  10 +-
 src/codegen/code-stub-assembler.cc            |   4 +-
 src/codegen/code-stub-assembler.h             |   2 +-
 src/codegen/ia32/assembler-ia32.h             |   2 +-
 src/codegen/ia32/macro-assembler-ia32.cc      |   8 +-
 src/codegen/ia32/macro-assembler-ia32.h       |   8 +-
 .../loong64/macro-assembler-loong64.cc        |   5 +-
 src/codegen/loong64/macro-assembler-loong64.h |   8 +-
 src/codegen/mips/macro-assembler-mips.cc      |  15 +-
 src/codegen/mips/macro-assembler-mips.h       |   8 +-
 src/codegen/mips64/macro-assembler-mips64.cc  |  15 +-
 src/codegen/mips64/macro-assembler-mips64.h   |   8 +-
 src/codegen/ppc/macro-assembler-ppc.cc        |   8 +-
 .../riscv64/macro-assembler-riscv64.cc        |  14 +-
 src/codegen/riscv64/macro-assembler-riscv64.h |   4 +-
 src/codegen/s390/macro-assembler-s390.cc      |   8 +-
 src/codegen/s390/macro-assembler-s390.h       |   4 +-
 src/codegen/x64/macro-assembler-x64.h         |   8 +-
 src/common/globals.h                          |  10 +-
 .../backend/arm/instruction-selector-arm.cc   |   2 +-
 .../backend/arm64/code-generator-arm64.cc     |   6 +-
 .../arm64/instruction-selector-arm64.cc       |   2 +-
 src/compiler/backend/code-generator-impl.h    |   4 +-
 src/compiler/backend/code-generator.h         |   6 +-
 .../backend/ia32/instruction-selector-ia32.cc |   4 +-
 .../backend/instruction-selector-impl.h       |   4 +-
 src/compiler/backend/instruction.cc           |   2 +-
 src/compiler/backend/instruction.h            |  19 +-
 .../backend/loong64/code-generator-loong64.cc |   4 +-
 .../loong64/instruction-selector-loong64.cc   |   2 +-
 .../backend/mips/code-generator-mips.cc       |   4 +-
 .../backend/mips/instruction-selector-mips.cc |   2 +-
 .../backend/mips64/code-generator-mips64.cc   |   4 +-
 .../mips64/instruction-selector-mips64.cc     |   2 +-
 .../backend/ppc/instruction-selector-ppc.cc   |   8 +-
 .../backend/riscv64/code-generator-riscv64.cc |   8 +-
 .../riscv64/instruction-selector-riscv64.cc   |   8 +-
 .../backend/s390/instruction-selector-s390.cc |   8 +-
 .../backend/x64/code-generator-x64.cc         |   4 +-
 .../backend/x64/instruction-selector-x64.cc   |   4 +-
 src/compiler/code-assembler.h                 |   9 +-
 src/compiler/common-node-cache.cc             |   4 +-
 src/compiler/common-node-cache.h              |   6 +-
 src/compiler/effect-control-linearizer.cc     |   6 +-
 src/compiler/js-graph.cc                      |   6 +-
 src/compiler/js-operator.h                    |   5 +-
 src/compiler/machine-graph.h                  |   6 +-
 src/compiler/machine-operator-reducer.cc      |  17 +-
 src/compiler/machine-operator-reducer.h       |   4 +-
 src/compiler/simplified-lowering.cc           |   2 +-
 src/compiler/simplified-operator-reducer.h    |   2 +-
 src/compiler/wasm-compiler.cc                 |   2 +-
 src/d8/d8-posix.cc                            |   2 +-
 src/deoptimizer/ppc/deoptimizer-ppc.cc        |   2 +-
 src/deoptimizer/translation-array.cc          |  16 +-
 src/diagnostics/disassembler.cc               |   2 +-
 src/diagnostics/objects-debug.cc              |   2 +-
 src/diagnostics/ppc/disasm-ppc.cc             |   8 +-
 src/execution/arm/simulator-arm.cc            |  39 +--
 src/execution/arm64/simulator-arm64.cc        |   6 +-
 src/execution/arm64/simulator-logic-arm64.cc  |  16 +-
 src/execution/frames.cc                       |   2 +-
 src/execution/loong64/simulator-loong64.cc    |   8 +-
 src/execution/mips/simulator-mips.cc          | 201 +++++------
 src/execution/mips64/simulator-mips64.cc      | 197 +++++------
 src/execution/ppc/simulator-ppc.cc            |  46 +--
 src/execution/ppc/simulator-ppc.h             |   8 +-
 src/execution/riscv64/simulator-riscv64.cc    |  12 +-
 src/execution/riscv64/simulator-riscv64.h     |   6 +-
 src/execution/s390/simulator-s390.cc          |  56 ++--
 src/execution/stack-guard.h                   |   4 +-
 src/handles/handles.h                         |   4 +-
 src/heap/factory.cc                           |   2 +-
 src/inspector/value-mirror.cc                 |   3 +-
 src/json/json-parser.cc                       |   2 +-
 src/numbers/conversions-inl.h                 |   2 +-
 src/numbers/conversions.cc                    |   2 +-
 src/numbers/conversions.h                     |   2 +-
 src/objects/bigint.cc                         |   6 +-
 src/objects/bigint.h                          |   2 +-
 src/objects/free-space-inl.h                  |   4 +-
 src/objects/js-objects-inl.h                  |   9 +-
 src/objects/lookup.cc                         |   7 +-
 src/objects/managed.h                         |   4 +-
 src/objects/object-macros.h                   |   2 +-
 src/runtime/runtime-atomics.cc                |  58 ++--
 src/snapshot/snapshot-compression.cc          |  18 +-
 src/torque/implementation-visitor.cc          |   2 +-
 src/utils/boxed-float.h                       |  16 +-
 .../baseline/ia32/liftoff-assembler-ia32.h    |   4 +-
 src/wasm/function-body-decoder-impl.h         |   9 +-
 src/wasm/wasm-external-refs.cc                |   2 +-
 src/wasm/wasm-js.cc                           |   8 +-
 src/wasm/wasm-module-builder.h                |   4 +-
 .../cctest/compiler/test-js-constant-cache.cc |  10 +-
 test/cctest/compiler/test-run-machops.cc      |  52 +--
 test/cctest/test-allocation.cc                |   3 +-
 test/cctest/test-assembler-arm.cc             | 162 +++++----
 test/cctest/test-assembler-arm64.cc           | 315 ++++++++++--------
 test/cctest/test-assembler-mips.cc            | 252 +++++++-------
 test/cctest/test-assembler-mips64.cc          | 259 +++++++-------
 test/cctest/test-assembler-riscv64.cc         |   8 +-
 test/cctest/test-field-type-tracking.cc       |   7 +-
 test/cctest/test-helper-riscv64.h             |  29 +-
 test/cctest/test-macro-assembler-loong64.cc   |  60 ++--
 test/cctest/test-macro-assembler-mips.cc      |  64 ++--
 test/cctest/test-macro-assembler-mips64.cc    |  60 ++--
 test/cctest/test-macro-assembler-riscv64.cc   |  63 ++--
 test/cctest/test-random-number-generator.cc   |   4 +-
 test/cctest/test-utils-arm64.cc               |  20 +-
 test/cctest/test-utils-arm64.h                |   4 +-
 test/cctest/wasm/test-run-wasm-64.cc          |   6 +-
 .../cctest/wasm/test-run-wasm-relaxed-simd.cc |   2 +-
 test/cctest/wasm/test-run-wasm-simd.cc        |   6 +-
 test/cctest/wasm/test-run-wasm.cc             |  13 +-
 test/cctest/wasm/wasm-run-utils.cc            |   9 +-
 test/cctest/wasm/wasm-run-utils.h             |   7 +-
 test/cctest/wasm/wasm-simd-utils.cc           |  22 +-
 test/common/wasm/wasm-macro-gen.h             |  42 ++-
 .../base/platform/platform-unittest.cc        |   2 +-
 .../instruction-selector-arm64-unittest.cc    |   4 +-
 .../compiler/common-operator-unittest.cc      |   6 +-
 test/unittests/compiler/graph-unittest.h      |   2 +-
 .../compiler/int64-lowering-unittest.cc       |   9 +-
 .../machine-operator-reducer-unittest.cc      |  35 +-
 .../instruction-selector-riscv64-unittest.cc  |   4 +-
 .../compiler/simplified-lowering-unittest.cc  |   2 +-
 .../simplified-operator-reducer-unittest.cc   |   4 +-
 test/unittests/wasm/decoder-unittest.cc       |   3 +-
 test/unittests/wasm/leb-helper-unittest.cc    |   8 +-
 145 files changed, 1560 insertions(+), 1314 deletions(-)

diff --git a/src/base/bits.cc b/src/base/bits.cc
index 7b6dd57d8f1..93754694bcb 100644
--- a/src/base/bits.cc
+++ b/src/base/bits.cc
@@ -48,13 +48,15 @@ uint64_t RoundUpToPowerOfTwo64(uint64_t value) {
 
 int32_t SignedMulHigh32(int32_t lhs, int32_t rhs) {
   int64_t const value = static_cast<int64_t>(lhs) * static_cast<int64_t>(rhs);
-  return bit_cast<int32_t, uint32_t>(bit_cast<uint64_t>(value) >> 32u);
+  return base::bit_cast<int32_t, uint32_t>(base::bit_cast<uint64_t>(value) >>
+                                           32u);
 }
 
 
 int32_t SignedMulHighAndAdd32(int32_t lhs, int32_t rhs, int32_t acc) {
-  return bit_cast<int32_t>(bit_cast<uint32_t>(acc) +
-                           bit_cast<uint32_t>(SignedMulHigh32(lhs, rhs)));
+  return base::bit_cast<int32_t>(
+      base::bit_cast<uint32_t>(acc) +
+      base::bit_cast<uint32_t>(SignedMulHigh32(lhs, rhs)));
 }
 
 
diff --git a/src/base/bits.h b/src/base/bits.h
index 9fe237fb305..2f919d3f85e 100644
--- a/src/base/bits.h
+++ b/src/base/bits.h
@@ -239,7 +239,7 @@ inline bool SignedAddOverflow32(int32_t lhs, int32_t rhs, int32_t* val) {
   return __builtin_sadd_overflow(lhs, rhs, val);
 #else
   uint32_t res = static_cast<uint32_t>(lhs) + static_cast<uint32_t>(rhs);
-  *val = bit_cast<int32_t>(res);
+  *val = base::bit_cast<int32_t>(res);
   return ((res ^ lhs) & (res ^ rhs) & (1U << 31)) != 0;
 #endif
 }
@@ -253,7 +253,7 @@ inline bool SignedSubOverflow32(int32_t lhs, int32_t rhs, int32_t* val) {
   return __builtin_ssub_overflow(lhs, rhs, val);
 #else
   uint32_t res = static_cast<uint32_t>(lhs) - static_cast<uint32_t>(rhs);
-  *val = bit_cast<int32_t>(res);
+  *val = base::bit_cast<int32_t>(res);
   return ((res ^ lhs) & (res ^ ~rhs) & (1U << 31)) != 0;
 #endif
 }
@@ -268,7 +268,7 @@ V8_BASE_EXPORT bool SignedMulOverflow32(int32_t lhs, int32_t rhs, int32_t* val);
 // returns true if the signed summation resulted in an overflow.
 inline bool SignedAddOverflow64(int64_t lhs, int64_t rhs, int64_t* val) {
   uint64_t res = static_cast<uint64_t>(lhs) + static_cast<uint64_t>(rhs);
-  *val = bit_cast<int64_t>(res);
+  *val = base::bit_cast<int64_t>(res);
   return ((res ^ lhs) & (res ^ rhs) & (1ULL << 63)) != 0;
 }
 
@@ -278,7 +278,7 @@ inline bool SignedAddOverflow64(int64_t lhs, int64_t rhs, int64_t* val) {
 // returns true if the signed subtraction resulted in an overflow.
 inline bool SignedSubOverflow64(int64_t lhs, int64_t rhs, int64_t* val) {
   uint64_t res = static_cast<uint64_t>(lhs) - static_cast<uint64_t>(rhs);
-  *val = bit_cast<int64_t>(res);
+  *val = base::bit_cast<int64_t>(res);
   return ((res ^ lhs) & (res ^ ~rhs) & (1ULL << 63)) != 0;
 }
 
diff --git a/src/base/functional.h b/src/base/functional.h
index 8820c1e1b7a..04d646ccbab 100644
--- a/src/base/functional.h
+++ b/src/base/functional.h
@@ -97,9 +97,9 @@ V8_BASE_EXPORT size_t hash_value(unsigned int);
 V8_BASE_EXPORT size_t hash_value(unsigned long);       // NOLINT(runtime/int)
 V8_BASE_EXPORT size_t hash_value(unsigned long long);  // NOLINT(runtime/int)
 
-#define V8_BASE_HASH_VALUE_SIGNED(type)            \
-  V8_INLINE size_t hash_value(signed type v) {     \
-    return hash_value(bit_cast<unsigned type>(v)); \
+#define V8_BASE_HASH_VALUE_SIGNED(type)                  \
+  V8_INLINE size_t hash_value(signed type v) {           \
+    return hash_value(base::bit_cast<unsigned type>(v)); \
   }
 V8_BASE_HASH_VALUE_SIGNED(char)
 V8_BASE_HASH_VALUE_SIGNED(short)      // NOLINT(runtime/int)
@@ -110,12 +110,12 @@ V8_BASE_HASH_VALUE_SIGNED(long long)  // NOLINT(runtime/int)
 
 V8_INLINE size_t hash_value(float v) {
   // 0 and -0 both hash to zero.
-  return v != 0.0f ? hash_value(bit_cast<uint32_t>(v)) : 0;
+  return v != 0.0f ? hash_value(base::bit_cast<uint32_t>(v)) : 0;
 }
 
 V8_INLINE size_t hash_value(double v) {
   // 0 and -0 both hash to zero.
-  return v != 0.0 ? hash_value(bit_cast<uint64_t>(v)) : 0;
+  return v != 0.0 ? hash_value(base::bit_cast<uint64_t>(v)) : 0;
 }
 
 template <typename T, size_t N>
@@ -130,7 +130,7 @@ V8_INLINE size_t hash_value(T (&v)[N]) {
 
 template <typename T>
 V8_INLINE size_t hash_value(T* const& v) {
-  return hash_value(bit_cast<uintptr_t>(v));
+  return hash_value(base::bit_cast<uintptr_t>(v));
 }
 
 template <typename T1, typename T2>
@@ -219,19 +219,19 @@ V8_BASE_BIT_SPECIALIZE_TRIVIAL(long long)           // NOLINT(runtime/int)
 V8_BASE_BIT_SPECIALIZE_TRIVIAL(unsigned long long)  // NOLINT(runtime/int)
 #undef V8_BASE_BIT_SPECIALIZE_TRIVIAL
 
-#define V8_BASE_BIT_SPECIALIZE_BIT_CAST(type, btype)       \
-  template <>                                              \
-  struct bit_equal_to<type> {                              \
-    V8_INLINE bool operator()(type lhs, type rhs) const {  \
-      return bit_cast<btype>(lhs) == bit_cast<btype>(rhs); \
-    }                                                      \
-  };                                                       \
-  template <>                                              \
-  struct bit_hash<type> {                                  \
-    V8_INLINE size_t operator()(type v) const {            \
-      hash<btype> h;                                       \
-      return h(bit_cast<btype>(v));                        \
-    }                                                      \
+#define V8_BASE_BIT_SPECIALIZE_BIT_CAST(type, btype)                   \
+  template <>                                                          \
+  struct bit_equal_to<type> {                                          \
+    V8_INLINE bool operator()(type lhs, type rhs) const {              \
+      return base::bit_cast<btype>(lhs) == base::bit_cast<btype>(rhs); \
+    }                                                                  \
+  };                                                                   \
+  template <>                                                          \
+  struct bit_hash<type> {                                              \
+    V8_INLINE size_t operator()(type v) const {                        \
+      hash<btype> h;                                                   \
+      return h(base::bit_cast<btype>(v));                              \
+    }                                                                  \
   };
 V8_BASE_BIT_SPECIALIZE_BIT_CAST(float, uint32_t)
 V8_BASE_BIT_SPECIALIZE_BIT_CAST(double, uint64_t)
diff --git a/src/base/ieee754.cc b/src/base/ieee754.cc
index 1706b56dfd9..73672001cf1 100644
--- a/src/base/ieee754.cc
+++ b/src/base/ieee754.cc
@@ -51,27 +51,27 @@ namespace {
 
 /* Get two 32 bit ints from a double.  */
 
-#define EXTRACT_WORDS(ix0, ix1, d)         \
-  do {                                     \
-    uint64_t bits = bit_cast<uint64_t>(d); \
-    (ix0) = bits >> 32;                    \
-    (ix1) = bits & 0xFFFFFFFFu;            \
+#define EXTRACT_WORDS(ix0, ix1, d)               \
+  do {                                           \
+    uint64_t bits = base::bit_cast<uint64_t>(d); \
+    (ix0) = bits >> 32;                          \
+    (ix1) = bits & 0xFFFFFFFFu;                  \
   } while (false)
 
 /* Get the more significant 32 bit int from a double.  */
 
-#define GET_HIGH_WORD(i, d)                \
-  do {                                     \
-    uint64_t bits = bit_cast<uint64_t>(d); \
-    (i) = bits >> 32;                      \
+#define GET_HIGH_WORD(i, d)                      \
+  do {                                           \
+    uint64_t bits = base::bit_cast<uint64_t>(d); \
+    (i) = bits >> 32;                            \
   } while (false)
 
 /* Get the less significant 32 bit int from a double.  */
 
-#define GET_LOW_WORD(i, d)                 \
-  do {                                     \
-    uint64_t bits = bit_cast<uint64_t>(d); \
-    (i) = bits & 0xFFFFFFFFu;              \
+#define GET_LOW_WORD(i, d)                       \
+  do {                                           \
+    uint64_t bits = base::bit_cast<uint64_t>(d); \
+    (i) = bits & 0xFFFFFFFFu;                    \
   } while (false)
 
 /* Set a double from two 32 bit ints.  */
@@ -81,27 +81,27 @@ namespace {
     uint64_t bits = 0;                        \
     bits |= static_cast<uint64_t>(ix0) << 32; \
     bits |= static_cast<uint32_t>(ix1);       \
-    (d) = bit_cast<double>(bits);             \
+    (d) = base::bit_cast<double>(bits);       \
   } while (false)
 
 /* Set the more significant 32 bits of a double from an int.  */
 
-#define SET_HIGH_WORD(d, v)                 \
-  do {                                      \
-    uint64_t bits = bit_cast<uint64_t>(d);  \
-    bits &= 0x0000'0000'FFFF'FFFF;          \
-    bits |= static_cast<uint64_t>(v) << 32; \
-    (d) = bit_cast<double>(bits);           \
+#define SET_HIGH_WORD(d, v)                      \
+  do {                                           \
+    uint64_t bits = base::bit_cast<uint64_t>(d); \
+    bits &= 0x0000'0000'FFFF'FFFF;               \
+    bits |= static_cast<uint64_t>(v) << 32;      \
+    (d) = base::bit_cast<double>(bits);          \
   } while (false)
 
 /* Set the less significant 32 bits of a double from an int.  */
 
-#define SET_LOW_WORD(d, v)                 \
-  do {                                     \
-    uint64_t bits = bit_cast<uint64_t>(d); \
-    bits &= 0xFFFF'FFFF'0000'0000;         \
-    bits |= static_cast<uint32_t>(v);      \
-    (d) = bit_cast<double>(bits);          \
+#define SET_LOW_WORD(d, v)                       \
+  do {                                           \
+    uint64_t bits = base::bit_cast<uint64_t>(d); \
+    bits &= 0xFFFF'FFFF'0000'0000;               \
+    bits |= static_cast<uint32_t>(v);            \
+    (d) = base::bit_cast<double>(bits);          \
   } while (false)
 
 int32_t __ieee754_rem_pio2(double x, double* y) V8_WARN_UNUSED_RESULT;
@@ -2396,9 +2396,9 @@ double cbrt(double x) {
    * 0.667; the error in the rounded t can be up to about 3 23-bit ulps
    * before the final error is larger than 0.667 ulps.
    */
-  uint64_t bits = bit_cast<uint64_t>(t);
+  uint64_t bits = base::bit_cast<uint64_t>(t);
   bits = (bits + 0x80000000) & 0xFFFFFFFFC0000000ULL;
-  t = bit_cast<double>(bits);
+  t = base::bit_cast<double>(bits);
 
   /* one step Newton iteration to 53 bits with error < 0.667 ulps */
   s = t * t;             /* t*t is exact */
diff --git a/src/base/macros.h b/src/base/macros.h
index 61644ffe058..76b1e9ebe23 100644
--- a/src/base/macros.h
+++ b/src/base/macros.h
@@ -105,6 +105,7 @@ char (&ArraySizeHelper(const T (&array)[N]))[N];
 //
 // WARNING: if Dest or Source is a non-POD type, the result of the memcpy
 // is likely to surprise you.
+namespace v8::base {
 template <class Dest, class Source>
 V8_INLINE Dest bit_cast(Source const& source) {
   static_assert(sizeof(Dest) == sizeof(Source),
@@ -113,6 +114,7 @@ V8_INLINE Dest bit_cast(Source const& source) {
   memcpy(&dest, &source, sizeof(dest));
   return dest;
 }
+}  // namespace v8::base
 
 // Explicitly declare the assignment operator as deleted.
 // Note: This macro is deprecated and will be removed soon. Please explicitly
diff --git a/src/base/numbers/double.h b/src/base/numbers/double.h
index 8cb9d2a6b8a..c56ab7b0d0a 100644
--- a/src/base/numbers/double.h
+++ b/src/base/numbers/double.h
@@ -12,8 +12,12 @@ namespace v8 {
 namespace base {
 
 // We assume that doubles and uint64_t have the same endianness.
-inline uint64_t double_to_uint64(double d) { return bit_cast<uint64_t>(d); }
-inline double uint64_to_double(uint64_t d64) { return bit_cast<double>(d64); }
+inline uint64_t double_to_uint64(double d) {
+  return base::bit_cast<uint64_t>(d);
+}
+inline double uint64_to_double(uint64_t d64) {
+  return base::bit_cast<double>(d64);
+}
 
 // Helper functions for doubles.
 class Double {
diff --git a/src/base/utils/random-number-generator.cc b/src/base/utils/random-number-generator.cc
index f6dc62893cf..91b7c6fc666 100644
--- a/src/base/utils/random-number-generator.cc
+++ b/src/base/utils/random-number-generator.cc
@@ -119,7 +119,7 @@ double RandomNumberGenerator::NextDouble() {
 
 int64_t RandomNumberGenerator::NextInt64() {
   XorShift128(&state0_, &state1_);
-  return bit_cast<int64_t>(state0_ + state1_);
+  return base::bit_cast<int64_t>(state0_ + state1_);
 }
 
 
@@ -219,7 +219,7 @@ int RandomNumberGenerator::Next(int bits) {
 
 void RandomNumberGenerator::SetSeed(int64_t seed) {
   initial_seed_ = seed;
-  state0_ = MurmurHash3(bit_cast<uint64_t>(seed));
+  state0_ = MurmurHash3(base::bit_cast<uint64_t>(seed));
   state1_ = MurmurHash3(~state0_);
   CHECK(state0_ != 0 || state1_ != 0);
 }
diff --git a/src/base/utils/random-number-generator.h b/src/base/utils/random-number-generator.h
index 55e20d544f1..9a488480058 100644
--- a/src/base/utils/random-number-generator.h
+++ b/src/base/utils/random-number-generator.h
@@ -112,7 +112,7 @@ class V8_BASE_EXPORT RandomNumberGenerator final {
     // Exponent for double values for [1.0 .. 2.0)
     static const uint64_t kExponentBits = uint64_t{0x3FF0000000000000};
     uint64_t random = (state0 >> 12) | kExponentBits;
-    return bit_cast<double>(random) - 1;
+    return base::bit_cast<double>(random) - 1;
   }
 
   // Static and exposed for external use.
diff --git a/src/builtins/ia32/builtins-ia32.cc b/src/builtins/ia32/builtins-ia32.cc
index eff42f84ad0..9214898f80e 100644
--- a/src/builtins/ia32/builtins-ia32.cc
+++ b/src/builtins/ia32/builtins-ia32.cc
@@ -3266,7 +3266,7 @@ void PrepareCallApiFunction(MacroAssembler* masm, int argc, Register scratch) {
   ASM_CODE_COMMENT(masm);
   __ EnterApiExitFrame(argc, scratch);
   if (FLAG_debug_code) {
-    __ mov(esi, Immediate(bit_cast<int32_t>(kZapValue)));
+    __ mov(esi, Immediate(base::bit_cast<int32_t>(kZapValue)));
   }
 }
 
diff --git a/src/codegen/arm64/assembler-arm64.cc b/src/codegen/arm64/assembler-arm64.cc
index 1edc2bd6cb0..2511a075203 100644
--- a/src/codegen/arm64/assembler-arm64.cc
+++ b/src/codegen/arm64/assembler-arm64.cc
@@ -3570,7 +3570,7 @@ uint32_t Assembler::FPToImm8(double imm) {
   DCHECK(IsImmFP64(imm));
   // bits: aBbb.bbbb.bbcd.efgh.0000.0000.0000.0000
   //       0000.0000.0000.0000.0000.0000.0000.0000
-  uint64_t bits = bit_cast<uint64_t>(imm);
+  uint64_t bits = base::bit_cast<uint64_t>(imm);
   // bit7: a000.0000
   uint64_t bit7 = ((bits >> 63) & 0x1) << 7;
   // bit6: 0b00.0000
@@ -4235,7 +4235,7 @@ bool Assembler::IsImmConditionalCompare(int64_t immediate) {
 bool Assembler::IsImmFP32(float imm) {
   // Valid values will have the form:
   // aBbb.bbbc.defg.h000.0000.0000.0000.0000
-  uint32_t bits = bit_cast<uint32_t>(imm);
+  uint32_t bits = base::bit_cast<uint32_t>(imm);
   // bits[19..0] are cleared.
   if ((bits & 0x7FFFF) != 0) {
     return false;
@@ -4259,7 +4259,7 @@ bool Assembler::IsImmFP64(double imm) {
   // Valid values will have the form:
   // aBbb.bbbb.bbcd.efgh.0000.0000.0000.0000
   // 0000.0000.0000.0000.0000.0000.0000.0000
-  uint64_t bits = bit_cast<uint64_t>(imm);
+  uint64_t bits = base::bit_cast<uint64_t>(imm);
   // bits[47..0] are cleared.
   if ((bits & 0xFFFFFFFFFFFFL) != 0) {
     return false;
diff --git a/src/codegen/arm64/instructions-arm64-constants.cc b/src/codegen/arm64/instructions-arm64-constants.cc
index 1a88cebe0fa..8f82609c0ee 100644
--- a/src/codegen/arm64/instructions-arm64-constants.cc
+++ b/src/codegen/arm64/instructions-arm64-constants.cc
@@ -48,34 +48,34 @@ extern "C" {
 #endif
 
 extern const float16 kFP16PositiveInfinity =
-    bit_cast<float16>(integer_constants::kFP16PositiveInfinity);
+    base::bit_cast<float16>(integer_constants::kFP16PositiveInfinity);
 extern const float16 kFP16NegativeInfinity =
-    bit_cast<float16>(integer_constants::kFP16NegativeInfinity);
+    base::bit_cast<float16>(integer_constants::kFP16NegativeInfinity);
 V8_EXPORT_PRIVATE extern const float kFP32PositiveInfinity =
-    bit_cast<float>(integer_constants::kFP32PositiveInfinity);
+    base::bit_cast<float>(integer_constants::kFP32PositiveInfinity);
 V8_EXPORT_PRIVATE extern const float kFP32NegativeInfinity =
-    bit_cast<float>(integer_constants::kFP32NegativeInfinity);
+    base::bit_cast<float>(integer_constants::kFP32NegativeInfinity);
 V8_EXPORT_PRIVATE extern const double kFP64PositiveInfinity =
-    bit_cast<double>(integer_constants::kFP64PositiveInfinity);
+    base::bit_cast<double>(integer_constants::kFP64PositiveInfinity);
 V8_EXPORT_PRIVATE extern const double kFP64NegativeInfinity =
-    bit_cast<double>(integer_constants::kFP64NegativeInfinity);
+    base::bit_cast<double>(integer_constants::kFP64NegativeInfinity);
 
 V8_EXPORT_PRIVATE extern const double kFP64SignallingNaN =
-    bit_cast<double>(integer_constants::kFP64SignallingNaN);
+    base::bit_cast<double>(integer_constants::kFP64SignallingNaN);
 V8_EXPORT_PRIVATE extern const float kFP32SignallingNaN =
-    bit_cast<float>(integer_constants::kFP32SignallingNaN);
+    base::bit_cast<float>(integer_constants::kFP32SignallingNaN);
 
 V8_EXPORT_PRIVATE extern const double kFP64QuietNaN =
-    bit_cast<double>(integer_constants::kFP64QuietNaN);
+    base::bit_cast<double>(integer_constants::kFP64QuietNaN);
 V8_EXPORT_PRIVATE extern const float kFP32QuietNaN =
-    bit_cast<float>(integer_constants::kFP32QuietNaN);
+    base::bit_cast<float>(integer_constants::kFP32QuietNaN);
 
 V8_EXPORT_PRIVATE extern const double kFP64DefaultNaN =
-    bit_cast<double>(integer_constants::kFP64DefaultNaN);
+    base::bit_cast<double>(integer_constants::kFP64DefaultNaN);
 V8_EXPORT_PRIVATE extern const float kFP32DefaultNaN =
-    bit_cast<float>(integer_constants::kFP32DefaultNaN);
+    base::bit_cast<float>(integer_constants::kFP32DefaultNaN);
 extern const float16 kFP16DefaultNaN =
-    bit_cast<float16>(integer_constants::kFP16DefaultNaN);
+    base::bit_cast<float16>(integer_constants::kFP16DefaultNaN);
 
 #if defined(V8_OS_WIN)
 }  // end of extern "C"
diff --git a/src/codegen/arm64/instructions-arm64.h b/src/codegen/arm64/instructions-arm64.h
index b8335e0741b..87a24558496 100644
--- a/src/codegen/arm64/instructions-arm64.h
+++ b/src/codegen/arm64/instructions-arm64.h
@@ -187,7 +187,7 @@ class Instruction {
     uint32_t bit5_to_0 = bits & 0x3f;
     uint32_t result = (bit7 << 31) | ((32 - bit6) << 25) | (bit5_to_0 << 19);
 
-    return bit_cast<float>(result);
+    return base::bit_cast<float>(result);
   }
 
   static double Imm8ToFP64(uint32_t imm8) {
@@ -201,7 +201,7 @@ class Instruction {
     uint64_t bit5_to_0 = bits & 0x3f;
     uint64_t result = (bit7 << 63) | ((256 - bit6) << 54) | (bit5_to_0 << 48);
 
-    return bit_cast<double>(result);
+    return base::bit_cast<double>(result);
   }
 
   bool IsLdrLiteral() const {
diff --git a/src/codegen/arm64/macro-assembler-arm64-inl.h b/src/codegen/arm64/macro-assembler-arm64-inl.h
index 803afc367d1..e92a65d3cee 100644
--- a/src/codegen/arm64/macro-assembler-arm64-inl.h
+++ b/src/codegen/arm64/macro-assembler-arm64-inl.h
@@ -671,7 +671,7 @@ void TurboAssembler::Fmov(VRegister vd, double imm) {
   if (IsImmFP64(imm)) {
     fmov(vd, imm);
   } else {
-    uint64_t bits = bit_cast<uint64_t>(imm);
+    uint64_t bits = base::bit_cast<uint64_t>(imm);
     if (vd.IsScalar()) {
       if (bits == 0) {
         fmov(vd, xzr);
@@ -698,7 +698,7 @@ void TurboAssembler::Fmov(VRegister vd, float imm) {
   if (IsImmFP32(imm)) {
     fmov(vd, imm);
   } else {
-    uint32_t bits = bit_cast<uint32_t>(imm);
+    uint32_t bits = base::bit_cast<uint32_t>(imm);
     if (vd.IsScalar()) {
       if (bits == 0) {
         fmov(vd, wzr);
diff --git a/src/codegen/arm64/macro-assembler-arm64.cc b/src/codegen/arm64/macro-assembler-arm64.cc
index 9e5b90e044d..31ebcad387f 100644
--- a/src/codegen/arm64/macro-assembler-arm64.cc
+++ b/src/codegen/arm64/macro-assembler-arm64.cc
@@ -353,7 +353,7 @@ void TurboAssembler::Mov(const Register& rd, const Operand& operand,
     if (root_array_available_ && options().isolate_independent_code) {
       if (operand.ImmediateRMode() == RelocInfo::EXTERNAL_REFERENCE) {
         Address addr = static_cast<Address>(operand.ImmediateValue());
-        ExternalReference reference = bit_cast<ExternalReference>(addr);
+        ExternalReference reference = base::bit_cast<ExternalReference>(addr);
         IndirectLoadExternalReference(rd, reference);
         return;
       } else if (RelocInfo::IsEmbeddedObjectMode(operand.ImmediateRMode())) {
diff --git a/src/codegen/arm64/utils-arm64.cc b/src/codegen/arm64/utils-arm64.cc
index dba2eeb7e10..618110ad570 100644
--- a/src/codegen/arm64/utils-arm64.cc
+++ b/src/codegen/arm64/utils-arm64.cc
@@ -12,43 +12,43 @@ namespace internal {
 #define __ assm->
 
 uint32_t float_sign(float val) {
-  uint32_t bits = bit_cast<uint32_t>(val);
+  uint32_t bits = base::bit_cast<uint32_t>(val);
   return unsigned_bitextract_32(31, 31, bits);
 }
 
 uint32_t float_exp(float val) {
-  uint32_t bits = bit_cast<uint32_t>(val);
+  uint32_t bits = base::bit_cast<uint32_t>(val);
   return unsigned_bitextract_32(30, 23, bits);
 }
 
 uint32_t float_mantissa(float val) {
-  uint32_t bits = bit_cast<uint32_t>(val);
+  uint32_t bits = base::bit_cast<uint32_t>(val);
   return unsigned_bitextract_32(22, 0, bits);
 }
 
 uint32_t double_sign(double val) {
-  uint64_t bits = bit_cast<uint64_t>(val);
+  uint64_t bits = base::bit_cast<uint64_t>(val);
   return static_cast<uint32_t>(unsigned_bitextract_64(63, 63, bits));
 }
 
 uint32_t double_exp(double val) {
-  uint64_t bits = bit_cast<uint64_t>(val);
+  uint64_t bits = base::bit_cast<uint64_t>(val);
   return static_cast<uint32_t>(unsigned_bitextract_64(62, 52, bits));
 }
 
 uint64_t double_mantissa(double val) {
-  uint64_t bits = bit_cast<uint64_t>(val);
+  uint64_t bits = base::bit_cast<uint64_t>(val);
   return unsigned_bitextract_64(51, 0, bits);
 }
 
 float float_pack(uint32_t sign, uint32_t exp, uint32_t mantissa) {
   uint32_t bits = sign << kFloatExponentBits | exp;
-  return bit_cast<float>((bits << kFloatMantissaBits) | mantissa);
+  return base::bit_cast<float>((bits << kFloatMantissaBits) | mantissa);
 }
 
 double double_pack(uint64_t sign, uint64_t exp, uint64_t mantissa) {
   uint64_t bits = sign << kDoubleExponentBits | exp;
-  return bit_cast<double>((bits << kDoubleMantissaBits) | mantissa);
+  return base::bit_cast<double>((bits << kDoubleMantissaBits) | mantissa);
 }
 
 int float16classify(float16 value) {
diff --git a/src/codegen/arm64/utils-arm64.h b/src/codegen/arm64/utils-arm64.h
index 182d781d55d..922298a7f66 100644
--- a/src/codegen/arm64/utils-arm64.h
+++ b/src/codegen/arm64/utils-arm64.h
@@ -70,7 +70,7 @@ T ReverseBytes(T value, int block_bytes_log2) {
 
 // NaN tests.
 inline bool IsSignallingNaN(double num) {
-  uint64_t raw = bit_cast<uint64_t>(num);
+  uint64_t raw = base::bit_cast<uint64_t>(num);
   if (std::isnan(num) && ((raw & kDQuietNanMask) == 0)) {
     return true;
   }
@@ -78,7 +78,7 @@ inline bool IsSignallingNaN(double num) {
 }
 
 inline bool IsSignallingNaN(float num) {
-  uint32_t raw = bit_cast<uint32_t>(num);
+  uint32_t raw = base::bit_cast<uint32_t>(num);
   if (std::isnan(num) && ((raw & kSQuietNanMask) == 0)) {
     return true;
   }
@@ -98,13 +98,13 @@ inline bool IsQuietNaN(T num) {
 // Convert the NaN in 'num' to a quiet NaN.
 inline double ToQuietNaN(double num) {
   DCHECK(std::isnan(num));
-  return bit_cast<double>(bit_cast<uint64_t>(num) | kDQuietNanMask);
+  return base::bit_cast<double>(base::bit_cast<uint64_t>(num) | kDQuietNanMask);
 }
 
 inline float ToQuietNaN(float num) {
   DCHECK(std::isnan(num));
-  return bit_cast<float>(bit_cast<uint32_t>(num) |
-                         static_cast<uint32_t>(kSQuietNanMask));
+  return base::bit_cast<float>(base::bit_cast<uint32_t>(num) |
+                               static_cast<uint32_t>(kSQuietNanMask));
 }
 
 // Fused multiply-add.
diff --git a/src/codegen/code-stub-assembler.cc b/src/codegen/code-stub-assembler.cc
index d1f275afcc7..5df58426926 100644
--- a/src/codegen/code-stub-assembler.cc
+++ b/src/codegen/code-stub-assembler.cc
@@ -5142,8 +5142,8 @@ void CodeStubAssembler::CopyFixedArrayElements(
     if (if_hole == &store_double_hole) {
       BIND(&store_double_hole);
       // Don't use doubles to store the hole double, since manipulating the
-      // signaling NaN used for the hole in C++, e.g. with bit_cast, will
-      // change its value on ia32 (the x87 stack is used to return values
+      // signaling NaN used for the hole in C++, e.g. with base::bit_cast,
+      // will change its value on ia32 (the x87 stack is used to return values
       // and stores to the stack silently clear the signalling bit).
       //
       // TODO(danno): When we have a Float32/Float64 wrapper class that
diff --git a/src/codegen/code-stub-assembler.h b/src/codegen/code-stub-assembler.h
index 123795af961..30bbd9c732a 100644
--- a/src/codegen/code-stub-assembler.h
+++ b/src/codegen/code-stub-assembler.h
@@ -2955,7 +2955,7 @@ class V8_EXPORT_PRIVATE CodeStubAssembler
   // Returns true if any of the mask's bit are set in the given Smi.
   // Smi-encoding of the mask is performed implicitly!
   TNode<BoolT> IsSetSmi(TNode<Smi> smi, int untagged_mask) {
-    intptr_t mask_word = bit_cast<intptr_t>(Smi::FromInt(untagged_mask));
+    intptr_t mask_word = base::bit_cast<intptr_t>(Smi::FromInt(untagged_mask));
     return WordNotEqual(WordAnd(BitcastTaggedToWordForTagAndSmiBits(smi),
                                 IntPtrConstant(mask_word)),
                         IntPtrConstant(0));
diff --git a/src/codegen/ia32/assembler-ia32.h b/src/codegen/ia32/assembler-ia32.h
index 8c5f20a112b..a3ed0b0f2b0 100644
--- a/src/codegen/ia32/assembler-ia32.h
+++ b/src/codegen/ia32/assembler-ia32.h
@@ -154,7 +154,7 @@ class Immediate {
 
   ExternalReference external_reference() const {
     DCHECK(is_external_reference());
-    return bit_cast<ExternalReference>(immediate());
+    return base::bit_cast<ExternalReference>(immediate());
   }
 
   bool is_zero() const {
diff --git a/src/codegen/ia32/macro-assembler-ia32.cc b/src/codegen/ia32/macro-assembler-ia32.cc
index 8e8bcf6304a..f6e092a5781 100644
--- a/src/codegen/ia32/macro-assembler-ia32.cc
+++ b/src/codegen/ia32/macro-assembler-ia32.cc
@@ -422,8 +422,8 @@ void MacroAssembler::RecordWriteField(Register object, int offset,
   // Clobber clobbered input registers when running with the debug-code flag
   // turned on to provoke errors.
   if (FLAG_debug_code) {
-    mov(value, Immediate(bit_cast<int32_t>(kZapValue)));
-    mov(slot_address, Immediate(bit_cast<int32_t>(kZapValue)));
+    mov(value, Immediate(base::bit_cast<int32_t>(kZapValue)));
+    mov(slot_address, Immediate(base::bit_cast<int32_t>(kZapValue)));
   }
 }
 
@@ -569,8 +569,8 @@ void MacroAssembler::RecordWrite(Register object, Register slot_address,
   // turned on to provoke errors.
   if (FLAG_debug_code) {
     ASM_CODE_COMMENT_STRING(this, "Clobber slot_address and value");
-    mov(slot_address, Immediate(bit_cast<int32_t>(kZapValue)));
-    mov(value, Immediate(bit_cast<int32_t>(kZapValue)));
+    mov(slot_address, Immediate(base::bit_cast<int32_t>(kZapValue)));
+    mov(value, Immediate(base::bit_cast<int32_t>(kZapValue)));
   }
 }
 
diff --git a/src/codegen/ia32/macro-assembler-ia32.h b/src/codegen/ia32/macro-assembler-ia32.h
index 442a82eb1e6..0e9e63133f1 100644
--- a/src/codegen/ia32/macro-assembler-ia32.h
+++ b/src/codegen/ia32/macro-assembler-ia32.h
@@ -137,8 +137,12 @@ class V8_EXPORT_PRIVATE TurboAssembler
   // Move an immediate into an XMM register.
   void Move(XMMRegister dst, uint32_t src);
   void Move(XMMRegister dst, uint64_t src);
-  void Move(XMMRegister dst, float src) { Move(dst, bit_cast<uint32_t>(src)); }
-  void Move(XMMRegister dst, double src) { Move(dst, bit_cast<uint64_t>(src)); }
+  void Move(XMMRegister dst, float src) {
+    Move(dst, base::bit_cast<uint32_t>(src));
+  }
+  void Move(XMMRegister dst, double src) {
+    Move(dst, base::bit_cast<uint64_t>(src));
+  }
 
   Operand EntryFromBuiltinAsOperand(Builtin builtin);
 
diff --git a/src/codegen/loong64/macro-assembler-loong64.cc b/src/codegen/loong64/macro-assembler-loong64.cc
index ba0ac0b0d87..80a2aad66e4 100644
--- a/src/codegen/loong64/macro-assembler-loong64.cc
+++ b/src/codegen/loong64/macro-assembler-loong64.cc
@@ -1888,9 +1888,10 @@ void TurboAssembler::Move(FPURegister dst, uint32_t src) {
 
 void TurboAssembler::Move(FPURegister dst, uint64_t src) {
   // Handle special values first.
-  if (src == bit_cast<uint64_t>(0.0) && has_double_zero_reg_set_) {
+  if (src == base::bit_cast<uint64_t>(0.0) && has_double_zero_reg_set_) {
     fmov_d(dst, kDoubleRegZero);
-  } else if (src == bit_cast<uint64_t>(-0.0) && has_double_zero_reg_set_) {
+  } else if (src == base::bit_cast<uint64_t>(-0.0) &&
+             has_double_zero_reg_set_) {
     Neg_d(dst, kDoubleRegZero);
   } else {
     UseScratchRegisterScope temps(this);
diff --git a/src/codegen/loong64/macro-assembler-loong64.h b/src/codegen/loong64/macro-assembler-loong64.h
index 7d1e58d4785..320871809bb 100644
--- a/src/codegen/loong64/macro-assembler-loong64.h
+++ b/src/codegen/loong64/macro-assembler-loong64.h
@@ -621,8 +621,12 @@ class V8_EXPORT_PRIVATE TurboAssembler : public TurboAssemblerBase {
     }
   }
 
-  void Move(FPURegister dst, float imm) { Move(dst, bit_cast<uint32_t>(imm)); }
-  void Move(FPURegister dst, double imm) { Move(dst, bit_cast<uint64_t>(imm)); }
+  void Move(FPURegister dst, float imm) {
+    Move(dst, base::bit_cast<uint32_t>(imm));
+  }
+  void Move(FPURegister dst, double imm) {
+    Move(dst, base::bit_cast<uint64_t>(imm));
+  }
   void Move(FPURegister dst, uint32_t src);
   void Move(FPURegister dst, uint64_t src);
 
diff --git a/src/codegen/mips/macro-assembler-mips.cc b/src/codegen/mips/macro-assembler-mips.cc
index 2c800df1021..e284dc4f505 100644
--- a/src/codegen/mips/macro-assembler-mips.cc
+++ b/src/codegen/mips/macro-assembler-mips.cc
@@ -175,8 +175,8 @@ void MacroAssembler::RecordWriteField(Register object, int offset,
   // Clobber clobbered input registers when running with the debug-code flag
   // turned on to provoke errors.
   if (FLAG_debug_code) {
-    li(value, Operand(bit_cast<int32_t>(kZapValue + 4)));
-    li(dst, Operand(bit_cast<int32_t>(kZapValue + 8)));
+    li(value, Operand(base::bit_cast<int32_t>(kZapValue + 4)));
+    li(dst, Operand(base::bit_cast<int32_t>(kZapValue + 8)));
   }
 }
 
@@ -331,9 +331,9 @@ void MacroAssembler::RecordWrite(Register object, Register address,
   // Clobber clobbered registers when running with the debug-code flag
   // turned on to provoke errors.
   if (FLAG_debug_code) {
-    li(address, Operand(bit_cast<int32_t>(kZapValue + 12)));
-    li(value, Operand(bit_cast<int32_t>(kZapValue + 16)));
-    li(slot_address, Operand(bit_cast<int32_t>(kZapValue + 20)));
+    li(address, Operand(base::bit_cast<int32_t>(kZapValue + 12)));
+    li(value, Operand(base::bit_cast<int32_t>(kZapValue + 16)));
+    li(slot_address, Operand(base::bit_cast<int32_t>(kZapValue + 20)));
   }
 }
 
@@ -2329,9 +2329,10 @@ void TurboAssembler::Move(FPURegister dst, uint32_t src) {
 
 void TurboAssembler::Move(FPURegister dst, uint64_t src) {
   // Handle special values first.
-  if (src == bit_cast<uint64_t>(0.0) && has_double_zero_reg_set_) {
+  if (src == base::bit_cast<uint64_t>(0.0) && has_double_zero_reg_set_) {
     mov_d(dst, kDoubleRegZero);
-  } else if (src == bit_cast<uint64_t>(-0.0) && has_double_zero_reg_set_) {
+  } else if (src == base::bit_cast<uint64_t>(-0.0) &&
+             has_double_zero_reg_set_) {
     Neg_d(dst, kDoubleRegZero);
   } else {
     uint32_t lo = src & 0xFFFFFFFF;
diff --git a/src/codegen/mips/macro-assembler-mips.h b/src/codegen/mips/macro-assembler-mips.h
index 4c292b2238b..024ab0ffddc 100644
--- a/src/codegen/mips/macro-assembler-mips.h
+++ b/src/codegen/mips/macro-assembler-mips.h
@@ -754,8 +754,12 @@ class V8_EXPORT_PRIVATE TurboAssembler : public TurboAssemblerBase {
     Mthc1(src_high, dst);
   }
 
-  void Move(FPURegister dst, float imm) { Move(dst, bit_cast<uint32_t>(imm)); }
-  void Move(FPURegister dst, double imm) { Move(dst, bit_cast<uint64_t>(imm)); }
+  void Move(FPURegister dst, float imm) {
+    Move(dst, base::bit_cast<uint32_t>(imm));
+  }
+  void Move(FPURegister dst, double imm) {
+    Move(dst, base::bit_cast<uint64_t>(imm));
+  }
   void Move(FPURegister dst, uint32_t src);
   void Move(FPURegister dst, uint64_t src);
 
diff --git a/src/codegen/mips64/macro-assembler-mips64.cc b/src/codegen/mips64/macro-assembler-mips64.cc
index 001a282965e..c6efc4fc2b8 100644
--- a/src/codegen/mips64/macro-assembler-mips64.cc
+++ b/src/codegen/mips64/macro-assembler-mips64.cc
@@ -171,8 +171,8 @@ void MacroAssembler::RecordWriteField(Register object, int offset,
   // Clobber clobbered input registers when running with the debug-code flag
   // turned on to provoke errors.
   if (FLAG_debug_code) {
-    li(value, Operand(bit_cast<int64_t>(kZapValue + 4)));
-    li(dst, Operand(bit_cast<int64_t>(kZapValue + 8)));
+    li(value, Operand(base::bit_cast<int64_t>(kZapValue + 4)));
+    li(dst, Operand(base::bit_cast<int64_t>(kZapValue + 8)));
   }
 }
 
@@ -326,9 +326,9 @@ void MacroAssembler::RecordWrite(Register object, Register address,
   // Clobber clobbered registers when running with the debug-code flag
   // turned on to provoke errors.
   if (FLAG_debug_code) {
-    li(address, Operand(bit_cast<int64_t>(kZapValue + 12)));
-    li(value, Operand(bit_cast<int64_t>(kZapValue + 16)));
-    li(slot_address, Operand(bit_cast<int64_t>(kZapValue + 20)));
+    li(address, Operand(base::bit_cast<int64_t>(kZapValue + 12)));
+    li(value, Operand(base::bit_cast<int64_t>(kZapValue + 16)));
+    li(slot_address, Operand(base::bit_cast<int64_t>(kZapValue + 20)));
   }
 }
 
@@ -2976,9 +2976,10 @@ void TurboAssembler::Move(FPURegister dst, uint32_t src) {
 
 void TurboAssembler::Move(FPURegister dst, uint64_t src) {
   // Handle special values first.
-  if (src == bit_cast<uint64_t>(0.0) && has_double_zero_reg_set_) {
+  if (src == base::bit_cast<uint64_t>(0.0) && has_double_zero_reg_set_) {
     mov_d(dst, kDoubleRegZero);
-  } else if (src == bit_cast<uint64_t>(-0.0) && has_double_zero_reg_set_) {
+  } else if (src == base::bit_cast<uint64_t>(-0.0) &&
+             has_double_zero_reg_set_) {
     Neg_d(dst, kDoubleRegZero);
   } else {
     uint32_t lo = src & 0xFFFFFFFF;
diff --git a/src/codegen/mips64/macro-assembler-mips64.h b/src/codegen/mips64/macro-assembler-mips64.h
index baa9e406101..e13fa7eac2b 100644
--- a/src/codegen/mips64/macro-assembler-mips64.h
+++ b/src/codegen/mips64/macro-assembler-mips64.h
@@ -752,8 +752,12 @@ class V8_EXPORT_PRIVATE TurboAssembler : public TurboAssemblerBase {
     }
   }
 
-  void Move(FPURegister dst, float imm) { Move(dst, bit_cast<uint32_t>(imm)); }
-  void Move(FPURegister dst, double imm) { Move(dst, bit_cast<uint64_t>(imm)); }
+  void Move(FPURegister dst, float imm) {
+    Move(dst, base::bit_cast<uint32_t>(imm));
+  }
+  void Move(FPURegister dst, double imm) {
+    Move(dst, base::bit_cast<uint64_t>(imm));
+  }
   void Move(FPURegister dst, uint32_t src);
   void Move(FPURegister dst, uint64_t src);
 
diff --git a/src/codegen/ppc/macro-assembler-ppc.cc b/src/codegen/ppc/macro-assembler-ppc.cc
index 53301de42b0..f0c33f518d2 100644
--- a/src/codegen/ppc/macro-assembler-ppc.cc
+++ b/src/codegen/ppc/macro-assembler-ppc.cc
@@ -691,8 +691,8 @@ void MacroAssembler::RecordWriteField(Register object, int offset,
   // Clobber clobbered input registers when running with the debug-code flag
   // turned on to provoke errors.
   if (FLAG_debug_code) {
-    mov(value, Operand(bit_cast<intptr_t>(kZapValue + 4)));
-    mov(slot_address, Operand(bit_cast<intptr_t>(kZapValue + 8)));
+    mov(value, Operand(base::bit_cast<intptr_t>(kZapValue + 4)));
+    mov(slot_address, Operand(base::bit_cast<intptr_t>(kZapValue + 8)));
   }
 }
 
@@ -842,8 +842,8 @@ void MacroAssembler::RecordWrite(Register object, Register slot_address,
   // Clobber clobbered registers when running with the debug-code flag
   // turned on to provoke errors.
   if (FLAG_debug_code) {
-    mov(slot_address, Operand(bit_cast<intptr_t>(kZapValue + 12)));
-    mov(value, Operand(bit_cast<intptr_t>(kZapValue + 16)));
+    mov(slot_address, Operand(base::bit_cast<intptr_t>(kZapValue + 12)));
+    mov(value, Operand(base::bit_cast<intptr_t>(kZapValue + 16)));
   }
 }
 
diff --git a/src/codegen/riscv64/macro-assembler-riscv64.cc b/src/codegen/riscv64/macro-assembler-riscv64.cc
index e0f5d32a343..8cf27979006 100644
--- a/src/codegen/riscv64/macro-assembler-riscv64.cc
+++ b/src/codegen/riscv64/macro-assembler-riscv64.cc
@@ -2415,13 +2415,14 @@ void TurboAssembler::InsertLowWordF64(FPURegister dst, Register src_low) {
 
 void TurboAssembler::LoadFPRImmediate(FPURegister dst, uint32_t src) {
   // Handle special values first.
-  if (src == bit_cast<uint32_t>(0.0f) && has_single_zero_reg_set_) {
+  if (src == base::bit_cast<uint32_t>(0.0f) && has_single_zero_reg_set_) {
     if (dst != kDoubleRegZero) fmv_s(dst, kDoubleRegZero);
-  } else if (src == bit_cast<uint32_t>(-0.0f) && has_single_zero_reg_set_) {
+  } else if (src == base::bit_cast<uint32_t>(-0.0f) &&
+             has_single_zero_reg_set_) {
     Neg_s(dst, kDoubleRegZero);
   } else {
     if (dst == kDoubleRegZero) {
-      DCHECK(src == bit_cast<uint32_t>(0.0f));
+      DCHECK(src == base::bit_cast<uint32_t>(0.0f));
       fmv_w_x(dst, zero_reg);
       has_single_zero_reg_set_ = true;
       has_double_zero_reg_set_ = false;
@@ -2436,13 +2437,14 @@ void TurboAssembler::LoadFPRImmediate(FPURegister dst, uint32_t src) {
 
 void TurboAssembler::LoadFPRImmediate(FPURegister dst, uint64_t src) {
   // Handle special values first.
-  if (src == bit_cast<uint64_t>(0.0) && has_double_zero_reg_set_) {
+  if (src == base::bit_cast<uint64_t>(0.0) && has_double_zero_reg_set_) {
     if (dst != kDoubleRegZero) fmv_d(dst, kDoubleRegZero);
-  } else if (src == bit_cast<uint64_t>(-0.0) && has_double_zero_reg_set_) {
+  } else if (src == base::bit_cast<uint64_t>(-0.0) &&
+             has_double_zero_reg_set_) {
     Neg_d(dst, kDoubleRegZero);
   } else {
     if (dst == kDoubleRegZero) {
-      DCHECK(src == bit_cast<uint64_t>(0.0));
+      DCHECK(src == base::bit_cast<uint64_t>(0.0));
       fmv_d_x(dst, zero_reg);
       has_double_zero_reg_set_ = true;
       has_single_zero_reg_set_ = false;
diff --git a/src/codegen/riscv64/macro-assembler-riscv64.h b/src/codegen/riscv64/macro-assembler-riscv64.h
index f91714ae315..3ee0b8c8356 100644
--- a/src/codegen/riscv64/macro-assembler-riscv64.h
+++ b/src/codegen/riscv64/macro-assembler-riscv64.h
@@ -729,10 +729,10 @@ class V8_EXPORT_PRIVATE TurboAssembler : public TurboAssemblerBase {
   void InsertLowWordF64(FPURegister dst, Register src_low);
 
   void LoadFPRImmediate(FPURegister dst, float imm) {
-    LoadFPRImmediate(dst, bit_cast<uint32_t>(imm));
+    LoadFPRImmediate(dst, base::bit_cast<uint32_t>(imm));
   }
   void LoadFPRImmediate(FPURegister dst, double imm) {
-    LoadFPRImmediate(dst, bit_cast<uint64_t>(imm));
+    LoadFPRImmediate(dst, base::bit_cast<uint64_t>(imm));
   }
   void LoadFPRImmediate(FPURegister dst, uint32_t src);
   void LoadFPRImmediate(FPURegister dst, uint64_t src);
diff --git a/src/codegen/s390/macro-assembler-s390.cc b/src/codegen/s390/macro-assembler-s390.cc
index 73e61ce0da2..3b07b994c3a 100644
--- a/src/codegen/s390/macro-assembler-s390.cc
+++ b/src/codegen/s390/macro-assembler-s390.cc
@@ -933,8 +933,8 @@ void MacroAssembler::RecordWriteField(Register object, int offset,
   // Clobber clobbered input registers when running with the debug-code flag
   // turned on to provoke errors.
   if (FLAG_debug_code) {
-    mov(value, Operand(bit_cast<intptr_t>(kZapValue + 4)));
-    mov(slot_address, Operand(bit_cast<intptr_t>(kZapValue + 8)));
+    mov(value, Operand(base::bit_cast<intptr_t>(kZapValue + 4)));
+    mov(slot_address, Operand(base::bit_cast<intptr_t>(kZapValue + 8)));
   }
 }
 
@@ -1078,8 +1078,8 @@ void MacroAssembler::RecordWrite(Register object, Register slot_address,
   // Clobber clobbered registers when running with the debug-code flag
   // turned on to provoke errors.
   if (FLAG_debug_code) {
-    mov(slot_address, Operand(bit_cast<intptr_t>(kZapValue + 12)));
-    mov(value, Operand(bit_cast<intptr_t>(kZapValue + 16)));
+    mov(slot_address, Operand(base::bit_cast<intptr_t>(kZapValue + 12)));
+    mov(value, Operand(base::bit_cast<intptr_t>(kZapValue + 16)));
   }
 }
 
diff --git a/src/codegen/s390/macro-assembler-s390.h b/src/codegen/s390/macro-assembler-s390.h
index 6dc568bb9ec..dd95c7a31d5 100644
--- a/src/codegen/s390/macro-assembler-s390.h
+++ b/src/codegen/s390/macro-assembler-s390.h
@@ -808,7 +808,7 @@ class V8_EXPORT_PRIVATE TurboAssembler : public TurboAssemblerBase {
   template <class T>
   void LoadF64(DoubleRegister result, T value, Register scratch) {
     static_assert(sizeof(T) == kDoubleSize, "Expect input size to be 8");
-    uint64_t int_val = bit_cast<uint64_t, T>(value);
+    uint64_t int_val = base::bit_cast<uint64_t, T>(value);
     // Load the 64-bit value into a GPR, then transfer it to FPR via LDGR
     uint32_t hi_32 = int_val >> 32;
     uint32_t lo_32 = static_cast<uint32_t>(int_val);
@@ -828,7 +828,7 @@ class V8_EXPORT_PRIVATE TurboAssembler : public TurboAssemblerBase {
   template <class T>
   void LoadF32(DoubleRegister result, T value, Register scratch) {
     static_assert(sizeof(T) == kFloatSize, "Expect input size to be 4");
-    uint32_t int_val = bit_cast<uint32_t, T>(value);
+    uint32_t int_val = base::bit_cast<uint32_t, T>(value);
     LoadF64(result, static_cast<uint64_t>(int_val) << 32, scratch);
   }
 
diff --git a/src/codegen/x64/macro-assembler-x64.h b/src/codegen/x64/macro-assembler-x64.h
index 296b79b0517..cc7e04acdbd 100644
--- a/src/codegen/x64/macro-assembler-x64.h
+++ b/src/codegen/x64/macro-assembler-x64.h
@@ -314,8 +314,12 @@ class V8_EXPORT_PRIVATE TurboAssembler
 
   void Move(XMMRegister dst, uint32_t src);
   void Move(XMMRegister dst, uint64_t src);
-  void Move(XMMRegister dst, float src) { Move(dst, bit_cast<uint32_t>(src)); }
-  void Move(XMMRegister dst, double src) { Move(dst, bit_cast<uint64_t>(src)); }
+  void Move(XMMRegister dst, float src) {
+    Move(dst, base::bit_cast<uint32_t>(src));
+  }
+  void Move(XMMRegister dst, double src) {
+    Move(dst, base::bit_cast<uint64_t>(src));
+  }
   void Move(XMMRegister dst, uint64_t high, uint64_t low);
 
   // Move if the registers are not identical.
diff --git a/src/common/globals.h b/src/common/globals.h
index 0f4c61e2fee..b456f2c3bb6 100644
--- a/src/common/globals.h
+++ b/src/common/globals.h
@@ -1033,7 +1033,9 @@ enum class InlineCacheState {
   GENERIC,
 };
 
-inline size_t hash_value(InlineCacheState mode) { return bit_cast<int>(mode); }
+inline size_t hash_value(InlineCacheState mode) {
+  return base::bit_cast<int>(mode);
+}
 
 // Printing support.
 inline const char* InlineCacheState2String(InlineCacheState state) {
@@ -1157,7 +1159,7 @@ enum class ConvertReceiverMode : unsigned {
 };
 
 inline size_t hash_value(ConvertReceiverMode mode) {
-  return bit_cast<unsigned>(mode);
+  return base::bit_cast<unsigned>(mode);
 }
 
 inline std::ostream& operator<<(std::ostream& os, ConvertReceiverMode mode) {
@@ -1188,7 +1190,7 @@ enum class CreateArgumentsType : uint8_t {
 };
 
 inline size_t hash_value(CreateArgumentsType type) {
-  return bit_cast<uint8_t>(type);
+  return base::bit_cast<uint8_t>(type);
 }
 
 inline std::ostream& operator<<(std::ostream& os, CreateArgumentsType type) {
@@ -1469,7 +1471,7 @@ enum class InterpreterPushArgsMode : unsigned {
 };
 
 inline size_t hash_value(InterpreterPushArgsMode mode) {
-  return bit_cast<unsigned>(mode);
+  return base::bit_cast<unsigned>(mode);
 }
 
 inline std::ostream& operator<<(std::ostream& os,
diff --git a/src/compiler/backend/arm/instruction-selector-arm.cc b/src/compiler/backend/arm/instruction-selector-arm.cc
index 10bb4af9954..536485f8d34 100644
--- a/src/compiler/backend/arm/instruction-selector-arm.cc
+++ b/src/compiler/backend/arm/instruction-selector-arm.cc
@@ -26,7 +26,7 @@ class ArmOperandGenerator : public OperandGenerator {
   }
 
   bool CanBeImmediate(uint32_t value) const {
-    return CanBeImmediate(bit_cast<int32_t>(value));
+    return CanBeImmediate(base::bit_cast<int32_t>(value));
   }
 
   bool CanBeImmediate(Node* node, InstructionCode opcode) {
diff --git a/src/compiler/backend/arm64/code-generator-arm64.cc b/src/compiler/backend/arm64/code-generator-arm64.cc
index 070edfaa4fe..612ac15eb48 100644
--- a/src/compiler/backend/arm64/code-generator-arm64.cc
+++ b/src/compiler/backend/arm64/code-generator-arm64.cc
@@ -44,7 +44,7 @@ class Arm64OperandConverter final : public InstructionOperandConverter {
 
   CPURegister InputFloat32OrZeroRegister(size_t index) {
     if (instr_->InputAt(index)->IsImmediate()) {
-      DCHECK_EQ(0, bit_cast<int32_t>(InputFloat32(index)));
+      DCHECK_EQ(0, base::bit_cast<int32_t>(InputFloat32(index)));
       return wzr;
     }
     DCHECK(instr_->InputAt(index)->IsFPRegister());
@@ -53,7 +53,7 @@ class Arm64OperandConverter final : public InstructionOperandConverter {
 
   CPURegister InputFloat64OrZeroRegister(size_t index) {
     if (instr_->InputAt(index)->IsImmediate()) {
-      DCHECK_EQ(0, bit_cast<int64_t>(InputDouble(index)));
+      DCHECK_EQ(0, base::bit_cast<int64_t>(InputDouble(index)));
       return xzr;
     }
     DCHECK(instr_->InputAt(index)->IsDoubleRegister());
@@ -3453,7 +3453,7 @@ void CodeGenerator::AssembleMove(InstructionOperand* source,
         MoveConstantToRegister(temp, src);
         __ Str(temp, dst);
       } else if (destination->IsFloatStackSlot()) {
-        if (bit_cast<int32_t>(src.ToFloat32()) == 0) {
+        if (base::bit_cast<int32_t>(src.ToFloat32()) == 0) {
           __ Str(wzr, dst);
         } else {
           UseScratchRegisterScope scope(tasm());
diff --git a/src/compiler/backend/arm64/instruction-selector-arm64.cc b/src/compiler/backend/arm64/instruction-selector-arm64.cc
index 4531acfb680..8f458174857 100644
--- a/src/compiler/backend/arm64/instruction-selector-arm64.cc
+++ b/src/compiler/backend/arm64/instruction-selector-arm64.cc
@@ -49,7 +49,7 @@ class Arm64OperandGenerator final : public OperandGenerator {
   InstructionOperand UseRegisterOrImmediateZero(Node* node) {
     if ((IsIntegerConstant(node) && (GetIntegerConstantValue(node) == 0)) ||
         (IsFloatConstant(node) &&
-         (bit_cast<int64_t>(GetFloatConstantValue(node)) == 0))) {
+         (base::bit_cast<int64_t>(GetFloatConstantValue(node)) == 0))) {
       return UseImmediate(node);
     }
     return UseRegister(node);
diff --git a/src/compiler/backend/code-generator-impl.h b/src/compiler/backend/code-generator-impl.h
index 56b62ec1868..87066c5bd36 100644
--- a/src/compiler/backend/code-generator-impl.h
+++ b/src/compiler/backend/code-generator-impl.h
@@ -51,7 +51,7 @@ class InstructionOperandConverter {
   }
 
   uint32_t InputUint32(size_t index) {
-    return bit_cast<uint32_t>(InputInt32(index));
+    return base::bit_cast<uint32_t>(InputInt32(index));
   }
 
   int64_t InputInt64(size_t index) {
@@ -63,7 +63,7 @@ class InstructionOperandConverter {
   }
 
   uint8_t InputUint8(size_t index) {
-    return bit_cast<uint8_t>(InputInt8(index));
+    return base::bit_cast<uint8_t>(InputInt8(index));
   }
 
   int16_t InputInt16(size_t index) {
diff --git a/src/compiler/backend/code-generator.h b/src/compiler/backend/code-generator.h
index c893066c114..48c95f15c09 100644
--- a/src/compiler/backend/code-generator.h
+++ b/src/compiler/backend/code-generator.h
@@ -79,8 +79,10 @@ class DeoptimizationLiteral {
 
   bool operator==(const DeoptimizationLiteral& other) const {
     return kind_ == other.kind_ && object_.equals(other.object_) &&
-           bit_cast<uint64_t>(number_) == bit_cast<uint64_t>(other.number_) &&
-           bit_cast<intptr_t>(string_) == bit_cast<intptr_t>(other.string_);
+           base::bit_cast<uint64_t>(number_) ==
+               base::bit_cast<uint64_t>(other.number_) &&
+           base::bit_cast<intptr_t>(string_) ==
+               base::bit_cast<intptr_t>(other.string_);
   }
 
   Handle<Object> Reify(Isolate* isolate) const;
diff --git a/src/compiler/backend/ia32/instruction-selector-ia32.cc b/src/compiler/backend/ia32/instruction-selector-ia32.cc
index bc87c3d5e5e..29f479e0f6f 100644
--- a/src/compiler/backend/ia32/instruction-selector-ia32.cc
+++ b/src/compiler/backend/ia32/instruction-selector-ia32.cc
@@ -106,7 +106,7 @@ class IA32OperandGenerator final : public OperandGenerator {
         return true;
       case IrOpcode::kNumberConstant: {
         const double value = OpParameter<double>(node->op());
-        return bit_cast<int64_t>(value) == 0;
+        return base::bit_cast<int64_t>(value) == 0;
       }
       case IrOpcode::kHeapConstant: {
 // TODO(bmeurer): We must not dereference handles concurrently. If we
@@ -1995,7 +1995,7 @@ void InstructionSelector::VisitFloat64InsertLowWord32(Node* node) {
   Node* right = node->InputAt(1);
   Float64Matcher mleft(left);
   if (mleft.HasResolvedValue() &&
-      (bit_cast<uint64_t>(mleft.ResolvedValue()) >> 32) == 0u) {
+      (base::bit_cast<uint64_t>(mleft.ResolvedValue()) >> 32) == 0u) {
     Emit(kIA32Float64LoadLowWord32, g.DefineAsRegister(node), g.Use(right));
     return;
   }
diff --git a/src/compiler/backend/instruction-selector-impl.h b/src/compiler/backend/instruction-selector-impl.h
index 386f690fed3..d8abfb21b2c 100644
--- a/src/compiler/backend/instruction-selector-impl.h
+++ b/src/compiler/backend/instruction-selector-impl.h
@@ -40,8 +40,8 @@ class SwitchInfo {
       DCHECK_LE(min_value, max_value);
       // Note that {value_range} can be 0 if {min_value} is -2^31 and
       // {max_value} is 2^31-1, so don't assume that it's non-zero below.
-      value_range_ =
-          1u + bit_cast<uint32_t>(max_value) - bit_cast<uint32_t>(min_value);
+      value_range_ = 1u + base::bit_cast<uint32_t>(max_value) -
+                     base::bit_cast<uint32_t>(min_value);
     } else {
       value_range_ = 0;
     }
diff --git a/src/compiler/backend/instruction.cc b/src/compiler/backend/instruction.cc
index 1748d6176cb..ba7173c9d7d 100644
--- a/src/compiler/backend/instruction.cc
+++ b/src/compiler/backend/instruction.cc
@@ -570,7 +570,7 @@ Handle<CodeT> Constant::ToCode() const {
 const StringConstantBase* Constant::ToDelayedStringConstant() const {
   DCHECK_EQ(kDelayedStringConstant, type());
   const StringConstantBase* value =
-      bit_cast<StringConstantBase*>(static_cast<intptr_t>(value_));
+      base::bit_cast<StringConstantBase*>(static_cast<intptr_t>(value_));
   return value;
 }
 
diff --git a/src/compiler/backend/instruction.h b/src/compiler/backend/instruction.h
index a29991d42d3..59ae6e3398b 100644
--- a/src/compiler/backend/instruction.h
+++ b/src/compiler/backend/instruction.h
@@ -1114,16 +1114,19 @@ class V8_EXPORT_PRIVATE Constant final {
 
   explicit Constant(int32_t v);
   explicit Constant(int64_t v) : type_(kInt64), value_(v) {}
-  explicit Constant(float v) : type_(kFloat32), value_(bit_cast<int32_t>(v)) {}
-  explicit Constant(double v) : type_(kFloat64), value_(bit_cast<int64_t>(v)) {}
+  explicit Constant(float v)
+      : type_(kFloat32), value_(base::bit_cast<int32_t>(v)) {}
+  explicit Constant(double v)
+      : type_(kFloat64), value_(base::bit_cast<int64_t>(v)) {}
   explicit Constant(ExternalReference ref)
-      : type_(kExternalReference), value_(bit_cast<intptr_t>(ref.address())) {}
+      : type_(kExternalReference),
+        value_(base::bit_cast<intptr_t>(ref.address())) {}
   explicit Constant(Handle<HeapObject> obj, bool is_compressed = false)
       : type_(is_compressed ? kCompressedHeapObject : kHeapObject),
-        value_(bit_cast<intptr_t>(obj)) {}
+        value_(base::bit_cast<intptr_t>(obj)) {}
   explicit Constant(RpoNumber rpo) : type_(kRpoNumber), value_(rpo.ToInt()) {}
   explicit Constant(const StringConstantBase* str)
-      : type_(kDelayedStringConstant), value_(bit_cast<intptr_t>(str)) {}
+      : type_(kDelayedStringConstant), value_(base::bit_cast<intptr_t>(str)) {}
   explicit Constant(RelocatablePtrConstantInfo info);
 
   Type type() const { return type_; }
@@ -1155,17 +1158,17 @@ class V8_EXPORT_PRIVATE Constant final {
     // representation of a signalling NaN, then returning it as float can cause
     // the signalling bit to flip, and value_ is returned as a quiet NaN.
     DCHECK_EQ(kFloat32, type());
-    return bit_cast<float>(static_cast<int32_t>(value_));
+    return base::bit_cast<float>(static_cast<int32_t>(value_));
   }
 
   uint32_t ToFloat32AsInt() const {
     DCHECK_EQ(kFloat32, type());
-    return bit_cast<uint32_t>(static_cast<int32_t>(value_));
+    return base::bit_cast<uint32_t>(static_cast<int32_t>(value_));
   }
 
   base::Double ToFloat64() const {
     DCHECK_EQ(kFloat64, type());
-    return base::Double(bit_cast<uint64_t>(value_));
+    return base::Double(base::bit_cast<uint64_t>(value_));
   }
 
   ExternalReference ToExternalReference() const {
diff --git a/src/compiler/backend/loong64/code-generator-loong64.cc b/src/compiler/backend/loong64/code-generator-loong64.cc
index eeb1c3b21a5..727117d70db 100644
--- a/src/compiler/backend/loong64/code-generator-loong64.cc
+++ b/src/compiler/backend/loong64/code-generator-loong64.cc
@@ -2483,12 +2483,12 @@ void CodeGenerator::AssembleMove(InstructionOperand* source,
     } else if (src.type() == Constant::kFloat32) {
       if (destination->IsFPStackSlot()) {
         MemOperand dst = g.ToMemOperand(destination);
-        if (bit_cast<int32_t>(src.ToFloat32()) == 0) {
+        if (base::bit_cast<int32_t>(src.ToFloat32()) == 0) {
           __ St_d(zero_reg, dst);
         } else {
           UseScratchRegisterScope temps(tasm());
           Register scratch = temps.Acquire();
-          __ li(scratch, Operand(bit_cast<int32_t>(src.ToFloat32())));
+          __ li(scratch, Operand(base::bit_cast<int32_t>(src.ToFloat32())));
           __ St_d(scratch, dst);
         }
       } else {
diff --git a/src/compiler/backend/loong64/instruction-selector-loong64.cc b/src/compiler/backend/loong64/instruction-selector-loong64.cc
index 3fd3c09a9fe..a81fdaf7595 100644
--- a/src/compiler/backend/loong64/instruction-selector-loong64.cc
+++ b/src/compiler/backend/loong64/instruction-selector-loong64.cc
@@ -36,7 +36,7 @@ class Loong64OperandGenerator final : public OperandGenerator {
   InstructionOperand UseRegisterOrImmediateZero(Node* node) {
     if ((IsIntegerConstant(node) && (GetIntegerConstantValue(node) == 0)) ||
         (IsFloatConstant(node) &&
-         (bit_cast<int64_t>(GetFloatConstantValue(node)) == 0))) {
+         (base::bit_cast<int64_t>(GetFloatConstantValue(node)) == 0))) {
       return UseImmediate(node);
     }
     return UseRegister(node);
diff --git a/src/compiler/backend/mips/code-generator-mips.cc b/src/compiler/backend/mips/code-generator-mips.cc
index 9ac309b00d2..7be64b70554 100644
--- a/src/compiler/backend/mips/code-generator-mips.cc
+++ b/src/compiler/backend/mips/code-generator-mips.cc
@@ -4219,10 +4219,10 @@ void CodeGenerator::AssembleMove(InstructionOperand* source,
     } else if (src.type() == Constant::kFloat32) {
       if (destination->IsFPStackSlot()) {
         MemOperand dst = g.ToMemOperand(destination);
-        if (bit_cast<int32_t>(src.ToFloat32()) == 0) {
+        if (base::bit_cast<int32_t>(src.ToFloat32()) == 0) {
           __ sw(zero_reg, dst);
         } else {
-          __ li(kScratchReg, Operand(bit_cast<int32_t>(src.ToFloat32())));
+          __ li(kScratchReg, Operand(base::bit_cast<int32_t>(src.ToFloat32())));
           __ sw(kScratchReg, dst);
         }
       } else {
diff --git a/src/compiler/backend/mips/instruction-selector-mips.cc b/src/compiler/backend/mips/instruction-selector-mips.cc
index b073c854e66..d9c3f9cae60 100644
--- a/src/compiler/backend/mips/instruction-selector-mips.cc
+++ b/src/compiler/backend/mips/instruction-selector-mips.cc
@@ -34,7 +34,7 @@ class MipsOperandGenerator final : public OperandGenerator {
   InstructionOperand UseRegisterOrImmediateZero(Node* node) {
     if ((IsIntegerConstant(node) && (GetIntegerConstantValue(node) == 0)) ||
         (IsFloatConstant(node) &&
-         (bit_cast<int64_t>(GetFloatConstantValue(node)) == 0))) {
+         (base::bit_cast<int64_t>(GetFloatConstantValue(node)) == 0))) {
       return UseImmediate(node);
     }
     return UseRegister(node);
diff --git a/src/compiler/backend/mips64/code-generator-mips64.cc b/src/compiler/backend/mips64/code-generator-mips64.cc
index da249e458d8..e6fbc50e719 100644
--- a/src/compiler/backend/mips64/code-generator-mips64.cc
+++ b/src/compiler/backend/mips64/code-generator-mips64.cc
@@ -4424,10 +4424,10 @@ void CodeGenerator::AssembleMove(InstructionOperand* source,
     } else if (src.type() == Constant::kFloat32) {
       if (destination->IsFPStackSlot()) {
         MemOperand dst = g.ToMemOperand(destination);
-        if (bit_cast<int32_t>(src.ToFloat32()) == 0) {
+        if (base::bit_cast<int32_t>(src.ToFloat32()) == 0) {
           __ Sd(zero_reg, dst);
         } else {
-          __ li(kScratchReg, Operand(bit_cast<int32_t>(src.ToFloat32())));
+          __ li(kScratchReg, Operand(base::bit_cast<int32_t>(src.ToFloat32())));
           __ Sd(kScratchReg, dst);
         }
       } else {
diff --git a/src/compiler/backend/mips64/instruction-selector-mips64.cc b/src/compiler/backend/mips64/instruction-selector-mips64.cc
index d8f023c4a26..83a87873e0f 100644
--- a/src/compiler/backend/mips64/instruction-selector-mips64.cc
+++ b/src/compiler/backend/mips64/instruction-selector-mips64.cc
@@ -36,7 +36,7 @@ class Mips64OperandGenerator final : public OperandGenerator {
   InstructionOperand UseRegisterOrImmediateZero(Node* node) {
     if ((IsIntegerConstant(node) && (GetIntegerConstantValue(node) == 0)) ||
         (IsFloatConstant(node) &&
-         (bit_cast<int64_t>(GetFloatConstantValue(node)) == 0))) {
+         (base::bit_cast<int64_t>(GetFloatConstantValue(node)) == 0))) {
       return UseImmediate(node);
     }
     return UseRegister(node);
diff --git a/src/compiler/backend/ppc/instruction-selector-ppc.cc b/src/compiler/backend/ppc/instruction-selector-ppc.cc
index 4881910cecd..a34c250a684 100644
--- a/src/compiler/backend/ppc/instruction-selector-ppc.cc
+++ b/src/compiler/backend/ppc/instruction-selector-ppc.cc
@@ -2578,10 +2578,10 @@ void InstructionSelector::VisitS128Const(Node* node) {
     // We have to use Pack4Lanes to reverse the bytes (lanes) on BE,
     // Which in this case is ineffective on LE.
     Emit(kPPC_S128Const, g.DefineAsRegister(node),
-         g.UseImmediate(Pack4Lanes(bit_cast<uint8_t*>(&val[0]))),
-         g.UseImmediate(Pack4Lanes(bit_cast<uint8_t*>(&val[0]) + 4)),
-         g.UseImmediate(Pack4Lanes(bit_cast<uint8_t*>(&val[0]) + 8)),
-         g.UseImmediate(Pack4Lanes(bit_cast<uint8_t*>(&val[0]) + 12)));
+         g.UseImmediate(Pack4Lanes(base::bit_cast<uint8_t*>(&val[0]))),
+         g.UseImmediate(Pack4Lanes(base::bit_cast<uint8_t*>(&val[0]) + 4)),
+         g.UseImmediate(Pack4Lanes(base::bit_cast<uint8_t*>(&val[0]) + 8)),
+         g.UseImmediate(Pack4Lanes(base::bit_cast<uint8_t*>(&val[0]) + 12)));
   }
 }
 
diff --git a/src/compiler/backend/riscv64/code-generator-riscv64.cc b/src/compiler/backend/riscv64/code-generator-riscv64.cc
index 18a7e32d2a4..a8c84774c35 100644
--- a/src/compiler/backend/riscv64/code-generator-riscv64.cc
+++ b/src/compiler/backend/riscv64/code-generator-riscv64.cc
@@ -59,10 +59,10 @@ class RiscvOperandConverter final : public InstructionOperandConverter {
           DCHECK_EQ(0, InputInt32(index));
           break;
         case Constant::kFloat32:
-          DCHECK_EQ(0, bit_cast<int32_t>(InputFloat32(index)));
+          DCHECK_EQ(0, base::bit_cast<int32_t>(InputFloat32(index)));
           break;
         case Constant::kFloat64:
-          DCHECK_EQ(0, bit_cast<int64_t>(InputDouble(index)));
+          DCHECK_EQ(0, base::bit_cast<int64_t>(InputDouble(index)));
           break;
         default:
           UNREACHABLE();
@@ -4157,10 +4157,10 @@ void CodeGenerator::AssembleMove(InstructionOperand* source,
     } else if (src.type() == Constant::kFloat32) {
       if (destination->IsFPStackSlot()) {
         MemOperand dst = g.ToMemOperand(destination);
-        if (bit_cast<int32_t>(src.ToFloat32()) == 0) {
+        if (base::bit_cast<int32_t>(src.ToFloat32()) == 0) {
           __ Sw(zero_reg, dst);
         } else {
-          __ li(kScratchReg, Operand(bit_cast<int32_t>(src.ToFloat32())));
+          __ li(kScratchReg, Operand(base::bit_cast<int32_t>(src.ToFloat32())));
           __ Sw(kScratchReg, dst);
         }
       } else {
diff --git a/src/compiler/backend/riscv64/instruction-selector-riscv64.cc b/src/compiler/backend/riscv64/instruction-selector-riscv64.cc
index f3584812f4f..8951199bd61 100644
--- a/src/compiler/backend/riscv64/instruction-selector-riscv64.cc
+++ b/src/compiler/backend/riscv64/instruction-selector-riscv64.cc
@@ -34,7 +34,7 @@ class RiscvOperandGenerator final : public OperandGenerator {
   InstructionOperand UseRegisterOrImmediateZero(Node* node) {
     if ((IsIntegerConstant(node) && (GetIntegerConstantValue(node) == 0)) ||
         (IsFloatConstant(node) &&
-         (bit_cast<int64_t>(GetFloatConstantValue(node)) == 0))) {
+         (base::bit_cast<int64_t>(GetFloatConstantValue(node)) == 0))) {
       return UseImmediate(node);
     }
     return UseRegister(node);
@@ -43,7 +43,7 @@ class RiscvOperandGenerator final : public OperandGenerator {
   bool IsIntegerConstant(Node* node) {
     if (node->opcode() == IrOpcode::kNumberConstant) {
       const double value = OpParameter<double>(node->op());
-      return bit_cast<int64_t>(value) == 0;
+      return base::bit_cast<int64_t>(value) == 0;
     }
     return (node->opcode() == IrOpcode::kInt32Constant) ||
            (node->opcode() == IrOpcode::kInt64Constant);
@@ -57,8 +57,8 @@ class RiscvOperandGenerator final : public OperandGenerator {
     }
     DCHECK_EQ(node->opcode(), IrOpcode::kNumberConstant);
     const double value = OpParameter<double>(node->op());
-    DCHECK_EQ(bit_cast<int64_t>(value), 0);
-    return bit_cast<int64_t>(value);
+    DCHECK_EQ(base::bit_cast<int64_t>(value), 0);
+    return base::bit_cast<int64_t>(value);
   }
 
   bool IsFloatConstant(Node* node) {
diff --git a/src/compiler/backend/s390/instruction-selector-s390.cc b/src/compiler/backend/s390/instruction-selector-s390.cc
index 11b93303c4a..2f12b76d3e1 100644
--- a/src/compiler/backend/s390/instruction-selector-s390.cc
+++ b/src/compiler/backend/s390/instruction-selector-s390.cc
@@ -2749,10 +2749,10 @@ void InstructionSelector::VisitS128Const(Node* node) {
     // We have to use Pack4Lanes to reverse the bytes (lanes) on BE,
     // Which in this case is ineffective on LE.
     Emit(kS390_S128Const, dst,
-         g.UseImmediate(Pack4Lanes(bit_cast<uint8_t*>(&val[0]))),
-         g.UseImmediate(Pack4Lanes(bit_cast<uint8_t*>(&val[0]) + 4)),
-         g.UseImmediate(Pack4Lanes(bit_cast<uint8_t*>(&val[0]) + 8)),
-         g.UseImmediate(Pack4Lanes(bit_cast<uint8_t*>(&val[0]) + 12)));
+         g.UseImmediate(Pack4Lanes(base::bit_cast<uint8_t*>(&val[0]))),
+         g.UseImmediate(Pack4Lanes(base::bit_cast<uint8_t*>(&val[0]) + 4)),
+         g.UseImmediate(Pack4Lanes(base::bit_cast<uint8_t*>(&val[0]) + 8)),
+         g.UseImmediate(Pack4Lanes(base::bit_cast<uint8_t*>(&val[0]) + 12)));
   }
 }
 
diff --git a/src/compiler/backend/x64/code-generator-x64.cc b/src/compiler/backend/x64/code-generator-x64.cc
index 327424bacbb..966df3edd89 100644
--- a/src/compiler/backend/x64/code-generator-x64.cc
+++ b/src/compiler/backend/x64/code-generator-x64.cc
@@ -5069,7 +5069,7 @@ void CodeGenerator::AssembleMove(InstructionOperand* source,
         XMMRegister dst = g.ToDoubleRegister(destination);
         if (src.type() == Constant::kFloat32) {
           // TODO(turbofan): Can we do better here?
-          __ Move(dst, bit_cast<uint32_t>(src.ToFloat32()));
+          __ Move(dst, base::bit_cast<uint32_t>(src.ToFloat32()));
         } else {
           DCHECK_EQ(src.type(), Constant::kFloat64);
           __ Move(dst, src.ToFloat64().AsUint64());
@@ -5085,7 +5085,7 @@ void CodeGenerator::AssembleMove(InstructionOperand* source,
       } else {
         DCHECK(destination->IsFPStackSlot());
         if (src.type() == Constant::kFloat32) {
-          __ movl(dst, Immediate(bit_cast<uint32_t>(src.ToFloat32())));
+          __ movl(dst, Immediate(base::bit_cast<uint32_t>(src.ToFloat32())));
         } else {
           DCHECK_EQ(src.type(), Constant::kFloat64);
           __ Move(dst, src.ToFloat64().AsUint64());
diff --git a/src/compiler/backend/x64/instruction-selector-x64.cc b/src/compiler/backend/x64/instruction-selector-x64.cc
index a32dd2b01db..f18d317a28a 100644
--- a/src/compiler/backend/x64/instruction-selector-x64.cc
+++ b/src/compiler/backend/x64/instruction-selector-x64.cc
@@ -49,7 +49,7 @@ class X64OperandGenerator final : public OperandGenerator {
       }
       case IrOpcode::kNumberConstant: {
         const double value = OpParameter<double>(node->op());
-        return bit_cast<int64_t>(value) == 0;
+        return base::bit_cast<int64_t>(value) == 0;
       }
       default:
         return false;
@@ -2845,7 +2845,7 @@ void InstructionSelector::VisitFloat64InsertLowWord32(Node* node) {
   Node* right = node->InputAt(1);
   Float64Matcher mleft(left);
   if (mleft.HasResolvedValue() &&
-      (bit_cast<uint64_t>(mleft.ResolvedValue()) >> 32) == 0u) {
+      (base::bit_cast<uint64_t>(mleft.ResolvedValue()) >> 32) == 0u) {
     Emit(kSSEFloat64LoadLowWord32, g.DefineAsRegister(node), g.Use(right));
     return;
   }
diff --git a/src/compiler/code-assembler.h b/src/compiler/code-assembler.h
index 26d0cb09943..768f9e3295c 100644
--- a/src/compiler/code-assembler.h
+++ b/src/compiler/code-assembler.h
@@ -523,18 +523,19 @@ class V8_EXPORT_PRIVATE CodeAssembler {
   TNode<Int32T> Int32Constant(int32_t value);
   TNode<Int64T> Int64Constant(int64_t value);
   TNode<Uint64T> Uint64Constant(uint64_t value) {
-    return Unsigned(Int64Constant(bit_cast<int64_t>(value)));
+    return Unsigned(Int64Constant(base::bit_cast<int64_t>(value)));
   }
   TNode<IntPtrT> IntPtrConstant(intptr_t value);
   TNode<Uint32T> Uint32Constant(uint32_t value) {
-    return Unsigned(Int32Constant(bit_cast<int32_t>(value)));
+    return Unsigned(Int32Constant(base::bit_cast<int32_t>(value)));
   }
   TNode<UintPtrT> UintPtrConstant(uintptr_t value) {
-    return Unsigned(IntPtrConstant(bit_cast<intptr_t>(value)));
+    return Unsigned(IntPtrConstant(base::bit_cast<intptr_t>(value)));
   }
   TNode<TaggedIndex> TaggedIndexConstant(intptr_t value);
   TNode<RawPtrT> PointerConstant(void* value) {
-    return ReinterpretCast<RawPtrT>(IntPtrConstant(bit_cast<intptr_t>(value)));
+    return ReinterpretCast<RawPtrT>(
+        IntPtrConstant(base::bit_cast<intptr_t>(value)));
   }
   TNode<Number> NumberConstant(double value);
   TNode<Smi> SmiConstant(Smi value);
diff --git a/src/compiler/common-node-cache.cc b/src/compiler/common-node-cache.cc
index 97d2774016d..f66fe51f67a 100644
--- a/src/compiler/common-node-cache.cc
+++ b/src/compiler/common-node-cache.cc
@@ -12,12 +12,12 @@ namespace internal {
 namespace compiler {
 
 Node** CommonNodeCache::FindExternalConstant(ExternalReference value) {
-  return external_constants_.Find(bit_cast<intptr_t>(value.address()));
+  return external_constants_.Find(base::bit_cast<intptr_t>(value.address()));
 }
 
 
 Node** CommonNodeCache::FindHeapConstant(Handle<HeapObject> value) {
-  return heap_constants_.Find(bit_cast<intptr_t>(value.address()));
+  return heap_constants_.Find(base::bit_cast<intptr_t>(value.address()));
 }
 
 
diff --git a/src/compiler/common-node-cache.h b/src/compiler/common-node-cache.h
index 561f5e61f4e..7f87d1ba1f9 100644
--- a/src/compiler/common-node-cache.h
+++ b/src/compiler/common-node-cache.h
@@ -53,12 +53,12 @@ class CommonNodeCache final {
 
   Node** FindFloat32Constant(float value) {
     // We canonicalize float constants at the bit representation level.
-    return float32_constants_.Find(bit_cast<int32_t>(value));
+    return float32_constants_.Find(base::bit_cast<int32_t>(value));
   }
 
   Node** FindFloat64Constant(double value) {
     // We canonicalize double constants at the bit representation level.
-    return float64_constants_.Find(bit_cast<int64_t>(value));
+    return float64_constants_.Find(base::bit_cast<int64_t>(value));
   }
 
   Node** FindExternalConstant(ExternalReference value);
@@ -69,7 +69,7 @@ class CommonNodeCache final {
 
   Node** FindNumberConstant(double value) {
     // We canonicalize double constants at the bit representation level.
-    return number_constants_.Find(bit_cast<int64_t>(value));
+    return number_constants_.Find(base::bit_cast<int64_t>(value));
   }
 
   Node** FindHeapConstant(Handle<HeapObject> value);
diff --git a/src/compiler/effect-control-linearizer.cc b/src/compiler/effect-control-linearizer.cc
index 191f50e9e10..56220ee0548 100644
--- a/src/compiler/effect-control-linearizer.cc
+++ b/src/compiler/effect-control-linearizer.cc
@@ -3282,9 +3282,9 @@ Node* EffectControlLinearizer::LowerObjectIsSafeInteger(Node* node) {
 
 namespace {
 
-// There is no (currently) available constexpr version of bit_cast, so we have
-// to make do with constructing the -0.0 bits manually (by setting the sign bit
-// to 1 and everything else to 0).
+// There is no (currently) available constexpr version of base::bit_cast, so
+// we have to make do with constructing the -0.0 bits manually (by setting the
+// sign bit to 1 and everything else to 0).
 // TODO(leszeks): Revisit when upgrading to C++20.
 constexpr int32_t kMinusZeroLoBits = static_cast<int32_t>(0);
 constexpr int32_t kMinusZeroHiBits = static_cast<int32_t>(1) << 31;
diff --git a/src/compiler/js-graph.cc b/src/compiler/js-graph.cc
index 652c7391faf..80392b257db 100644
--- a/src/compiler/js-graph.cc
+++ b/src/compiler/js-graph.cc
@@ -76,8 +76,10 @@ Node* JSGraph::Constant(const ObjectRef& ref) {
 }
 
 Node* JSGraph::Constant(double value) {
-  if (bit_cast<int64_t>(value) == bit_cast<int64_t>(0.0)) return ZeroConstant();
-  if (bit_cast<int64_t>(value) == bit_cast<int64_t>(1.0)) return OneConstant();
+  if (base::bit_cast<int64_t>(value) == base::bit_cast<int64_t>(0.0))
+    return ZeroConstant();
+  if (base::bit_cast<int64_t>(value) == base::bit_cast<int64_t>(1.0))
+    return OneConstant();
   return NumberConstant(value);
 }
 
diff --git a/src/compiler/js-operator.h b/src/compiler/js-operator.h
index 9fdb3f21f59..4f3452533b9 100644
--- a/src/compiler/js-operator.h
+++ b/src/compiler/js-operator.h
@@ -95,12 +95,13 @@ class CallFrequency final {
   }
 
   bool operator==(CallFrequency const& that) const {
-    return bit_cast<uint32_t>(this->value_) == bit_cast<uint32_t>(that.value_);
+    return base::bit_cast<uint32_t>(this->value_) ==
+           base::bit_cast<uint32_t>(that.value_);
   }
   bool operator!=(CallFrequency const& that) const { return !(*this == that); }
 
   friend size_t hash_value(CallFrequency const& f) {
-    return bit_cast<uint32_t>(f.value_);
+    return base::bit_cast<uint32_t>(f.value_);
   }
 
   static constexpr float kNoFeedbackCallFrequency = -1;
diff --git a/src/compiler/machine-graph.h b/src/compiler/machine-graph.h
index a110a4b7e83..2d1a37917aa 100644
--- a/src/compiler/machine-graph.h
+++ b/src/compiler/machine-graph.h
@@ -31,13 +31,13 @@ class V8_EXPORT_PRIVATE MachineGraph : public NON_EXPORTED_BASE(ZoneObject) {
   // Creates a Int32Constant node, usually canonicalized.
   Node* Int32Constant(int32_t value);
   Node* Uint32Constant(uint32_t value) {
-    return Int32Constant(bit_cast<int32_t>(value));
+    return Int32Constant(base::bit_cast<int32_t>(value));
   }
 
   // Creates a Int64Constant node, usually canonicalized.
   Node* Int64Constant(int64_t value);
   Node* Uint64Constant(uint64_t value) {
-    return Int64Constant(bit_cast<int64_t>(value));
+    return Int64Constant(base::bit_cast<int64_t>(value));
   }
 
   // Creates a Int32Constant/Int64Constant node, depending on the word size of
@@ -63,7 +63,7 @@ class V8_EXPORT_PRIVATE MachineGraph : public NON_EXPORTED_BASE(ZoneObject) {
   Node* PointerConstant(intptr_t value);
   template <typename T>
   Node* PointerConstant(T* value) {
-    return PointerConstant(bit_cast<intptr_t>(value));
+    return PointerConstant(base::bit_cast<intptr_t>(value));
   }
 
   // Creates an ExternalConstant node, usually canonicalized.
diff --git a/src/compiler/machine-operator-reducer.cc b/src/compiler/machine-operator-reducer.cc
index 676e16c3a2e..1c287555345 100644
--- a/src/compiler/machine-operator-reducer.cc
+++ b/src/compiler/machine-operator-reducer.cc
@@ -249,12 +249,12 @@ Node* MachineOperatorReducer::Int32Div(Node* dividend, int32_t divisor) {
   DCHECK_NE(0, divisor);
   DCHECK_NE(std::numeric_limits<int32_t>::min(), divisor);
   base::MagicNumbersForDivision<uint32_t> const mag =
-      base::SignedDivisionByConstant(bit_cast<uint32_t>(divisor));
+      base::SignedDivisionByConstant(base::bit_cast<uint32_t>(divisor));
   Node* quotient = graph()->NewNode(machine()->Int32MulHigh(), dividend,
                                     Uint32Constant(mag.multiplier));
-  if (divisor > 0 && bit_cast<int32_t>(mag.multiplier) < 0) {
+  if (divisor > 0 && base::bit_cast<int32_t>(mag.multiplier) < 0) {
     quotient = Int32Add(quotient, dividend);
-  } else if (divisor < 0 && bit_cast<int32_t>(mag.multiplier) > 0) {
+  } else if (divisor < 0 && base::bit_cast<int32_t>(mag.multiplier) > 0) {
     quotient = Int32Sub(quotient, dividend);
   }
   return Int32Add(Word32Sar(quotient, mag.shift), Word32Shr(dividend, 31));
@@ -2095,9 +2095,9 @@ Reduction MachineOperatorReducer::ReduceFloat64InsertLowWord32(Node* node) {
   Uint32Matcher mrhs(node->InputAt(1));
   if (mlhs.HasResolvedValue() && mrhs.HasResolvedValue()) {
     return ReplaceFloat64(
-        bit_cast<double>((bit_cast<uint64_t>(mlhs.ResolvedValue()) &
-                          uint64_t{0xFFFFFFFF00000000}) |
-                         mrhs.ResolvedValue()));
+        base::bit_cast<double>((base::bit_cast<uint64_t>(mlhs.ResolvedValue()) &
+                                uint64_t{0xFFFFFFFF00000000}) |
+                               mrhs.ResolvedValue()));
   }
   return NoChange();
 }
@@ -2107,8 +2107,9 @@ Reduction MachineOperatorReducer::ReduceFloat64InsertHighWord32(Node* node) {
   Float64Matcher mlhs(node->InputAt(0));
   Uint32Matcher mrhs(node->InputAt(1));
   if (mlhs.HasResolvedValue() && mrhs.HasResolvedValue()) {
-    return ReplaceFloat64(bit_cast<double>(
-        (bit_cast<uint64_t>(mlhs.ResolvedValue()) & uint64_t{0xFFFFFFFF}) |
+    return ReplaceFloat64(base::bit_cast<double>(
+        (base::bit_cast<uint64_t>(mlhs.ResolvedValue()) &
+         uint64_t{0xFFFFFFFF}) |
         (static_cast<uint64_t>(mrhs.ResolvedValue()) << 32)));
   }
   return NoChange();
diff --git a/src/compiler/machine-operator-reducer.h b/src/compiler/machine-operator-reducer.h
index ec8bea5412f..04439fec79b 100644
--- a/src/compiler/machine-operator-reducer.h
+++ b/src/compiler/machine-operator-reducer.h
@@ -42,10 +42,10 @@ class V8_EXPORT_PRIVATE MachineOperatorReducer final
   Node* Int32Constant(int32_t value);
   Node* Int64Constant(int64_t value);
   Node* Uint32Constant(uint32_t value) {
-    return Int32Constant(bit_cast<int32_t>(value));
+    return Int32Constant(base::bit_cast<int32_t>(value));
   }
   Node* Uint64Constant(uint64_t value) {
-    return Int64Constant(bit_cast<int64_t>(value));
+    return Int64Constant(base::bit_cast<int64_t>(value));
   }
   Node* Float64Mul(Node* lhs, Node* rhs);
   Node* Float64PowHalf(Node* value);
diff --git a/src/compiler/simplified-lowering.cc b/src/compiler/simplified-lowering.cc
index b77508321c3..f6a1fbe00fa 100644
--- a/src/compiler/simplified-lowering.cc
+++ b/src/compiler/simplified-lowering.cc
@@ -2134,7 +2134,7 @@ class RepresentationSelector {
         if (DoubleToSmiInteger(value, &value_as_int)) {
           VisitLeaf<T>(node, MachineRepresentation::kTaggedSigned);
           if (lower<T>()) {
-            intptr_t smi = bit_cast<intptr_t>(Smi::FromInt(value_as_int));
+            intptr_t smi = base::bit_cast<intptr_t>(Smi::FromInt(value_as_int));
             Node* constant = InsertTypeOverrideForVerifier(
                 NodeProperties::GetType(node),
                 lowering->jsgraph()->IntPtrConstant(smi));
diff --git a/src/compiler/simplified-operator-reducer.h b/src/compiler/simplified-operator-reducer.h
index ee6de7487ef..2f78d920167 100644
--- a/src/compiler/simplified-operator-reducer.h
+++ b/src/compiler/simplified-operator-reducer.h
@@ -47,7 +47,7 @@ class V8_EXPORT_PRIVATE SimplifiedOperatorReducer final
   Reduction ReplaceFloat64(double value);
   Reduction ReplaceInt32(int32_t value);
   Reduction ReplaceUint32(uint32_t value) {
-    return ReplaceInt32(bit_cast<int32_t>(value));
+    return ReplaceInt32(base::bit_cast<int32_t>(value));
   }
   Reduction ReplaceNumber(double value);
   Reduction ReplaceNumber(int32_t value);
diff --git a/src/compiler/wasm-compiler.cc b/src/compiler/wasm-compiler.cc
index 0c565720926..255aa248d92 100644
--- a/src/compiler/wasm-compiler.cc
+++ b/src/compiler/wasm-compiler.cc
@@ -3456,7 +3456,7 @@ Node* WasmGraphBuilder::BuildChangeUint32ToUintPtr(Node* node) {
   Uint32Matcher matcher(node);
   if (matcher.HasResolvedValue()) {
     uintptr_t value = matcher.ResolvedValue();
-    return mcgraph()->IntPtrConstant(bit_cast<intptr_t>(value));
+    return mcgraph()->IntPtrConstant(base::bit_cast<intptr_t>(value));
   }
   return gasm_->ChangeUint32ToUint64(node);
 }
diff --git a/src/d8/d8-posix.cc b/src/d8/d8-posix.cc
index 8db4beff0f0..fc2f3d43721 100644
--- a/src/d8/d8-posix.cc
+++ b/src/d8/d8-posix.cc
@@ -702,7 +702,7 @@ char* Shell::ReadCharsFromTcpPort(const char* name, int* size_out) {
     return nullptr;
   }
   // Reinterpretet the received file length as a signed big-endian integer.
-  int32_t file_length = bit_cast<int32_t>(htonl(big_endian_file_length));
+  int32_t file_length = base::bit_cast<int32_t>(htonl(big_endian_file_length));
 
   if (file_length < 0) {
     fprintf(stderr, "Received length %d for %s from localhost:%d\n",
diff --git a/src/deoptimizer/ppc/deoptimizer-ppc.cc b/src/deoptimizer/ppc/deoptimizer-ppc.cc
index 5a2557c24d5..ab1b122699e 100644
--- a/src/deoptimizer/ppc/deoptimizer-ppc.cc
+++ b/src/deoptimizer/ppc/deoptimizer-ppc.cc
@@ -23,7 +23,7 @@ const int Deoptimizer::kLazyDeoptExitSize = 3 * kInstrSize;
 
 Float32 RegisterValues::GetFloatRegister(unsigned n) const {
   float float_val = static_cast<float>(double_registers_[n].get_scalar());
-  return Float32::FromBits(bit_cast<uint32_t>(float_val));
+  return Float32::FromBits(base::bit_cast<uint32_t>(float_val));
 }
 
 void FrameDescription::SetCallerPc(unsigned offset, intptr_t value) {
diff --git a/src/deoptimizer/translation-array.cc b/src/deoptimizer/translation-array.cc
index fd34cb1fcdd..5f900accc63 100644
--- a/src/deoptimizer/translation-array.cc
+++ b/src/deoptimizer/translation-array.cc
@@ -33,13 +33,13 @@ TranslationArrayIterator::TranslationArrayIterator(TranslationArray buffer,
 
     uLongf uncompressed_size = size * kTranslationArrayElementSize;
 
-    CHECK_EQ(
-        zlib_internal::UncompressHelper(
-            zlib_internal::ZRAW,
-            bit_cast<Bytef*>(uncompressed_contents_.data()), &uncompressed_size,
-            buffer_.GetDataStartAddress() + kCompressedDataOffset,
-            buffer_.DataSize()),
-        Z_OK);
+    CHECK_EQ(zlib_internal::UncompressHelper(
+                 zlib_internal::ZRAW,
+                 base::bit_cast<Bytef*>(uncompressed_contents_.data()),
+                 &uncompressed_size,
+                 buffer_.GetDataStartAddress() + kCompressedDataOffset,
+                 buffer_.DataSize()),
+             Z_OK);
     DCHECK(index >= 0 && index < size);
   } else {
     DCHECK(index >= 0 && index < buffer.length());
@@ -83,7 +83,7 @@ Handle<TranslationArray> TranslationArrayBuilder::ToTranslationArray(
     CHECK_EQ(
         zlib_internal::CompressHelper(
             zlib_internal::ZRAW, compressed_data.data(), &compressed_data_size,
-            bit_cast<const Bytef*>(contents_for_compression_.data()),
+            base::bit_cast<const Bytef*>(contents_for_compression_.data()),
             input_size, Z_DEFAULT_COMPRESSION, nullptr, nullptr),
         Z_OK);
 
diff --git a/src/diagnostics/disassembler.cc b/src/diagnostics/disassembler.cc
index 55640459d71..713f10a6228 100644
--- a/src/diagnostics/disassembler.cc
+++ b/src/diagnostics/disassembler.cc
@@ -303,7 +303,7 @@ static int DecodeIt(Isolate* isolate, ExternalReferenceEncoder* ref_encoder,
   // Relocation exists if we either have no isolate (wasm code),
   // or we have an isolate and it is not an off-heap instruction stream.
   if (!isolate || !OffHeapInstructionStream::PcIsOffHeap(
-                      isolate, bit_cast<Address>(begin))) {
+                      isolate, base::bit_cast<Address>(begin))) {
     it = new RelocIterator(code);
   } else {
     // No relocation information when printing code stubs.
diff --git a/src/diagnostics/objects-debug.cc b/src/diagnostics/objects-debug.cc
index 138d527b0d6..47ece61828b 100644
--- a/src/diagnostics/objects-debug.cc
+++ b/src/diagnostics/objects-debug.cc
@@ -633,7 +633,7 @@ void FixedDoubleArray::FixedDoubleArrayVerify(Isolate* isolate) {
     if (!is_the_hole(i)) {
       uint64_t value = get_representation(i);
       uint64_t unexpected =
-          bit_cast<uint64_t>(std::numeric_limits<double>::quiet_NaN()) &
+          base::bit_cast<uint64_t>(std::numeric_limits<double>::quiet_NaN()) &
           uint64_t{0x7FF8000000000000};
       // Create implementation specific sNaN by inverting relevant bit.
       unexpected ^= uint64_t{0x0008000000000000};
diff --git a/src/diagnostics/ppc/disasm-ppc.cc b/src/diagnostics/ppc/disasm-ppc.cc
index 012e2ae400b..f15e2efa272 100644
--- a/src/diagnostics/ppc/disasm-ppc.cc
+++ b/src/diagnostics/ppc/disasm-ppc.cc
@@ -471,8 +471,8 @@ void Decoder::DecodeExtP(Instruction* instr) {
       // Read prefix.
       SetAsPrefixed(instr->Bits(17, 0));
       // Read suffix (next instruction).
-      Instruction* next_instr =
-          bit_cast<Instruction*>(bit_cast<intptr_t>(instr) + kInstrSize);
+      Instruction* next_instr = base::bit_cast<Instruction*>(
+          base::bit_cast<intptr_t>(instr) + kInstrSize);
       switch (next_instr->OpcodeBase()) {
           // Prefixed ADDI.
         case (ADDI): {
@@ -1555,8 +1555,8 @@ int Decoder::InstructionDecode(byte* instr_ptr) {
   } else {
     // Prefixed instructions have a 4-byte prefix and a 4-byte suffix. Print
     // both on the same line.
-    Instruction* next_instr =
-        bit_cast<Instruction*>(bit_cast<intptr_t>(instr) + kInstrSize);
+    Instruction* next_instr = base::bit_cast<Instruction*>(
+        base::bit_cast<intptr_t>(instr) + kInstrSize);
     out_buffer_pos_ +=
         base::SNPrintF(out_buffer_ + out_buffer_pos_, "%08x|%08x ",
                        instr->InstructionBits(), next_instr->InstructionBits());
diff --git a/src/execution/arm/simulator-arm.cc b/src/execution/arm/simulator-arm.cc
index 07597410600..aefb9820ea3 100644
--- a/src/execution/arm/simulator-arm.cc
+++ b/src/execution/arm/simulator-arm.cc
@@ -275,7 +275,7 @@ bool ArmDebugger::ExecDebugCommand(ArrayUniquePtr<char> line_ptr) {
         }
         for (int i = 0; i < DwVfpRegister::SupportedRegisterCount(); i++) {
           dvalue = GetVFPDoubleRegisterValue(i);
-          uint64_t as_words = bit_cast<uint64_t>(dvalue);
+          uint64_t as_words = base::bit_cast<uint64_t>(dvalue);
           PrintF("%3s: %f 0x%08x %08x\n", VFPRegisters::Name(i, true), dvalue,
                  static_cast<uint32_t>(as_words >> 32),
                  static_cast<uint32_t>(as_words & 0xFFFFFFFF));
@@ -284,10 +284,10 @@ bool ArmDebugger::ExecDebugCommand(ArrayUniquePtr<char> line_ptr) {
         if (GetValue(arg1, &value)) {
           PrintF("%s: 0x%08x %d \n", arg1, value, value);
         } else if (GetVFPSingleValue(arg1, &svalue)) {
-          uint32_t as_word = bit_cast<uint32_t>(svalue);
+          uint32_t as_word = base::bit_cast<uint32_t>(svalue);
           PrintF("%s: %f 0x%08x\n", arg1, svalue, as_word);
         } else if (GetVFPDoubleValue(arg1, &dvalue)) {
-          uint64_t as_words = bit_cast<uint64_t>(dvalue);
+          uint64_t as_words = base::bit_cast<uint64_t>(dvalue);
           PrintF("%s: %f 0x%08x %08x\n", arg1, dvalue,
                  static_cast<uint32_t>(as_words >> 32),
                  static_cast<uint32_t>(as_words & 0xFFFFFFFF));
@@ -1929,7 +1929,7 @@ float Simulator::canonicalizeNaN(float value) {
   // choices" of the ARM Reference Manual.
   constexpr uint32_t kDefaultNaN = 0x7FC00000u;
   if (FPSCR_default_NaN_mode_ && std::isnan(value)) {
-    value = bit_cast<float>(kDefaultNaN);
+    value = base::bit_cast<float>(kDefaultNaN);
   }
   return value;
 }
@@ -1946,7 +1946,7 @@ double Simulator::canonicalizeNaN(double value) {
   // choices" of the ARM Reference Manual.
   constexpr uint64_t kDefaultNaN = uint64_t{0x7FF8000000000000};
   if (FPSCR_default_NaN_mode_ && std::isnan(value)) {
-    value = bit_cast<double>(kDefaultNaN);
+    value = base::bit_cast<double>(kDefaultNaN);
   }
   return value;
 }
@@ -3005,8 +3005,9 @@ void Simulator::DecodeType3(Instruction* instr) {
           int32_t ret_val = 0;
           // udiv
           if (instr->Bit(21) == 0x1) {
-            ret_val = bit_cast<int32_t>(base::bits::UnsignedDiv32(
-                bit_cast<uint32_t>(rm_val), bit_cast<uint32_t>(rs_val)));
+            ret_val = base::bit_cast<int32_t>(
+                base::bits::UnsignedDiv32(base::bit_cast<uint32_t>(rm_val),
+                                          base::bit_cast<uint32_t>(rs_val)));
           } else {
             ret_val = base::bits::SignedDiv32(rm_val, rs_val);
           }
@@ -4851,18 +4852,18 @@ void Simulator::DecodeAdvancedSIMDTwoOrThreeRegisters(Instruction* instr) {
       get_neon_register(Vm, src);
       if (instr->Bit(7) == 0) {
         for (int i = 0; i < 4; i++) {
-          float denom = bit_cast<float>(src[i]);
+          float denom = base::bit_cast<float>(src[i]);
           div_zero_vfp_flag_ = (denom == 0);
           float result = 1.0f / denom;
           result = canonicalizeNaN(result);
-          src[i] = bit_cast<uint32_t>(result);
+          src[i] = base::bit_cast<uint32_t>(result);
         }
       } else {
         for (int i = 0; i < 4; i++) {
-          float radicand = bit_cast<float>(src[i]);
+          float radicand = base::bit_cast<float>(src[i]);
           float result = 1.0f / std::sqrt(radicand);
           result = canonicalizeNaN(result);
-          src[i] = bit_cast<uint32_t>(result);
+          src[i] = base::bit_cast<uint32_t>(result);
         }
       }
       set_neon_register(Vd, src);
@@ -4877,23 +4878,23 @@ void Simulator::DecodeAdvancedSIMDTwoOrThreeRegisters(Instruction* instr) {
         switch (op) {
           case 0:
             // f32 <- s32, round towards nearest.
-            q_data[i] = bit_cast<uint32_t>(
-                std::round(static_cast<float>(bit_cast<int32_t>(q_data[i]))));
+            q_data[i] = base::bit_cast<uint32_t>(std::round(
+                static_cast<float>(base::bit_cast<int32_t>(q_data[i]))));
             break;
           case 1:
             // f32 <- u32, round towards nearest.
-            q_data[i] =
-                bit_cast<uint32_t>(std::round(static_cast<float>(q_data[i])));
+            q_data[i] = base::bit_cast<uint32_t>(
+                std::round(static_cast<float>(q_data[i])));
             break;
           case 2:
             // s32 <- f32, round to zero.
-            q_data[i] = static_cast<uint32_t>(
-                ConvertDoubleToInt(bit_cast<float>(q_data[i]), false, RZ));
+            q_data[i] = static_cast<uint32_t>(ConvertDoubleToInt(
+                base::bit_cast<float>(q_data[i]), false, RZ));
             break;
           case 3:
             // u32 <- f32, round to zero.
             q_data[i] = static_cast<uint32_t>(
-                ConvertDoubleToInt(bit_cast<float>(q_data[i]), true, RZ));
+                ConvertDoubleToInt(base::bit_cast<float>(q_data[i]), true, RZ));
             break;
         }
       }
@@ -5924,7 +5925,7 @@ void Simulator::DecodeAdvancedSIMDLoadStoreSingleStructureToOneLane(
         DCHECK_EQ(0, instr->Bits(6, 4));  // Alignment not supported.
         int i = instr->Bit(7) * 32;
         dreg = (dreg >> i) & 0xffffffff;
-        WriteW(address, bit_cast<int>(static_cast<uint32_t>(dreg)));
+        WriteW(address, base::bit_cast<int>(static_cast<uint32_t>(dreg)));
         break;
       }
       case Neon64: {
diff --git a/src/execution/arm64/simulator-arm64.cc b/src/execution/arm64/simulator-arm64.cc
index da2acd7d0c8..23e3e17678e 100644
--- a/src/execution/arm64/simulator-arm64.cc
+++ b/src/execution/arm64/simulator-arm64.cc
@@ -3453,7 +3453,7 @@ bool Simulator::PrintValue(const char* desc) {
   if (desc[0] == 'v') {
     PrintF(stream_, "%s %s:%s 0x%016" PRIx64 "%s (%s%s:%s %g%s %s:%s %g%s)\n",
            clr_vreg_name, VRegNameForCode(i), clr_vreg_value,
-           bit_cast<uint64_t>(dreg(i)), clr_normal, clr_vreg_name,
+           base::bit_cast<uint64_t>(dreg(i)), clr_normal, clr_vreg_name,
            DRegNameForCode(i), clr_vreg_value, dreg(i), clr_vreg_name,
            SRegNameForCode(i), clr_vreg_value, sreg(i), clr_normal);
     return true;
@@ -5273,10 +5273,10 @@ void Simulator::VisitNEONModifiedImmediate(Instruction* instr) {
       } else {  // cmode_0 == 1, cmode == 0xF.
         if (op_bit == 0) {
           vform = q ? kFormat4S : kFormat2S;
-          imm = bit_cast<uint32_t>(instr->ImmNEONFP32());
+          imm = base::bit_cast<uint32_t>(instr->ImmNEONFP32());
         } else if (q == 1) {
           vform = kFormat2D;
-          imm = bit_cast<uint64_t>(instr->ImmNEONFP64());
+          imm = base::bit_cast<uint64_t>(instr->ImmNEONFP64());
         } else {
           DCHECK((q == 0) && (op_bit == 1) && (cmode == 0xF));
           VisitUnallocated(instr);
diff --git a/src/execution/arm64/simulator-logic-arm64.cc b/src/execution/arm64/simulator-logic-arm64.cc
index e2283765a13..555625988c1 100644
--- a/src/execution/arm64/simulator-logic-arm64.cc
+++ b/src/execution/arm64/simulator-logic-arm64.cc
@@ -18,7 +18,7 @@ inline double FPRoundToDouble(int64_t sign, int64_t exponent, uint64_t mantissa,
                               FPRounding round_mode) {
   uint64_t bits = FPRound<uint64_t, kDoubleExponentBits, kDoubleMantissaBits>(
       sign, exponent, mantissa, round_mode);
-  return bit_cast<double>(bits);
+  return base::bit_cast<double>(bits);
 }
 
 // See FPRound for a description of this function.
@@ -26,7 +26,7 @@ inline float FPRoundToFloat(int64_t sign, int64_t exponent, uint64_t mantissa,
                             FPRounding round_mode) {
   uint32_t bits = FPRound<uint32_t, kFloatExponentBits, kFloatMantissaBits>(
       sign, exponent, mantissa, round_mode);
-  return bit_cast<float>(bits);
+  return base::bit_cast<float>(bits);
 }
 
 // See FPRound for a description of this function.
@@ -101,7 +101,7 @@ double Simulator::FPToDouble(float value) {
       //  - The mantissa is transferred entirely, except that the top bit is
       //    forced to '1', making the result a quiet NaN. The unused (low-order)
       //    mantissa bits are set to 0.
-      uint32_t raw = bit_cast<uint32_t>(value);
+      uint32_t raw = base::bit_cast<uint32_t>(value);
 
       uint64_t sign = raw >> 31;
       uint64_t exponent = (1 << kDoubleExponentBits) - 1;
@@ -306,7 +306,7 @@ float Simulator::FPToFloat(double value, FPRounding round_mode) {
       //  - The mantissa is transferred as much as possible, except that the
       //    top bit is forced to '1', making the result a quiet NaN.
 
-      uint64_t raw = bit_cast<uint64_t>(value);
+      uint64_t raw = base::bit_cast<uint64_t>(value);
 
       uint32_t sign = raw >> 63;
       uint32_t exponent = (1 << 8) - 1;
@@ -1659,7 +1659,7 @@ LogicVRegister Simulator::suqadd(VectorFormat vform, LogicVRegister dst,
     uint64_t ub = src.UintLeftJustified(vform, i);
     uint64_t ur = sa + ub;
 
-    int64_t sr = bit_cast<int64_t>(ur);
+    int64_t sr = base::bit_cast<int64_t>(ur);
     if (sr < sa) {  // Test for signed positive saturation.
       dst.SetInt(vform, i, MaxIntFromFormat(vform));
     } else {
@@ -3446,12 +3446,12 @@ LogicVRegister Simulator::fcmp_zero(VectorFormat vform, LogicVRegister dst,
   SimVRegister temp;
   if (LaneSizeInBytesFromFormat(vform) == kSRegSize) {
     LogicVRegister zero_reg =
-        dup_immediate(vform, temp, bit_cast<uint32_t>(0.0f));
+        dup_immediate(vform, temp, base::bit_cast<uint32_t>(0.0f));
     fcmp<float>(vform, dst, src, zero_reg, cond);
   } else {
     DCHECK_EQ(LaneSizeInBytesFromFormat(vform), kDRegSize);
     LogicVRegister zero_reg =
-        dup_immediate(vform, temp, bit_cast<uint64_t>(0.0));
+        dup_immediate(vform, temp, base::bit_cast<uint64_t>(0.0));
     fcmp<double>(vform, dst, src, zero_reg, cond);
   }
   return dst;
@@ -3951,7 +3951,7 @@ T Simulator::FPRecipSqrtEstimate(T op) {
       result_exp = (3068 - exp) / 2;
     }
 
-    uint64_t estimate = bit_cast<uint64_t>(recip_sqrt_estimate(scaled));
+    uint64_t estimate = base::bit_cast<uint64_t>(recip_sqrt_estimate(scaled));
 
     if (sizeof(T) == sizeof(float)) {
       uint32_t exp_bits = static_cast<uint32_t>(Bits(result_exp, 7, 0));
diff --git a/src/execution/frames.cc b/src/execution/frames.cc
index af0e957abda..b0a64de04d6 100644
--- a/src/execution/frames.cc
+++ b/src/execution/frames.cc
@@ -826,7 +826,7 @@ StackFrame::Type ExitFrame::ComputeFrameType(Address fp) {
     return EXIT;
   }
 
-  intptr_t marker_int = bit_cast<intptr_t>(marker);
+  intptr_t marker_int = base::bit_cast<intptr_t>(marker);
 
   StackFrame::Type frame_type = static_cast<StackFrame::Type>(marker_int >> 1);
   switch (frame_type) {
diff --git a/src/execution/loong64/simulator-loong64.cc b/src/execution/loong64/simulator-loong64.cc
index 7e3d9302727..31f511fc695 100644
--- a/src/execution/loong64/simulator-loong64.cc
+++ b/src/execution/loong64/simulator-loong64.cc
@@ -928,12 +928,12 @@ void Simulator::set_fpu_register_hi_word(int fpureg, int32_t value) {
 
 void Simulator::set_fpu_register_float(int fpureg, float value) {
   DCHECK((fpureg >= 0) && (fpureg < kNumFPURegisters));
-  *bit_cast<float*>(&FPUregisters_[fpureg]) = value;
+  *base::bit_cast<float*>(&FPUregisters_[fpureg]) = value;
 }
 
 void Simulator::set_fpu_register_double(int fpureg, double value) {
   DCHECK((fpureg >= 0) && (fpureg < kNumFPURegisters));
-  *bit_cast<double*>(&FPUregisters_[fpureg]) = value;
+  *base::bit_cast<double*>(&FPUregisters_[fpureg]) = value;
 }
 
 void Simulator::set_cf_register(int cfreg, bool value) {
@@ -986,12 +986,12 @@ int32_t Simulator::get_fpu_register_hi_word(int fpureg) const {
 
 float Simulator::get_fpu_register_float(int fpureg) const {
   DCHECK((fpureg >= 0) && (fpureg < kNumFPURegisters));
-  return *bit_cast<float*>(const_cast<int64_t*>(&FPUregisters_[fpureg]));
+  return *base::bit_cast<float*>(const_cast<int64_t*>(&FPUregisters_[fpureg]));
 }
 
 double Simulator::get_fpu_register_double(int fpureg) const {
   DCHECK((fpureg >= 0) && (fpureg < kNumFPURegisters));
-  return *bit_cast<double*>(&FPUregisters_[fpureg]);
+  return *base::bit_cast<double*>(&FPUregisters_[fpureg]);
 }
 
 bool Simulator::get_cf_register(int cfreg) const {
diff --git a/src/execution/mips/simulator-mips.cc b/src/execution/mips/simulator-mips.cc
index f22c5158993..7aa5e00fbe9 100644
--- a/src/execution/mips/simulator-mips.cc
+++ b/src/execution/mips/simulator-mips.cc
@@ -955,16 +955,16 @@ void Simulator::set_fpu_register_hi_word(int fpureg, int32_t value) {
 
 void Simulator::set_fpu_register_float(int fpureg, float value) {
   DCHECK((fpureg >= 0) && (fpureg < kNumFPURegisters));
-  *bit_cast<float*>(&FPUregisters_[fpureg * 2]) = value;
+  *base::bit_cast<float*>(&FPUregisters_[fpureg * 2]) = value;
 }
 
 void Simulator::set_fpu_register_double(int fpureg, double value) {
   if (IsFp64Mode()) {
     DCHECK((fpureg >= 0) && (fpureg < kNumFPURegisters));
-    *bit_cast<double*>(&FPUregisters_[fpureg * 2]) = value;
+    *base::bit_cast<double*>(&FPUregisters_[fpureg * 2]) = value;
   } else {
     DCHECK((fpureg >= 0) && (fpureg < kNumFPURegisters) && ((fpureg % 2) == 0));
-    int64_t i64 = bit_cast<int64_t>(value);
+    int64_t i64 = base::bit_cast<int64_t>(value);
     set_fpu_register_word(fpureg, i64 & 0xFFFFFFFF);
     set_fpu_register_word(fpureg + 1, i64 >> 32);
   }
@@ -1023,19 +1023,20 @@ int32_t Simulator::get_fpu_register_hi_word(int fpureg) const {
 
 float Simulator::get_fpu_register_float(int fpureg) const {
   DCHECK((fpureg >= 0) && (fpureg < kNumFPURegisters));
-  return *bit_cast<float*>(const_cast<int64_t*>(&FPUregisters_[fpureg * 2]));
+  return *base::bit_cast<float*>(
+      const_cast<int64_t*>(&FPUregisters_[fpureg * 2]));
 }
 
 double Simulator::get_fpu_register_double(int fpureg) const {
   if (IsFp64Mode()) {
     DCHECK((fpureg >= 0) && (fpureg < kNumFPURegisters));
-    return *bit_cast<double*>(&FPUregisters_[fpureg * 2]);
+    return *base::bit_cast<double*>(&FPUregisters_[fpureg * 2]);
   } else {
     DCHECK((fpureg >= 0) && (fpureg < kNumFPURegisters) && ((fpureg % 2) == 0));
     int64_t i64;
     i64 = static_cast<uint32_t>(get_fpu_register_word(fpureg));
     i64 |= static_cast<uint64_t>(get_fpu_register_word(fpureg + 1)) << 32;
-    return bit_cast<double>(i64);
+    return base::bit_cast<double>(i64);
   }
 }
 
@@ -2684,8 +2685,8 @@ void Simulator::DecodeTypeRegisterDRsType() {
   ft = (instr_.FunctionFieldRaw() != MOVF) ? get_fpu_register_double(ft_reg())
                                            : 0.0;
   fd = get_fpu_register_double(fd_reg());
-  int64_t ft_int = bit_cast<int64_t>(ft);
-  int64_t fd_int = bit_cast<int64_t>(fd);
+  int64_t ft_int = base::bit_cast<int64_t>(ft);
+  int64_t fd_int = base::bit_cast<int64_t>(fd);
   cc = instr_.FCccValue();
   fcsr_cc = get_fcsr_condition_bit(cc);
   switch (instr_.FunctionFieldRaw()) {
@@ -3001,7 +3002,7 @@ void Simulator::DecodeTypeRegisterDRsType() {
     }
     case CLASS_D: {  // Mips32r6 instruction
       // Convert double input to uint64_t for easier bit manipulation
-      uint64_t classed = bit_cast<uint64_t>(fs);
+      uint64_t classed = base::bit_cast<uint64_t>(fs);
 
       // Extracting sign, exponent and mantissa from the input double
       uint32_t sign = (classed >> 63) & 1;
@@ -3059,7 +3060,7 @@ void Simulator::DecodeTypeRegisterDRsType() {
 
       DCHECK_NE(result, 0);
 
-      dResult = bit_cast<double>(result);
+      dResult = base::bit_cast<double>(result);
       SetFPUDoubleResult(fd_reg(), dResult);
 
       break;
@@ -3170,8 +3171,8 @@ void Simulator::DecodeTypeRegisterSRsType() {
   fs = get_fpu_register_float(fs_reg());
   ft = get_fpu_register_float(ft_reg());
   fd = get_fpu_register_float(fd_reg());
-  int32_t ft_int = bit_cast<int32_t>(ft);
-  int32_t fd_int = bit_cast<int32_t>(fd);
+  int32_t ft_int = base::bit_cast<int32_t>(ft);
+  int32_t fd_int = base::bit_cast<int32_t>(fd);
   uint32_t cc, fcsr_cc;
   cc = instr_.FCccValue();
   fcsr_cc = get_fcsr_condition_bit(cc);
@@ -3314,7 +3315,7 @@ void Simulator::DecodeTypeRegisterSRsType() {
     case CLASS_S: {  // Mips32r6 instruction
       // Convert float input to uint32_t for easier bit manipulation
       float fs = get_fpu_register_float(fs_reg());
-      uint32_t classed = bit_cast<uint32_t>(fs);
+      uint32_t classed = base::bit_cast<uint32_t>(fs);
 
       // Extracting sign, exponent and mantissa from the input float
       uint32_t sign = (classed >> 31) & 1;
@@ -3372,7 +3373,7 @@ void Simulator::DecodeTypeRegisterSRsType() {
 
       DCHECK_NE(result, 0);
 
-      fResult = bit_cast<float>(result);
+      fResult = base::bit_cast<float>(result);
       SetFPUFloatResult(fd_reg(), fResult);
 
       break;
@@ -4557,12 +4558,12 @@ void Simulator::DecodeTypeMsaELM() {
   switch (opcode) {
     case CTCMSA:
       DCHECK_EQ(sa(), kMSACSRRegister);
-      MSACSR_ = bit_cast<uint32_t>(registers_[rd_reg()]);
+      MSACSR_ = base::bit_cast<uint32_t>(registers_[rd_reg()]);
       TraceRegWr(static_cast<int32_t>(MSACSR_));
       break;
     case CFCMSA:
       DCHECK_EQ(rd_reg(), kMSACSRRegister);
-      SetResult(sa(), bit_cast<int32_t>(MSACSR_));
+      SetResult(sa(), base::bit_cast<int32_t>(MSACSR_));
       break;
     case MOVE_V: {
       msa_reg_t ws;
@@ -5402,44 +5403,44 @@ void Msa3RFInstrHelper(uint32_t opcode, T_reg ws, T_reg wt, T_reg* wd) {
       }
     } break;
     case FADD:
-      *wd = bit_cast<T_int>(s_element + t_element);
+      *wd = base::bit_cast<T_int>(s_element + t_element);
       break;
     case FSUB:
-      *wd = bit_cast<T_int>(s_element - t_element);
+      *wd = base::bit_cast<T_int>(s_element - t_element);
       break;
     case FMUL:
-      *wd = bit_cast<T_int>(s_element * t_element);
+      *wd = base::bit_cast<T_int>(s_element * t_element);
       break;
     case FDIV: {
       if (t_element == 0) {
-        *wd = bit_cast<T_int>(std::numeric_limits<T_fp>::quiet_NaN());
+        *wd = base::bit_cast<T_int>(std::numeric_limits<T_fp>::quiet_NaN());
       } else {
-        *wd = bit_cast<T_int>(s_element / t_element);
+        *wd = base::bit_cast<T_int>(s_element / t_element);
       }
     } break;
     case FMADD:
-      *wd = bit_cast<T_int>(
+      *wd = base::bit_cast<T_int>(
           std::fma(s_element, t_element, *reinterpret_cast<T_fp*>(wd)));
       break;
     case FMSUB:
-      *wd = bit_cast<T_int>(
+      *wd = base::bit_cast<T_int>(
           std::fma(s_element, -t_element, *reinterpret_cast<T_fp*>(wd)));
       break;
     case FEXP2:
-      *wd = bit_cast<T_int>(std::ldexp(s_element, static_cast<int>(wt)));
+      *wd = base::bit_cast<T_int>(std::ldexp(s_element, static_cast<int>(wt)));
       break;
     case FMIN:
-      *wd = bit_cast<T_int>(std::min(s_element, t_element));
+      *wd = base::bit_cast<T_int>(std::min(s_element, t_element));
       break;
     case FMAX:
-      *wd = bit_cast<T_int>(std::max(s_element, t_element));
+      *wd = base::bit_cast<T_int>(std::max(s_element, t_element));
       break;
     case FMIN_A: {
-      *wd = bit_cast<T_int>(
+      *wd = base::bit_cast<T_int>(
           std::fabs(s_element) < std::fabs(t_element) ? s_element : t_element);
     } break;
     case FMAX_A: {
-      *wd = bit_cast<T_int>(
+      *wd = base::bit_cast<T_int>(
           std::fabs(s_element) > std::fabs(t_element) ? s_element : t_element);
     } break;
     case FSOR:
@@ -5474,7 +5475,8 @@ void Msa3RFInstrHelper2(uint32_t opcode, T_reg ws, T_reg wt, T_reg* wd) {
   switch (opcode) {
     case MUL_Q: {
       const T_int_dbl min_fix_dbl =
-          bit_cast<T_uint_dbl>(std::numeric_limits<T_int_dbl>::min()) >> 1U;
+          base::bit_cast<T_uint_dbl>(std::numeric_limits<T_int_dbl>::min()) >>
+          1U;
       const T_int_dbl max_fix_dbl = std::numeric_limits<T_int_dbl>::max() >> 1U;
       if (product == min_fix_dbl) {
         product = max_fix_dbl;
@@ -5493,7 +5495,8 @@ void Msa3RFInstrHelper2(uint32_t opcode, T_reg ws, T_reg wt, T_reg* wd) {
     } break;
     case MULR_Q: {
       const T_int_dbl min_fix_dbl =
-          bit_cast<T_uint_dbl>(std::numeric_limits<T_int_dbl>::min()) >> 1U;
+          base::bit_cast<T_uint_dbl>(std::numeric_limits<T_int_dbl>::min()) >>
+          1U;
       const T_int_dbl max_fix_dbl = std::numeric_limits<T_int_dbl>::max() >> 1U;
       if (product == min_fix_dbl) {
         *wd = static_cast<T_int>(max_fix_dbl >> shift);
@@ -5622,10 +5625,10 @@ void Simulator::DecodeTypeMsa3RF() {
           break;
         case MSA_WORD:
           for (int i = 0; i < kMSALanesDword; i++) {
-            wd.w[i + kMSALanesWord / 2] = bit_cast<int32_t>(
-                static_cast<float>(bit_cast<double>(ws.d[i])));
-            wd.w[i] = bit_cast<int32_t>(
-                static_cast<float>(bit_cast<double>(wt.d[i])));
+            wd.w[i + kMSALanesWord / 2] = base::bit_cast<int32_t>(
+                static_cast<float>(base::bit_cast<double>(ws.d[i])));
+            wd.w[i] = base::bit_cast<int32_t>(
+                static_cast<float>(base::bit_cast<double>(wt.d[i])));
           }
           break;
         default:
@@ -5636,7 +5639,7 @@ void Simulator::DecodeTypeMsa3RF() {
 #undef FEXDO_DF
     case FTQ:
 #define FTQ_DF(source, dst, fp_type, int_type)                  \
-  element = bit_cast<fp_type>(source) *                         \
+  element = base::bit_cast<fp_type>(source) *                   \
             (1U << (sizeof(int_type) * kBitsPerByte - 1));      \
   if (element > std::numeric_limits<int_type>::max()) {         \
     dst = std::numeric_limits<int_type>::max();                 \
@@ -5898,8 +5901,8 @@ void Simulator::DecodeTypeMsa2R() {
 }
 
 #define BIT(n) (0x1LL << n)
-#define QUIET_BIT_S(nan) (bit_cast<int32_t>(nan) & BIT(22))
-#define QUIET_BIT_D(nan) (bit_cast<int64_t>(nan) & BIT(51))
+#define QUIET_BIT_S(nan) (base::bit_cast<int32_t>(nan) & BIT(22))
+#define QUIET_BIT_D(nan) (base::bit_cast<int64_t>(nan) & BIT(51))
 static inline bool isSnan(float fp) { return !QUIET_BIT_S(fp); }
 static inline bool isSnan(double fp) { return !QUIET_BIT_D(fp); }
 #undef QUIET_BIT_S
@@ -5975,7 +5978,7 @@ T_int Msa2RFInstrHelper(uint32_t opcode, T_src src, T_dst* dst,
 #undef POS_SUBNORMAL_BIT
 #undef POS_ZERO_BIT
     case FTRUNC_S: {
-      T_fp element = bit_cast<T_fp>(src);
+      T_fp element = base::bit_cast<T_fp>(src);
       const T_int max_int = std::numeric_limits<T_int>::max();
       const T_int min_int = std::numeric_limits<T_int>::min();
       if (std::isnan(element)) {
@@ -5988,7 +5991,7 @@ T_int Msa2RFInstrHelper(uint32_t opcode, T_src src, T_dst* dst,
       break;
     }
     case FTRUNC_U: {
-      T_fp element = bit_cast<T_fp>(src);
+      T_fp element = base::bit_cast<T_fp>(src);
       const T_uint max_int = std::numeric_limits<T_uint>::max();
       if (std::isnan(element)) {
         *dst = 0;
@@ -6000,61 +6003,62 @@ T_int Msa2RFInstrHelper(uint32_t opcode, T_src src, T_dst* dst,
       break;
     }
     case FSQRT: {
-      T_fp element = bit_cast<T_fp>(src);
+      T_fp element = base::bit_cast<T_fp>(src);
       if (element < 0 || std::isnan(element)) {
-        *dst = bit_cast<T_int>(std::numeric_limits<T_fp>::quiet_NaN());
+        *dst = base::bit_cast<T_int>(std::numeric_limits<T_fp>::quiet_NaN());
       } else {
-        *dst = bit_cast<T_int>(std::sqrt(element));
+        *dst = base::bit_cast<T_int>(std::sqrt(element));
       }
       break;
     }
     case FRSQRT: {
-      T_fp element = bit_cast<T_fp>(src);
+      T_fp element = base::bit_cast<T_fp>(src);
       if (element < 0 || std::isnan(element)) {
-        *dst = bit_cast<T_int>(std::numeric_limits<T_fp>::quiet_NaN());
+        *dst = base::bit_cast<T_int>(std::numeric_limits<T_fp>::quiet_NaN());
       } else {
-        *dst = bit_cast<T_int>(1 / std::sqrt(element));
+        *dst = base::bit_cast<T_int>(1 / std::sqrt(element));
       }
       break;
     }
     case FRCP: {
-      T_fp element = bit_cast<T_fp>(src);
+      T_fp element = base::bit_cast<T_fp>(src);
       if (std::isnan(element)) {
-        *dst = bit_cast<T_int>(std::numeric_limits<T_fp>::quiet_NaN());
+        *dst = base::bit_cast<T_int>(std::numeric_limits<T_fp>::quiet_NaN());
       } else {
-        *dst = bit_cast<T_int>(1 / element);
+        *dst = base::bit_cast<T_int>(1 / element);
       }
       break;
     }
     case FRINT: {
-      T_fp element = bit_cast<T_fp>(src);
+      T_fp element = base::bit_cast<T_fp>(src);
       if (std::isnan(element)) {
-        *dst = bit_cast<T_int>(std::numeric_limits<T_fp>::quiet_NaN());
+        *dst = base::bit_cast<T_int>(std::numeric_limits<T_fp>::quiet_NaN());
       } else {
         T_int dummy;
         sim->round_according_to_msacsr<T_fp, T_int>(element, &element, &dummy);
-        *dst = bit_cast<T_int>(element);
+        *dst = base::bit_cast<T_int>(element);
       }
       break;
     }
     case FLOG2: {
-      T_fp element = bit_cast<T_fp>(src);
+      T_fp element = base::bit_cast<T_fp>(src);
       switch (std::fpclassify(element)) {
         case FP_NORMAL:
         case FP_SUBNORMAL:
-          *dst = bit_cast<T_int>(std::logb(element));
+          *dst = base::bit_cast<T_int>(std::logb(element));
           break;
         case FP_ZERO:
-          *dst = bit_cast<T_int>(-std::numeric_limits<T_fp>::infinity());
+          *dst = base::bit_cast<T_int>(-std::numeric_limits<T_fp>::infinity());
           break;
         case FP_NAN:
-          *dst = bit_cast<T_int>(std::numeric_limits<T_fp>::quiet_NaN());
+          *dst = base::bit_cast<T_int>(std::numeric_limits<T_fp>::quiet_NaN());
           break;
         case FP_INFINITE:
           if (element < 0) {
-            *dst = bit_cast<T_int>(std::numeric_limits<T_fp>::quiet_NaN());
+            *dst =
+                base::bit_cast<T_int>(std::numeric_limits<T_fp>::quiet_NaN());
           } else {
-            *dst = bit_cast<T_int>(std::numeric_limits<T_fp>::infinity());
+            *dst = base::bit_cast<T_int>(std::numeric_limits<T_fp>::infinity());
           }
           break;
         default:
@@ -6063,7 +6067,7 @@ T_int Msa2RFInstrHelper(uint32_t opcode, T_src src, T_dst* dst,
       break;
     }
     case FTINT_S: {
-      T_fp element = bit_cast<T_fp>(src);
+      T_fp element = base::bit_cast<T_fp>(src);
       const T_int max_int = std::numeric_limits<T_int>::max();
       const T_int min_int = std::numeric_limits<T_int>::min();
       if (std::isnan(element)) {
@@ -6076,7 +6080,7 @@ T_int Msa2RFInstrHelper(uint32_t opcode, T_src src, T_dst* dst,
       break;
     }
     case FTINT_U: {
-      T_fp element = bit_cast<T_fp>(src);
+      T_fp element = base::bit_cast<T_fp>(src);
       const T_uint max_uint = std::numeric_limits<T_uint>::max();
       if (std::isnan(element)) {
         *dst = 0;
@@ -6090,11 +6094,12 @@ T_int Msa2RFInstrHelper(uint32_t opcode, T_src src, T_dst* dst,
       break;
     }
     case FFINT_S:
-      *dst = bit_cast<T_int>(static_cast<T_fp>(src));
+      *dst = base::bit_cast<T_int>(static_cast<T_fp>(src));
       break;
     case FFINT_U:
       using uT_src = typename std::make_unsigned<T_src>::type;
-      *dst = bit_cast<T_int>(static_cast<T_fp>(bit_cast<uT_src>(src)));
+      *dst =
+          base::bit_cast<T_int>(static_cast<T_fp>(base::bit_cast<uT_src>(src)));
       break;
     default:
       UNREACHABLE();
@@ -6110,61 +6115,65 @@ T_int Msa2RFInstrHelper2(uint32_t opcode, T_reg ws, int i) {
 #define EXTRACT_FLOAT16_FRAC(fp16) (fp16 & 0x3FF)
 #define PACK_FLOAT32(sign, exp, frac) \
   static_cast<uint32_t>(((sign) << 31) + ((exp) << 23) + (frac))
-#define FEXUP_DF(src_index)                                                   \
-  uint_fast16_t element = ws.uh[src_index];                                   \
-  uint_fast32_t aSign, aFrac;                                                 \
-  int_fast32_t aExp;                                                          \
-  aSign = EXTRACT_FLOAT16_SIGN(element);                                      \
-  aExp = EXTRACT_FLOAT16_EXP(element);                                        \
-  aFrac = EXTRACT_FLOAT16_FRAC(element);                                      \
-  if (V8_LIKELY(aExp && aExp != 0x1F)) {                                      \
-    return PACK_FLOAT32(aSign, aExp + 0x70, aFrac << 13);                     \
-  } else if (aExp == 0x1F) {                                                  \
-    if (aFrac) {                                                              \
-      return bit_cast<int32_t>(std::numeric_limits<float>::quiet_NaN());      \
-    } else {                                                                  \
-      return bit_cast<uint32_t>(std::numeric_limits<float>::infinity()) |     \
-             static_cast<uint32_t>(aSign) << 31;                              \
-    }                                                                         \
-  } else {                                                                    \
-    if (aFrac == 0) {                                                         \
-      return PACK_FLOAT32(aSign, 0, 0);                                       \
-    } else {                                                                  \
-      int_fast16_t shiftCount =                                               \
-          base::bits::CountLeadingZeros32(static_cast<uint32_t>(aFrac)) - 21; \
-      aFrac <<= shiftCount;                                                   \
-      aExp = -shiftCount;                                                     \
-      return PACK_FLOAT32(aSign, aExp + 0x70, aFrac << 13);                   \
-    }                                                                         \
+#define FEXUP_DF(src_index)                                                    \
+  uint_fast16_t element = ws.uh[src_index];                                    \
+  uint_fast32_t aSign, aFrac;                                                  \
+  int_fast32_t aExp;                                                           \
+  aSign = EXTRACT_FLOAT16_SIGN(element);                                       \
+  aExp = EXTRACT_FLOAT16_EXP(element);                                         \
+  aFrac = EXTRACT_FLOAT16_FRAC(element);                                       \
+  if (V8_LIKELY(aExp && aExp != 0x1F)) {                                       \
+    return PACK_FLOAT32(aSign, aExp + 0x70, aFrac << 13);                      \
+  } else if (aExp == 0x1F) {                                                   \
+    if (aFrac) {                                                               \
+      return base::bit_cast<int32_t>(std::numeric_limits<float>::quiet_NaN()); \
+    } else {                                                                   \
+      return base::bit_cast<uint32_t>(                                         \
+                 std::numeric_limits<float>::infinity()) |                     \
+             static_cast<uint32_t>(aSign) << 31;                               \
+    }                                                                          \
+  } else {                                                                     \
+    if (aFrac == 0) {                                                          \
+      return PACK_FLOAT32(aSign, 0, 0);                                        \
+    } else {                                                                   \
+      int_fast16_t shiftCount =                                                \
+          base::bits::CountLeadingZeros32(static_cast<uint32_t>(aFrac)) - 21;  \
+      aFrac <<= shiftCount;                                                    \
+      aExp = -shiftCount;                                                      \
+      return PACK_FLOAT32(aSign, aExp + 0x70, aFrac << 13);                    \
+    }                                                                          \
   }
     case FEXUPL:
       if (std::is_same<int32_t, T_int>::value) {
         FEXUP_DF(i + kMSALanesWord)
       } else {
-        return bit_cast<int64_t>(
-            static_cast<double>(bit_cast<float>(ws.w[i + kMSALanesDword])));
+        return base::bit_cast<int64_t>(static_cast<double>(
+            base::bit_cast<float>(ws.w[i + kMSALanesDword])));
       }
     case FEXUPR:
       if (std::is_same<int32_t, T_int>::value) {
         FEXUP_DF(i)
       } else {
-        return bit_cast<int64_t>(static_cast<double>(bit_cast<float>(ws.w[i])));
+        return base::bit_cast<int64_t>(
+            static_cast<double>(base::bit_cast<float>(ws.w[i])));
       }
     case FFQL: {
       if (std::is_same<int32_t, T_int>::value) {
-        return bit_cast<int32_t>(static_cast<float>(ws.h[i + kMSALanesWord]) /
-                                 (1U << 15));
+        return base::bit_cast<int32_t>(
+            static_cast<float>(ws.h[i + kMSALanesWord]) / (1U << 15));
       } else {
-        return bit_cast<int64_t>(static_cast<double>(ws.w[i + kMSALanesDword]) /
-                                 (1U << 31));
+        return base::bit_cast<int64_t>(
+            static_cast<double>(ws.w[i + kMSALanesDword]) / (1U << 31));
       }
       break;
     }
     case FFQR: {
       if (std::is_same<int32_t, T_int>::value) {
-        return bit_cast<int32_t>(static_cast<float>(ws.h[i]) / (1U << 15));
+        return base::bit_cast<int32_t>(static_cast<float>(ws.h[i]) /
+                                       (1U << 15));
       } else {
-        return bit_cast<int64_t>(static_cast<double>(ws.w[i]) / (1U << 31));
+        return base::bit_cast<int64_t>(static_cast<double>(ws.w[i]) /
+                                       (1U << 31));
       }
       break;
       default:
diff --git a/src/execution/mips64/simulator-mips64.cc b/src/execution/mips64/simulator-mips64.cc
index 0f927307b5f..6abe0a74f7b 100644
--- a/src/execution/mips64/simulator-mips64.cc
+++ b/src/execution/mips64/simulator-mips64.cc
@@ -906,12 +906,12 @@ void Simulator::set_fpu_register_hi_word(int fpureg, int32_t value) {
 
 void Simulator::set_fpu_register_float(int fpureg, float value) {
   DCHECK((fpureg >= 0) && (fpureg < kNumFPURegisters));
-  *bit_cast<float*>(&FPUregisters_[fpureg * 2]) = value;
+  *base::bit_cast<float*>(&FPUregisters_[fpureg * 2]) = value;
 }
 
 void Simulator::set_fpu_register_double(int fpureg, double value) {
   DCHECK((fpureg >= 0) && (fpureg < kNumFPURegisters));
-  *bit_cast<double*>(&FPUregisters_[fpureg * 2]) = value;
+  *base::bit_cast<double*>(&FPUregisters_[fpureg * 2]) = value;
 }
 
 // Get the register from the architecture state. This function does handle
@@ -959,12 +959,13 @@ int32_t Simulator::get_fpu_register_hi_word(int fpureg) const {
 
 float Simulator::get_fpu_register_float(int fpureg) const {
   DCHECK((fpureg >= 0) && (fpureg < kNumFPURegisters));
-  return *bit_cast<float*>(const_cast<int64_t*>(&FPUregisters_[fpureg * 2]));
+  return *base::bit_cast<float*>(
+      const_cast<int64_t*>(&FPUregisters_[fpureg * 2]));
 }
 
 double Simulator::get_fpu_register_double(int fpureg) const {
   DCHECK((fpureg >= 0) && (fpureg < kNumFPURegisters));
-  return *bit_cast<double*>(&FPUregisters_[fpureg * 2]);
+  return *base::bit_cast<double*>(&FPUregisters_[fpureg * 2]);
 }
 
 template <typename T>
@@ -2827,8 +2828,8 @@ void Simulator::DecodeTypeRegisterSRsType() {
   fs = get_fpu_register_float(fs_reg());
   ft = get_fpu_register_float(ft_reg());
   fd = get_fpu_register_float(fd_reg());
-  int32_t ft_int = bit_cast<int32_t>(ft);
-  int32_t fd_int = bit_cast<int32_t>(fd);
+  int32_t ft_int = base::bit_cast<int32_t>(ft);
+  int32_t fd_int = base::bit_cast<int32_t>(fd);
   uint32_t cc, fcsr_cc;
   cc = instr_.FCccValue();
   fcsr_cc = get_fcsr_condition_bit(cc);
@@ -2966,7 +2967,7 @@ void Simulator::DecodeTypeRegisterSRsType() {
       break;
     case CLASS_S: {  // Mips64r6 instruction
       // Convert float input to uint32_t for easier bit manipulation
-      uint32_t classed = bit_cast<uint32_t>(fs);
+      uint32_t classed = base::bit_cast<uint32_t>(fs);
 
       // Extracting sign, exponent and mantissa from the input float
       uint32_t sign = (classed >> 31) & 1;
@@ -3024,7 +3025,7 @@ void Simulator::DecodeTypeRegisterSRsType() {
 
       DCHECK_NE(result, 0);
 
-      fResult = bit_cast<float>(result);
+      fResult = base::bit_cast<float>(result);
       SetFPUFloatResult(fd_reg(), fResult);
       break;
     }
@@ -3206,8 +3207,8 @@ void Simulator::DecodeTypeRegisterDRsType() {
   fd = get_fpu_register_double(fd_reg());
   cc = instr_.FCccValue();
   fcsr_cc = get_fcsr_condition_bit(cc);
-  int64_t ft_int = bit_cast<int64_t>(ft);
-  int64_t fd_int = bit_cast<int64_t>(fd);
+  int64_t ft_int = base::bit_cast<int64_t>(ft);
+  int64_t fd_int = base::bit_cast<int64_t>(fd);
   switch (instr_.FunctionFieldRaw()) {
     case RINT: {
       DCHECK_EQ(kArchVariant, kMips64r6);
@@ -3496,7 +3497,7 @@ void Simulator::DecodeTypeRegisterDRsType() {
     }
     case CLASS_D: {  // Mips64r6 instruction
       // Convert double input to uint64_t for easier bit manipulation
-      uint64_t classed = bit_cast<uint64_t>(fs);
+      uint64_t classed = base::bit_cast<uint64_t>(fs);
 
       // Extracting sign, exponent and mantissa from the input double
       uint32_t sign = (classed >> 63) & 1;
@@ -3554,7 +3555,7 @@ void Simulator::DecodeTypeRegisterDRsType() {
 
       DCHECK_NE(result, 0);
 
-      dResult = bit_cast<double>(result);
+      dResult = base::bit_cast<double>(result);
       SetFPUDoubleResult(fd_reg(), dResult);
       break;
     }
@@ -4967,13 +4968,13 @@ void Simulator::DecodeTypeMsaELM() {
   switch (opcode) {
     case CTCMSA:
       DCHECK_EQ(sa(), kMSACSRRegister);
-      MSACSR_ = bit_cast<uint32_t>(
+      MSACSR_ = base::bit_cast<uint32_t>(
           static_cast<int32_t>(registers_[rd_reg()] & kMaxUInt32));
       TraceRegWr(static_cast<int32_t>(MSACSR_));
       break;
     case CFCMSA:
       DCHECK_EQ(rd_reg(), kMSACSRRegister);
-      SetResult(sa(), static_cast<int64_t>(bit_cast<int32_t>(MSACSR_)));
+      SetResult(sa(), static_cast<int64_t>(base::bit_cast<int32_t>(MSACSR_)));
       break;
     case MOVE_V: {
       msa_reg_t ws;
@@ -5825,44 +5826,44 @@ void Msa3RFInstrHelper(uint32_t opcode, T_reg ws, T_reg wt, T_reg* wd) {
       }
     } break;
     case FADD:
-      *wd = bit_cast<T_int>(s_element + t_element);
+      *wd = base::bit_cast<T_int>(s_element + t_element);
       break;
     case FSUB:
-      *wd = bit_cast<T_int>(s_element - t_element);
+      *wd = base::bit_cast<T_int>(s_element - t_element);
       break;
     case FMUL:
-      *wd = bit_cast<T_int>(s_element * t_element);
+      *wd = base::bit_cast<T_int>(s_element * t_element);
       break;
     case FDIV: {
       if (t_element == 0) {
-        *wd = bit_cast<T_int>(std::numeric_limits<T_fp>::quiet_NaN());
+        *wd = base::bit_cast<T_int>(std::numeric_limits<T_fp>::quiet_NaN());
       } else {
-        *wd = bit_cast<T_int>(s_element / t_element);
+        *wd = base::bit_cast<T_int>(s_element / t_element);
       }
     } break;
     case FMADD:
-      *wd = bit_cast<T_int>(
+      *wd = base::bit_cast<T_int>(
           std::fma(s_element, t_element, *reinterpret_cast<T_fp*>(wd)));
       break;
     case FMSUB:
-      *wd = bit_cast<T_int>(
+      *wd = base::bit_cast<T_int>(
           std::fma(-s_element, t_element, *reinterpret_cast<T_fp*>(wd)));
       break;
     case FEXP2:
-      *wd = bit_cast<T_int>(std::ldexp(s_element, static_cast<int>(wt)));
+      *wd = base::bit_cast<T_int>(std::ldexp(s_element, static_cast<int>(wt)));
       break;
     case FMIN:
-      *wd = bit_cast<T_int>(std::min(s_element, t_element));
+      *wd = base::bit_cast<T_int>(std::min(s_element, t_element));
       break;
     case FMAX:
-      *wd = bit_cast<T_int>(std::max(s_element, t_element));
+      *wd = base::bit_cast<T_int>(std::max(s_element, t_element));
       break;
     case FMIN_A: {
-      *wd = bit_cast<T_int>(
+      *wd = base::bit_cast<T_int>(
           std::fabs(s_element) < std::fabs(t_element) ? s_element : t_element);
     } break;
     case FMAX_A: {
-      *wd = bit_cast<T_int>(
+      *wd = base::bit_cast<T_int>(
           std::fabs(s_element) > std::fabs(t_element) ? s_element : t_element);
     } break;
     case FSOR:
@@ -5897,7 +5898,8 @@ void Msa3RFInstrHelper2(uint32_t opcode, T_reg ws, T_reg wt, T_reg* wd) {
   switch (opcode) {
     case MUL_Q: {
       const T_int_dbl min_fix_dbl =
-          bit_cast<T_uint_dbl>(std::numeric_limits<T_int_dbl>::min()) >> 1U;
+          base::bit_cast<T_uint_dbl>(std::numeric_limits<T_int_dbl>::min()) >>
+          1U;
       const T_int_dbl max_fix_dbl = std::numeric_limits<T_int_dbl>::max() >> 1U;
       if (product == min_fix_dbl) {
         product = max_fix_dbl;
@@ -5916,7 +5918,8 @@ void Msa3RFInstrHelper2(uint32_t opcode, T_reg ws, T_reg wt, T_reg* wd) {
     } break;
     case MULR_Q: {
       const T_int_dbl min_fix_dbl =
-          bit_cast<T_uint_dbl>(std::numeric_limits<T_int_dbl>::min()) >> 1U;
+          base::bit_cast<T_uint_dbl>(std::numeric_limits<T_int_dbl>::min()) >>
+          1U;
       const T_int_dbl max_fix_dbl = std::numeric_limits<T_int_dbl>::max() >> 1U;
       if (product == min_fix_dbl) {
         *wd = static_cast<T_int>(max_fix_dbl >> shift);
@@ -6045,10 +6048,10 @@ void Simulator::DecodeTypeMsa3RF() {
           break;
         case MSA_WORD:
           for (int i = 0; i < kMSALanesDword; i++) {
-            wd.w[i + kMSALanesWord / 2] = bit_cast<int32_t>(
-                static_cast<float>(bit_cast<double>(ws.d[i])));
-            wd.w[i] = bit_cast<int32_t>(
-                static_cast<float>(bit_cast<double>(wt.d[i])));
+            wd.w[i + kMSALanesWord / 2] = base::bit_cast<int32_t>(
+                static_cast<float>(base::bit_cast<double>(ws.d[i])));
+            wd.w[i] = base::bit_cast<int32_t>(
+                static_cast<float>(base::bit_cast<double>(wt.d[i])));
           }
           break;
         default:
@@ -6059,7 +6062,7 @@ void Simulator::DecodeTypeMsa3RF() {
 #undef FEXDO_DF
     case FTQ:
 #define FTQ_DF(source, dst, fp_type, int_type)                  \
-  element = bit_cast<fp_type>(source) *                         \
+  element = base::bit_cast<fp_type>(source) *                   \
             (1U << (sizeof(int_type) * kBitsPerByte - 1));      \
   if (element > std::numeric_limits<int_type>::max()) {         \
     dst = std::numeric_limits<int_type>::max();                 \
@@ -6328,8 +6331,8 @@ void Simulator::DecodeTypeMsa2R() {
 }
 
 #define BIT(n) (0x1LL << n)
-#define QUIET_BIT_S(nan) (bit_cast<int32_t>(nan) & BIT(22))
-#define QUIET_BIT_D(nan) (bit_cast<int64_t>(nan) & BIT(51))
+#define QUIET_BIT_S(nan) (base::bit_cast<int32_t>(nan) & BIT(22))
+#define QUIET_BIT_D(nan) (base::bit_cast<int64_t>(nan) & BIT(51))
 static inline bool isSnan(float fp) { return !QUIET_BIT_S(fp); }
 static inline bool isSnan(double fp) { return !QUIET_BIT_D(fp); }
 #undef QUIET_BIT_S
@@ -6405,7 +6408,7 @@ T_int Msa2RFInstrHelper(uint32_t opcode, T_src src, T_dst* dst,
 #undef POS_SUBNORMAL_BIT
 #undef POS_ZERO_BIT
     case FTRUNC_S: {
-      T_fp element = bit_cast<T_fp>(src);
+      T_fp element = base::bit_cast<T_fp>(src);
       const T_int max_int = std::numeric_limits<T_int>::max();
       const T_int min_int = std::numeric_limits<T_int>::min();
       if (std::isnan(element)) {
@@ -6418,7 +6421,7 @@ T_int Msa2RFInstrHelper(uint32_t opcode, T_src src, T_dst* dst,
       break;
     }
     case FTRUNC_U: {
-      T_fp element = bit_cast<T_fp>(src);
+      T_fp element = base::bit_cast<T_fp>(src);
       const T_uint max_int = std::numeric_limits<T_uint>::max();
       if (std::isnan(element)) {
         *dst = 0;
@@ -6430,61 +6433,62 @@ T_int Msa2RFInstrHelper(uint32_t opcode, T_src src, T_dst* dst,
       break;
     }
     case FSQRT: {
-      T_fp element = bit_cast<T_fp>(src);
+      T_fp element = base::bit_cast<T_fp>(src);
       if (element < 0 || std::isnan(element)) {
-        *dst = bit_cast<T_int>(std::numeric_limits<T_fp>::quiet_NaN());
+        *dst = base::bit_cast<T_int>(std::numeric_limits<T_fp>::quiet_NaN());
       } else {
-        *dst = bit_cast<T_int>(std::sqrt(element));
+        *dst = base::bit_cast<T_int>(std::sqrt(element));
       }
       break;
     }
     case FRSQRT: {
-      T_fp element = bit_cast<T_fp>(src);
+      T_fp element = base::bit_cast<T_fp>(src);
       if (element < 0 || std::isnan(element)) {
-        *dst = bit_cast<T_int>(std::numeric_limits<T_fp>::quiet_NaN());
+        *dst = base::bit_cast<T_int>(std::numeric_limits<T_fp>::quiet_NaN());
       } else {
-        *dst = bit_cast<T_int>(1 / std::sqrt(element));
+        *dst = base::bit_cast<T_int>(1 / std::sqrt(element));
       }
       break;
     }
     case FRCP: {
-      T_fp element = bit_cast<T_fp>(src);
+      T_fp element = base::bit_cast<T_fp>(src);
       if (std::isnan(element)) {
-        *dst = bit_cast<T_int>(std::numeric_limits<T_fp>::quiet_NaN());
+        *dst = base::bit_cast<T_int>(std::numeric_limits<T_fp>::quiet_NaN());
       } else {
-        *dst = bit_cast<T_int>(1 / element);
+        *dst = base::bit_cast<T_int>(1 / element);
       }
       break;
     }
     case FRINT: {
-      T_fp element = bit_cast<T_fp>(src);
+      T_fp element = base::bit_cast<T_fp>(src);
       if (std::isnan(element)) {
-        *dst = bit_cast<T_int>(std::numeric_limits<T_fp>::quiet_NaN());
+        *dst = base::bit_cast<T_int>(std::numeric_limits<T_fp>::quiet_NaN());
       } else {
         T_int dummy;
         sim->round_according_to_msacsr<T_fp, T_int>(element, &element, &dummy);
-        *dst = bit_cast<T_int>(element);
+        *dst = base::bit_cast<T_int>(element);
       }
       break;
     }
     case FLOG2: {
-      T_fp element = bit_cast<T_fp>(src);
+      T_fp element = base::bit_cast<T_fp>(src);
       switch (std::fpclassify(element)) {
         case FP_NORMAL:
         case FP_SUBNORMAL:
-          *dst = bit_cast<T_int>(std::logb(element));
+          *dst = base::bit_cast<T_int>(std::logb(element));
           break;
         case FP_ZERO:
-          *dst = bit_cast<T_int>(-std::numeric_limits<T_fp>::infinity());
+          *dst = base::bit_cast<T_int>(-std::numeric_limits<T_fp>::infinity());
           break;
         case FP_NAN:
-          *dst = bit_cast<T_int>(std::numeric_limits<T_fp>::quiet_NaN());
+          *dst = base::bit_cast<T_int>(std::numeric_limits<T_fp>::quiet_NaN());
           break;
         case FP_INFINITE:
           if (element < 0) {
-            *dst = bit_cast<T_int>(std::numeric_limits<T_fp>::quiet_NaN());
+            *dst =
+                base::bit_cast<T_int>(std::numeric_limits<T_fp>::quiet_NaN());
           } else {
-            *dst = bit_cast<T_int>(std::numeric_limits<T_fp>::infinity());
+            *dst = base::bit_cast<T_int>(std::numeric_limits<T_fp>::infinity());
           }
           break;
         default:
@@ -6493,7 +6497,7 @@ T_int Msa2RFInstrHelper(uint32_t opcode, T_src src, T_dst* dst,
       break;
     }
     case FTINT_S: {
-      T_fp element = bit_cast<T_fp>(src);
+      T_fp element = base::bit_cast<T_fp>(src);
       const T_int max_int = std::numeric_limits<T_int>::max();
       const T_int min_int = std::numeric_limits<T_int>::min();
       if (std::isnan(element)) {
@@ -6506,7 +6510,7 @@ T_int Msa2RFInstrHelper(uint32_t opcode, T_src src, T_dst* dst,
       break;
     }
     case FTINT_U: {
-      T_fp element = bit_cast<T_fp>(src);
+      T_fp element = base::bit_cast<T_fp>(src);
       const T_uint max_uint = std::numeric_limits<T_uint>::max();
       if (std::isnan(element)) {
         *dst = 0;
@@ -6520,11 +6524,12 @@ T_int Msa2RFInstrHelper(uint32_t opcode, T_src src, T_dst* dst,
       break;
     }
     case FFINT_S:
-      *dst = bit_cast<T_int>(static_cast<T_fp>(src));
+      *dst = base::bit_cast<T_int>(static_cast<T_fp>(src));
       break;
     case FFINT_U:
       using uT_src = typename std::make_unsigned<T_src>::type;
-      *dst = bit_cast<T_int>(static_cast<T_fp>(bit_cast<uT_src>(src)));
+      *dst =
+          base::bit_cast<T_int>(static_cast<T_fp>(base::bit_cast<uT_src>(src)));
       break;
     default:
       UNREACHABLE();
@@ -6540,61 +6545,65 @@ T_int Msa2RFInstrHelper2(uint32_t opcode, T_reg ws, int i) {
 #define EXTRACT_FLOAT16_FRAC(fp16) (fp16 & 0x3FF)
 #define PACK_FLOAT32(sign, exp, frac) \
   static_cast<uint32_t>(((sign) << 31) + ((exp) << 23) + (frac))
-#define FEXUP_DF(src_index)                                                   \
-  uint_fast16_t element = ws.uh[src_index];                                   \
-  uint_fast32_t aSign, aFrac;                                                 \
-  int_fast32_t aExp;                                                          \
-  aSign = EXTRACT_FLOAT16_SIGN(element);                                      \
-  aExp = EXTRACT_FLOAT16_EXP(element);                                        \
-  aFrac = EXTRACT_FLOAT16_FRAC(element);                                      \
-  if (V8_LIKELY(aExp && aExp != 0x1F)) {                                      \
-    return PACK_FLOAT32(aSign, aExp + 0x70, aFrac << 13);                     \
-  } else if (aExp == 0x1F) {                                                  \
-    if (aFrac) {                                                              \
-      return bit_cast<int32_t>(std::numeric_limits<float>::quiet_NaN());      \
-    } else {                                                                  \
-      return bit_cast<uint32_t>(std::numeric_limits<float>::infinity()) |     \
-             static_cast<uint32_t>(aSign) << 31;                              \
-    }                                                                         \
-  } else {                                                                    \
-    if (aFrac == 0) {                                                         \
-      return PACK_FLOAT32(aSign, 0, 0);                                       \
-    } else {                                                                  \
-      int_fast16_t shiftCount =                                               \
-          base::bits::CountLeadingZeros32(static_cast<uint32_t>(aFrac)) - 21; \
-      aFrac <<= shiftCount;                                                   \
-      aExp = -shiftCount;                                                     \
-      return PACK_FLOAT32(aSign, aExp + 0x70, aFrac << 13);                   \
-    }                                                                         \
+#define FEXUP_DF(src_index)                                                    \
+  uint_fast16_t element = ws.uh[src_index];                                    \
+  uint_fast32_t aSign, aFrac;                                                  \
+  int_fast32_t aExp;                                                           \
+  aSign = EXTRACT_FLOAT16_SIGN(element);                                       \
+  aExp = EXTRACT_FLOAT16_EXP(element);                                         \
+  aFrac = EXTRACT_FLOAT16_FRAC(element);                                       \
+  if (V8_LIKELY(aExp && aExp != 0x1F)) {                                       \
+    return PACK_FLOAT32(aSign, aExp + 0x70, aFrac << 13);                      \
+  } else if (aExp == 0x1F) {                                                   \
+    if (aFrac) {                                                               \
+      return base::bit_cast<int32_t>(std::numeric_limits<float>::quiet_NaN()); \
+    } else {                                                                   \
+      return base::bit_cast<uint32_t>(                                         \
+                 std::numeric_limits<float>::infinity()) |                     \
+             static_cast<uint32_t>(aSign) << 31;                               \
+    }                                                                          \
+  } else {                                                                     \
+    if (aFrac == 0) {                                                          \
+      return PACK_FLOAT32(aSign, 0, 0);                                        \
+    } else {                                                                   \
+      int_fast16_t shiftCount =                                                \
+          base::bits::CountLeadingZeros32(static_cast<uint32_t>(aFrac)) - 21;  \
+      aFrac <<= shiftCount;                                                    \
+      aExp = -shiftCount;                                                      \
+      return PACK_FLOAT32(aSign, aExp + 0x70, aFrac << 13);                    \
+    }                                                                          \
   }
     case FEXUPL:
       if (std::is_same<int32_t, T_int>::value) {
         FEXUP_DF(i + kMSALanesWord)
       } else {
-        return bit_cast<int64_t>(
-            static_cast<double>(bit_cast<float>(ws.w[i + kMSALanesDword])));
+        return base::bit_cast<int64_t>(static_cast<double>(
+            base::bit_cast<float>(ws.w[i + kMSALanesDword])));
       }
     case FEXUPR:
       if (std::is_same<int32_t, T_int>::value) {
         FEXUP_DF(i)
       } else {
-        return bit_cast<int64_t>(static_cast<double>(bit_cast<float>(ws.w[i])));
+        return base::bit_cast<int64_t>(
+            static_cast<double>(base::bit_cast<float>(ws.w[i])));
       }
     case FFQL: {
       if (std::is_same<int32_t, T_int>::value) {
-        return bit_cast<int32_t>(static_cast<float>(ws.h[i + kMSALanesWord]) /
-                                 (1U << 15));
+        return base::bit_cast<int32_t>(
+            static_cast<float>(ws.h[i + kMSALanesWord]) / (1U << 15));
       } else {
-        return bit_cast<int64_t>(static_cast<double>(ws.w[i + kMSALanesDword]) /
-                                 (1U << 31));
+        return base::bit_cast<int64_t>(
+            static_cast<double>(ws.w[i + kMSALanesDword]) / (1U << 31));
       }
       break;
     }
     case FFQR: {
       if (std::is_same<int32_t, T_int>::value) {
-        return bit_cast<int32_t>(static_cast<float>(ws.h[i]) / (1U << 15));
+        return base::bit_cast<int32_t>(static_cast<float>(ws.h[i]) /
+                                       (1U << 15));
       } else {
-        return bit_cast<int64_t>(static_cast<double>(ws.w[i]) / (1U << 31));
+        return base::bit_cast<int64_t>(static_cast<double>(ws.w[i]) /
+                                       (1U << 31));
       }
       break;
       default:
diff --git a/src/execution/ppc/simulator-ppc.cc b/src/execution/ppc/simulator-ppc.cc
index c31a2c6d33e..2a79184cd93 100644
--- a/src/execution/ppc/simulator-ppc.cc
+++ b/src/execution/ppc/simulator-ppc.cc
@@ -292,7 +292,7 @@ void PPCDebugger::Debug() {
           } else if (strcmp(arg1, "allf") == 0) {
             for (int i = 0; i < DoubleRegister::kNumRegisters; i++) {
               dvalue = GetFPDoubleRegisterValue(i);
-              uint64_t as_words = bit_cast<uint64_t>(dvalue);
+              uint64_t as_words = base::bit_cast<uint64_t>(dvalue);
               PrintF("%3s: %f 0x%08x %08x\n",
                      RegisterName(DoubleRegister::from_code(i)), dvalue,
                      static_cast<uint32_t>(as_words >> 32),
@@ -315,7 +315,7 @@ void PPCDebugger::Debug() {
               PrintF("%s: 0x%08" V8PRIxPTR " %" V8PRIdPTR "\n", arg1, value,
                      value);
             } else if (GetFPDoubleValue(arg1, &dvalue)) {
-              uint64_t as_words = bit_cast<uint64_t>(dvalue);
+              uint64_t as_words = base::bit_cast<uint64_t>(dvalue);
               PrintF("%s: %f 0x%08x %08x\n", arg1, dvalue,
                      static_cast<uint32_t>(as_words >> 32),
                      static_cast<uint32_t>(as_words & 0xFFFFFFFF));
@@ -644,13 +644,13 @@ static bool AllOnOnePage(uintptr_t start, int size) {
 
 static bool is_snan(float input) {
   uint32_t kQuietNanFPBit = 1 << 22;
-  uint32_t InputAsUint = bit_cast<uint32_t>(input);
+  uint32_t InputAsUint = base::bit_cast<uint32_t>(input);
   return isnan(input) && ((InputAsUint & kQuietNanFPBit) == 0);
 }
 
 static bool is_snan(double input) {
   uint64_t kQuietNanDPBit = 1L << 51;
-  uint64_t InputAsUint = bit_cast<uint64_t>(input);
+  uint64_t InputAsUint = base::bit_cast<uint64_t>(input);
   return isnan(input) && ((InputAsUint & kQuietNanDPBit) == 0);
 }
 
@@ -1145,7 +1145,7 @@ void Simulator::SoftwareInterrupt(Instruction* instr) {
         SimulatorRuntimeDirectGetterCall target =
             reinterpret_cast<SimulatorRuntimeDirectGetterCall>(external);
         if (!ABI_PASSES_HANDLES_IN_REGS) {
-          arg[0] = bit_cast<intptr_t>(arg[0]);
+          arg[0] = base::bit_cast<intptr_t>(arg[0]);
         }
         target(arg[0], arg[1]);
       } else if (redirection->type() ==
@@ -1164,7 +1164,7 @@ void Simulator::SoftwareInterrupt(Instruction* instr) {
         SimulatorRuntimeProfilingGetterCall target =
             reinterpret_cast<SimulatorRuntimeProfilingGetterCall>(external);
         if (!ABI_PASSES_HANDLES_IN_REGS) {
-          arg[0] = bit_cast<intptr_t>(arg[0]);
+          arg[0] = base::bit_cast<intptr_t>(arg[0]);
         }
         target(arg[0], arg[1], Redirection::ReverseRedirection(arg[2]));
       } else {
@@ -1550,7 +1550,8 @@ void Simulator::ExecuteGeneric(Instruction* instr) {
       // Read prefix value.
       uint64_t prefix_value = instr->Bits(17, 0);
       // Read suffix (next instruction).
-      Instruction* next_instr = bit_cast<Instruction*>(get_pc() + kInstrSize);
+      Instruction* next_instr =
+          base::bit_cast<Instruction*>(get_pc() + kInstrSize);
       uint16_t suffix_value = next_instr->Bits(15, 0);
       int64_t im_val = SIGN_EXT_IMM34((prefix_value << 16) | suffix_value);
       switch (next_instr->OpcodeBase()) {
@@ -4155,7 +4156,7 @@ void Simulator::ExecuteGeneric(Instruction* instr) {
     case STVX: {
       DECODE_VX_INSTRUCTION(vrs, ra, rb, S)
       GET_ADDRESS(ra, rb, ra_val, rb_val)
-      __int128 vrs_val = bit_cast<__int128>(get_simd_register(vrs).int8);
+      __int128 vrs_val = base::bit_cast<__int128>(get_simd_register(vrs).int8);
       WriteQW((ra_val + rb_val) & 0xFFFFFFFFFFFFFFF0, vrs_val);
       break;
     }
@@ -4187,7 +4188,7 @@ void Simulator::ExecuteGeneric(Instruction* instr) {
       DECODE_VX_INSTRUCTION(vrs, ra, rb, S)
       GET_ADDRESS(ra, rb, ra_val, rb_val)
       intptr_t addr = ra_val + rb_val;
-      __int128 vrs_val = bit_cast<__int128>(get_simd_register(vrs).int8);
+      __int128 vrs_val = base::bit_cast<__int128>(get_simd_register(vrs).int8);
       WriteQW(addr, vrs_val);
       break;
     }
@@ -4242,9 +4243,9 @@ void Simulator::ExecuteGeneric(Instruction* instr) {
     case XXBRQ: {
       int t = instr->RTValue();
       int b = instr->RBValue();
-      __int128 xb_val = bit_cast<__int128>(get_simd_register(b).int8);
+      __int128 xb_val = base::bit_cast<__int128>(get_simd_register(b).int8);
       __int128 xb_val_reversed = __builtin_bswap128(xb_val);
-      simdr_t simdr_xb = bit_cast<simdr_t>(xb_val_reversed);
+      simdr_t simdr_xb = base::bit_cast<simdr_t>(xb_val_reversed);
       set_simd_register(t, simdr_xb);
       break;
     }
@@ -4887,9 +4888,9 @@ void Simulator::ExecuteGeneric(Instruction* instr) {
       int b = instr->RBValue();
       uint64_t double_bits = get_d_register(b);
       // Value is at the high 32 bits of the register.
-      float f =
-          bit_cast<float, uint32_t>(static_cast<uint32_t>(double_bits >> 32));
-      double_bits = bit_cast<uint64_t, double>(static_cast<double>(f));
+      float f = base::bit_cast<float, uint32_t>(
+          static_cast<uint32_t>(double_bits >> 32));
+      double_bits = base::bit_cast<uint64_t, double>(static_cast<double>(f));
       // Preserve snan.
       if (is_snan(f)) {
         double_bits &= 0xFFF7FFFFFFFFFFFFU;  // Clear bit 51.
@@ -4902,7 +4903,7 @@ void Simulator::ExecuteGeneric(Instruction* instr) {
       int b = instr->RBValue();
       double b_val = get_double_from_d_register(b);
       uint64_t float_bits = static_cast<uint64_t>(
-          bit_cast<uint32_t, float>(static_cast<float>(b_val)));
+          base::bit_cast<uint32_t, float>(static_cast<float>(b_val)));
       // Preserve snan.
       if (is_snan(b_val)) {
         float_bits &= 0xFFBFFFFFU;  // Clear bit 22.
@@ -5059,11 +5060,14 @@ void Simulator::ExecuteGeneric(Instruction* instr) {
       int vra = instr->RAValue();
       int vrb = instr->RBValue();
       int vrc = instr->RCValue();
-      unsigned __int128 src_1 = bit_cast<__int128>(get_simd_register(vra).int8);
-      unsigned __int128 src_2 = bit_cast<__int128>(get_simd_register(vrb).int8);
-      unsigned __int128 src_3 = bit_cast<__int128>(get_simd_register(vrc).int8);
+      unsigned __int128 src_1 =
+          base::bit_cast<__int128>(get_simd_register(vra).int8);
+      unsigned __int128 src_2 =
+          base::bit_cast<__int128>(get_simd_register(vrb).int8);
+      unsigned __int128 src_3 =
+          base::bit_cast<__int128>(get_simd_register(vrc).int8);
       unsigned __int128 tmp = (src_1 & ~src_3) | (src_2 & src_3);
-      simdr_t* result = bit_cast<simdr_t*>(&tmp);
+      simdr_t* result = base::bit_cast<simdr_t*>(&tmp);
       set_simd_register(vrt, *result);
       break;
     }
@@ -5093,7 +5097,7 @@ void Simulator::ExecuteGeneric(Instruction* instr) {
       DECODE_VX_INSTRUCTION(t, a, b, T)
       uint16_t result_bits = 0;
       unsigned __int128 src_bits =
-          bit_cast<__int128>(get_simd_register(a).int8);
+          base::bit_cast<__int128>(get_simd_register(a).int8);
       for (int i = 0; i < kSimd128Size; i++) {
         result_bits <<= 1;
         uint8_t selected_bit_index = get_simd_register_by_lane<uint8_t>(b, i);
@@ -5372,7 +5376,7 @@ void Simulator::CallInternal(Address entry) {
   // Prepare to execute the code at entry
   if (ABI_USES_FUNCTION_DESCRIPTORS) {
     // entry is the function descriptor
-    set_pc(*(bit_cast<intptr_t*>(entry)));
+    set_pc(*(base::bit_cast<intptr_t*>(entry)));
   } else {
     // entry is the instruction address
     set_pc(static_cast<intptr_t>(entry));
diff --git a/src/execution/ppc/simulator-ppc.h b/src/execution/ppc/simulator-ppc.h
index 5a781c63a6f..c0586e73b2e 100644
--- a/src/execution/ppc/simulator-ppc.h
+++ b/src/execution/ppc/simulator-ppc.h
@@ -177,11 +177,11 @@ class Simulator : public SimulatorBase {
   double get_double_from_register_pair(int reg);
   void set_d_register_from_double(int dreg, const double dbl) {
     DCHECK(dreg >= 0 && dreg < kNumFPRs);
-    *bit_cast<double*>(&fp_registers_[dreg]) = dbl;
+    *base::bit_cast<double*>(&fp_registers_[dreg]) = dbl;
   }
   double get_double_from_d_register(int dreg) {
     DCHECK(dreg >= 0 && dreg < kNumFPRs);
-    return *bit_cast<double*>(&fp_registers_[dreg]);
+    return *base::bit_cast<double*>(&fp_registers_[dreg]);
   }
   void set_d_register(int dreg, int64_t value) {
     DCHECK(dreg >= 0 && dreg < kNumFPRs);
@@ -434,7 +434,7 @@ class Simulator : public SimulatorBase {
   T get_simd_register_bytes(int reg, int byte_from) {
     // Byte location is reversed in memory.
     int from = kSimd128Size - 1 - (byte_from + sizeof(T) - 1);
-    void* src = bit_cast<uint8_t*>(&simd_registers_[reg]) + from;
+    void* src = base::bit_cast<uint8_t*>(&simd_registers_[reg]) + from;
     T dst;
     memcpy(&dst, src, sizeof(T));
     return dst;
@@ -457,7 +457,7 @@ class Simulator : public SimulatorBase {
   void set_simd_register_bytes(int reg, int byte_from, T value) {
     // Byte location is reversed in memory.
     int from = kSimd128Size - 1 - (byte_from + sizeof(T) - 1);
-    void* dst = bit_cast<uint8_t*>(&simd_registers_[reg]) + from;
+    void* dst = base::bit_cast<uint8_t*>(&simd_registers_[reg]) + from;
     memcpy(dst, &value, sizeof(T));
   }
 
diff --git a/src/execution/riscv64/simulator-riscv64.cc b/src/execution/riscv64/simulator-riscv64.cc
index f4159dae0d3..cd231390157 100644
--- a/src/execution/riscv64/simulator-riscv64.cc
+++ b/src/execution/riscv64/simulator-riscv64.cc
@@ -2296,7 +2296,7 @@ void Simulator::set_fpu_register_float(int fpureg, float value) {
 
 void Simulator::set_fpu_register_double(int fpureg, double value) {
   DCHECK((fpureg >= 0) && (fpureg < kNumFPURegisters));
-  *bit_cast<double*>(&FPUregisters_[fpureg]) = value;
+  *base::bit_cast<double*>(&FPUregisters_[fpureg]) = value;
 }
 
 // Get the register from the architecture state. This function does handle
@@ -2347,12 +2347,12 @@ float Simulator::get_fpu_register_float(int fpureg) const {
   if (!is_boxed_float(FPUregisters_[fpureg])) {
     return std::numeric_limits<float>::quiet_NaN();
   }
-  return *bit_cast<float*>(const_cast<int64_t*>(&FPUregisters_[fpureg]));
+  return *base::bit_cast<float*>(const_cast<int64_t*>(&FPUregisters_[fpureg]));
 }
 
 double Simulator::get_fpu_register_double(int fpureg) const {
   DCHECK((fpureg >= 0) && (fpureg < kNumFPURegisters));
-  return *bit_cast<double*>(&FPUregisters_[fpureg]);
+  return *base::bit_cast<double*>(&FPUregisters_[fpureg]);
 }
 
 #ifdef CAN_USE_RVV_INSTRUCTIONS
@@ -3906,7 +3906,7 @@ void Simulator::DecodeRVRFPType() {
     case RO_FMV_W_X: {
       if (instr_.Funct3Value() == 0b000) {
         // since FMV preserves source bit-pattern, no need to canonize
-        set_frd(bit_cast<float>((uint32_t)rs1()));
+        set_frd(base::bit_cast<float>((uint32_t)rs1()));
       } else {
         UNSUPPORTED();
       }
@@ -4072,7 +4072,7 @@ void Simulator::DecodeRVRFPType() {
         }
 #ifdef V8_TARGET_ARCH_64_BIT
         case 0b000: {  // RO_FMV_X_D
-          set_rd(bit_cast<int64_t>(drs1()));
+          set_rd(base::bit_cast<int64_t>(drs1()));
           break;
         }
 #endif /* V8_TARGET_ARCH_64_BIT */
@@ -4140,7 +4140,7 @@ void Simulator::DecodeRVRFPType() {
     case RO_FMV_D_X: {
       if (instr_.Funct3Value() == 0b000 && instr_.Rs2Value() == 0b00000) {
         // Since FMV preserves source bit-pattern, no need to canonize
-        set_drd(bit_cast<double>(rs1()));
+        set_drd(base::bit_cast<double>(rs1()));
       } else {
         UNSUPPORTED();
       }
diff --git a/src/execution/riscv64/simulator-riscv64.h b/src/execution/riscv64/simulator-riscv64.h
index 532a9eb51e7..56b8d4673a5 100644
--- a/src/execution/riscv64/simulator-riscv64.h
+++ b/src/execution/riscv64/simulator-riscv64.h
@@ -101,8 +101,8 @@ using reg_t = uint64_t;
 #define zext_xlen(x) (((reg_t)(x) << (64 - xlen)) >> (64 - xlen))
 
 #define BIT(n) (0x1LL << n)
-#define QUIET_BIT_S(nan) (bit_cast<int32_t>(nan) & BIT(22))
-#define QUIET_BIT_D(nan) (bit_cast<int64_t>(nan) & BIT(51))
+#define QUIET_BIT_S(nan) (base::bit_cast<int32_t>(nan) & BIT(22))
+#define QUIET_BIT_D(nan) (base::bit_cast<int64_t>(nan) & BIT(51))
 static inline bool isSnan(float fp) { return !QUIET_BIT_S(fp); }
 static inline bool isSnan(double fp) { return !QUIET_BIT_D(fp); }
 #undef QUIET_BIT_S
@@ -157,7 +157,7 @@ inline double fsgnj64(double rs1, double rs2, bool n, bool x) {
 
 inline bool is_boxed_float(int64_t v) { return (uint32_t)((v >> 32) + 1) == 0; }
 inline int64_t box_float(float v) {
-  return (0xFFFFFFFF00000000 | bit_cast<int32_t>(v));
+  return (0xFFFFFFFF00000000 | base::bit_cast<int32_t>(v));
 }
 
 // -----------------------------------------------------------------------------
diff --git a/src/execution/s390/simulator-s390.cc b/src/execution/s390/simulator-s390.cc
index 77b6dd22ba3..aa331ec9d51 100644
--- a/src/execution/s390/simulator-s390.cc
+++ b/src/execution/s390/simulator-s390.cc
@@ -316,7 +316,7 @@ void S390Debugger::Debug() {
           } else if (strcmp(arg1, "allf") == 0) {
             for (int i = 0; i < DoubleRegister::kNumRegisters; i++) {
               float fvalue = GetFPFloatRegisterValue(i);
-              uint32_t as_words = bit_cast<uint32_t>(fvalue);
+              uint32_t as_words = base::bit_cast<uint32_t>(fvalue);
               PrintF("%3s: %f 0x%08x\n",
                      RegisterName(DoubleRegister::from_code(i)), fvalue,
                      as_words);
@@ -324,7 +324,7 @@ void S390Debugger::Debug() {
           } else if (strcmp(arg1, "alld") == 0) {
             for (int i = 0; i < DoubleRegister::kNumRegisters; i++) {
               dvalue = GetFPDoubleRegisterValue(i);
-              uint64_t as_words = bit_cast<uint64_t>(dvalue);
+              uint64_t as_words = base::bit_cast<uint64_t>(dvalue);
               PrintF("%3s: %f 0x%08x %08x\n",
                      RegisterName(DoubleRegister::from_code(i)), dvalue,
                      static_cast<uint32_t>(as_words >> 32),
@@ -347,7 +347,7 @@ void S390Debugger::Debug() {
               PrintF("%s: 0x%08" V8PRIxPTR " %" V8PRIdPTR "\n", arg1, value,
                      value);
             } else if (GetFPDoubleValue(arg1, &dvalue)) {
-              uint64_t as_words = bit_cast<uint64_t>(dvalue);
+              uint64_t as_words = base::bit_cast<uint64_t>(dvalue);
               PrintF("%s: %f 0x%08x %08x\n", arg1, dvalue,
                      static_cast<uint32_t>(as_words >> 32),
                      static_cast<uint32_t>(as_words & 0xFFFFFFFF));
@@ -2009,8 +2009,8 @@ void Simulator::SoftwareInterrupt(Instruction* instr) {
           (redirection->type() == ExternalReference::BUILTIN_FP_INT_CALL);
 
       // Place the return address on the stack, making the call GC safe.
-      *bit_cast<intptr_t*>(get_register(sp) +
-                           kStackFrameRASlot * kSystemPointerSize) =
+      *base::bit_cast<intptr_t*>(get_register(sp) +
+                                 kStackFrameRASlot * kSystemPointerSize) =
           get_register(r14);
 
       intptr_t external =
@@ -2147,7 +2147,7 @@ void Simulator::SoftwareInterrupt(Instruction* instr) {
         SimulatorRuntimeDirectGetterCall target =
             reinterpret_cast<SimulatorRuntimeDirectGetterCall>(external);
         if (!ABI_PASSES_HANDLES_IN_REGS) {
-          arg[0] = bit_cast<intptr_t>(arg[0]);
+          arg[0] = base::bit_cast<intptr_t>(arg[0]);
         }
         target(arg[0], arg[1]);
       } else if (redirection->type() ==
@@ -2166,7 +2166,7 @@ void Simulator::SoftwareInterrupt(Instruction* instr) {
         SimulatorRuntimeProfilingGetterCall target =
             reinterpret_cast<SimulatorRuntimeProfilingGetterCall>(external);
         if (!ABI_PASSES_HANDLES_IN_REGS) {
-          arg[0] = bit_cast<intptr_t>(arg[0]);
+          arg[0] = base::bit_cast<intptr_t>(arg[0]);
         }
         target(arg[0], arg[1], Redirection::ReverseRedirection(arg[2]));
       } else {
@@ -2294,7 +2294,7 @@ void Simulator::SoftwareInterrupt(Instruction* instr) {
         //         }
         // #endif
       }
-      int64_t saved_lr = *bit_cast<intptr_t*>(
+      int64_t saved_lr = *base::bit_cast<intptr_t*>(
           get_register(sp) + kStackFrameRASlot * kSystemPointerSize);
 #if (!V8_TARGET_ARCH_S390X && V8_HOST_ARCH_S390)
       // On zLinux-31, the saved_lr might be tagged with a high bit of 1.
@@ -2511,7 +2511,7 @@ void Simulator::CallInternal(Address entry, int reg_arg_count) {
   // Prepare to execute the code at entry
   if (ABI_USES_FUNCTION_DESCRIPTORS) {
     // entry is the function descriptor
-    set_pc(*(bit_cast<intptr_t*>(entry)));
+    set_pc(*(base::bit_cast<intptr_t*>(entry)));
   } else {
     // entry is the instruction address
     set_pc(static_cast<intptr_t>(entry));
@@ -2633,7 +2633,7 @@ intptr_t Simulator::CallImpl(Address entry, int argument_count,
 // Prepare to execute the code at entry
 #if ABI_USES_FUNCTION_DESCRIPTORS
   // entry is the function descriptor
-  set_pc(*(bit_cast<intptr_t*>(entry)));
+  set_pc(*(base::bit_cast<intptr_t*>(entry)));
 #else
   // entry is the instruction address
   set_pc(static_cast<intptr_t>(entry));
@@ -3160,12 +3160,12 @@ EVALUATE(VLREP) {
   DCHECK_OPCODE(VLREP);
   DECODE_VRX_INSTRUCTION(r1, x2, b2, d2, m3);
   intptr_t addr = GET_ADDRESS(x2, b2, d2);
-#define CASE(i, type)                                                 \
-  case i: {                                                           \
-    FOR_EACH_LANE(j, type) {                                          \
-      set_simd_register_by_lane<type>(r1, j, *bit_cast<type*>(addr)); \
-    }                                                                 \
-    break;                                                            \
+#define CASE(i, type)                                                       \
+  case i: {                                                                 \
+    FOR_EACH_LANE(j, type) {                                                \
+      set_simd_register_by_lane<type>(r1, j, *base::bit_cast<type*>(addr)); \
+    }                                                                       \
+    break;                                                                  \
   }
   switch (m3) {
     CASE(0, uint8_t);
@@ -4030,7 +4030,8 @@ EVALUATE(VBPERM) {
   USE(m5);
   USE(m6);
   uint16_t result_bits = 0;
-  unsigned __int128 src_bits = bit_cast<__int128>(get_simd_register(r2).int8);
+  unsigned __int128 src_bits =
+      base::bit_cast<__int128>(get_simd_register(r2).int8);
   for (int i = 0; i < kSimd128Size; i++) {
     result_bits <<= 1;
     uint8_t selected_bit_index = get_simd_register_by_lane<uint8_t>(r3, i);
@@ -4055,11 +4056,14 @@ EVALUATE(VSEL) {
   DECODE_VRR_E_INSTRUCTION(r1, r2, r3, r4, m6, m5);
   USE(m5);
   USE(m6);
-  unsigned __int128 src_1 = bit_cast<__int128>(get_simd_register(r2).int8);
-  unsigned __int128 src_2 = bit_cast<__int128>(get_simd_register(r3).int8);
-  unsigned __int128 src_3 = bit_cast<__int128>(get_simd_register(r4).int8);
+  unsigned __int128 src_1 =
+      base::bit_cast<__int128>(get_simd_register(r2).int8);
+  unsigned __int128 src_2 =
+      base::bit_cast<__int128>(get_simd_register(r3).int8);
+  unsigned __int128 src_3 =
+      base::bit_cast<__int128>(get_simd_register(r4).int8);
   unsigned __int128 tmp = (src_1 & src_3) | (src_2 & ~src_3);
-  fpr_t* result = bit_cast<fpr_t*>(&tmp);
+  fpr_t* result = base::bit_cast<fpr_t*>(&tmp);
   set_simd_register(r1, *result);
   return length;
 }
@@ -5582,7 +5586,7 @@ EVALUATE(LD) {
   int64_t b2_val = (b2 == 0) ? 0 : get_register(b2);
   int64_t x2_val = (x2 == 0) ? 0 : get_register(x2);
   intptr_t addr = b2_val + x2_val + d2_val;
-  int64_t dbl_val = *bit_cast<int64_t*>(addr);
+  int64_t dbl_val = *base::bit_cast<int64_t*>(addr);
   set_fpr(r1, dbl_val);
   return length;
 }
@@ -5621,7 +5625,7 @@ EVALUATE(LE) {
   int64_t b2_val = (b2 == 0) ? 0 : get_register(b2);
   int64_t x2_val = (x2 == 0) ? 0 : get_register(x2);
   intptr_t addr = b2_val + x2_val + d2_val;
-  float float_val = *bit_cast<float*>(addr);
+  float float_val = *base::bit_cast<float*>(addr);
   set_fpr(r1, float_val);
   return length;
 }
@@ -7303,7 +7307,7 @@ EVALUATE(LTDBR) {
   DCHECK_OPCODE(LTDBR);
   DECODE_RRE_INSTRUCTION(r1, r2);
   int64_t r2_val = get_fpr<int64_t>(r2);
-  SetS390ConditionCode<double>(bit_cast<double, int64_t>(r2_val), 0.0);
+  SetS390ConditionCode<double>(base::bit_cast<double, int64_t>(r2_val), 0.0);
   set_fpr(r1, r2_val);
   return length;
 }
@@ -11302,7 +11306,7 @@ EVALUATE(LEY) {
   int64_t x2_val = (x2 == 0) ? 0 : get_register(x2);
   int64_t b2_val = (b2 == 0) ? 0 : get_register(b2);
   intptr_t addr = x2_val + b2_val + d2;
-  float float_val = *bit_cast<float*>(addr);
+  float float_val = *base::bit_cast<float*>(addr);
   set_fpr(r1, float_val);
   return length;
 }
@@ -11314,7 +11318,7 @@ EVALUATE(LDY) {
   int64_t x2_val = (x2 == 0) ? 0 : get_register(x2);
   int64_t b2_val = (b2 == 0) ? 0 : get_register(b2);
   intptr_t addr = x2_val + b2_val + d2;
-  uint64_t dbl_val = *bit_cast<uint64_t*>(addr);
+  uint64_t dbl_val = *base::bit_cast<uint64_t*>(addr);
   set_fpr(r1, dbl_val);
   return length;
 }
diff --git a/src/execution/stack-guard.h b/src/execution/stack-guard.h
index b115b9b7438..4c70ab15988 100644
--- a/src/execution/stack-guard.h
+++ b/src/execution/stack-guard.h
@@ -163,14 +163,14 @@ class V8_EXPORT_PRIVATE V8_NODISCARD StackGuard final {
     base::AtomicWord climit_ = kIllegalLimit;
 
     uintptr_t jslimit() {
-      return bit_cast<uintptr_t>(base::Relaxed_Load(&jslimit_));
+      return base::bit_cast<uintptr_t>(base::Relaxed_Load(&jslimit_));
     }
     void set_jslimit(uintptr_t limit) {
       return base::Relaxed_Store(&jslimit_,
                                  static_cast<base::AtomicWord>(limit));
     }
     uintptr_t climit() {
-      return bit_cast<uintptr_t>(base::Relaxed_Load(&climit_));
+      return base::bit_cast<uintptr_t>(base::Relaxed_Load(&climit_));
     }
     void set_climit(uintptr_t limit) {
       return base::Relaxed_Store(&climit_,
diff --git a/src/handles/handles.h b/src/handles/handles.h
index 8d4399477e9..0d2bdb078fb 100644
--- a/src/handles/handles.h
+++ b/src/handles/handles.h
@@ -52,7 +52,9 @@ class HandleBase {
 
   // Returns the raw address where this handle is stored. This should only be
   // used for hashing handles; do not ever try to dereference it.
-  V8_INLINE Address address() const { return bit_cast<Address>(location_); }
+  V8_INLINE Address address() const {
+    return base::bit_cast<Address>(location_);
+  }
 
   // Returns the address to where the raw pointer is stored.
   // TODO(leszeks): This should probably be a const Address*, to encourage using
diff --git a/src/heap/factory.cc b/src/heap/factory.cc
index e147315afea..32e53098812 100644
--- a/src/heap/factory.cc
+++ b/src/heap/factory.cc
@@ -3220,7 +3220,7 @@ V8_INLINE int NumberToStringCacheHash(Handle<FixedArray> cache, Smi number) {
 
 V8_INLINE int NumberToStringCacheHash(Handle<FixedArray> cache, double number) {
   int mask = (cache->length() >> 1) - 1;
-  int64_t bits = bit_cast<int64_t>(number);
+  int64_t bits = base::bit_cast<int64_t>(number);
   return (static_cast<int>(bits) ^ static_cast<int>(bits >> 32)) & mask;
 }
 
diff --git a/src/inspector/value-mirror.cc b/src/inspector/value-mirror.cc
index df4ed3629ff..358bc4f474b 100644
--- a/src/inspector/value-mirror.cc
+++ b/src/inspector/value-mirror.cc
@@ -95,7 +95,8 @@ std::unique_ptr<protocol::FundamentalValue> toProtocolValue(
     double doubleValue) {
   if (doubleValue >= std::numeric_limits<int>::min() &&
       doubleValue <= std::numeric_limits<int>::max() &&
-      bit_cast<int64_t>(doubleValue) != bit_cast<int64_t>(-0.0)) {
+      v8::base::bit_cast<int64_t>(doubleValue) !=
+          v8::base::bit_cast<int64_t>(-0.0)) {
     int intValue = static_cast<int>(doubleValue);
     if (intValue == doubleValue) {
       return protocol::FundamentalValue::create(intValue);
diff --git a/src/json/json-parser.cc b/src/json/json-parser.cc
index 03dd2938852..ac8c82a2940 100644
--- a/src/json/json-parser.cc
+++ b/src/json/json-parser.cc
@@ -608,7 +608,7 @@ Handle<Object> JsonParser<Char>::BuildJsonObject(
           }
 
           uint64_t bits =
-              bit_cast<uint64_t>(static_cast<double>(Smi::ToInt(value)));
+              base::bit_cast<uint64_t>(static_cast<double>(Smi::ToInt(value)));
           // Allocate simple heapnumber with immortal map, with non-pointer
           // payload, so we can skip notifying object layout change.
 
diff --git a/src/numbers/conversions-inl.h b/src/numbers/conversions-inl.h
index 8bfeb4787d0..24a1daeab03 100644
--- a/src/numbers/conversions-inl.h
+++ b/src/numbers/conversions-inl.h
@@ -183,7 +183,7 @@ bool DoubleToUint32IfEqualToSelf(double value, uint32_t* uint32_value) {
   // exponent and remaining significand bits are valid, and only then check the
   // value in the bottom 32 bits.
 
-  uint64_t result = bit_cast<uint64_t>(shifted_value);
+  uint64_t result = base::bit_cast<uint64_t>(shifted_value);
   if ((result >> 32) == kValidTopBits) {
     *uint32_value = result & kBottomBitMask;
     return FastUI2D(result & kBottomBitMask) == value;
diff --git a/src/numbers/conversions.cc b/src/numbers/conversions.cc
index 0683402794d..2b9106180e2 100644
--- a/src/numbers/conversions.cc
+++ b/src/numbers/conversions.cc
@@ -140,7 +140,7 @@ class SimpleStringBuilder {
 };
 
 inline double JunkStringValue() {
-  return bit_cast<double, uint64_t>(kQuietNaNMask);
+  return base::bit_cast<double, uint64_t>(kQuietNaNMask);
 }
 
 inline double SignedZero(bool negative) {
diff --git a/src/numbers/conversions.h b/src/numbers/conversions.h
index 9232de93caf..3300d2a8c9c 100644
--- a/src/numbers/conversions.h
+++ b/src/numbers/conversions.h
@@ -131,7 +131,7 @@ char* DoubleToPrecisionCString(double value, int f);
 char* DoubleToRadixCString(double value, int radix);
 
 static inline bool IsMinusZero(double value) {
-  return bit_cast<int64_t>(value) == bit_cast<int64_t>(-0.0);
+  return base::bit_cast<int64_t>(value) == base::bit_cast<int64_t>(-0.0);
 }
 
 // Returns true if value can be converted to a SMI, and returns the resulting
diff --git a/src/objects/bigint.cc b/src/objects/bigint.cc
index f24a1548871..a296b1406f1 100644
--- a/src/objects/bigint.cc
+++ b/src/objects/bigint.cc
@@ -221,7 +221,7 @@ Handle<BigInt> MutableBigInt::NewFromDouble(Isolate* isolate, double value) {
   if (value == 0) return Zero(isolate);
 
   bool sign = value < 0;  // -0 was already handled above.
-  uint64_t double_bits = bit_cast<uint64_t>(value);
+  uint64_t double_bits = base::bit_cast<uint64_t>(value);
   int raw_exponent =
       static_cast<int>(double_bits >> base::Double::kPhysicalSignificandSize) &
       0x7FF;
@@ -833,7 +833,7 @@ ComparisonResult BigInt::CompareToDouble(Handle<BigInt> x, double y) {
     DCHECK(!y_sign);
     return ComparisonResult::kLessThan;
   }
-  uint64_t double_bits = bit_cast<uint64_t>(y);
+  uint64_t double_bits = base::bit_cast<uint64_t>(y);
   int raw_exponent =
       static_cast<int>(double_bits >> base::Double::kPhysicalSignificandSize) &
       0x7FF;
@@ -1137,7 +1137,7 @@ double MutableBigInt::ToDouble(Handle<BigIntBase> x) {
   uint64_t sign_bit = x->sign() ? (static_cast<uint64_t>(1) << 63) : 0;
   exponent = (exponent + 0x3FF) << base::Double::kPhysicalSignificandSize;
   uint64_t double_bits = sign_bit | exponent | mantissa;
-  return bit_cast<double>(double_bits);
+  return base::bit_cast<double>(double_bits);
 }
 
 // This is its own function to simplify control flow. The meaning of the
diff --git a/src/objects/bigint.h b/src/objects/bigint.h
index 58856d737ef..016fad90cfb 100644
--- a/src/objects/bigint.h
+++ b/src/objects/bigint.h
@@ -127,7 +127,7 @@ class FreshlyAllocatedBigInt : public BigIntBase {
  public:
   inline static FreshlyAllocatedBigInt cast(Object object);
   inline static FreshlyAllocatedBigInt unchecked_cast(Object o) {
-    return bit_cast<FreshlyAllocatedBigInt>(o);
+    return base::bit_cast<FreshlyAllocatedBigInt>(o);
   }
 
   // Clear uninitialized padding space.
diff --git a/src/objects/free-space-inl.h b/src/objects/free-space-inl.h
index 443ff25caa6..9a2a00f729e 100644
--- a/src/objects/free-space-inl.h
+++ b/src/objects/free-space-inl.h
@@ -39,11 +39,11 @@ void FreeSpace::set_next(FreeSpace next) {
 FreeSpace FreeSpace::cast(HeapObject o) {
   SLOW_DCHECK((!GetHeapFromWritableObject(o)->deserialization_complete()) ||
               o.IsFreeSpace());
-  return bit_cast<FreeSpace>(o);
+  return base::bit_cast<FreeSpace>(o);
 }
 
 FreeSpace FreeSpace::unchecked_cast(const Object o) {
-  return bit_cast<FreeSpace>(o);
+  return base::bit_cast<FreeSpace>(o);
 }
 
 bool FreeSpace::IsValid() {
diff --git a/src/objects/js-objects-inl.h b/src/objects/js-objects-inl.h
index 2f90c818613..c4c4ba6232e 100644
--- a/src/objects/js-objects-inl.h
+++ b/src/objects/js-objects-inl.h
@@ -458,12 +458,13 @@ void JSObject::WriteToField(InternalIndex descriptor, PropertyDetails details,
   FieldIndex index = FieldIndex::ForDescriptor(map(), descriptor);
   if (details.representation().IsDouble()) {
     // Manipulating the signaling NaN used for the hole and uninitialized
-    // double field sentinel in C++, e.g. with bit_cast or value()/set_value(),
-    // will change its value on ia32 (the x87 stack is used to return values
-    // and stores to the stack silently clear the signalling bit).
+    // double field sentinel in C++, e.g. with base::bit_cast or
+    // value()/set_value(), will change its value on ia32 (the x87 stack is used
+    // to return values and stores to the stack silently clear the signalling
+    // bit).
     uint64_t bits;
     if (value.IsSmi()) {
-      bits = bit_cast<uint64_t>(static_cast<double>(Smi::ToInt(value)));
+      bits = base::bit_cast<uint64_t>(static_cast<double>(Smi::ToInt(value)));
     } else if (value.IsUninitialized()) {
       bits = kHoleNanInt64;
     } else {
diff --git a/src/objects/lookup.cc b/src/objects/lookup.cc
index 81f83302e7b..bb81e182f5c 100644
--- a/src/objects/lookup.cc
+++ b/src/objects/lookup.cc
@@ -962,14 +962,15 @@ bool LookupIterator::IsConstFieldValueEqualTo(Object value) const {
     bits = HeapNumber::cast(current_value).value_as_bits(kRelaxedLoad);
     // Use bit representation of double to check for hole double, since
     // manipulating the signaling NaN used for the hole in C++, e.g. with
-    // bit_cast or value(), will change its value on ia32 (the x87 stack is
-    // used to return values and stores to the stack silently clear the
+    // base::bit_cast or value(), will change its value on ia32 (the x87
+    // stack is used to return values and stores to the stack silently clear the
     // signalling bit).
     if (bits == kHoleNanInt64) {
       // Uninitialized double field.
       return true;
     }
-    return Object::SameNumberValue(bit_cast<double>(bits), value.Number());
+    return Object::SameNumberValue(base::bit_cast<double>(bits),
+                                   value.Number());
   } else {
     Object current_value = holder->RawFastPropertyAt(isolate_, field_index);
     if (current_value.IsUninitialized(isolate()) || current_value == value) {
diff --git a/src/objects/managed.h b/src/objects/managed.h
index b681230ba23..ba350a26735 100644
--- a/src/objects/managed.h
+++ b/src/objects/managed.h
@@ -58,7 +58,9 @@ class Managed : public Foreign {
   V8_INLINE const std::shared_ptr<CppType>& get() { return *GetSharedPtrPtr(); }
 
   static Managed cast(Object obj) { return Managed(obj.ptr()); }
-  static Managed unchecked_cast(Object obj) { return bit_cast<Managed>(obj); }
+  static Managed unchecked_cast(Object obj) {
+    return base::bit_cast<Managed>(obj);
+  }
 
   // Allocate a new {CppType} and wrap it in a {Managed<CppType>}.
   template <typename... Args>
diff --git a/src/objects/object-macros.h b/src/objects/object-macros.h
index 10cbdc720b9..0a261c4a4a9 100644
--- a/src/objects/object-macros.h
+++ b/src/objects/object-macros.h
@@ -155,7 +155,7 @@
 #define DECL_CAST(Type)                                 \
   V8_INLINE static Type cast(Object object);            \
   V8_INLINE static Type unchecked_cast(Object object) { \
-    return bit_cast<Type>(object);                      \
+    return base::bit_cast<Type>(object);                \
   }
 
 #define CAST_ACCESSOR(Type) \
diff --git a/src/runtime/runtime-atomics.cc b/src/runtime/runtime-atomics.cc
index 613a7bcd850..f1214325b05 100644
--- a/src/runtime/runtime-atomics.cc
+++ b/src/runtime/runtime-atomics.cc
@@ -140,35 +140,35 @@ inline T XorSeqCst(T* p, T value) {
 #define InterlockedExchange8 _InterlockedExchange8
 #endif
 
-#define ATOMIC_OPS(type, suffix, vctype)                                    \
-  inline type ExchangeSeqCst(type* p, type value) {                         \
-    return InterlockedExchange##suffix(reinterpret_cast<vctype*>(p),        \
-                                       bit_cast<vctype>(value));            \
-  }                                                                         \
-  inline type CompareExchangeSeqCst(type* p, type oldval, type newval) {    \
-    return InterlockedCompareExchange##suffix(reinterpret_cast<vctype*>(p), \
-                                              bit_cast<vctype>(newval),     \
-                                              bit_cast<vctype>(oldval));    \
-  }                                                                         \
-  inline type AddSeqCst(type* p, type value) {                              \
-    return InterlockedExchangeAdd##suffix(reinterpret_cast<vctype*>(p),     \
-                                          bit_cast<vctype>(value));         \
-  }                                                                         \
-  inline type SubSeqCst(type* p, type value) {                              \
-    return InterlockedExchangeAdd##suffix(reinterpret_cast<vctype*>(p),     \
-                                          -bit_cast<vctype>(value));        \
-  }                                                                         \
-  inline type AndSeqCst(type* p, type value) {                              \
-    return InterlockedAnd##suffix(reinterpret_cast<vctype*>(p),             \
-                                  bit_cast<vctype>(value));                 \
-  }                                                                         \
-  inline type OrSeqCst(type* p, type value) {                               \
-    return InterlockedOr##suffix(reinterpret_cast<vctype*>(p),              \
-                                 bit_cast<vctype>(value));                  \
-  }                                                                         \
-  inline type XorSeqCst(type* p, type value) {                              \
-    return InterlockedXor##suffix(reinterpret_cast<vctype*>(p),             \
-                                  bit_cast<vctype>(value));                 \
+#define ATOMIC_OPS(type, suffix, vctype)                                       \
+  inline type ExchangeSeqCst(type* p, type value) {                            \
+    return InterlockedExchange##suffix(reinterpret_cast<vctype*>(p),           \
+                                       base::bit_cast<vctype>(value));         \
+  }                                                                            \
+  inline type CompareExchangeSeqCst(type* p, type oldval, type newval) {       \
+    return InterlockedCompareExchange##suffix(reinterpret_cast<vctype*>(p),    \
+                                              base::bit_cast<vctype>(newval),  \
+                                              base::bit_cast<vctype>(oldval)); \
+  }                                                                            \
+  inline type AddSeqCst(type* p, type value) {                                 \
+    return InterlockedExchangeAdd##suffix(reinterpret_cast<vctype*>(p),        \
+                                          base::bit_cast<vctype>(value));      \
+  }                                                                            \
+  inline type SubSeqCst(type* p, type value) {                                 \
+    return InterlockedExchangeAdd##suffix(reinterpret_cast<vctype*>(p),        \
+                                          -base::bit_cast<vctype>(value));     \
+  }                                                                            \
+  inline type AndSeqCst(type* p, type value) {                                 \
+    return InterlockedAnd##suffix(reinterpret_cast<vctype*>(p),                \
+                                  base::bit_cast<vctype>(value));              \
+  }                                                                            \
+  inline type OrSeqCst(type* p, type value) {                                  \
+    return InterlockedOr##suffix(reinterpret_cast<vctype*>(p),                 \
+                                 base::bit_cast<vctype>(value));               \
+  }                                                                            \
+  inline type XorSeqCst(type* p, type value) {                                 \
+    return InterlockedXor##suffix(reinterpret_cast<vctype*>(p),                \
+                                  base::bit_cast<vctype>(value));              \
   }
 
 ATOMIC_OPS(int8_t, 8, char)
diff --git a/src/snapshot/snapshot-compression.cc b/src/snapshot/snapshot-compression.cc
index 81e983f2635..4c5a61d1410 100644
--- a/src/snapshot/snapshot-compression.cc
+++ b/src/snapshot/snapshot-compression.cc
@@ -41,12 +41,13 @@ SnapshotData SnapshotCompression::Compress(
   // manually store the uncompressed size.
   MemCopy(compressed_data, &payload_length, sizeof(payload_length));
 
-  CHECK_EQ(zlib_internal::CompressHelper(
-               zlib_internal::ZRAW, compressed_data + sizeof(payload_length),
-               &compressed_data_size,
-               bit_cast<const Bytef*>(uncompressed_data->RawData().begin()),
-               input_size, Z_DEFAULT_COMPRESSION, nullptr, nullptr),
-           Z_OK);
+  CHECK_EQ(
+      zlib_internal::CompressHelper(
+          zlib_internal::ZRAW, compressed_data + sizeof(payload_length),
+          &compressed_data_size,
+          base::bit_cast<const Bytef*>(uncompressed_data->RawData().begin()),
+          input_size, Z_DEFAULT_COMPRESSION, nullptr, nullptr),
+      Z_OK);
 
   // Reallocating to exactly the size we need.
   snapshot_data.Resize(static_cast<uint32_t>(compressed_data_size) +
@@ -67,7 +68,8 @@ SnapshotData SnapshotCompression::Decompress(
   base::ElapsedTimer timer;
   if (FLAG_profile_deserialization) timer.Start();
 
-  const Bytef* input_bytef = bit_cast<const Bytef*>(compressed_data.begin());
+  const Bytef* input_bytef =
+      base::bit_cast<const Bytef*>(compressed_data.begin());
 
   // Since we are doing raw compression (no zlib or gzip headers), we need to
   // manually retrieve the uncompressed size.
@@ -79,7 +81,7 @@ SnapshotData SnapshotCompression::Decompress(
   uLongf uncompressed_size = uncompressed_payload_length;
   CHECK_EQ(zlib_internal::UncompressHelper(
                zlib_internal::ZRAW,
-               bit_cast<Bytef*>(snapshot_data.RawData().begin()),
+               base::bit_cast<Bytef*>(snapshot_data.RawData().begin()),
                &uncompressed_size, input_bytef,
                static_cast<uLong>(compressed_data.size() -
                                   sizeof(uncompressed_payload_length))),
diff --git a/src/torque/implementation-visitor.cc b/src/torque/implementation-visitor.cc
index 14b12ec5878..1f233e12614 100644
--- a/src/torque/implementation-visitor.cc
+++ b/src/torque/implementation-visitor.cc
@@ -4286,7 +4286,7 @@ void CppClassGenerator::GenerateClassCasts() {
   // V8_INLINE static D unchecked_cast(Object)
   f.SetName("unchecked_cast");
   f.PrintInlineDefinition(hdr_, [](std::ostream& stream) {
-    stream << "    return bit_cast<D>(object);\n";
+    stream << "    return base::bit_cast<D>(object);\n";
   });
 }
 
diff --git a/src/utils/boxed-float.h b/src/utils/boxed-float.h
index 93f6baee4a6..07cca02ea49 100644
--- a/src/utils/boxed-float.h
+++ b/src/utils/boxed-float.h
@@ -22,15 +22,17 @@ class Float32 {
 
   // This constructor does not guarantee that bit pattern of the input value
   // is preserved if the input is a NaN.
-  explicit Float32(float value) : bit_pattern_(bit_cast<uint32_t>(value)) {
+  explicit Float32(float value)
+      : bit_pattern_(base::bit_cast<uint32_t>(value)) {
     // Check that the provided value is not a NaN, because the bit pattern of a
-    // NaN may be changed by a bit_cast, e.g. for signalling NaNs on ia32.
+    // NaN may be changed by a base::bit_cast, e.g. for signalling NaNs on
+    // ia32.
     DCHECK(!std::isnan(value));
   }
 
   uint32_t get_bits() const { return bit_pattern_; }
 
-  float get_scalar() const { return bit_cast<float>(bit_pattern_); }
+  float get_scalar() const { return base::bit_cast<float>(bit_pattern_); }
 
   bool is_nan() const {
     // Even though {get_scalar()} might flip the quiet NaN bit, it's ok here,
@@ -62,14 +64,16 @@ class Float64 {
 
   // This constructor does not guarantee that bit pattern of the input value
   // is preserved if the input is a NaN.
-  explicit Float64(double value) : bit_pattern_(bit_cast<uint64_t>(value)) {
+  explicit Float64(double value)
+      : bit_pattern_(base::bit_cast<uint64_t>(value)) {
     // Check that the provided value is not a NaN, because the bit pattern of a
-    // NaN may be changed by a bit_cast, e.g. for signalling NaNs on ia32.
+    // NaN may be changed by a base::bit_cast, e.g. for signalling NaNs on
+    // ia32.
     DCHECK(!std::isnan(value));
   }
 
   uint64_t get_bits() const { return bit_pattern_; }
-  double get_scalar() const { return bit_cast<double>(bit_pattern_); }
+  double get_scalar() const { return base::bit_cast<double>(bit_pattern_); }
   bool is_hole_nan() const { return bit_pattern_ == kHoleNanInt64; }
   bool is_nan() const {
     // Even though {get_scalar()} might flip the quiet NaN bit, it's ok here,
diff --git a/src/wasm/baseline/ia32/liftoff-assembler-ia32.h b/src/wasm/baseline/ia32/liftoff-assembler-ia32.h
index 7470bbbcfbc..be3bc10af91 100644
--- a/src/wasm/baseline/ia32/liftoff-assembler-ia32.h
+++ b/src/wasm/baseline/ia32/liftoff-assembler-ia32.h
@@ -490,7 +490,7 @@ void LiftoffAssembler::Load(LiftoffRegister dst, Register src_addr,
       // Compute the operand for the load of the upper half.
       Operand upper_src_op =
           offset_reg == no_reg
-              ? Operand(src_addr, bit_cast<int32_t>(offset_imm + 4))
+              ? Operand(src_addr, base::bit_cast<int32_t>(offset_imm + 4))
               : Operand(src_addr, offset_reg, times_1, offset_imm + 4);
       // The high word has to be mov'ed first, such that this is the protected
       // instruction. The mov of the low word cannot segfault.
@@ -558,7 +558,7 @@ void LiftoffAssembler::Store(Register dst_addr, Register offset_reg,
       // Compute the operand for the store of the upper half.
       Operand upper_dst_op =
           offset_reg == no_reg
-              ? Operand(dst_addr, bit_cast<int32_t>(offset_imm + 4))
+              ? Operand(dst_addr, base::bit_cast<int32_t>(offset_imm + 4))
               : Operand(dst_addr, offset_reg, times_1, offset_imm + 4);
       // The high word has to be mov'ed first, such that this is the protected
       // instruction. The mov of the low word cannot segfault.
diff --git a/src/wasm/function-body-decoder-impl.h b/src/wasm/function-body-decoder-impl.h
index cbb7b4f630b..400111cd850 100644
--- a/src/wasm/function-body-decoder-impl.h
+++ b/src/wasm/function-body-decoder-impl.h
@@ -414,9 +414,9 @@ struct ImmF32Immediate {
   float value;
   uint32_t length = 4;
   ImmF32Immediate(Decoder* decoder, const byte* pc) {
-    // We can't use bit_cast here because calling any helper function that
-    // returns a float would potentially flip NaN bits per C++ semantics, so we
-    // have to inline the memcpy call directly.
+    // We can't use base::bit_cast here because calling any helper function
+    // that returns a float would potentially flip NaN bits per C++ semantics,
+    // so we have to inline the memcpy call directly.
     uint32_t tmp = decoder->read_u32<validate>(pc, "immf32");
     memcpy(&value, &tmp, sizeof(value));
   }
@@ -427,7 +427,8 @@ struct ImmF64Immediate {
   double value;
   uint32_t length = 8;
   ImmF64Immediate(Decoder* decoder, const byte* pc) {
-    // Avoid bit_cast because it might not preserve the signalling bit of a NaN.
+    // Avoid base::bit_cast because it might not preserve the signalling bit
+    // of a NaN.
     uint64_t tmp = decoder->read_u64<validate>(pc, "immf64");
     memcpy(&value, &tmp, sizeof(value));
   }
diff --git a/src/wasm/wasm-external-refs.cc b/src/wasm/wasm-external-refs.cc
index 73f25dbcca2..c9fd2c104d3 100644
--- a/src/wasm/wasm-external-refs.cc
+++ b/src/wasm/wasm-external-refs.cc
@@ -153,7 +153,7 @@ void uint64_to_float32_wrapper(Address data) {
     // the second MSB (a.k.a '<< 23'). The encoded exponent itself is
     // ('actual exponent' - 127).
     int32_t multiplier_bits = ((shift_back - 127) & 0xff) << 23;
-    result *= bit_cast<float>(multiplier_bits);
+    result *= base::bit_cast<float>(multiplier_bits);
     WriteUnalignedValue<float>(data, result);
     return;
   }
diff --git a/src/wasm/wasm-js.cc b/src/wasm/wasm-js.cc
index 7ecab4b61e4..7eef7a4aed9 100644
--- a/src/wasm/wasm-js.cc
+++ b/src/wasm/wasm-js.cc
@@ -1699,14 +1699,14 @@ void EncodeExceptionValues(v8::Isolate* isolate,
       case i::wasm::kF32: {
         float f32 = 0;
         if (!ToF32(value, context, &f32)) return;
-        int32_t i32 = bit_cast<int32_t>(f32);
+        int32_t i32 = base::bit_cast<int32_t>(f32);
         i::EncodeI32ExceptionValue(values_out, &index, i32);
         break;
       }
       case i::wasm::kF64: {
         double f64 = 0;
         if (!ToF64(value, context, &f64)) return;
-        int64_t i64 = bit_cast<int64_t>(f64);
+        int64_t i64 = base::bit_cast<int64_t>(f64);
         i::EncodeI64ExceptionValue(values_out, &index, i64);
         break;
       }
@@ -2320,14 +2320,14 @@ void WebAssemblyExceptionGetArg(
     case i::wasm::kF32: {
       uint32_t f32_bits = 0;
       DecodeI32ExceptionValue(values, &decode_index, &f32_bits);
-      float f32 = bit_cast<float>(f32_bits);
+      float f32 = base::bit_cast<float>(f32_bits);
       result = v8::Number::New(isolate, f32);
       break;
     }
     case i::wasm::kF64: {
       uint64_t f64_bits = 0;
       DecodeI64ExceptionValue(values, &decode_index, &f64_bits);
-      double f64 = bit_cast<double>(f64_bits);
+      double f64 = base::bit_cast<double>(f64_bits);
       result = v8::Number::New(isolate, f64);
       break;
     }
diff --git a/src/wasm/wasm-module-builder.h b/src/wasm/wasm-module-builder.h
index dbf2eb0ccd8..09c0b68c927 100644
--- a/src/wasm/wasm-module-builder.h
+++ b/src/wasm/wasm-module-builder.h
@@ -86,9 +86,9 @@ class ZoneBuffer : public ZoneObject {
     LEBHelper::write_u32v(&pos_, static_cast<uint32_t>(val));
   }
 
-  void write_f32(float val) { write_u32(bit_cast<uint32_t>(val)); }
+  void write_f32(float val) { write_u32(base::bit_cast<uint32_t>(val)); }
 
-  void write_f64(double val) { write_u64(bit_cast<uint64_t>(val)); }
+  void write_f64(double val) { write_u64(base::bit_cast<uint64_t>(val)); }
 
   void write(const byte* data, size_t size) {
     if (size == 0) return;
diff --git a/test/cctest/compiler/test-js-constant-cache.cc b/test/cctest/compiler/test-js-constant-cache.cc
index b1cfe7a5823..709dee1baea 100644
--- a/test/cctest/compiler/test-js-constant-cache.cc
+++ b/test/cctest/compiler/test-js-constant-cache.cc
@@ -87,10 +87,12 @@ TEST(MinusZeroConstant) {
   double zero_value = OpParameter<double>(zero->op());
   double minus_zero_value = OpParameter<double>(minus_zero->op());
 
-  CHECK(bit_cast<uint64_t>(0.0) == bit_cast<uint64_t>(zero_value));
-  CHECK(bit_cast<uint64_t>(-0.0) != bit_cast<uint64_t>(zero_value));
-  CHECK(bit_cast<uint64_t>(0.0) != bit_cast<uint64_t>(minus_zero_value));
-  CHECK(bit_cast<uint64_t>(-0.0) == bit_cast<uint64_t>(minus_zero_value));
+  CHECK(base::bit_cast<uint64_t>(0.0) == base::bit_cast<uint64_t>(zero_value));
+  CHECK(base::bit_cast<uint64_t>(-0.0) != base::bit_cast<uint64_t>(zero_value));
+  CHECK(base::bit_cast<uint64_t>(0.0) !=
+        base::bit_cast<uint64_t>(minus_zero_value));
+  CHECK(base::bit_cast<uint64_t>(-0.0) ==
+        base::bit_cast<uint64_t>(minus_zero_value));
 }
 
 
diff --git a/test/cctest/compiler/test-run-machops.cc b/test/cctest/compiler/test-run-machops.cc
index 7582201d126..122161a7d7e 100644
--- a/test/cctest/compiler/test-run-machops.cc
+++ b/test/cctest/compiler/test-run-machops.cc
@@ -1502,7 +1502,7 @@ TEST(RunInt32AddAndWord32EqualP) {
         FOR_INT32_INPUTS(k) {
           // Use uint32_t because signed overflow is UB in C.
           int32_t const expected =
-              bit_cast<int32_t>(bit_cast<uint32_t>(i) + (j == k));
+              base::bit_cast<int32_t>(base::bit_cast<uint32_t>(i) + (j == k));
           CHECK_EQ(expected, m.Call(i, j, k));
         }
       }
@@ -1518,7 +1518,7 @@ TEST(RunInt32AddAndWord32EqualP) {
         FOR_INT32_INPUTS(k) {
           // Use uint32_t because signed overflow is UB in C.
           int32_t const expected =
-              bit_cast<int32_t>((i == j) + bit_cast<uint32_t>(k));
+              base::bit_cast<int32_t>((i == j) + base::bit_cast<uint32_t>(k));
           CHECK_EQ(expected, m.Call(i, j, k));
         }
       }
@@ -1538,7 +1538,7 @@ TEST(RunInt32AddAndWord32EqualImm) {
     FOR_INT32_INPUTS(k) {
       // Use uint32_t because signed overflow is UB in C.
       int32_t const expected =
-          bit_cast<int32_t>(bit_cast<uint32_t>(i) + (j == k));
+          base::bit_cast<int32_t>(base::bit_cast<uint32_t>(i) + (j == k));
       CHECK_EQ(expected, m.Call(j, k));
     }
   }
@@ -1554,7 +1554,7 @@ TEST(RunInt32AddAndWord32EqualImm) {
         FOR_INT32_INPUTS(k) {
           // Use uint32_t because signed overflow is UB in C.
           int32_t const expected =
-              bit_cast<int32_t>((i == j) + bit_cast<uint32_t>(k));
+              base::bit_cast<int32_t>((i == j) + base::bit_cast<uint32_t>(k));
           CHECK_EQ(expected, m.Call(j, k));
         }
       }
@@ -1574,7 +1574,7 @@ TEST(RunInt32AddAndWord32NotEqualP) {
         FOR_INT32_INPUTS(k) {
           // Use uint32_t because signed overflow is UB in C.
           int32_t const expected =
-              bit_cast<int32_t>(bit_cast<uint32_t>(i) + (j != k));
+              base::bit_cast<int32_t>(base::bit_cast<uint32_t>(i) + (j != k));
           CHECK_EQ(expected, m.Call(i, j, k));
         }
       }
@@ -1590,7 +1590,7 @@ TEST(RunInt32AddAndWord32NotEqualP) {
         FOR_INT32_INPUTS(k) {
           // Use uint32_t because signed overflow is UB in C.
           int32_t const expected =
-              bit_cast<int32_t>((i != j) + bit_cast<uint32_t>(k));
+              base::bit_cast<int32_t>((i != j) + base::bit_cast<uint32_t>(k));
           CHECK_EQ(expected, m.Call(i, j, k));
         }
       }
@@ -1610,7 +1610,7 @@ TEST(RunInt32AddAndWord32NotEqualImm) {
     FOR_INT32_INPUTS(k) {
       // Use uint32_t because signed overflow is UB in C.
       int32_t const expected =
-          bit_cast<int32_t>(bit_cast<uint32_t>(i) + (j != k));
+          base::bit_cast<int32_t>(base::bit_cast<uint32_t>(i) + (j != k));
       CHECK_EQ(expected, m.Call(j, k));
     }
   }
@@ -1626,7 +1626,7 @@ TEST(RunInt32AddAndWord32NotEqualImm) {
         FOR_INT32_INPUTS(k) {
           // Use uint32_t because signed overflow is UB in C.
           int32_t const expected =
-              bit_cast<int32_t>((i != j) + bit_cast<uint32_t>(k));
+              base::bit_cast<int32_t>((i != j) + base::bit_cast<uint32_t>(k));
           CHECK_EQ(expected, m.Call(j, k));
         }
       }
@@ -2466,9 +2466,10 @@ TEST(RunUint32MulHighP) {
   bt.AddReturn(m.Uint32MulHigh(bt.param0, bt.param1));
   FOR_UINT32_INPUTS(i) {
     FOR_UINT32_INPUTS(j) {
-      int32_t expected = bit_cast<int32_t>(static_cast<uint32_t>(
+      int32_t expected = base::bit_cast<int32_t>(static_cast<uint32_t>(
           (static_cast<uint64_t>(i) * static_cast<uint64_t>(j)) >> 32));
-      CHECK_EQ(expected, bt.call(bit_cast<int32_t>(i), bit_cast<int32_t>(j)));
+      CHECK_EQ(expected,
+               bt.call(base::bit_cast<int32_t>(i), base::bit_cast<int32_t>(j)));
     }
   }
 }
@@ -2519,7 +2520,7 @@ TEST(RunUint32DivP) {
         uint32_t p0 = i;
         uint32_t p1 = j;
         if (p1 != 0) {
-          int32_t expected = bit_cast<int32_t>(p0 / p1);
+          int32_t expected = base::bit_cast<int32_t>(p0 / p1);
           CHECK_EQ(expected, bt.call(p0, p1));
         }
       }
@@ -2534,7 +2535,7 @@ TEST(RunUint32DivP) {
         uint32_t p0 = i;
         uint32_t p1 = j;
         if (p1 != 0) {
-          int32_t expected = bit_cast<int32_t>(p0 + (p0 / p1));
+          int32_t expected = base::bit_cast<int32_t>(p0 + (p0 / p1));
           CHECK_EQ(expected, bt.call(p0, p1));
         }
       }
@@ -3553,7 +3554,7 @@ TEST(RunWord32SarP) {
         CHECK_EQ(expected, bt.call(i, shift));
       }
     }
-    CHECK_EQ(bit_cast<int32_t>(0xFFFF0000), bt.call(0x80000000, 15));
+    CHECK_EQ(base::bit_cast<int32_t>(0xFFFF0000), bt.call(0x80000000, 15));
   }
 }
 
@@ -6126,7 +6127,7 @@ TEST(RunFloat64ExtractLowWord32) {
   BufferedRawMachineAssemblerTester<uint32_t> m(MachineType::Float64());
   m.Return(m.Float64ExtractLowWord32(m.Parameter(0)));
   FOR_FLOAT64_INPUTS(i) {
-    uint32_t expected = static_cast<uint32_t>(bit_cast<uint64_t>(i));
+    uint32_t expected = static_cast<uint32_t>(base::bit_cast<uint64_t>(i));
     CHECK_EQ(expected, m.Call(i));
   }
 }
@@ -6136,7 +6137,8 @@ TEST(RunFloat64ExtractHighWord32) {
   BufferedRawMachineAssemblerTester<uint32_t> m(MachineType::Float64());
   m.Return(m.Float64ExtractHighWord32(m.Parameter(0)));
   FOR_FLOAT64_INPUTS(i) {
-    uint32_t expected = static_cast<uint32_t>(bit_cast<uint64_t>(i) >> 32);
+    uint32_t expected =
+        static_cast<uint32_t>(base::bit_cast<uint64_t>(i) >> 32);
     CHECK_EQ(expected, m.Call(i));
   }
 }
@@ -6148,9 +6150,9 @@ TEST(RunFloat64InsertLowWord32) {
   m.Return(m.Float64InsertLowWord32(m.Parameter(0), m.Parameter(1)));
   FOR_FLOAT64_INPUTS(i) {
     FOR_INT32_INPUTS(j) {
-      double expected =
-          bit_cast<double>((bit_cast<uint64_t>(i) & ~(uint64_t{0xFFFFFFFF})) |
-                           (static_cast<uint64_t>(bit_cast<uint32_t>(j))));
+      double expected = base::bit_cast<double>(
+          (base::bit_cast<uint64_t>(i) & ~(uint64_t{0xFFFFFFFF})) |
+          (static_cast<uint64_t>(base::bit_cast<uint32_t>(j))));
       CHECK_DOUBLE_EQ(expected, m.Call(i, j));
     }
   }
@@ -6163,10 +6165,10 @@ TEST(RunFloat64InsertHighWord32) {
   m.Return(m.Float64InsertHighWord32(m.Parameter(0), m.Parameter(1)));
   FOR_FLOAT64_INPUTS(i) {
     FOR_UINT32_INPUTS(j) {
-      uint64_t expected = (bit_cast<uint64_t>(i) & 0xFFFFFFFF) |
+      uint64_t expected = (base::bit_cast<uint64_t>(i) & 0xFFFFFFFF) |
                           (static_cast<uint64_t>(j) << 32);
 
-      CHECK_DOUBLE_EQ(bit_cast<double>(expected), m.Call(i, j));
+      CHECK_DOUBLE_EQ(base::bit_cast<double>(expected), m.Call(i, j));
     }
   }
 }
@@ -7048,7 +7050,7 @@ TEST(RunBitcastFloat64ToInt64) {
   BufferedRawMachineAssemblerTester<int64_t> m(MachineType::Float64());
 
   m.Return(m.BitcastFloat64ToInt64(m.Parameter(0)));
-  FOR_FLOAT64_INPUTS(i) { CHECK_EQ(bit_cast<int64_t>(i), m.Call(i)); }
+  FOR_FLOAT64_INPUTS(i) { CHECK_EQ(base::bit_cast<int64_t>(i), m.Call(i)); }
 }
 
 
@@ -7295,7 +7297,8 @@ TEST(RunRoundUint64ToFloat64) {
   m.Return(m.RoundUint64ToFloat64(m.Parameter(0)));
 
   for (size_t i = 0; i < arraysize(values); i++) {
-    CHECK_EQ(bit_cast<double>(values[i].expected), m.Call(values[i].input));
+    CHECK_EQ(base::bit_cast<double>(values[i].expected),
+             m.Call(values[i].input));
   }
 }
 
@@ -7385,7 +7388,8 @@ TEST(RunRoundUint64ToFloat32) {
   m.Return(m.RoundUint64ToFloat32(m.Parameter(0)));
 
   for (size_t i = 0; i < arraysize(values); i++) {
-    CHECK_EQ(bit_cast<float>(values[i].expected), m.Call(values[i].input));
+    CHECK_EQ(base::bit_cast<float>(values[i].expected),
+             m.Call(values[i].input));
   }
 }
 
@@ -7400,7 +7404,7 @@ TEST(RunBitcastFloat32ToInt32) {
       m.LoadFromPointer(&input, MachineType::Float32())));
   FOR_FLOAT32_INPUTS(i) {
     input = i;
-    int32_t expected = bit_cast<int32_t>(input);
+    int32_t expected = base::bit_cast<int32_t>(input);
     CHECK_EQ(expected, m.Call());
   }
 }
diff --git a/test/cctest/test-allocation.cc b/test/cctest/test-allocation.cc
index 0081e8e29c7..032b1160c67 100644
--- a/test/cctest/test-allocation.cc
+++ b/test/cctest/test-allocation.cc
@@ -60,7 +60,8 @@ size_t GetHugeMemoryAmount() {
   static size_t huge_memory = 0;
   if (!huge_memory) {
     for (int i = 0; i < 100; i++) {
-      huge_memory |= bit_cast<size_t>(v8::internal::GetRandomMmapAddr());
+      huge_memory |=
+          v8::base::bit_cast<size_t>(v8::internal::GetRandomMmapAddr());
     }
     // Make it larger than the available address space.
     huge_memory *= 2;
diff --git a/test/cctest/test-assembler-arm.cc b/test/cctest/test-assembler-arm.cc
index 43c5e276e21..bdad7948337 100644
--- a/test/cctest/test-assembler-arm.cc
+++ b/test/cctest/test-assembler-arm.cc
@@ -1171,7 +1171,7 @@ TEST(14) {
   code->Print(os);
 #endif
   auto f = GeneratedCode<F_piiii>::FromCode(*code);
-  t.left = bit_cast<double>(kHoleNanInt64);
+  t.left = base::bit_cast<double>(kHoleNanInt64);
   t.right = 1;
   t.add_result = 0;
   t.sub_result = 0;
@@ -1188,17 +1188,17 @@ TEST(14) {
   // With VFP2 the sign of the canonicalized Nan is undefined. So
   // we remove the sign bit for the upper tests.
   CHECK_EQ(kArmNanUpper32,
-           (bit_cast<int64_t>(t.add_result) >> 32) & 0x7FFFFFFF);
-  CHECK_EQ(kArmNanLower32, bit_cast<int64_t>(t.add_result) & 0xFFFFFFFFu);
+           (base::bit_cast<int64_t>(t.add_result) >> 32) & 0x7FFFFFFF);
+  CHECK_EQ(kArmNanLower32, base::bit_cast<int64_t>(t.add_result) & 0xFFFFFFFFu);
   CHECK_EQ(kArmNanUpper32,
-           (bit_cast<int64_t>(t.sub_result) >> 32) & 0x7FFFFFFF);
-  CHECK_EQ(kArmNanLower32, bit_cast<int64_t>(t.sub_result) & 0xFFFFFFFFu);
+           (base::bit_cast<int64_t>(t.sub_result) >> 32) & 0x7FFFFFFF);
+  CHECK_EQ(kArmNanLower32, base::bit_cast<int64_t>(t.sub_result) & 0xFFFFFFFFu);
   CHECK_EQ(kArmNanUpper32,
-           (bit_cast<int64_t>(t.mul_result) >> 32) & 0x7FFFFFFF);
-  CHECK_EQ(kArmNanLower32, bit_cast<int64_t>(t.mul_result) & 0xFFFFFFFFu);
+           (base::bit_cast<int64_t>(t.mul_result) >> 32) & 0x7FFFFFFF);
+  CHECK_EQ(kArmNanLower32, base::bit_cast<int64_t>(t.mul_result) & 0xFFFFFFFFu);
   CHECK_EQ(kArmNanUpper32,
-           (bit_cast<int64_t>(t.div_result) >> 32) & 0x7FFFFFFF);
-  CHECK_EQ(kArmNanLower32, bit_cast<int64_t>(t.div_result) & 0xFFFFFFFFu);
+           (base::bit_cast<int64_t>(t.div_result) >> 32) & 0x7FFFFFFF);
+  CHECK_EQ(kArmNanLower32, base::bit_cast<int64_t>(t.div_result) & 0xFFFFFFFFu);
 }
 
 #define CHECK_EQ_SPLAT(field, ex) \
@@ -1228,9 +1228,9 @@ TEST(14) {
   CHECK_ESTIMATE(ex, tol, t.field[3]);
 
 #define INT32_TO_FLOAT(val) \
-  std::round(static_cast<float>(bit_cast<int32_t>(val)))
+  std::round(static_cast<float>(base::bit_cast<int32_t>(val)))
 #define UINT32_TO_FLOAT(val) \
-  std::round(static_cast<float>(bit_cast<uint32_t>(val)))
+  std::round(static_cast<float>(base::bit_cast<uint32_t>(val)))
 
 TEST(15) {
   // Test the Neon instructions.
@@ -3155,11 +3155,11 @@ TEST(ARMv8_float32_vrintX) {
     float nan = std::numeric_limits<float>::quiet_NaN();
     t.input = nan;
     f.Call(&t, 0, 0, 0, 0);
-    CHECK_EQ(bit_cast<int32_t>(nan), bit_cast<int32_t>(t.ar));
-    CHECK_EQ(bit_cast<int32_t>(nan), bit_cast<int32_t>(t.nr));
-    CHECK_EQ(bit_cast<int32_t>(nan), bit_cast<int32_t>(t.mr));
-    CHECK_EQ(bit_cast<int32_t>(nan), bit_cast<int32_t>(t.pr));
-    CHECK_EQ(bit_cast<int32_t>(nan), bit_cast<int32_t>(t.zr));
+    CHECK_EQ(base::bit_cast<int32_t>(nan), base::bit_cast<int32_t>(t.ar));
+    CHECK_EQ(base::bit_cast<int32_t>(nan), base::bit_cast<int32_t>(t.nr));
+    CHECK_EQ(base::bit_cast<int32_t>(nan), base::bit_cast<int32_t>(t.mr));
+    CHECK_EQ(base::bit_cast<int32_t>(nan), base::bit_cast<int32_t>(t.pr));
+    CHECK_EQ(base::bit_cast<int32_t>(nan), base::bit_cast<int32_t>(t.zr));
 
 #undef CHECK_VRINT
   }
@@ -3256,11 +3256,11 @@ TEST(ARMv8_vrintX) {
     double nan = std::numeric_limits<double>::quiet_NaN();
     t.input = nan;
     f.Call(&t, 0, 0, 0, 0);
-    CHECK_EQ(bit_cast<int64_t>(nan), bit_cast<int64_t>(t.ar));
-    CHECK_EQ(bit_cast<int64_t>(nan), bit_cast<int64_t>(t.nr));
-    CHECK_EQ(bit_cast<int64_t>(nan), bit_cast<int64_t>(t.mr));
-    CHECK_EQ(bit_cast<int64_t>(nan), bit_cast<int64_t>(t.pr));
-    CHECK_EQ(bit_cast<int64_t>(nan), bit_cast<int64_t>(t.zr));
+    CHECK_EQ(base::bit_cast<int64_t>(nan), base::bit_cast<int64_t>(t.ar));
+    CHECK_EQ(base::bit_cast<int64_t>(nan), base::bit_cast<int64_t>(t.nr));
+    CHECK_EQ(base::bit_cast<int64_t>(nan), base::bit_cast<int64_t>(t.mr));
+    CHECK_EQ(base::bit_cast<int64_t>(nan), base::bit_cast<int64_t>(t.pr));
+    CHECK_EQ(base::bit_cast<int64_t>(nan), base::bit_cast<int64_t>(t.zr));
 
 #undef CHECK_VRINT
   }
@@ -3460,18 +3460,20 @@ TEST(ARMv8_vminmax_f64) {
 #endif
     auto f = GeneratedCode<F_ppiii>::FromCode(*code);
 
-#define CHECK_VMINMAX(left, right, vminnm, vmaxnm)                             \
-  do {                                                                         \
-    Inputs inputs = {left, right};                                             \
-    Results results;                                                           \
-    f.Call(&inputs, &results, 0, 0, 0);                                        \
-    /* Use a bit_cast to correctly identify -0.0 and NaNs. */                  \
-    CHECK_EQ(bit_cast<uint64_t>(vminnm), bit_cast<uint64_t>(results.vminnm_)); \
-    CHECK_EQ(bit_cast<uint64_t>(vmaxnm), bit_cast<uint64_t>(results.vmaxnm_)); \
+#define CHECK_VMINMAX(left, right, vminnm, vmaxnm)                  \
+  do {                                                              \
+    Inputs inputs = {left, right};                                  \
+    Results results;                                                \
+    f.Call(&inputs, &results, 0, 0, 0);                             \
+    /* Use a base::bit_cast to correctly identify -0.0 and NaNs. */ \
+    CHECK_EQ(base::bit_cast<uint64_t>(vminnm),                      \
+             base::bit_cast<uint64_t>(results.vminnm_));            \
+    CHECK_EQ(base::bit_cast<uint64_t>(vmaxnm),                      \
+             base::bit_cast<uint64_t>(results.vmaxnm_));            \
   } while (0);
 
-    double nan_a = bit_cast<double>(UINT64_C(0x7FF8000000000001));
-    double nan_b = bit_cast<double>(UINT64_C(0x7FF8000000000002));
+    double nan_a = base::bit_cast<double>(UINT64_C(0x7FF8000000000001));
+    double nan_b = base::bit_cast<double>(UINT64_C(0x7FF8000000000002));
 
     CHECK_VMINMAX(1.0, -1.0, -1.0, 1.0);
     CHECK_VMINMAX(-1.0, 1.0, -1.0, 1.0);
@@ -3540,18 +3542,20 @@ TEST(ARMv8_vminmax_f32) {
 #endif
     auto f = GeneratedCode<F_ppiii>::FromCode(*code);
 
-#define CHECK_VMINMAX(left, right, vminnm, vmaxnm)                             \
-  do {                                                                         \
-    Inputs inputs = {left, right};                                             \
-    Results results;                                                           \
-    f.Call(&inputs, &results, 0, 0, 0);                                        \
-    /* Use a bit_cast to correctly identify -0.0 and NaNs. */                  \
-    CHECK_EQ(bit_cast<uint32_t>(vminnm), bit_cast<uint32_t>(results.vminnm_)); \
-    CHECK_EQ(bit_cast<uint32_t>(vmaxnm), bit_cast<uint32_t>(results.vmaxnm_)); \
+#define CHECK_VMINMAX(left, right, vminnm, vmaxnm)                  \
+  do {                                                              \
+    Inputs inputs = {left, right};                                  \
+    Results results;                                                \
+    f.Call(&inputs, &results, 0, 0, 0);                             \
+    /* Use a base::bit_cast to correctly identify -0.0 and NaNs. */ \
+    CHECK_EQ(base::bit_cast<uint32_t>(vminnm),                      \
+             base::bit_cast<uint32_t>(results.vminnm_));            \
+    CHECK_EQ(base::bit_cast<uint32_t>(vmaxnm),                      \
+             base::bit_cast<uint32_t>(results.vmaxnm_));            \
   } while (0);
 
-    float nan_a = bit_cast<float>(UINT32_C(0x7FC00001));
-    float nan_b = bit_cast<float>(UINT32_C(0x7FC00002));
+    float nan_a = base::bit_cast<float>(UINT32_C(0x7FC00001));
+    float nan_b = base::bit_cast<float>(UINT32_C(0x7FC00002));
 
     CHECK_VMINMAX(1.0f, -1.0f, -1.0f, 1.0f);
     CHECK_VMINMAX(-1.0f, 1.0f, -1.0f, 1.0f);
@@ -3700,22 +3704,28 @@ TEST(macro_float_minmax_f64) {
 
   auto f = GenerateMacroFloatMinMax<DwVfpRegister, Inputs, Results>(&assm);
 
-#define CHECK_MINMAX(left, right, min, max)                                  \
-  do {                                                                       \
-    Inputs inputs = {left, right};                                           \
-    Results results;                                                         \
-    f.Call(&inputs, &results, 0, 0, 0);                                      \
-    /* Use a bit_cast to correctly identify -0.0 and NaNs. */                \
-    CHECK_EQ(bit_cast<uint64_t>(min), bit_cast<uint64_t>(results.min_abc_)); \
-    CHECK_EQ(bit_cast<uint64_t>(min), bit_cast<uint64_t>(results.min_aab_)); \
-    CHECK_EQ(bit_cast<uint64_t>(min), bit_cast<uint64_t>(results.min_aba_)); \
-    CHECK_EQ(bit_cast<uint64_t>(max), bit_cast<uint64_t>(results.max_abc_)); \
-    CHECK_EQ(bit_cast<uint64_t>(max), bit_cast<uint64_t>(results.max_aab_)); \
-    CHECK_EQ(bit_cast<uint64_t>(max), bit_cast<uint64_t>(results.max_aba_)); \
+#define CHECK_MINMAX(left, right, min, max)                         \
+  do {                                                              \
+    Inputs inputs = {left, right};                                  \
+    Results results;                                                \
+    f.Call(&inputs, &results, 0, 0, 0);                             \
+    /* Use a base::bit_cast to correctly identify -0.0 and NaNs. */ \
+    CHECK_EQ(base::bit_cast<uint64_t>(min),                         \
+             base::bit_cast<uint64_t>(results.min_abc_));           \
+    CHECK_EQ(base::bit_cast<uint64_t>(min),                         \
+             base::bit_cast<uint64_t>(results.min_aab_));           \
+    CHECK_EQ(base::bit_cast<uint64_t>(min),                         \
+             base::bit_cast<uint64_t>(results.min_aba_));           \
+    CHECK_EQ(base::bit_cast<uint64_t>(max),                         \
+             base::bit_cast<uint64_t>(results.max_abc_));           \
+    CHECK_EQ(base::bit_cast<uint64_t>(max),                         \
+             base::bit_cast<uint64_t>(results.max_aab_));           \
+    CHECK_EQ(base::bit_cast<uint64_t>(max),                         \
+             base::bit_cast<uint64_t>(results.max_aba_));           \
   } while (0)
 
-  double nan_a = bit_cast<double>(UINT64_C(0x7FF8000000000001));
-  double nan_b = bit_cast<double>(UINT64_C(0x7FF8000000000002));
+  double nan_a = base::bit_cast<double>(UINT64_C(0x7FF8000000000001));
+  double nan_b = base::bit_cast<double>(UINT64_C(0x7FF8000000000002));
 
   CHECK_MINMAX(1.0, -1.0, -1.0, 1.0);
   CHECK_MINMAX(-1.0, 1.0, -1.0, 1.0);
@@ -3765,22 +3775,28 @@ TEST(macro_float_minmax_f32) {
 
   auto f = GenerateMacroFloatMinMax<SwVfpRegister, Inputs, Results>(&assm);
 
-#define CHECK_MINMAX(left, right, min, max)                                  \
-  do {                                                                       \
-    Inputs inputs = {left, right};                                           \
-    Results results;                                                         \
-    f.Call(&inputs, &results, 0, 0, 0);                                      \
-    /* Use a bit_cast to correctly identify -0.0 and NaNs. */                \
-    CHECK_EQ(bit_cast<uint32_t>(min), bit_cast<uint32_t>(results.min_abc_)); \
-    CHECK_EQ(bit_cast<uint32_t>(min), bit_cast<uint32_t>(results.min_aab_)); \
-    CHECK_EQ(bit_cast<uint32_t>(min), bit_cast<uint32_t>(results.min_aba_)); \
-    CHECK_EQ(bit_cast<uint32_t>(max), bit_cast<uint32_t>(results.max_abc_)); \
-    CHECK_EQ(bit_cast<uint32_t>(max), bit_cast<uint32_t>(results.max_aab_)); \
-    CHECK_EQ(bit_cast<uint32_t>(max), bit_cast<uint32_t>(results.max_aba_)); \
+#define CHECK_MINMAX(left, right, min, max)                         \
+  do {                                                              \
+    Inputs inputs = {left, right};                                  \
+    Results results;                                                \
+    f.Call(&inputs, &results, 0, 0, 0);                             \
+    /* Use a base::bit_cast to correctly identify -0.0 and NaNs. */ \
+    CHECK_EQ(base::bit_cast<uint32_t>(min),                         \
+             base::bit_cast<uint32_t>(results.min_abc_));           \
+    CHECK_EQ(base::bit_cast<uint32_t>(min),                         \
+             base::bit_cast<uint32_t>(results.min_aab_));           \
+    CHECK_EQ(base::bit_cast<uint32_t>(min),                         \
+             base::bit_cast<uint32_t>(results.min_aba_));           \
+    CHECK_EQ(base::bit_cast<uint32_t>(max),                         \
+             base::bit_cast<uint32_t>(results.max_abc_));           \
+    CHECK_EQ(base::bit_cast<uint32_t>(max),                         \
+             base::bit_cast<uint32_t>(results.max_aab_));           \
+    CHECK_EQ(base::bit_cast<uint32_t>(max),                         \
+             base::bit_cast<uint32_t>(results.max_aba_));           \
   } while (0)
 
-  float nan_a = bit_cast<float>(UINT32_C(0x7FC00001));
-  float nan_b = bit_cast<float>(UINT32_C(0x7FC00002));
+  float nan_a = base::bit_cast<float>(UINT32_C(0x7FC00001));
+  float nan_b = base::bit_cast<float>(UINT32_C(0x7FC00002));
 
   CHECK_MINMAX(1.0f, -1.0f, -1.0f, 1.0f);
   CHECK_MINMAX(-1.0f, 1.0f, -1.0f, 1.0f);
@@ -3932,10 +3948,10 @@ TEST(vswp) {
 
   __ stm(db_w, sp, {r4, r5, r6, r7, lr});
 
-  uint64_t one = bit_cast<uint64_t>(1.0);
+  uint64_t one = base::bit_cast<uint64_t>(1.0);
   __ mov(r5, Operand(one >> 32));
   __ mov(r4, Operand(one & 0xFFFFFFFF));
-  uint64_t minus_one = bit_cast<uint64_t>(-1.0);
+  uint64_t minus_one = base::bit_cast<uint64_t>(-1.0);
   __ mov(r7, Operand(minus_one >> 32));
   __ mov(r6, Operand(minus_one & 0xFFFFFFFF));
 
@@ -4244,7 +4260,7 @@ namespace {
 std::vector<Float32> Float32Inputs() {
   std::vector<Float32> inputs;
   FOR_FLOAT32_INPUTS(f) {
-    inputs.push_back(Float32::FromBits(bit_cast<uint32_t>(f)));
+    inputs.push_back(Float32::FromBits(base::bit_cast<uint32_t>(f)));
   }
   FOR_UINT32_INPUTS(bits) { inputs.push_back(Float32::FromBits(bits)); }
   return inputs;
@@ -4253,7 +4269,7 @@ std::vector<Float32> Float32Inputs() {
 std::vector<Float64> Float64Inputs() {
   std::vector<Float64> inputs;
   FOR_FLOAT64_INPUTS(f) {
-    inputs.push_back(Float64::FromBits(bit_cast<uint64_t>(f)));
+    inputs.push_back(Float64::FromBits(base::bit_cast<uint64_t>(f)));
   }
   FOR_UINT64_INPUTS(bits) { inputs.push_back(Float64::FromBits(bits)); }
   return inputs;
diff --git a/test/cctest/test-assembler-arm64.cc b/test/cctest/test-assembler-arm64.cc
index fc6429a9c1f..2311c5e10db 100644
--- a/test/cctest/test-assembler-arm64.cc
+++ b/test/cctest/test-assembler-arm64.cc
@@ -8728,19 +8728,19 @@ TEST(fmov_reg) {
   __ Fmov(x1, d1);
   __ Fmov(d2, x1);
   __ Fmov(d4, d1);
-  __ Fmov(d6, bit_cast<double>(0x0123456789ABCDEFL));
+  __ Fmov(d6, base::bit_cast<double>(0x0123456789ABCDEFL));
   __ Fmov(s6, s6);
   END();
 
   RUN();
 
-  CHECK_EQUAL_32(bit_cast<uint32_t>(1.0f), w10);
+  CHECK_EQUAL_32(base::bit_cast<uint32_t>(1.0f), w10);
   CHECK_EQUAL_FP32(1.0, s30);
   CHECK_EQUAL_FP32(1.0, s5);
-  CHECK_EQUAL_64(bit_cast<uint64_t>(-13.0), x1);
+  CHECK_EQUAL_64(base::bit_cast<uint64_t>(-13.0), x1);
   CHECK_EQUAL_FP64(-13.0, d2);
   CHECK_EQUAL_FP64(-13.0, d4);
-  CHECK_EQUAL_FP32(bit_cast<float>(0x89ABCDEF), s6);
+  CHECK_EQUAL_FP32(base::bit_cast<float>(0x89ABCDEF), s6);
 }
 
 TEST(fadd) {
@@ -9037,12 +9037,12 @@ TEST(fmadd_fmsub_float) {
 TEST(fmadd_fmsub_double_nans) {
   INIT_V8();
   // Make sure that NaN propagation works correctly.
-  double s1 = bit_cast<double>(0x7FF5555511111111);
-  double s2 = bit_cast<double>(0x7FF5555522222222);
-  double sa = bit_cast<double>(0x7FF55555AAAAAAAA);
-  double q1 = bit_cast<double>(0x7FFAAAAA11111111);
-  double q2 = bit_cast<double>(0x7FFAAAAA22222222);
-  double qa = bit_cast<double>(0x7FFAAAAAAAAAAAAA);
+  double s1 = base::bit_cast<double>(0x7FF5555511111111);
+  double s2 = base::bit_cast<double>(0x7FF5555522222222);
+  double sa = base::bit_cast<double>(0x7FF55555AAAAAAAA);
+  double q1 = base::bit_cast<double>(0x7FFAAAAA11111111);
+  double q2 = base::bit_cast<double>(0x7FFAAAAA22222222);
+  double qa = base::bit_cast<double>(0x7FFAAAAAAAAAAAAA);
   CHECK(IsSignallingNaN(s1));
   CHECK(IsSignallingNaN(s2));
   CHECK(IsSignallingNaN(sa));
@@ -9051,9 +9051,9 @@ TEST(fmadd_fmsub_double_nans) {
   CHECK(IsQuietNaN(qa));
 
   // The input NaNs after passing through ProcessNaN.
-  double s1_proc = bit_cast<double>(0x7FFD555511111111);
-  double s2_proc = bit_cast<double>(0x7FFD555522222222);
-  double sa_proc = bit_cast<double>(0x7FFD5555AAAAAAAA);
+  double s1_proc = base::bit_cast<double>(0x7FFD555511111111);
+  double s2_proc = base::bit_cast<double>(0x7FFD555522222222);
+  double sa_proc = base::bit_cast<double>(0x7FFD5555AAAAAAAA);
   double q1_proc = q1;
   double q2_proc = q2;
   double qa_proc = qa;
@@ -9065,10 +9065,10 @@ TEST(fmadd_fmsub_double_nans) {
   CHECK(IsQuietNaN(qa_proc));
 
   // Negated NaNs as it would be done on ARMv8 hardware.
-  double s1_proc_neg = bit_cast<double>(0xFFFD555511111111);
-  double sa_proc_neg = bit_cast<double>(0xFFFD5555AAAAAAAA);
-  double q1_proc_neg = bit_cast<double>(0xFFFAAAAA11111111);
-  double qa_proc_neg = bit_cast<double>(0xFFFAAAAAAAAAAAAA);
+  double s1_proc_neg = base::bit_cast<double>(0xFFFD555511111111);
+  double sa_proc_neg = base::bit_cast<double>(0xFFFD5555AAAAAAAA);
+  double q1_proc_neg = base::bit_cast<double>(0xFFFAAAAA11111111);
+  double qa_proc_neg = base::bit_cast<double>(0xFFFAAAAAAAAAAAAA);
   CHECK(IsQuietNaN(s1_proc_neg));
   CHECK(IsQuietNaN(sa_proc_neg));
   CHECK(IsQuietNaN(q1_proc_neg));
@@ -9119,12 +9119,12 @@ TEST(fmadd_fmsub_double_nans) {
 TEST(fmadd_fmsub_float_nans) {
   INIT_V8();
   // Make sure that NaN propagation works correctly.
-  float s1 = bit_cast<float>(0x7F951111);
-  float s2 = bit_cast<float>(0x7F952222);
-  float sa = bit_cast<float>(0x7F95AAAA);
-  float q1 = bit_cast<float>(0x7FEA1111);
-  float q2 = bit_cast<float>(0x7FEA2222);
-  float qa = bit_cast<float>(0x7FEAAAAA);
+  float s1 = base::bit_cast<float>(0x7F951111);
+  float s2 = base::bit_cast<float>(0x7F952222);
+  float sa = base::bit_cast<float>(0x7F95AAAA);
+  float q1 = base::bit_cast<float>(0x7FEA1111);
+  float q2 = base::bit_cast<float>(0x7FEA2222);
+  float qa = base::bit_cast<float>(0x7FEAAAAA);
   CHECK(IsSignallingNaN(s1));
   CHECK(IsSignallingNaN(s2));
   CHECK(IsSignallingNaN(sa));
@@ -9133,9 +9133,9 @@ TEST(fmadd_fmsub_float_nans) {
   CHECK(IsQuietNaN(qa));
 
   // The input NaNs after passing through ProcessNaN.
-  float s1_proc = bit_cast<float>(0x7FD51111);
-  float s2_proc = bit_cast<float>(0x7FD52222);
-  float sa_proc = bit_cast<float>(0x7FD5AAAA);
+  float s1_proc = base::bit_cast<float>(0x7FD51111);
+  float s2_proc = base::bit_cast<float>(0x7FD52222);
+  float sa_proc = base::bit_cast<float>(0x7FD5AAAA);
   float q1_proc = q1;
   float q2_proc = q2;
   float qa_proc = qa;
@@ -9147,10 +9147,10 @@ TEST(fmadd_fmsub_float_nans) {
   CHECK(IsQuietNaN(qa_proc));
 
   // Negated NaNs as it would be done on ARMv8 hardware.
-  float s1_proc_neg = bit_cast<float>(0xFFD51111);
-  float sa_proc_neg = bit_cast<float>(0xFFD5AAAA);
-  float q1_proc_neg = bit_cast<float>(0xFFEA1111);
-  float qa_proc_neg = bit_cast<float>(0xFFEAAAAA);
+  float s1_proc_neg = base::bit_cast<float>(0xFFD51111);
+  float sa_proc_neg = base::bit_cast<float>(0xFFD5AAAA);
+  float q1_proc_neg = base::bit_cast<float>(0xFFEA1111);
+  float qa_proc_neg = base::bit_cast<float>(0xFFEAAAAA);
   CHECK(IsQuietNaN(s1_proc_neg));
   CHECK(IsQuietNaN(sa_proc_neg));
   CHECK(IsQuietNaN(q1_proc_neg));
@@ -9258,15 +9258,15 @@ static float MinMaxHelper(float n,
                           float m,
                           bool min,
                           float quiet_nan_substitute = 0.0) {
-  uint32_t raw_n = bit_cast<uint32_t>(n);
-  uint32_t raw_m = bit_cast<uint32_t>(m);
+  uint32_t raw_n = base::bit_cast<uint32_t>(n);
+  uint32_t raw_m = base::bit_cast<uint32_t>(m);
 
   if (std::isnan(n) && ((raw_n & kSQuietNanMask) == 0)) {
     // n is signalling NaN.
-    return bit_cast<float>(raw_n | static_cast<uint32_t>(kSQuietNanMask));
+    return base::bit_cast<float>(raw_n | static_cast<uint32_t>(kSQuietNanMask));
   } else if (std::isnan(m) && ((raw_m & kSQuietNanMask) == 0)) {
     // m is signalling NaN.
-    return bit_cast<float>(raw_m | static_cast<uint32_t>(kSQuietNanMask));
+    return base::bit_cast<float>(raw_m | static_cast<uint32_t>(kSQuietNanMask));
   } else if (quiet_nan_substitute == 0.0) {
     if (std::isnan(n)) {
       // n is quiet NaN.
@@ -9299,15 +9299,15 @@ static double MinMaxHelper(double n,
                            double m,
                            bool min,
                            double quiet_nan_substitute = 0.0) {
-  uint64_t raw_n = bit_cast<uint64_t>(n);
-  uint64_t raw_m = bit_cast<uint64_t>(m);
+  uint64_t raw_n = base::bit_cast<uint64_t>(n);
+  uint64_t raw_m = base::bit_cast<uint64_t>(m);
 
   if (std::isnan(n) && ((raw_n & kDQuietNanMask) == 0)) {
     // n is signalling NaN.
-    return bit_cast<double>(raw_n | kDQuietNanMask);
+    return base::bit_cast<double>(raw_n | kDQuietNanMask);
   } else if (std::isnan(m) && ((raw_m & kDQuietNanMask) == 0)) {
     // m is signalling NaN.
-    return bit_cast<double>(raw_m | kDQuietNanMask);
+    return base::bit_cast<double>(raw_m | kDQuietNanMask);
   } else if (quiet_nan_substitute == 0.0) {
     if (std::isnan(n)) {
       // n is quiet NaN.
@@ -9360,10 +9360,10 @@ static void FminFmaxDoubleHelper(double n, double m, double min, double max,
 TEST(fmax_fmin_d) {
   INIT_V8();
   // Use non-standard NaNs to check that the payload bits are preserved.
-  double snan = bit_cast<double>(0x7FF5555512345678);
-  double qnan = bit_cast<double>(0x7FFAAAAA87654321);
+  double snan = base::bit_cast<double>(0x7FF5555512345678);
+  double qnan = base::bit_cast<double>(0x7FFAAAAA87654321);
 
-  double snan_processed = bit_cast<double>(0x7FFD555512345678);
+  double snan_processed = base::bit_cast<double>(0x7FFD555512345678);
   double qnan_processed = qnan;
 
   CHECK(IsSignallingNaN(snan));
@@ -9441,10 +9441,10 @@ static void FminFmaxFloatHelper(float n, float m, float min, float max,
 TEST(fmax_fmin_s) {
   INIT_V8();
   // Use non-standard NaNs to check that the payload bits are preserved.
-  float snan = bit_cast<float>(0x7F951234);
-  float qnan = bit_cast<float>(0x7FEA8765);
+  float snan = base::bit_cast<float>(0x7F951234);
+  float qnan = base::bit_cast<float>(0x7FEA8765);
 
-  float snan_processed = bit_cast<float>(0x7FD51234);
+  float snan_processed = base::bit_cast<float>(0x7FD51234);
   float qnan_processed = qnan;
 
   CHECK(IsSignallingNaN(snan));
@@ -10245,8 +10245,8 @@ TEST(fcvt_ds) {
   __ Fmov(s26, -0.0);
   __ Fmov(s27, FLT_MAX);
   __ Fmov(s28, FLT_MIN);
-  __ Fmov(s29, bit_cast<float>(0x7FC12345));  // Quiet NaN.
-  __ Fmov(s30, bit_cast<float>(0x7F812345));  // Signalling NaN.
+  __ Fmov(s29, base::bit_cast<float>(0x7FC12345));  // Quiet NaN.
+  __ Fmov(s30, base::bit_cast<float>(0x7F812345));  // Signalling NaN.
 
   __ Fcvt(d0, s16);
   __ Fcvt(d1, s17);
@@ -10287,8 +10287,8 @@ TEST(fcvt_ds) {
   //  - The top bit of the mantissa is forced to 1 (making it a quiet NaN).
   //  - The remaining mantissa bits are copied until they run out.
   //  - The low-order bits that haven't already been assigned are set to 0.
-  CHECK_EQUAL_FP64(bit_cast<double>(0x7FF82468A0000000), d13);
-  CHECK_EQUAL_FP64(bit_cast<double>(0x7FF82468A0000000), d14);
+  CHECK_EQUAL_FP64(base::bit_cast<double>(0x7FF82468A0000000), d13);
+  CHECK_EQUAL_FP64(base::bit_cast<double>(0x7FF82468A0000000), d14);
 }
 
 TEST(fcvt_sd) {
@@ -10316,23 +10316,38 @@ TEST(fcvt_sd) {
       //    For normalized numbers:
       //         bit 29 (0x0000000020000000) is the lowest-order bit which will
       //                                     fit in the float's mantissa.
-      {bit_cast<double>(0x3FF0000000000000), bit_cast<float>(0x3F800000)},
-      {bit_cast<double>(0x3FF0000000000001), bit_cast<float>(0x3F800000)},
-      {bit_cast<double>(0x3FF0000010000000), bit_cast<float>(0x3F800000)},
-      {bit_cast<double>(0x3FF0000010000001), bit_cast<float>(0x3F800001)},
-      {bit_cast<double>(0x3FF0000020000000), bit_cast<float>(0x3F800001)},
-      {bit_cast<double>(0x3FF0000020000001), bit_cast<float>(0x3F800001)},
-      {bit_cast<double>(0x3FF0000030000000), bit_cast<float>(0x3F800002)},
-      {bit_cast<double>(0x3FF0000030000001), bit_cast<float>(0x3F800002)},
-      {bit_cast<double>(0x3FF0000040000000), bit_cast<float>(0x3F800002)},
-      {bit_cast<double>(0x3FF0000040000001), bit_cast<float>(0x3F800002)},
-      {bit_cast<double>(0x3FF0000050000000), bit_cast<float>(0x3F800002)},
-      {bit_cast<double>(0x3FF0000050000001), bit_cast<float>(0x3F800003)},
-      {bit_cast<double>(0x3FF0000060000000), bit_cast<float>(0x3F800003)},
+      {base::bit_cast<double>(0x3FF0000000000000),
+       base::bit_cast<float>(0x3F800000)},
+      {base::bit_cast<double>(0x3FF0000000000001),
+       base::bit_cast<float>(0x3F800000)},
+      {base::bit_cast<double>(0x3FF0000010000000),
+       base::bit_cast<float>(0x3F800000)},
+      {base::bit_cast<double>(0x3FF0000010000001),
+       base::bit_cast<float>(0x3F800001)},
+      {base::bit_cast<double>(0x3FF0000020000000),
+       base::bit_cast<float>(0x3F800001)},
+      {base::bit_cast<double>(0x3FF0000020000001),
+       base::bit_cast<float>(0x3F800001)},
+      {base::bit_cast<double>(0x3FF0000030000000),
+       base::bit_cast<float>(0x3F800002)},
+      {base::bit_cast<double>(0x3FF0000030000001),
+       base::bit_cast<float>(0x3F800002)},
+      {base::bit_cast<double>(0x3FF0000040000000),
+       base::bit_cast<float>(0x3F800002)},
+      {base::bit_cast<double>(0x3FF0000040000001),
+       base::bit_cast<float>(0x3F800002)},
+      {base::bit_cast<double>(0x3FF0000050000000),
+       base::bit_cast<float>(0x3F800002)},
+      {base::bit_cast<double>(0x3FF0000050000001),
+       base::bit_cast<float>(0x3F800003)},
+      {base::bit_cast<double>(0x3FF0000060000000),
+       base::bit_cast<float>(0x3F800003)},
       //  - A mantissa that overflows into the exponent during rounding.
-      {bit_cast<double>(0x3FEFFFFFF0000000), bit_cast<float>(0x3F800000)},
+      {base::bit_cast<double>(0x3FEFFFFFF0000000),
+       base::bit_cast<float>(0x3F800000)},
       //  - The largest double that rounds to a normal float.
-      {bit_cast<double>(0x47EFFFFFEFFFFFFF), bit_cast<float>(0x7F7FFFFF)},
+      {base::bit_cast<double>(0x47EFFFFFEFFFFFFF),
+       base::bit_cast<float>(0x7F7FFFFF)},
 
       // Doubles that are too big for a float.
       {kFP64PositiveInfinity, kFP32PositiveInfinity},
@@ -10340,46 +10355,68 @@ TEST(fcvt_sd) {
       //  - The smallest exponent that's too big for a float.
       {pow(2.0, 128), kFP32PositiveInfinity},
       //  - This exponent is in range, but the value rounds to infinity.
-      {bit_cast<double>(0x47EFFFFFF0000000), kFP32PositiveInfinity},
+      {base::bit_cast<double>(0x47EFFFFFF0000000), kFP32PositiveInfinity},
 
       // Doubles that are too small for a float.
       //  - The smallest (subnormal) double.
       {DBL_MIN, 0.0},
       //  - The largest double which is too small for a subnormal float.
-      {bit_cast<double>(0x3690000000000000), bit_cast<float>(0x00000000)},
+      {base::bit_cast<double>(0x3690000000000000),
+       base::bit_cast<float>(0x00000000)},
 
       // Normal doubles that become subnormal floats.
       //  - The largest subnormal float.
-      {bit_cast<double>(0x380FFFFFC0000000), bit_cast<float>(0x007FFFFF)},
+      {base::bit_cast<double>(0x380FFFFFC0000000),
+       base::bit_cast<float>(0x007FFFFF)},
       //  - The smallest subnormal float.
-      {bit_cast<double>(0x36A0000000000000), bit_cast<float>(0x00000001)},
+      {base::bit_cast<double>(0x36A0000000000000),
+       base::bit_cast<float>(0x00000001)},
       //  - Subnormal floats that need (ties-to-even) rounding.
       //    For these subnormals:
       //         bit 34 (0x0000000400000000) is the lowest-order bit which will
       //                                     fit in the float's mantissa.
-      {bit_cast<double>(0x37C159E000000000), bit_cast<float>(0x00045678)},
-      {bit_cast<double>(0x37C159E000000001), bit_cast<float>(0x00045678)},
-      {bit_cast<double>(0x37C159E200000000), bit_cast<float>(0x00045678)},
-      {bit_cast<double>(0x37C159E200000001), bit_cast<float>(0x00045679)},
-      {bit_cast<double>(0x37C159E400000000), bit_cast<float>(0x00045679)},
-      {bit_cast<double>(0x37C159E400000001), bit_cast<float>(0x00045679)},
-      {bit_cast<double>(0x37C159E600000000), bit_cast<float>(0x0004567A)},
-      {bit_cast<double>(0x37C159E600000001), bit_cast<float>(0x0004567A)},
-      {bit_cast<double>(0x37C159E800000000), bit_cast<float>(0x0004567A)},
-      {bit_cast<double>(0x37C159E800000001), bit_cast<float>(0x0004567A)},
-      {bit_cast<double>(0x37C159EA00000000), bit_cast<float>(0x0004567A)},
-      {bit_cast<double>(0x37C159EA00000001), bit_cast<float>(0x0004567B)},
-      {bit_cast<double>(0x37C159EC00000000), bit_cast<float>(0x0004567B)},
+      {base::bit_cast<double>(0x37C159E000000000),
+       base::bit_cast<float>(0x00045678)},
+      {base::bit_cast<double>(0x37C159E000000001),
+       base::bit_cast<float>(0x00045678)},
+      {base::bit_cast<double>(0x37C159E200000000),
+       base::bit_cast<float>(0x00045678)},
+      {base::bit_cast<double>(0x37C159E200000001),
+       base::bit_cast<float>(0x00045679)},
+      {base::bit_cast<double>(0x37C159E400000000),
+       base::bit_cast<float>(0x00045679)},
+      {base::bit_cast<double>(0x37C159E400000001),
+       base::bit_cast<float>(0x00045679)},
+      {base::bit_cast<double>(0x37C159E600000000),
+       base::bit_cast<float>(0x0004567A)},
+      {base::bit_cast<double>(0x37C159E600000001),
+       base::bit_cast<float>(0x0004567A)},
+      {base::bit_cast<double>(0x37C159E800000000),
+       base::bit_cast<float>(0x0004567A)},
+      {base::bit_cast<double>(0x37C159E800000001),
+       base::bit_cast<float>(0x0004567A)},
+      {base::bit_cast<double>(0x37C159EA00000000),
+       base::bit_cast<float>(0x0004567A)},
+      {base::bit_cast<double>(0x37C159EA00000001),
+       base::bit_cast<float>(0x0004567B)},
+      {base::bit_cast<double>(0x37C159EC00000000),
+       base::bit_cast<float>(0x0004567B)},
       //  - The smallest double which rounds up to become a subnormal float.
-      {bit_cast<double>(0x3690000000000001), bit_cast<float>(0x00000001)},
+      {base::bit_cast<double>(0x3690000000000001),
+       base::bit_cast<float>(0x00000001)},
 
       // Check NaN payload preservation.
-      {bit_cast<double>(0x7FF82468A0000000), bit_cast<float>(0x7FC12345)},
-      {bit_cast<double>(0x7FF82468BFFFFFFF), bit_cast<float>(0x7FC12345)},
+      {base::bit_cast<double>(0x7FF82468A0000000),
+       base::bit_cast<float>(0x7FC12345)},
+      {base::bit_cast<double>(0x7FF82468BFFFFFFF),
+       base::bit_cast<float>(0x7FC12345)},
       //  - Signalling NaNs become quiet NaNs.
-      {bit_cast<double>(0x7FF02468A0000000), bit_cast<float>(0x7FC12345)},
-      {bit_cast<double>(0x7FF02468BFFFFFFF), bit_cast<float>(0x7FC12345)},
-      {bit_cast<double>(0x7FF000001FFFFFFF), bit_cast<float>(0x7FC00000)},
+      {base::bit_cast<double>(0x7FF02468A0000000),
+       base::bit_cast<float>(0x7FC12345)},
+      {base::bit_cast<double>(0x7FF02468BFFFFFFF),
+       base::bit_cast<float>(0x7FC12345)},
+      {base::bit_cast<double>(0x7FF000001FFFFFFF),
+       base::bit_cast<float>(0x7FC00000)},
   };
   int count = sizeof(test) / sizeof(test[0]);
 
@@ -11175,7 +11212,7 @@ static void FjcvtzsHelper(uint64_t value, uint64_t expected,
                           uint32_t expected_z) {
   SETUP();
   START();
-  __ Fmov(d0, bit_cast<double>(value));
+  __ Fmov(d0, base::bit_cast<double>(value));
   __ Fjcvtzs(w0, d0);
   __ Mrs(x1, NZCV);
   END();
@@ -11462,8 +11499,8 @@ static void TestUScvtfHelper(uint64_t in,
   RUN();
 
   // Check the results.
-  double expected_scvtf_base = bit_cast<double>(expected_scvtf_bits);
-  double expected_ucvtf_base = bit_cast<double>(expected_ucvtf_bits);
+  double expected_scvtf_base = base::bit_cast<double>(expected_scvtf_bits);
+  double expected_ucvtf_base = base::bit_cast<double>(expected_ucvtf_bits);
 
   for (int fbits = 0; fbits <= 32; fbits++) {
     double expected_scvtf = expected_scvtf_base / pow(2.0, fbits);
@@ -11613,8 +11650,8 @@ static void TestUScvtf32Helper(uint64_t in,
   RUN();
 
   // Check the results.
-  float expected_scvtf_base = bit_cast<float>(expected_scvtf_bits);
-  float expected_ucvtf_base = bit_cast<float>(expected_ucvtf_bits);
+  float expected_scvtf_base = base::bit_cast<float>(expected_scvtf_bits);
+  float expected_ucvtf_base = base::bit_cast<float>(expected_ucvtf_bits);
 
   for (int fbits = 0; fbits <= 32; fbits++) {
     float expected_scvtf = expected_scvtf_base / powf(2, fbits);
@@ -14198,13 +14235,13 @@ TEST(barriers) {
 TEST(process_nan_double) {
   INIT_V8();
   // Make sure that NaN propagation works correctly.
-  double sn = bit_cast<double>(0x7FF5555511111111);
-  double qn = bit_cast<double>(0x7FFAAAAA11111111);
+  double sn = base::bit_cast<double>(0x7FF5555511111111);
+  double qn = base::bit_cast<double>(0x7FFAAAAA11111111);
   CHECK(IsSignallingNaN(sn));
   CHECK(IsQuietNaN(qn));
 
   // The input NaNs after passing through ProcessNaN.
-  double sn_proc = bit_cast<double>(0x7FFD555511111111);
+  double sn_proc = base::bit_cast<double>(0x7FFD555511111111);
   double qn_proc = qn;
   CHECK(IsQuietNaN(sn_proc));
   CHECK(IsQuietNaN(qn_proc));
@@ -14244,17 +14281,17 @@ TEST(process_nan_double) {
   END();
   RUN();
 
-  uint64_t qn_raw = bit_cast<uint64_t>(qn);
-  uint64_t sn_raw = bit_cast<uint64_t>(sn);
+  uint64_t qn_raw = base::bit_cast<uint64_t>(qn);
+  uint64_t sn_raw = base::bit_cast<uint64_t>(sn);
 
   //   - Signalling NaN
   CHECK_EQUAL_FP64(sn, d1);
-  CHECK_EQUAL_FP64(bit_cast<double>(sn_raw & ~kDSignMask), d2);
-  CHECK_EQUAL_FP64(bit_cast<double>(sn_raw ^ kDSignMask), d3);
+  CHECK_EQUAL_FP64(base::bit_cast<double>(sn_raw & ~kDSignMask), d2);
+  CHECK_EQUAL_FP64(base::bit_cast<double>(sn_raw ^ kDSignMask), d3);
   //   - Quiet NaN
   CHECK_EQUAL_FP64(qn, d11);
-  CHECK_EQUAL_FP64(bit_cast<double>(qn_raw & ~kDSignMask), d12);
-  CHECK_EQUAL_FP64(bit_cast<double>(qn_raw ^ kDSignMask), d13);
+  CHECK_EQUAL_FP64(base::bit_cast<double>(qn_raw & ~kDSignMask), d12);
+  CHECK_EQUAL_FP64(base::bit_cast<double>(qn_raw ^ kDSignMask), d13);
 
   //   - Signalling NaN
   CHECK_EQUAL_FP64(sn_proc, d4);
@@ -14271,13 +14308,13 @@ TEST(process_nan_double) {
 TEST(process_nan_float) {
   INIT_V8();
   // Make sure that NaN propagation works correctly.
-  float sn = bit_cast<float>(0x7F951111);
-  float qn = bit_cast<float>(0x7FEA1111);
+  float sn = base::bit_cast<float>(0x7F951111);
+  float qn = base::bit_cast<float>(0x7FEA1111);
   CHECK(IsSignallingNaN(sn));
   CHECK(IsQuietNaN(qn));
 
   // The input NaNs after passing through ProcessNaN.
-  float sn_proc = bit_cast<float>(0x7FD51111);
+  float sn_proc = base::bit_cast<float>(0x7FD51111);
   float qn_proc = qn;
   CHECK(IsQuietNaN(sn_proc));
   CHECK(IsQuietNaN(qn_proc));
@@ -14317,18 +14354,18 @@ TEST(process_nan_float) {
   END();
   RUN();
 
-  uint32_t qn_raw = bit_cast<uint32_t>(qn);
-  uint32_t sn_raw = bit_cast<uint32_t>(sn);
+  uint32_t qn_raw = base::bit_cast<uint32_t>(qn);
+  uint32_t sn_raw = base::bit_cast<uint32_t>(sn);
   uint32_t sign_mask = static_cast<uint32_t>(kSSignMask);
 
   //   - Signalling NaN
   CHECK_EQUAL_FP32(sn, s1);
-  CHECK_EQUAL_FP32(bit_cast<float>(sn_raw & ~sign_mask), s2);
-  CHECK_EQUAL_FP32(bit_cast<float>(sn_raw ^ sign_mask), s3);
+  CHECK_EQUAL_FP32(base::bit_cast<float>(sn_raw & ~sign_mask), s2);
+  CHECK_EQUAL_FP32(base::bit_cast<float>(sn_raw ^ sign_mask), s3);
   //   - Quiet NaN
   CHECK_EQUAL_FP32(qn, s11);
-  CHECK_EQUAL_FP32(bit_cast<float>(qn_raw & ~sign_mask), s12);
-  CHECK_EQUAL_FP32(bit_cast<float>(qn_raw ^ sign_mask), s13);
+  CHECK_EQUAL_FP32(base::bit_cast<float>(qn_raw & ~sign_mask), s12);
+  CHECK_EQUAL_FP32(base::bit_cast<float>(qn_raw ^ sign_mask), s13);
 
   //   - Signalling NaN
   CHECK_EQUAL_FP32(sn_proc, s4);
@@ -14376,18 +14413,18 @@ static void ProcessNaNsHelper(double n, double m, double expected) {
 TEST(process_nans_double) {
   INIT_V8();
   // Make sure that NaN propagation works correctly.
-  double sn = bit_cast<double>(0x7FF5555511111111);
-  double sm = bit_cast<double>(0x7FF5555522222222);
-  double qn = bit_cast<double>(0x7FFAAAAA11111111);
-  double qm = bit_cast<double>(0x7FFAAAAA22222222);
+  double sn = base::bit_cast<double>(0x7FF5555511111111);
+  double sm = base::bit_cast<double>(0x7FF5555522222222);
+  double qn = base::bit_cast<double>(0x7FFAAAAA11111111);
+  double qm = base::bit_cast<double>(0x7FFAAAAA22222222);
   CHECK(IsSignallingNaN(sn));
   CHECK(IsSignallingNaN(sm));
   CHECK(IsQuietNaN(qn));
   CHECK(IsQuietNaN(qm));
 
   // The input NaNs after passing through ProcessNaN.
-  double sn_proc = bit_cast<double>(0x7FFD555511111111);
-  double sm_proc = bit_cast<double>(0x7FFD555522222222);
+  double sn_proc = base::bit_cast<double>(0x7FFD555511111111);
+  double sm_proc = base::bit_cast<double>(0x7FFD555522222222);
   double qn_proc = qn;
   double qm_proc = qm;
   CHECK(IsQuietNaN(sn_proc));
@@ -14444,18 +14481,18 @@ static void ProcessNaNsHelper(float n, float m, float expected) {
 TEST(process_nans_float) {
   INIT_V8();
   // Make sure that NaN propagation works correctly.
-  float sn = bit_cast<float>(0x7F951111);
-  float sm = bit_cast<float>(0x7F952222);
-  float qn = bit_cast<float>(0x7FEA1111);
-  float qm = bit_cast<float>(0x7FEA2222);
+  float sn = base::bit_cast<float>(0x7F951111);
+  float sm = base::bit_cast<float>(0x7F952222);
+  float qn = base::bit_cast<float>(0x7FEA1111);
+  float qm = base::bit_cast<float>(0x7FEA2222);
   CHECK(IsSignallingNaN(sn));
   CHECK(IsSignallingNaN(sm));
   CHECK(IsQuietNaN(qn));
   CHECK(IsQuietNaN(qm));
 
   // The input NaNs after passing through ProcessNaN.
-  float sn_proc = bit_cast<float>(0x7FD51111);
-  float sm_proc = bit_cast<float>(0x7FD52222);
+  float sn_proc = base::bit_cast<float>(0x7FD51111);
+  float sm_proc = base::bit_cast<float>(0x7FD52222);
   float qn_proc = qn;
   float qm_proc = qm;
   CHECK(IsQuietNaN(sn_proc));
@@ -14536,11 +14573,11 @@ static void DefaultNaNHelper(float n, float m, float a) {
   RUN();
 
   if (test_1op) {
-    uint32_t n_raw = bit_cast<uint32_t>(n);
+    uint32_t n_raw = base::bit_cast<uint32_t>(n);
     uint32_t sign_mask = static_cast<uint32_t>(kSSignMask);
     CHECK_EQUAL_FP32(n, s10);
-    CHECK_EQUAL_FP32(bit_cast<float>(n_raw & ~sign_mask), s11);
-    CHECK_EQUAL_FP32(bit_cast<float>(n_raw ^ sign_mask), s12);
+    CHECK_EQUAL_FP32(base::bit_cast<float>(n_raw & ~sign_mask), s11);
+    CHECK_EQUAL_FP32(base::bit_cast<float>(n_raw ^ sign_mask), s12);
     CHECK_EQUAL_FP32(kFP32DefaultNaN, s13);
     CHECK_EQUAL_FP32(kFP32DefaultNaN, s14);
     CHECK_EQUAL_FP32(kFP32DefaultNaN, s15);
@@ -14565,12 +14602,12 @@ static void DefaultNaNHelper(float n, float m, float a) {
 
 TEST(default_nan_float) {
   INIT_V8();
-  float sn = bit_cast<float>(0x7F951111);
-  float sm = bit_cast<float>(0x7F952222);
-  float sa = bit_cast<float>(0x7F95AAAA);
-  float qn = bit_cast<float>(0x7FEA1111);
-  float qm = bit_cast<float>(0x7FEA2222);
-  float qa = bit_cast<float>(0x7FEAAAAA);
+  float sn = base::bit_cast<float>(0x7F951111);
+  float sm = base::bit_cast<float>(0x7F952222);
+  float sa = base::bit_cast<float>(0x7F95AAAA);
+  float qn = base::bit_cast<float>(0x7FEA1111);
+  float qm = base::bit_cast<float>(0x7FEA2222);
+  float qa = base::bit_cast<float>(0x7FEAAAAA);
   CHECK(IsSignallingNaN(sn));
   CHECK(IsSignallingNaN(sm));
   CHECK(IsSignallingNaN(sa));
@@ -14661,10 +14698,10 @@ static void DefaultNaNHelper(double n, double m, double a) {
   RUN();
 
   if (test_1op) {
-    uint64_t n_raw = bit_cast<uint64_t>(n);
+    uint64_t n_raw = base::bit_cast<uint64_t>(n);
     CHECK_EQUAL_FP64(n, d10);
-    CHECK_EQUAL_FP64(bit_cast<double>(n_raw & ~kDSignMask), d11);
-    CHECK_EQUAL_FP64(bit_cast<double>(n_raw ^ kDSignMask), d12);
+    CHECK_EQUAL_FP64(base::bit_cast<double>(n_raw & ~kDSignMask), d11);
+    CHECK_EQUAL_FP64(base::bit_cast<double>(n_raw ^ kDSignMask), d12);
     CHECK_EQUAL_FP64(kFP64DefaultNaN, d13);
     CHECK_EQUAL_FP64(kFP64DefaultNaN, d14);
     CHECK_EQUAL_FP64(kFP64DefaultNaN, d15);
@@ -14689,12 +14726,12 @@ static void DefaultNaNHelper(double n, double m, double a) {
 
 TEST(default_nan_double) {
   INIT_V8();
-  double sn = bit_cast<double>(0x7FF5555511111111);
-  double sm = bit_cast<double>(0x7FF5555522222222);
-  double sa = bit_cast<double>(0x7FF55555AAAAAAAA);
-  double qn = bit_cast<double>(0x7FFAAAAA11111111);
-  double qm = bit_cast<double>(0x7FFAAAAA22222222);
-  double qa = bit_cast<double>(0x7FFAAAAAAAAAAAAA);
+  double sn = base::bit_cast<double>(0x7FF5555511111111);
+  double sm = base::bit_cast<double>(0x7FF5555522222222);
+  double sa = base::bit_cast<double>(0x7FF55555AAAAAAAA);
+  double qn = base::bit_cast<double>(0x7FFAAAAA11111111);
+  double qm = base::bit_cast<double>(0x7FFAAAAA22222222);
+  double qa = base::bit_cast<double>(0x7FFAAAAAAAAAAAAA);
   CHECK(IsSignallingNaN(sn));
   CHECK(IsSignallingNaN(sm));
   CHECK(IsSignallingNaN(sa));
diff --git a/test/cctest/test-assembler-mips.cc b/test/cctest/test-assembler-mips.cc
index 002bf4cf007..61136236e19 100644
--- a/test/cctest/test-assembler-mips.cc
+++ b/test/cctest/test-assembler-mips.cc
@@ -3504,28 +3504,28 @@ TEST(class_fmt) {
 
     f.Call(&t, 0, 0, 0, 0);
     // Expected double results.
-    CHECK_EQ(bit_cast<int64_t>(t.dSignalingNan), 0x001);
-    CHECK_EQ(bit_cast<int64_t>(t.dQuietNan),     0x002);
-    CHECK_EQ(bit_cast<int64_t>(t.dNegInf),       0x004);
-    CHECK_EQ(bit_cast<int64_t>(t.dNegNorm),      0x008);
-    CHECK_EQ(bit_cast<int64_t>(t.dNegSubnorm),   0x010);
-    CHECK_EQ(bit_cast<int64_t>(t.dNegZero),      0x020);
-    CHECK_EQ(bit_cast<int64_t>(t.dPosInf),       0x040);
-    CHECK_EQ(bit_cast<int64_t>(t.dPosNorm),      0x080);
-    CHECK_EQ(bit_cast<int64_t>(t.dPosSubnorm),   0x100);
-    CHECK_EQ(bit_cast<int64_t>(t.dPosZero),      0x200);
+    CHECK_EQ(base::bit_cast<int64_t>(t.dSignalingNan), 0x001);
+    CHECK_EQ(base::bit_cast<int64_t>(t.dQuietNan), 0x002);
+    CHECK_EQ(base::bit_cast<int64_t>(t.dNegInf), 0x004);
+    CHECK_EQ(base::bit_cast<int64_t>(t.dNegNorm), 0x008);
+    CHECK_EQ(base::bit_cast<int64_t>(t.dNegSubnorm), 0x010);
+    CHECK_EQ(base::bit_cast<int64_t>(t.dNegZero), 0x020);
+    CHECK_EQ(base::bit_cast<int64_t>(t.dPosInf), 0x040);
+    CHECK_EQ(base::bit_cast<int64_t>(t.dPosNorm), 0x080);
+    CHECK_EQ(base::bit_cast<int64_t>(t.dPosSubnorm), 0x100);
+    CHECK_EQ(base::bit_cast<int64_t>(t.dPosZero), 0x200);
 
     // Expected float results.
-    CHECK_EQ(bit_cast<int32_t>(t.fSignalingNan), 0x001);
-    CHECK_EQ(bit_cast<int32_t>(t.fQuietNan),     0x002);
-    CHECK_EQ(bit_cast<int32_t>(t.fNegInf),       0x004);
-    CHECK_EQ(bit_cast<int32_t>(t.fNegNorm),      0x008);
-    CHECK_EQ(bit_cast<int32_t>(t.fNegSubnorm),   0x010);
-    CHECK_EQ(bit_cast<int32_t>(t.fNegZero),      0x020);
-    CHECK_EQ(bit_cast<int32_t>(t.fPosInf),       0x040);
-    CHECK_EQ(bit_cast<int32_t>(t.fPosNorm),      0x080);
-    CHECK_EQ(bit_cast<int32_t>(t.fPosSubnorm),   0x100);
-    CHECK_EQ(bit_cast<int32_t>(t.fPosZero),      0x200);
+    CHECK_EQ(base::bit_cast<int32_t>(t.fSignalingNan), 0x001);
+    CHECK_EQ(base::bit_cast<int32_t>(t.fQuietNan), 0x002);
+    CHECK_EQ(base::bit_cast<int32_t>(t.fNegInf), 0x004);
+    CHECK_EQ(base::bit_cast<int32_t>(t.fNegNorm), 0x008);
+    CHECK_EQ(base::bit_cast<int32_t>(t.fNegSubnorm), 0x010);
+    CHECK_EQ(base::bit_cast<int32_t>(t.fNegZero), 0x020);
+    CHECK_EQ(base::bit_cast<int32_t>(t.fPosInf), 0x040);
+    CHECK_EQ(base::bit_cast<int32_t>(t.fPosNorm), 0x080);
+    CHECK_EQ(base::bit_cast<int32_t>(t.fPosSubnorm), 0x100);
+    CHECK_EQ(base::bit_cast<int32_t>(t.fPosZero), 0x200);
   }
 }
 
@@ -4026,100 +4026,100 @@ TEST(CMP_COND_FMT) {
     test.fOp1 = 2.0;
     test.fOp2 = 3.0;
     (f.Call(&test, 0, 0, 0, 0));
-    CHECK_EQ(bit_cast<uint64_t>(test.dF), dFalse);
-    CHECK_EQ(bit_cast<uint64_t>(test.dUn), dFalse);
-    CHECK_EQ(bit_cast<uint64_t>(test.dEq), dFalse);
-    CHECK_EQ(bit_cast<uint64_t>(test.dUeq), dFalse);
-    CHECK_EQ(bit_cast<uint64_t>(test.dOlt), dTrue);
-    CHECK_EQ(bit_cast<uint64_t>(test.dUlt), dTrue);
-    CHECK_EQ(bit_cast<uint64_t>(test.dOle), dTrue);
-    CHECK_EQ(bit_cast<uint64_t>(test.dUle), dTrue);
-    CHECK_EQ(bit_cast<uint64_t>(test.dOr), dTrue);
-    CHECK_EQ(bit_cast<uint64_t>(test.dUne), dTrue);
-    CHECK_EQ(bit_cast<uint64_t>(test.dNe), dTrue);
-    CHECK_EQ(bit_cast<uint32_t>(test.fF), fFalse);
-    CHECK_EQ(bit_cast<uint32_t>(test.fUn), fFalse);
-    CHECK_EQ(bit_cast<uint32_t>(test.fEq), fFalse);
-    CHECK_EQ(bit_cast<uint32_t>(test.fUeq), fFalse);
-    CHECK_EQ(bit_cast<uint32_t>(test.fOlt), fTrue);
-    CHECK_EQ(bit_cast<uint32_t>(test.fUlt), fTrue);
-    CHECK_EQ(bit_cast<uint32_t>(test.fOle), fTrue);
-    CHECK_EQ(bit_cast<uint32_t>(test.fUle), fTrue);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dF), dFalse);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dUn), dFalse);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dEq), dFalse);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dUeq), dFalse);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dOlt), dTrue);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dUlt), dTrue);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dOle), dTrue);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dUle), dTrue);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dOr), dTrue);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dUne), dTrue);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dNe), dTrue);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fF), fFalse);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fUn), fFalse);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fEq), fFalse);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fUeq), fFalse);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fOlt), fTrue);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fUlt), fTrue);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fOle), fTrue);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fUle), fTrue);
 
     test.dOp1 = std::numeric_limits<double>::max();
     test.dOp2 = std::numeric_limits<double>::min();
     test.fOp1 = std::numeric_limits<float>::min();
     test.fOp2 = -std::numeric_limits<float>::max();  // lowest()
     (f.Call(&test, 0, 0, 0, 0));
-    CHECK_EQ(bit_cast<uint64_t>(test.dF), dFalse);
-    CHECK_EQ(bit_cast<uint64_t>(test.dUn), dFalse);
-    CHECK_EQ(bit_cast<uint64_t>(test.dEq), dFalse);
-    CHECK_EQ(bit_cast<uint64_t>(test.dUeq), dFalse);
-    CHECK_EQ(bit_cast<uint64_t>(test.dOlt), dFalse);
-    CHECK_EQ(bit_cast<uint64_t>(test.dUlt), dFalse);
-    CHECK_EQ(bit_cast<uint64_t>(test.dOle), dFalse);
-    CHECK_EQ(bit_cast<uint64_t>(test.dUle), dFalse);
-    CHECK_EQ(bit_cast<uint64_t>(test.dOr), dTrue);
-    CHECK_EQ(bit_cast<uint64_t>(test.dUne), dTrue);
-    CHECK_EQ(bit_cast<uint64_t>(test.dNe), dTrue);
-    CHECK_EQ(bit_cast<uint32_t>(test.fF), fFalse);
-    CHECK_EQ(bit_cast<uint32_t>(test.fUn), fFalse);
-    CHECK_EQ(bit_cast<uint32_t>(test.fEq), fFalse);
-    CHECK_EQ(bit_cast<uint32_t>(test.fUeq), fFalse);
-    CHECK_EQ(bit_cast<uint32_t>(test.fOlt), fFalse);
-    CHECK_EQ(bit_cast<uint32_t>(test.fUlt), fFalse);
-    CHECK_EQ(bit_cast<uint32_t>(test.fOle), fFalse);
-    CHECK_EQ(bit_cast<uint32_t>(test.fUle), fFalse);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dF), dFalse);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dUn), dFalse);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dEq), dFalse);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dUeq), dFalse);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dOlt), dFalse);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dUlt), dFalse);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dOle), dFalse);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dUle), dFalse);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dOr), dTrue);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dUne), dTrue);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dNe), dTrue);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fF), fFalse);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fUn), fFalse);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fEq), fFalse);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fUeq), fFalse);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fOlt), fFalse);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fUlt), fFalse);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fOle), fFalse);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fUle), fFalse);
 
     test.dOp1 = -std::numeric_limits<double>::max();  // lowest()
     test.dOp2 = -std::numeric_limits<double>::max();  // lowest()
     test.fOp1 = std::numeric_limits<float>::max();
     test.fOp2 = std::numeric_limits<float>::max();
     (f.Call(&test, 0, 0, 0, 0));
-    CHECK_EQ(bit_cast<uint64_t>(test.dF), dFalse);
-    CHECK_EQ(bit_cast<uint64_t>(test.dUn), dFalse);
-    CHECK_EQ(bit_cast<uint64_t>(test.dEq), dTrue);
-    CHECK_EQ(bit_cast<uint64_t>(test.dUeq), dTrue);
-    CHECK_EQ(bit_cast<uint64_t>(test.dOlt), dFalse);
-    CHECK_EQ(bit_cast<uint64_t>(test.dUlt), dFalse);
-    CHECK_EQ(bit_cast<uint64_t>(test.dOle), dTrue);
-    CHECK_EQ(bit_cast<uint64_t>(test.dUle), dTrue);
-    CHECK_EQ(bit_cast<uint64_t>(test.dOr), dTrue);
-    CHECK_EQ(bit_cast<uint64_t>(test.dUne), dFalse);
-    CHECK_EQ(bit_cast<uint64_t>(test.dNe), dFalse);
-    CHECK_EQ(bit_cast<uint32_t>(test.fF), fFalse);
-    CHECK_EQ(bit_cast<uint32_t>(test.fUn), fFalse);
-    CHECK_EQ(bit_cast<uint32_t>(test.fEq), fTrue);
-    CHECK_EQ(bit_cast<uint32_t>(test.fUeq), fTrue);
-    CHECK_EQ(bit_cast<uint32_t>(test.fOlt), fFalse);
-    CHECK_EQ(bit_cast<uint32_t>(test.fUlt), fFalse);
-    CHECK_EQ(bit_cast<uint32_t>(test.fOle), fTrue);
-    CHECK_EQ(bit_cast<uint32_t>(test.fUle), fTrue);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dF), dFalse);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dUn), dFalse);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dEq), dTrue);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dUeq), dTrue);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dOlt), dFalse);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dUlt), dFalse);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dOle), dTrue);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dUle), dTrue);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dOr), dTrue);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dUne), dFalse);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dNe), dFalse);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fF), fFalse);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fUn), fFalse);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fEq), fTrue);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fUeq), fTrue);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fOlt), fFalse);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fUlt), fFalse);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fOle), fTrue);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fUle), fTrue);
 
     test.dOp1 = std::numeric_limits<double>::quiet_NaN();
     test.dOp2 = 0.0;
     test.fOp1 = std::numeric_limits<float>::quiet_NaN();
     test.fOp2 = 0.0;
     (f.Call(&test, 0, 0, 0, 0));
-    CHECK_EQ(bit_cast<uint64_t>(test.dF), dFalse);
-    CHECK_EQ(bit_cast<uint64_t>(test.dUn), dTrue);
-    CHECK_EQ(bit_cast<uint64_t>(test.dEq), dFalse);
-    CHECK_EQ(bit_cast<uint64_t>(test.dUeq), dTrue);
-    CHECK_EQ(bit_cast<uint64_t>(test.dOlt), dFalse);
-    CHECK_EQ(bit_cast<uint64_t>(test.dUlt), dTrue);
-    CHECK_EQ(bit_cast<uint64_t>(test.dOle), dFalse);
-    CHECK_EQ(bit_cast<uint64_t>(test.dUle), dTrue);
-    CHECK_EQ(bit_cast<uint64_t>(test.dOr), dFalse);
-    CHECK_EQ(bit_cast<uint64_t>(test.dUne), dTrue);
-    CHECK_EQ(bit_cast<uint64_t>(test.dNe), dFalse);
-    CHECK_EQ(bit_cast<uint32_t>(test.fF), fFalse);
-    CHECK_EQ(bit_cast<uint32_t>(test.fUn), fTrue);
-    CHECK_EQ(bit_cast<uint32_t>(test.fEq), fFalse);
-    CHECK_EQ(bit_cast<uint32_t>(test.fUeq), fTrue);
-    CHECK_EQ(bit_cast<uint32_t>(test.fOlt), fFalse);
-    CHECK_EQ(bit_cast<uint32_t>(test.fUlt), fTrue);
-    CHECK_EQ(bit_cast<uint32_t>(test.fOle), fFalse);
-    CHECK_EQ(bit_cast<uint32_t>(test.fUle), fTrue);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dF), dFalse);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dUn), dTrue);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dEq), dFalse);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dUeq), dTrue);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dOlt), dFalse);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dUlt), dTrue);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dOle), dFalse);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dUle), dTrue);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dOr), dFalse);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dUne), dTrue);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dNe), dFalse);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fF), fFalse);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fUn), fTrue);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fEq), fFalse);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fUeq), fTrue);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fOlt), fFalse);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fUlt), fTrue);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fOle), fFalse);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fUle), fTrue);
   }
 }
 
@@ -10326,18 +10326,24 @@ TEST(MSA_fexdo) {
        static_cast<int16_t>(0xFC00), static_cast<int16_t>(0x0000)}};
 
   const struct ExpRes_32I exp_res_fexdo_d[] = {
-      {bit_cast<int32_t>(0x7F800000), bit_cast<int32_t>(0x7F7FC99E),
-       bit_cast<int32_t>(0x7F800000), bit_cast<int32_t>(0xC49A4000)},
-      {bit_cast<int32_t>(0xC21BAE14), bit_cast<int32_t>(0xFF800000),
-       bit_cast<int32_t>(0x0082AB1E), bit_cast<int32_t>(0x000BFA5A)},
-      {bit_cast<int32_t>(0x7673B164), bit_cast<int32_t>(0xFB13653D),
-       bit_cast<int32_t>(0x80000000), bit_cast<int32_t>(0x00000000)},
-      {bit_cast<int32_t>(0x000002CA), bit_cast<int32_t>(0x80000000),
-       bit_cast<int32_t>(0x80000001), bit_cast<int32_t>(0x00000001)},
-      {bit_cast<int32_t>(0xFF800000), bit_cast<int32_t>(0x56B5E621),
-       bit_cast<int32_t>(0x00000000), bit_cast<int32_t>(0x7F800000)},
-      {bit_cast<int32_t>(0xF673B164), bit_cast<int32_t>(0x7B13653D),
-       bit_cast<int32_t>(0x0000042E), bit_cast<int32_t>(0x00000000)}};
+      {base::bit_cast<int32_t>(0x7F800000), base::bit_cast<int32_t>(0x7F7FC99E),
+       base::bit_cast<int32_t>(0x7F800000),
+       base::bit_cast<int32_t>(0xC49A4000)},
+      {base::bit_cast<int32_t>(0xC21BAE14), base::bit_cast<int32_t>(0xFF800000),
+       base::bit_cast<int32_t>(0x0082AB1E),
+       base::bit_cast<int32_t>(0x000BFA5A)},
+      {base::bit_cast<int32_t>(0x7673B164), base::bit_cast<int32_t>(0xFB13653D),
+       base::bit_cast<int32_t>(0x80000000),
+       base::bit_cast<int32_t>(0x00000000)},
+      {base::bit_cast<int32_t>(0x000002CA), base::bit_cast<int32_t>(0x80000000),
+       base::bit_cast<int32_t>(0x80000001),
+       base::bit_cast<int32_t>(0x00000001)},
+      {base::bit_cast<int32_t>(0xFF800000), base::bit_cast<int32_t>(0x56B5E621),
+       base::bit_cast<int32_t>(0x00000000),
+       base::bit_cast<int32_t>(0x7F800000)},
+      {base::bit_cast<int32_t>(0xF673B164), base::bit_cast<int32_t>(0x7B13653D),
+       base::bit_cast<int32_t>(0x0000042E),
+       base::bit_cast<int32_t>(0x00000000)}};
 
 #define TEST_FEXDO_H(instruction, src, exp_res)                               \
   run_msa_3rf(reinterpret_cast<const struct TestCaseMsa3RF*>(src),            \
@@ -10401,18 +10407,24 @@ TEST(MSA_ftq) {
        static_cast<int16_t>(0x8000), static_cast<int16_t>(0x0000)}};
 
   const struct ExpRes_32I exp_res_ftq_d[] = {
-      {bit_cast<int32_t>(0x7FFFFFFF), bit_cast<int32_t>(0xFFFEFBF4),
-       bit_cast<int32_t>(0x7FFFFFFF), bit_cast<int32_t>(0x8020C49C)},
-      {bit_cast<int32_t>(0x004B5DCC), bit_cast<int32_t>(0x00000000),
-       bit_cast<int32_t>(0x000000D7), bit_cast<int32_t>(0xB374BC6A)},
-      {bit_cast<int32_t>(0x80000000), bit_cast<int32_t>(0x7FFFFFFF),
-       bit_cast<int32_t>(0x7FFFFFFF), bit_cast<int32_t>(0x80000000)},
-      {bit_cast<int32_t>(0x7FFCB900), bit_cast<int32_t>(0xFFF572DE),
-       bit_cast<int32_t>(0x00000000), bit_cast<int32_t>(0x80000000)},
-      {bit_cast<int32_t>(0x80000000), bit_cast<int32_t>(0x00000000),
-       bit_cast<int32_t>(0x00000000), bit_cast<int32_t>(0x7FFFFFFF)},
-      {bit_cast<int32_t>(0x7FFFFFFF), bit_cast<int32_t>(0x00000000),
-       bit_cast<int32_t>(0x80000000), bit_cast<int32_t>(0x00000000)}};
+      {base::bit_cast<int32_t>(0x7FFFFFFF), base::bit_cast<int32_t>(0xFFFEFBF4),
+       base::bit_cast<int32_t>(0x7FFFFFFF),
+       base::bit_cast<int32_t>(0x8020C49C)},
+      {base::bit_cast<int32_t>(0x004B5DCC), base::bit_cast<int32_t>(0x00000000),
+       base::bit_cast<int32_t>(0x000000D7),
+       base::bit_cast<int32_t>(0xB374BC6A)},
+      {base::bit_cast<int32_t>(0x80000000), base::bit_cast<int32_t>(0x7FFFFFFF),
+       base::bit_cast<int32_t>(0x7FFFFFFF),
+       base::bit_cast<int32_t>(0x80000000)},
+      {base::bit_cast<int32_t>(0x7FFCB900), base::bit_cast<int32_t>(0xFFF572DE),
+       base::bit_cast<int32_t>(0x00000000),
+       base::bit_cast<int32_t>(0x80000000)},
+      {base::bit_cast<int32_t>(0x80000000), base::bit_cast<int32_t>(0x00000000),
+       base::bit_cast<int32_t>(0x00000000),
+       base::bit_cast<int32_t>(0x7FFFFFFF)},
+      {base::bit_cast<int32_t>(0x7FFFFFFF), base::bit_cast<int32_t>(0x00000000),
+       base::bit_cast<int32_t>(0x80000000),
+       base::bit_cast<int32_t>(0x00000000)}};
 
 #define TEST_FTQ_H(instruction, src, exp_res)                                 \
   run_msa_3rf(reinterpret_cast<const struct TestCaseMsa3RF*>(src),            \
diff --git a/test/cctest/test-assembler-mips64.cc b/test/cctest/test-assembler-mips64.cc
index 0f1463dcaaf..b2b1d7145b9 100644
--- a/test/cctest/test-assembler-mips64.cc
+++ b/test/cctest/test-assembler-mips64.cc
@@ -3662,28 +3662,28 @@ TEST(class_fmt) {
 
     f.Call(&t, 0, 0, 0, 0);
     // Expected double results.
-    CHECK_EQ(bit_cast<int64_t>(t.dSignalingNan), 0x001);
-    CHECK_EQ(bit_cast<int64_t>(t.dQuietNan),     0x002);
-    CHECK_EQ(bit_cast<int64_t>(t.dNegInf),       0x004);
-    CHECK_EQ(bit_cast<int64_t>(t.dNegNorm),      0x008);
-    CHECK_EQ(bit_cast<int64_t>(t.dNegSubnorm),   0x010);
-    CHECK_EQ(bit_cast<int64_t>(t.dNegZero),      0x020);
-    CHECK_EQ(bit_cast<int64_t>(t.dPosInf),       0x040);
-    CHECK_EQ(bit_cast<int64_t>(t.dPosNorm),      0x080);
-    CHECK_EQ(bit_cast<int64_t>(t.dPosSubnorm),   0x100);
-    CHECK_EQ(bit_cast<int64_t>(t.dPosZero),      0x200);
+    CHECK_EQ(base::bit_cast<int64_t>(t.dSignalingNan), 0x001);
+    CHECK_EQ(base::bit_cast<int64_t>(t.dQuietNan), 0x002);
+    CHECK_EQ(base::bit_cast<int64_t>(t.dNegInf), 0x004);
+    CHECK_EQ(base::bit_cast<int64_t>(t.dNegNorm), 0x008);
+    CHECK_EQ(base::bit_cast<int64_t>(t.dNegSubnorm), 0x010);
+    CHECK_EQ(base::bit_cast<int64_t>(t.dNegZero), 0x020);
+    CHECK_EQ(base::bit_cast<int64_t>(t.dPosInf), 0x040);
+    CHECK_EQ(base::bit_cast<int64_t>(t.dPosNorm), 0x080);
+    CHECK_EQ(base::bit_cast<int64_t>(t.dPosSubnorm), 0x100);
+    CHECK_EQ(base::bit_cast<int64_t>(t.dPosZero), 0x200);
 
     // Expected float results.
-    CHECK_EQ(bit_cast<int32_t>(t.fSignalingNan), 0x001);
-    CHECK_EQ(bit_cast<int32_t>(t.fQuietNan),     0x002);
-    CHECK_EQ(bit_cast<int32_t>(t.fNegInf),       0x004);
-    CHECK_EQ(bit_cast<int32_t>(t.fNegNorm),      0x008);
-    CHECK_EQ(bit_cast<int32_t>(t.fNegSubnorm),   0x010);
-    CHECK_EQ(bit_cast<int32_t>(t.fNegZero),      0x020);
-    CHECK_EQ(bit_cast<int32_t>(t.fPosInf),       0x040);
-    CHECK_EQ(bit_cast<int32_t>(t.fPosNorm),      0x080);
-    CHECK_EQ(bit_cast<int32_t>(t.fPosSubnorm),   0x100);
-    CHECK_EQ(bit_cast<int32_t>(t.fPosZero),      0x200);
+    CHECK_EQ(base::bit_cast<int32_t>(t.fSignalingNan), 0x001);
+    CHECK_EQ(base::bit_cast<int32_t>(t.fQuietNan), 0x002);
+    CHECK_EQ(base::bit_cast<int32_t>(t.fNegInf), 0x004);
+    CHECK_EQ(base::bit_cast<int32_t>(t.fNegNorm), 0x008);
+    CHECK_EQ(base::bit_cast<int32_t>(t.fNegSubnorm), 0x010);
+    CHECK_EQ(base::bit_cast<int32_t>(t.fNegZero), 0x020);
+    CHECK_EQ(base::bit_cast<int32_t>(t.fPosInf), 0x040);
+    CHECK_EQ(base::bit_cast<int32_t>(t.fPosNorm), 0x080);
+    CHECK_EQ(base::bit_cast<int32_t>(t.fPosSubnorm), 0x100);
+    CHECK_EQ(base::bit_cast<int32_t>(t.fPosZero), 0x200);
   }
 }
 
@@ -4185,100 +4185,100 @@ TEST(CMP_COND_FMT) {
     test.fOp1 = 2.0;
     test.fOp2 = 3.0;
     f.Call(&test, 0, 0, 0, 0);
-    CHECK_EQ(bit_cast<uint64_t>(test.dF), dFalse);
-    CHECK_EQ(bit_cast<uint64_t>(test.dUn), dFalse);
-    CHECK_EQ(bit_cast<uint64_t>(test.dEq), dFalse);
-    CHECK_EQ(bit_cast<uint64_t>(test.dUeq), dFalse);
-    CHECK_EQ(bit_cast<uint64_t>(test.dOlt), dTrue);
-    CHECK_EQ(bit_cast<uint64_t>(test.dUlt), dTrue);
-    CHECK_EQ(bit_cast<uint64_t>(test.dOle), dTrue);
-    CHECK_EQ(bit_cast<uint64_t>(test.dUle), dTrue);
-    CHECK_EQ(bit_cast<uint64_t>(test.dOr), dTrue);
-    CHECK_EQ(bit_cast<uint64_t>(test.dUne), dTrue);
-    CHECK_EQ(bit_cast<uint64_t>(test.dNe), dTrue);
-    CHECK_EQ(bit_cast<uint32_t>(test.fF), fFalse);
-    CHECK_EQ(bit_cast<uint32_t>(test.fUn), fFalse);
-    CHECK_EQ(bit_cast<uint32_t>(test.fEq), fFalse);
-    CHECK_EQ(bit_cast<uint32_t>(test.fUeq), fFalse);
-    CHECK_EQ(bit_cast<uint32_t>(test.fOlt), fTrue);
-    CHECK_EQ(bit_cast<uint32_t>(test.fUlt), fTrue);
-    CHECK_EQ(bit_cast<uint32_t>(test.fOle), fTrue);
-    CHECK_EQ(bit_cast<uint32_t>(test.fUle), fTrue);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dF), dFalse);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dUn), dFalse);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dEq), dFalse);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dUeq), dFalse);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dOlt), dTrue);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dUlt), dTrue);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dOle), dTrue);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dUle), dTrue);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dOr), dTrue);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dUne), dTrue);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dNe), dTrue);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fF), fFalse);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fUn), fFalse);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fEq), fFalse);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fUeq), fFalse);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fOlt), fTrue);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fUlt), fTrue);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fOle), fTrue);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fUle), fTrue);
 
     test.dOp1 = std::numeric_limits<double>::max();
     test.dOp2 = std::numeric_limits<double>::min();
     test.fOp1 = std::numeric_limits<float>::min();
     test.fOp2 = -std::numeric_limits<float>::max();  // lowest()
     f.Call(&test, 0, 0, 0, 0);
-    CHECK_EQ(bit_cast<uint64_t>(test.dF), dFalse);
-    CHECK_EQ(bit_cast<uint64_t>(test.dUn), dFalse);
-    CHECK_EQ(bit_cast<uint64_t>(test.dEq), dFalse);
-    CHECK_EQ(bit_cast<uint64_t>(test.dUeq), dFalse);
-    CHECK_EQ(bit_cast<uint64_t>(test.dOlt), dFalse);
-    CHECK_EQ(bit_cast<uint64_t>(test.dUlt), dFalse);
-    CHECK_EQ(bit_cast<uint64_t>(test.dOle), dFalse);
-    CHECK_EQ(bit_cast<uint64_t>(test.dUle), dFalse);
-    CHECK_EQ(bit_cast<uint64_t>(test.dOr), dTrue);
-    CHECK_EQ(bit_cast<uint64_t>(test.dUne), dTrue);
-    CHECK_EQ(bit_cast<uint64_t>(test.dNe), dTrue);
-    CHECK_EQ(bit_cast<uint32_t>(test.fF), fFalse);
-    CHECK_EQ(bit_cast<uint32_t>(test.fUn), fFalse);
-    CHECK_EQ(bit_cast<uint32_t>(test.fEq), fFalse);
-    CHECK_EQ(bit_cast<uint32_t>(test.fUeq), fFalse);
-    CHECK_EQ(bit_cast<uint32_t>(test.fOlt), fFalse);
-    CHECK_EQ(bit_cast<uint32_t>(test.fUlt), fFalse);
-    CHECK_EQ(bit_cast<uint32_t>(test.fOle), fFalse);
-    CHECK_EQ(bit_cast<uint32_t>(test.fUle), fFalse);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dF), dFalse);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dUn), dFalse);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dEq), dFalse);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dUeq), dFalse);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dOlt), dFalse);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dUlt), dFalse);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dOle), dFalse);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dUle), dFalse);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dOr), dTrue);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dUne), dTrue);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dNe), dTrue);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fF), fFalse);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fUn), fFalse);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fEq), fFalse);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fUeq), fFalse);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fOlt), fFalse);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fUlt), fFalse);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fOle), fFalse);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fUle), fFalse);
 
     test.dOp1 = -std::numeric_limits<double>::max();  // lowest()
     test.dOp2 = -std::numeric_limits<double>::max();  // lowest()
     test.fOp1 = std::numeric_limits<float>::max();
     test.fOp2 = std::numeric_limits<float>::max();
     f.Call(&test, 0, 0, 0, 0);
-    CHECK_EQ(bit_cast<uint64_t>(test.dF), dFalse);
-    CHECK_EQ(bit_cast<uint64_t>(test.dUn), dFalse);
-    CHECK_EQ(bit_cast<uint64_t>(test.dEq), dTrue);
-    CHECK_EQ(bit_cast<uint64_t>(test.dUeq), dTrue);
-    CHECK_EQ(bit_cast<uint64_t>(test.dOlt), dFalse);
-    CHECK_EQ(bit_cast<uint64_t>(test.dUlt), dFalse);
-    CHECK_EQ(bit_cast<uint64_t>(test.dOle), dTrue);
-    CHECK_EQ(bit_cast<uint64_t>(test.dUle), dTrue);
-    CHECK_EQ(bit_cast<uint64_t>(test.dOr), dTrue);
-    CHECK_EQ(bit_cast<uint64_t>(test.dUne), dFalse);
-    CHECK_EQ(bit_cast<uint64_t>(test.dNe), dFalse);
-    CHECK_EQ(bit_cast<uint32_t>(test.fF), fFalse);
-    CHECK_EQ(bit_cast<uint32_t>(test.fUn), fFalse);
-    CHECK_EQ(bit_cast<uint32_t>(test.fEq), fTrue);
-    CHECK_EQ(bit_cast<uint32_t>(test.fUeq), fTrue);
-    CHECK_EQ(bit_cast<uint32_t>(test.fOlt), fFalse);
-    CHECK_EQ(bit_cast<uint32_t>(test.fUlt), fFalse);
-    CHECK_EQ(bit_cast<uint32_t>(test.fOle), fTrue);
-    CHECK_EQ(bit_cast<uint32_t>(test.fUle), fTrue);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dF), dFalse);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dUn), dFalse);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dEq), dTrue);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dUeq), dTrue);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dOlt), dFalse);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dUlt), dFalse);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dOle), dTrue);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dUle), dTrue);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dOr), dTrue);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dUne), dFalse);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dNe), dFalse);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fF), fFalse);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fUn), fFalse);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fEq), fTrue);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fUeq), fTrue);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fOlt), fFalse);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fUlt), fFalse);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fOle), fTrue);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fUle), fTrue);
 
     test.dOp1 = std::numeric_limits<double>::quiet_NaN();
     test.dOp2 = 0.0;
     test.fOp1 = std::numeric_limits<float>::quiet_NaN();
     test.fOp2 = 0.0;
     f.Call(&test, 0, 0, 0, 0);
-    CHECK_EQ(bit_cast<uint64_t>(test.dF), dFalse);
-    CHECK_EQ(bit_cast<uint64_t>(test.dUn), dTrue);
-    CHECK_EQ(bit_cast<uint64_t>(test.dEq), dFalse);
-    CHECK_EQ(bit_cast<uint64_t>(test.dUeq), dTrue);
-    CHECK_EQ(bit_cast<uint64_t>(test.dOlt), dFalse);
-    CHECK_EQ(bit_cast<uint64_t>(test.dUlt), dTrue);
-    CHECK_EQ(bit_cast<uint64_t>(test.dOle), dFalse);
-    CHECK_EQ(bit_cast<uint64_t>(test.dUle), dTrue);
-    CHECK_EQ(bit_cast<uint64_t>(test.dOr), dFalse);
-    CHECK_EQ(bit_cast<uint64_t>(test.dUne), dTrue);
-    CHECK_EQ(bit_cast<uint64_t>(test.dNe), dFalse);
-    CHECK_EQ(bit_cast<uint32_t>(test.fF), fFalse);
-    CHECK_EQ(bit_cast<uint32_t>(test.fUn), fTrue);
-    CHECK_EQ(bit_cast<uint32_t>(test.fEq), fFalse);
-    CHECK_EQ(bit_cast<uint32_t>(test.fUeq), fTrue);
-    CHECK_EQ(bit_cast<uint32_t>(test.fOlt), fFalse);
-    CHECK_EQ(bit_cast<uint32_t>(test.fUlt), fTrue);
-    CHECK_EQ(bit_cast<uint32_t>(test.fOle), fFalse);
-    CHECK_EQ(bit_cast<uint32_t>(test.fUle), fTrue);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dF), dFalse);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dUn), dTrue);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dEq), dFalse);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dUeq), dTrue);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dOlt), dFalse);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dUlt), dTrue);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dOle), dFalse);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dUle), dTrue);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dOr), dFalse);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dUne), dTrue);
+    CHECK_EQ(base::bit_cast<uint64_t>(test.dNe), dFalse);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fF), fFalse);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fUn), fTrue);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fEq), fFalse);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fUeq), fTrue);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fOlt), fFalse);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fUlt), fTrue);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fOle), fFalse);
+    CHECK_EQ(base::bit_cast<uint32_t>(test.fUle), fTrue);
   }
 }
 
@@ -7065,9 +7065,10 @@ void run_msa_ctc_cfc(uint64_t value) {
   uint64_t res;
   f.Call(&res, 0, 0, 0, 0);
 
-  CHECK_EQ(bit_cast<uint64_t>(static_cast<int64_t>(
-               bit_cast<int32_t>(static_cast<uint32_t>(value & 0x0167FFFF)))),
-           res);
+  CHECK_EQ(
+      base::bit_cast<uint64_t>(static_cast<int64_t>(
+          base::bit_cast<int32_t>(static_cast<uint32_t>(value & 0x0167FFFF)))),
+      res);
 }
 
 TEST(MSA_move_v) {
@@ -11240,18 +11241,24 @@ TEST(MSA_fexdo) {
        static_cast<int16_t>(0xFC00), static_cast<int16_t>(0x0000)}};
 
   const struct ExpRes_32I exp_res_fexdo_d[] = {
-      {bit_cast<int32_t>(0x7F800000), bit_cast<int32_t>(0x7F7FC99E),
-       bit_cast<int32_t>(0x7F800000), bit_cast<int32_t>(0xC49A4000)},
-      {bit_cast<int32_t>(0xC21BAE14), bit_cast<int32_t>(0xFF800000),
-       bit_cast<int32_t>(0x0082AB1E), bit_cast<int32_t>(0x000BFA5A)},
-      {bit_cast<int32_t>(0x7673B164), bit_cast<int32_t>(0xFB13653D),
-       bit_cast<int32_t>(0x80000000), bit_cast<int32_t>(0x00000000)},
-      {bit_cast<int32_t>(0x000002CA), bit_cast<int32_t>(0x80000000),
-       bit_cast<int32_t>(0x80000001), bit_cast<int32_t>(0x00000001)},
-      {bit_cast<int32_t>(0xFF800000), bit_cast<int32_t>(0x56B5E621),
-       bit_cast<int32_t>(0x00000000), bit_cast<int32_t>(0x7F800000)},
-      {bit_cast<int32_t>(0xF673B164), bit_cast<int32_t>(0x7B13653D),
-       bit_cast<int32_t>(0x0000042E), bit_cast<int32_t>(0x00000000)}};
+      {base::bit_cast<int32_t>(0x7F800000), base::bit_cast<int32_t>(0x7F7FC99E),
+       base::bit_cast<int32_t>(0x7F800000),
+       base::bit_cast<int32_t>(0xC49A4000)},
+      {base::bit_cast<int32_t>(0xC21BAE14), base::bit_cast<int32_t>(0xFF800000),
+       base::bit_cast<int32_t>(0x0082AB1E),
+       base::bit_cast<int32_t>(0x000BFA5A)},
+      {base::bit_cast<int32_t>(0x7673B164), base::bit_cast<int32_t>(0xFB13653D),
+       base::bit_cast<int32_t>(0x80000000),
+       base::bit_cast<int32_t>(0x00000000)},
+      {base::bit_cast<int32_t>(0x000002CA), base::bit_cast<int32_t>(0x80000000),
+       base::bit_cast<int32_t>(0x80000001),
+       base::bit_cast<int32_t>(0x00000001)},
+      {base::bit_cast<int32_t>(0xFF800000), base::bit_cast<int32_t>(0x56B5E621),
+       base::bit_cast<int32_t>(0x00000000),
+       base::bit_cast<int32_t>(0x7F800000)},
+      {base::bit_cast<int32_t>(0xF673B164), base::bit_cast<int32_t>(0x7B13653D),
+       base::bit_cast<int32_t>(0x0000042E),
+       base::bit_cast<int32_t>(0x00000000)}};
 
 #define TEST_FEXDO_H(instruction, src, exp_res)                               \
   run_msa_3rf(reinterpret_cast<const struct TestCaseMsa3RF*>(src),            \
@@ -11315,18 +11322,24 @@ TEST(MSA_ftq) {
        static_cast<int16_t>(0x8000), static_cast<int16_t>(0x0000)}};
 
   const struct ExpRes_32I exp_res_ftq_d[] = {
-      {bit_cast<int32_t>(0x7FFFFFFF), bit_cast<int32_t>(0xFFFEFBF4),
-       bit_cast<int32_t>(0x7FFFFFFF), bit_cast<int32_t>(0x8020C49C)},
-      {bit_cast<int32_t>(0x004B5DCC), bit_cast<int32_t>(0x00000000),
-       bit_cast<int32_t>(0x000000D7), bit_cast<int32_t>(0xB374BC6A)},
-      {bit_cast<int32_t>(0x80000000), bit_cast<int32_t>(0x7FFFFFFF),
-       bit_cast<int32_t>(0x7FFFFFFF), bit_cast<int32_t>(0x80000000)},
-      {bit_cast<int32_t>(0x7FFCB900), bit_cast<int32_t>(0xFFF572DE),
-       bit_cast<int32_t>(0x00000000), bit_cast<int32_t>(0x80000000)},
-      {bit_cast<int32_t>(0x80000000), bit_cast<int32_t>(0x00000000),
-       bit_cast<int32_t>(0x00000000), bit_cast<int32_t>(0x7FFFFFFF)},
-      {bit_cast<int32_t>(0x7FFFFFFF), bit_cast<int32_t>(0x00000000),
-       bit_cast<int32_t>(0x80000000), bit_cast<int32_t>(0x00000000)}};
+      {base::bit_cast<int32_t>(0x7FFFFFFF), base::bit_cast<int32_t>(0xFFFEFBF4),
+       base::bit_cast<int32_t>(0x7FFFFFFF),
+       base::bit_cast<int32_t>(0x8020C49C)},
+      {base::bit_cast<int32_t>(0x004B5DCC), base::bit_cast<int32_t>(0x00000000),
+       base::bit_cast<int32_t>(0x000000D7),
+       base::bit_cast<int32_t>(0xB374BC6A)},
+      {base::bit_cast<int32_t>(0x80000000), base::bit_cast<int32_t>(0x7FFFFFFF),
+       base::bit_cast<int32_t>(0x7FFFFFFF),
+       base::bit_cast<int32_t>(0x80000000)},
+      {base::bit_cast<int32_t>(0x7FFCB900), base::bit_cast<int32_t>(0xFFF572DE),
+       base::bit_cast<int32_t>(0x00000000),
+       base::bit_cast<int32_t>(0x80000000)},
+      {base::bit_cast<int32_t>(0x80000000), base::bit_cast<int32_t>(0x00000000),
+       base::bit_cast<int32_t>(0x00000000),
+       base::bit_cast<int32_t>(0x7FFFFFFF)},
+      {base::bit_cast<int32_t>(0x7FFFFFFF), base::bit_cast<int32_t>(0x00000000),
+       base::bit_cast<int32_t>(0x80000000),
+       base::bit_cast<int32_t>(0x00000000)}};
 
 #define TEST_FTQ_H(instruction, src, exp_res)                                 \
   run_msa_3rf(reinterpret_cast<const struct TestCaseMsa3RF*>(src),            \
diff --git a/test/cctest/test-assembler-riscv64.cc b/test/cctest/test-assembler-riscv64.cc
index 0e18c468edb..d9288bc8251 100644
--- a/test/cctest/test-assembler-riscv64.cc
+++ b/test/cctest/test-assembler-riscv64.cc
@@ -1171,13 +1171,13 @@ TEST(NAN_BOX) {
   {
     auto fn = [](MacroAssembler& assm) { __ fmv_x_d(a0, fa0); };
     auto res = GenAndRunTest<uint64_t>(1234.56f, fn);
-    CHECK_EQ(0xFFFFFFFF00000000 | bit_cast<uint32_t>(1234.56f), res);
+    CHECK_EQ(0xFFFFFFFF00000000 | base::bit_cast<uint32_t>(1234.56f), res);
   }
   // Test NaN boxing in FMV.X.W
   {
     auto fn = [](MacroAssembler& assm) { __ fmv_x_w(a0, fa0); };
     auto res = GenAndRunTest<uint64_t>(1234.56f, fn);
-    CHECK_EQ((uint64_t)bit_cast<uint32_t>(1234.56f), res);
+    CHECK_EQ((uint64_t)base::bit_cast<uint32_t>(1234.56f), res);
   }
 
   // Test FLW and FSW
@@ -1205,8 +1205,8 @@ TEST(NAN_BOX) {
   t.res = 0;
   f.Call(&t, 0, 0, 0, 0);
 
-  CHECK_EQ(0xFFFFFFFF00000000 | bit_cast<int32_t>(t.a), t.box);
-  CHECK_EQ((uint64_t)bit_cast<uint32_t>(t.a), t.res);
+  CHECK_EQ(0xFFFFFFFF00000000 | base::bit_cast<int32_t>(t.a), t.box);
+  CHECK_EQ((uint64_t)base::bit_cast<uint32_t>(t.a), t.res);
 }
 
 TEST(RVC_CI) {
diff --git a/test/cctest/test-field-type-tracking.cc b/test/cctest/test-field-type-tracking.cc
index 90e3341806d..6efee779b76 100644
--- a/test/cctest/test-field-type-tracking.cc
+++ b/test/cctest/test-field-type-tracking.cc
@@ -2897,12 +2897,13 @@ void TestStoreToConstantField_NaN(const char* store_func_source,
   CompileRun(store_func_source);
 
   uint64_t nan_bits = uint64_t{0x7FF8000000000001};
-  double nan_double1 = bit_cast<double>(nan_bits);
-  double nan_double2 = bit_cast<double>(nan_bits | 0x12300);
+  double nan_double1 = base::bit_cast<double>(nan_bits);
+  double nan_double2 = base::bit_cast<double>(nan_bits | 0x12300);
   CHECK(std::isnan(nan_double1));
   CHECK(std::isnan(nan_double2));
   CHECK_NE(nan_double1, nan_double2);
-  CHECK_NE(bit_cast<uint64_t>(nan_double1), bit_cast<uint64_t>(nan_double2));
+  CHECK_NE(base::bit_cast<uint64_t>(nan_double1),
+           base::bit_cast<uint64_t>(nan_double2));
 
   Handle<Object> nan1 = isolate->factory()->NewNumber(nan_double1);
   Handle<Object> nan2 = isolate->factory()->NewNumber(nan_double2);
diff --git a/test/cctest/test-helper-riscv64.h b/test/cctest/test-helper-riscv64.h
index 79a6dca9893..92e09bc5088 100644
--- a/test/cctest/test-helper-riscv64.h
+++ b/test/cctest/test-helper-riscv64.h
@@ -72,8 +72,8 @@ OUTPUT_T GenAndRunTest(INPUT_T input0, Func test_generator) {
 
   auto f = GeneratedCode<OINT_T(IINT_T)>::FromCode(*code);
 
-  auto res = f.Call(bit_cast<IINT_T>(input0));
-  return bit_cast<OUTPUT_T>(res);
+  auto res = f.Call(base::bit_cast<IINT_T>(input0));
+  return base::bit_cast<OUTPUT_T>(res);
 }
 
 template <typename OUTPUT_T, typename INPUT_T>
@@ -119,8 +119,9 @@ OUTPUT_T GenAndRunTest(INPUT_T input0, INPUT_T input1, Func test_generator) {
                                 int64_t>::type>::type;
   auto f = GeneratedCode<OINT_T(IINT_T, IINT_T)>::FromCode(*code);
 
-  auto res = f.Call(bit_cast<IINT_T>(input0), bit_cast<IINT_T>(input1));
-  return bit_cast<OUTPUT_T>(res);
+  auto res =
+      f.Call(base::bit_cast<IINT_T>(input0), base::bit_cast<IINT_T>(input1));
+  return base::bit_cast<OUTPUT_T>(res);
 }
 
 template <typename OUTPUT_T, typename INPUT_T>
@@ -169,9 +170,10 @@ OUTPUT_T GenAndRunTest(INPUT_T input0, INPUT_T input1, INPUT_T input2,
                                 int64_t>::type>::type;
   auto f = GeneratedCode<OINT_T(IINT_T, IINT_T, IINT_T)>::FromCode(*code);
 
-  auto res = f.Call(bit_cast<IINT_T>(input0), bit_cast<IINT_T>(input1),
-                    bit_cast<IINT_T>(input2));
-  return bit_cast<OUTPUT_T>(res);
+  auto res =
+      f.Call(base::bit_cast<IINT_T>(input0), base::bit_cast<IINT_T>(input1),
+             base::bit_cast<IINT_T>(input2));
+  return base::bit_cast<OUTPUT_T>(res);
 }
 
 template <typename T>
@@ -210,8 +212,8 @@ void GenAndRunTestForLoadStore(T value, Func test_generator) {
   auto f = GeneratedCode<INT_T(void* base, INT_T val)>::FromCode(*code);
 
   int64_t tmp = 0;
-  auto res = f.Call(&tmp, bit_cast<INT_T>(value));
-  CHECK_EQ(bit_cast<T>(res), value);
+  auto res = f.Call(&tmp, base::bit_cast<INT_T>(value));
+  CHECK_EQ(base::bit_cast<T>(res), value);
 }
 
 template <typename T, typename Func>
@@ -255,8 +257,8 @@ void GenAndRunTestForLRSC(T value, Func test_generator) {
 
   T tmp = 0;
   auto f = GeneratedCode<INT_T(void* base, INT_T val)>::FromCode(*code);
-  auto res = f.Call(&tmp, bit_cast<T>(value));
-  CHECK_EQ(bit_cast<T>(res), static_cast<T>(0));
+  auto res = f.Call(&tmp, base::bit_cast<T>(value));
+  CHECK_EQ(base::bit_cast<T>(res), static_cast<T>(0));
 }
 
 template <typename INPUT_T, typename OUTPUT_T, typename Func>
@@ -316,8 +318,9 @@ OUTPUT_T GenAndRunTestForAMO(INPUT_T input0, INPUT_T input1,
   OUTPUT_T tmp = 0;
   auto f =
       GeneratedCode<OUTPUT_T(void* base, INPUT_T, INPUT_T)>::FromCode(*code);
-  auto res = f.Call(&tmp, bit_cast<INPUT_T>(input0), bit_cast<INPUT_T>(input1));
-  return bit_cast<OUTPUT_T>(res);
+  auto res = f.Call(&tmp, base::bit_cast<INPUT_T>(input0),
+                    base::bit_cast<INPUT_T>(input1));
+  return base::bit_cast<OUTPUT_T>(res);
 }
 
 Handle<Code> AssembleCodeImpl(Func assemble);
diff --git a/test/cctest/test-macro-assembler-loong64.cc b/test/cctest/test-macro-assembler-loong64.cc
index eac64947e97..8c2005a0792 100644
--- a/test/cctest/test-macro-assembler-loong64.cc
+++ b/test/cctest/test-macro-assembler-loong64.cc
@@ -1521,18 +1521,24 @@ TEST(macro_float_minmax_f32) {
   GeneratedCode<F4> f =
       GenerateMacroFloat32MinMax<FPURegister, Inputs, Results>(masm);
 
-#define CHECK_MINMAX(src1, src2, min, max)                                   \
-  do {                                                                       \
-    Inputs inputs = {src1, src2};                                            \
-    Results results;                                                         \
-    f.Call(&inputs, &results, 0, 0, 0);                                      \
-    CHECK_EQ(bit_cast<uint32_t>(min), bit_cast<uint32_t>(results.min_abc_)); \
-    CHECK_EQ(bit_cast<uint32_t>(min), bit_cast<uint32_t>(results.min_aab_)); \
-    CHECK_EQ(bit_cast<uint32_t>(min), bit_cast<uint32_t>(results.min_aba_)); \
-    CHECK_EQ(bit_cast<uint32_t>(max), bit_cast<uint32_t>(results.max_abc_)); \
-    CHECK_EQ(bit_cast<uint32_t>(max), bit_cast<uint32_t>(results.max_aab_)); \
-    CHECK_EQ(bit_cast<uint32_t>(max), bit_cast<uint32_t>(results.max_aba_)); \
-    /* Use a bit_cast to correctly identify -0.0 and NaNs. */                \
+#define CHECK_MINMAX(src1, src2, min, max)                          \
+  do {                                                              \
+    Inputs inputs = {src1, src2};                                   \
+    Results results;                                                \
+    f.Call(&inputs, &results, 0, 0, 0);                             \
+    CHECK_EQ(base::bit_cast<uint32_t>(min),                         \
+             base::bit_cast<uint32_t>(results.min_abc_));           \
+    CHECK_EQ(base::bit_cast<uint32_t>(min),                         \
+             base::bit_cast<uint32_t>(results.min_aab_));           \
+    CHECK_EQ(base::bit_cast<uint32_t>(min),                         \
+             base::bit_cast<uint32_t>(results.min_aba_));           \
+    CHECK_EQ(base::bit_cast<uint32_t>(max),                         \
+             base::bit_cast<uint32_t>(results.max_abc_));           \
+    CHECK_EQ(base::bit_cast<uint32_t>(max),                         \
+             base::bit_cast<uint32_t>(results.max_aab_));           \
+    CHECK_EQ(base::bit_cast<uint32_t>(max),                         \
+             base::bit_cast<uint32_t>(results.max_aba_));           \
+    /* Use a base::bit_cast to correctly identify -0.0 and NaNs. */ \
   } while (0)
 
   float nan_a = std::numeric_limits<float>::quiet_NaN();
@@ -1662,18 +1668,24 @@ TEST(macro_float_minmax_f64) {
   GeneratedCode<F4> f =
       GenerateMacroFloat64MinMax<DoubleRegister, Inputs, Results>(masm);
 
-#define CHECK_MINMAX(src1, src2, min, max)                                   \
-  do {                                                                       \
-    Inputs inputs = {src1, src2};                                            \
-    Results results;                                                         \
-    f.Call(&inputs, &results, 0, 0, 0);                                      \
-    CHECK_EQ(bit_cast<uint64_t>(min), bit_cast<uint64_t>(results.min_abc_)); \
-    CHECK_EQ(bit_cast<uint64_t>(min), bit_cast<uint64_t>(results.min_aab_)); \
-    CHECK_EQ(bit_cast<uint64_t>(min), bit_cast<uint64_t>(results.min_aba_)); \
-    CHECK_EQ(bit_cast<uint64_t>(max), bit_cast<uint64_t>(results.max_abc_)); \
-    CHECK_EQ(bit_cast<uint64_t>(max), bit_cast<uint64_t>(results.max_aab_)); \
-    CHECK_EQ(bit_cast<uint64_t>(max), bit_cast<uint64_t>(results.max_aba_)); \
-    /* Use a bit_cast to correctly identify -0.0 and NaNs. */                \
+#define CHECK_MINMAX(src1, src2, min, max)                          \
+  do {                                                              \
+    Inputs inputs = {src1, src2};                                   \
+    Results results;                                                \
+    f.Call(&inputs, &results, 0, 0, 0);                             \
+    CHECK_EQ(base::bit_cast<uint64_t>(min),                         \
+             base::bit_cast<uint64_t>(results.min_abc_));           \
+    CHECK_EQ(base::bit_cast<uint64_t>(min),                         \
+             base::bit_cast<uint64_t>(results.min_aab_));           \
+    CHECK_EQ(base::bit_cast<uint64_t>(min),                         \
+             base::bit_cast<uint64_t>(results.min_aba_));           \
+    CHECK_EQ(base::bit_cast<uint64_t>(max),                         \
+             base::bit_cast<uint64_t>(results.max_abc_));           \
+    CHECK_EQ(base::bit_cast<uint64_t>(max),                         \
+             base::bit_cast<uint64_t>(results.max_aab_));           \
+    CHECK_EQ(base::bit_cast<uint64_t>(max),                         \
+             base::bit_cast<uint64_t>(results.max_aba_));           \
+    /* Use a base::bit_cast to correctly identify -0.0 and NaNs. */ \
   } while (0)
 
   double nan_a = std::numeric_limits<double>::quiet_NaN();
diff --git a/test/cctest/test-macro-assembler-mips.cc b/test/cctest/test-macro-assembler-mips.cc
index c4926af159c..b74f40f8f52 100644
--- a/test/cctest/test-macro-assembler-mips.cc
+++ b/test/cctest/test-macro-assembler-mips.cc
@@ -129,8 +129,8 @@ static void TestNaN(const char *code) {
   i::FixedDoubleArray a = i::FixedDoubleArray::cast(array1->elements());
   double value = a.get_scalar(0);
   CHECK(std::isnan(value) &&
-        bit_cast<uint64_t>(value) ==
-            bit_cast<uint64_t>(std::numeric_limits<double>::quiet_NaN()));
+        base::bit_cast<uint64_t>(value) ==
+            base::bit_cast<uint64_t>(std::numeric_limits<double>::quiet_NaN()));
 }
 
 
@@ -1155,18 +1155,24 @@ TEST(macro_float_minmax_f32) {
   GeneratedCode<F4> f =
       GenerateMacroFloat32MinMax<FPURegister, Inputs, Results>(masm);
 
-#define CHECK_MINMAX(src1, src2, min, max)                                   \
-  do {                                                                       \
-    Inputs inputs = {src1, src2};                                            \
-    Results results;                                                         \
-    f.Call(&inputs, &results, 0, 0, 0);                                      \
-    CHECK_EQ(bit_cast<uint32_t>(min), bit_cast<uint32_t>(results.min_abc_)); \
-    CHECK_EQ(bit_cast<uint32_t>(min), bit_cast<uint32_t>(results.min_aab_)); \
-    CHECK_EQ(bit_cast<uint32_t>(min), bit_cast<uint32_t>(results.min_aba_)); \
-    CHECK_EQ(bit_cast<uint32_t>(max), bit_cast<uint32_t>(results.max_abc_)); \
-    CHECK_EQ(bit_cast<uint32_t>(max), bit_cast<uint32_t>(results.max_aab_)); \
-    CHECK_EQ(bit_cast<uint32_t>(max), bit_cast<uint32_t>(results.max_aba_)); \
-    /* Use a bit_cast to correctly identify -0.0 and NaNs. */                \
+#define CHECK_MINMAX(src1, src2, min, max)                          \
+  do {                                                              \
+    Inputs inputs = {src1, src2};                                   \
+    Results results;                                                \
+    f.Call(&inputs, &results, 0, 0, 0);                             \
+    CHECK_EQ(base::bit_cast<uint32_t>(min),                         \
+             base::bit_cast<uint32_t>(results.min_abc_));           \
+    CHECK_EQ(base::bit_cast<uint32_t>(min),                         \
+             base::bit_cast<uint32_t>(results.min_aab_));           \
+    CHECK_EQ(base::bit_cast<uint32_t>(min),                         \
+             base::bit_cast<uint32_t>(results.min_aba_));           \
+    CHECK_EQ(base::bit_cast<uint32_t>(max),                         \
+             base::bit_cast<uint32_t>(results.max_abc_));           \
+    CHECK_EQ(base::bit_cast<uint32_t>(max),                         \
+             base::bit_cast<uint32_t>(results.max_aab_));           \
+    CHECK_EQ(base::bit_cast<uint32_t>(max),                         \
+             base::bit_cast<uint32_t>(results.max_aba_));           \
+    /* Use a base::bit_cast to correctly identify -0.0 and NaNs. */ \
   } while (0)
 
   float nan_a = std::numeric_limits<float>::quiet_NaN();
@@ -1297,18 +1303,24 @@ TEST(macro_float_minmax_f64) {
   GeneratedCode<F4> f =
       GenerateMacroFloat64MinMax<DoubleRegister, Inputs, Results>(masm);
 
-#define CHECK_MINMAX(src1, src2, min, max)                                   \
-  do {                                                                       \
-    Inputs inputs = {src1, src2};                                            \
-    Results results;                                                         \
-    f.Call(&inputs, &results, 0, 0, 0);                                      \
-    CHECK_EQ(bit_cast<uint64_t>(min), bit_cast<uint64_t>(results.min_abc_)); \
-    CHECK_EQ(bit_cast<uint64_t>(min), bit_cast<uint64_t>(results.min_aab_)); \
-    CHECK_EQ(bit_cast<uint64_t>(min), bit_cast<uint64_t>(results.min_aba_)); \
-    CHECK_EQ(bit_cast<uint64_t>(max), bit_cast<uint64_t>(results.max_abc_)); \
-    CHECK_EQ(bit_cast<uint64_t>(max), bit_cast<uint64_t>(results.max_aab_)); \
-    CHECK_EQ(bit_cast<uint64_t>(max), bit_cast<uint64_t>(results.max_aba_)); \
-    /* Use a bit_cast to correctly identify -0.0 and NaNs. */                \
+#define CHECK_MINMAX(src1, src2, min, max)                          \
+  do {                                                              \
+    Inputs inputs = {src1, src2};                                   \
+    Results results;                                                \
+    f.Call(&inputs, &results, 0, 0, 0);                             \
+    CHECK_EQ(base::bit_cast<uint64_t>(min),                         \
+             base::bit_cast<uint64_t>(results.min_abc_));           \
+    CHECK_EQ(base::bit_cast<uint64_t>(min),                         \
+             base::bit_cast<uint64_t>(results.min_aab_));           \
+    CHECK_EQ(base::bit_cast<uint64_t>(min),                         \
+             base::bit_cast<uint64_t>(results.min_aba_));           \
+    CHECK_EQ(base::bit_cast<uint64_t>(max),                         \
+             base::bit_cast<uint64_t>(results.max_abc_));           \
+    CHECK_EQ(base::bit_cast<uint64_t>(max),                         \
+             base::bit_cast<uint64_t>(results.max_aab_));           \
+    CHECK_EQ(base::bit_cast<uint64_t>(max),                         \
+             base::bit_cast<uint64_t>(results.max_aba_));           \
+    /* Use a base::bit_cast to correctly identify -0.0 and NaNs. */ \
   } while (0)
 
   double nan_a = std::numeric_limits<double>::quiet_NaN();
diff --git a/test/cctest/test-macro-assembler-mips64.cc b/test/cctest/test-macro-assembler-mips64.cc
index 2d87fb77502..f24f07af08c 100644
--- a/test/cctest/test-macro-assembler-mips64.cc
+++ b/test/cctest/test-macro-assembler-mips64.cc
@@ -1508,18 +1508,24 @@ TEST(macro_float_minmax_f32) {
   GeneratedCode<F4> f =
       GenerateMacroFloat32MinMax<FPURegister, Inputs, Results>(masm);
 
-#define CHECK_MINMAX(src1, src2, min, max)                                   \
-  do {                                                                       \
-    Inputs inputs = {src1, src2};                                            \
-    Results results;                                                         \
-    f.Call(&inputs, &results, 0, 0, 0);                                      \
-    CHECK_EQ(bit_cast<uint32_t>(min), bit_cast<uint32_t>(results.min_abc_)); \
-    CHECK_EQ(bit_cast<uint32_t>(min), bit_cast<uint32_t>(results.min_aab_)); \
-    CHECK_EQ(bit_cast<uint32_t>(min), bit_cast<uint32_t>(results.min_aba_)); \
-    CHECK_EQ(bit_cast<uint32_t>(max), bit_cast<uint32_t>(results.max_abc_)); \
-    CHECK_EQ(bit_cast<uint32_t>(max), bit_cast<uint32_t>(results.max_aab_)); \
-    CHECK_EQ(bit_cast<uint32_t>(max), bit_cast<uint32_t>(results.max_aba_)); \
-    /* Use a bit_cast to correctly identify -0.0 and NaNs. */                \
+#define CHECK_MINMAX(src1, src2, min, max)                          \
+  do {                                                              \
+    Inputs inputs = {src1, src2};                                   \
+    Results results;                                                \
+    f.Call(&inputs, &results, 0, 0, 0);                             \
+    CHECK_EQ(base::bit_cast<uint32_t>(min),                         \
+             base::bit_cast<uint32_t>(results.min_abc_));           \
+    CHECK_EQ(base::bit_cast<uint32_t>(min),                         \
+             base::bit_cast<uint32_t>(results.min_aab_));           \
+    CHECK_EQ(base::bit_cast<uint32_t>(min),                         \
+             base::bit_cast<uint32_t>(results.min_aba_));           \
+    CHECK_EQ(base::bit_cast<uint32_t>(max),                         \
+             base::bit_cast<uint32_t>(results.max_abc_));           \
+    CHECK_EQ(base::bit_cast<uint32_t>(max),                         \
+             base::bit_cast<uint32_t>(results.max_aab_));           \
+    CHECK_EQ(base::bit_cast<uint32_t>(max),                         \
+             base::bit_cast<uint32_t>(results.max_aba_));           \
+    /* Use a base::bit_cast to correctly identify -0.0 and NaNs. */ \
   } while (0)
 
   float nan_a = std::numeric_limits<float>::quiet_NaN();
@@ -1650,18 +1656,24 @@ TEST(macro_float_minmax_f64) {
   GeneratedCode<F4> f =
       GenerateMacroFloat64MinMax<DoubleRegister, Inputs, Results>(masm);
 
-#define CHECK_MINMAX(src1, src2, min, max)                                   \
-  do {                                                                       \
-    Inputs inputs = {src1, src2};                                            \
-    Results results;                                                         \
-    f.Call(&inputs, &results, 0, 0, 0);                                      \
-    CHECK_EQ(bit_cast<uint64_t>(min), bit_cast<uint64_t>(results.min_abc_)); \
-    CHECK_EQ(bit_cast<uint64_t>(min), bit_cast<uint64_t>(results.min_aab_)); \
-    CHECK_EQ(bit_cast<uint64_t>(min), bit_cast<uint64_t>(results.min_aba_)); \
-    CHECK_EQ(bit_cast<uint64_t>(max), bit_cast<uint64_t>(results.max_abc_)); \
-    CHECK_EQ(bit_cast<uint64_t>(max), bit_cast<uint64_t>(results.max_aab_)); \
-    CHECK_EQ(bit_cast<uint64_t>(max), bit_cast<uint64_t>(results.max_aba_)); \
-    /* Use a bit_cast to correctly identify -0.0 and NaNs. */                \
+#define CHECK_MINMAX(src1, src2, min, max)                          \
+  do {                                                              \
+    Inputs inputs = {src1, src2};                                   \
+    Results results;                                                \
+    f.Call(&inputs, &results, 0, 0, 0);                             \
+    CHECK_EQ(base::bit_cast<uint64_t>(min),                         \
+             base::bit_cast<uint64_t>(results.min_abc_));           \
+    CHECK_EQ(base::bit_cast<uint64_t>(min),                         \
+             base::bit_cast<uint64_t>(results.min_aab_));           \
+    CHECK_EQ(base::bit_cast<uint64_t>(min),                         \
+             base::bit_cast<uint64_t>(results.min_aba_));           \
+    CHECK_EQ(base::bit_cast<uint64_t>(max),                         \
+             base::bit_cast<uint64_t>(results.max_abc_));           \
+    CHECK_EQ(base::bit_cast<uint64_t>(max),                         \
+             base::bit_cast<uint64_t>(results.max_aab_));           \
+    CHECK_EQ(base::bit_cast<uint64_t>(max),                         \
+             base::bit_cast<uint64_t>(results.max_aba_));           \
+    /* Use a base::bit_cast to correctly identify -0.0 and NaNs. */ \
   } while (0)
 
   double nan_a = std::numeric_limits<double>::quiet_NaN();
diff --git a/test/cctest/test-macro-assembler-riscv64.cc b/test/cctest/test-macro-assembler-riscv64.cc
index 0bf9b5b363d..7148ac344c7 100644
--- a/test/cctest/test-macro-assembler-riscv64.cc
+++ b/test/cctest/test-macro-assembler-riscv64.cc
@@ -1059,20 +1059,25 @@ TEST(macro_float_minmax_f32) {
   auto f = AssembleCode<F4>(
       GenerateMacroFloat32MinMax<FPURegister, Inputs, Results>);
 
-#define CHECK_MINMAX(src1, src2, min, max)                                    \
-  do {                                                                        \
-    Inputs inputs = {src1, src2};                                             \
-    Results results;                                                          \
-    f.Call(&inputs, &results, 0, 0, 0);                                       \
-    CHECK_EQ(bit_cast<uint32_t>(min), bit_cast<uint32_t>(results.min_abc_));  \
-    CHECK_EQ(bit_cast<uint32_t>(min), bit_cast<uint32_t>(results.min_aab_));  \
-    CHECK_EQ(bit_cast<uint32_t>(min), bit_cast<uint32_t>(results.min_aba_));  \
-    CHECK_EQ(bit_cast<uint32_t>(max), bit_cast<uint32_t>(results.max_abc_));  \
-    CHECK_EQ(bit_cast<uint32_t>(max), bit_cast<uint32_t>(results.max_aab_));  \
-    CHECK_EQ(                                                                 \
-        bit_cast<uint32_t>(max),                                              \
-        bit_cast<uint32_t>(results.max_aba_)); /* Use a bit_cast to correctly \
-                                                  identify -0.0 and NaNs. */  \
+#define CHECK_MINMAX(src1, src2, min, max)                                \
+  do {                                                                    \
+    Inputs inputs = {src1, src2};                                         \
+    Results results;                                                      \
+    f.Call(&inputs, &results, 0, 0, 0);                                   \
+    CHECK_EQ(base::bit_cast<uint32_t>(min),                               \
+             base::bit_cast<uint32_t>(results.min_abc_));                 \
+    CHECK_EQ(base::bit_cast<uint32_t>(min),                               \
+             base::bit_cast<uint32_t>(results.min_aab_));                 \
+    CHECK_EQ(base::bit_cast<uint32_t>(min),                               \
+             base::bit_cast<uint32_t>(results.min_aba_));                 \
+    CHECK_EQ(base::bit_cast<uint32_t>(max),                               \
+             base::bit_cast<uint32_t>(results.max_abc_));                 \
+    CHECK_EQ(base::bit_cast<uint32_t>(max),                               \
+             base::bit_cast<uint32_t>(results.max_aab_));                 \
+    CHECK_EQ(base::bit_cast<uint32_t>(max),                               \
+             base::bit_cast<uint32_t>(                                    \
+                 results.max_aba_)); /* Use a base::bit_cast to correctly \
+                              identify -0.0 and NaNs. */                  \
   } while (0)
 
   float nan_a = std::numeric_limits<float>::quiet_NaN();
@@ -1154,18 +1159,24 @@ TEST(macro_float_minmax_f64) {
   auto f = AssembleCode<F4>(
       GenerateMacroFloat64MinMax<DoubleRegister, Inputs, Results>);
 
-#define CHECK_MINMAX(src1, src2, min, max)                                   \
-  do {                                                                       \
-    Inputs inputs = {src1, src2};                                            \
-    Results results;                                                         \
-    f.Call(&inputs, &results, 0, 0, 0);                                      \
-    CHECK_EQ(bit_cast<uint64_t>(min), bit_cast<uint64_t>(results.min_abc_)); \
-    CHECK_EQ(bit_cast<uint64_t>(min), bit_cast<uint64_t>(results.min_aab_)); \
-    CHECK_EQ(bit_cast<uint64_t>(min), bit_cast<uint64_t>(results.min_aba_)); \
-    CHECK_EQ(bit_cast<uint64_t>(max), bit_cast<uint64_t>(results.max_abc_)); \
-    CHECK_EQ(bit_cast<uint64_t>(max), bit_cast<uint64_t>(results.max_aab_)); \
-    CHECK_EQ(bit_cast<uint64_t>(max), bit_cast<uint64_t>(results.max_aba_)); \
-    /* Use a bit_cast to correctly identify -0.0 and NaNs. */                \
+#define CHECK_MINMAX(src1, src2, min, max)                          \
+  do {                                                              \
+    Inputs inputs = {src1, src2};                                   \
+    Results results;                                                \
+    f.Call(&inputs, &results, 0, 0, 0);                             \
+    CHECK_EQ(base::bit_cast<uint64_t>(min),                         \
+             base::bit_cast<uint64_t>(results.min_abc_));           \
+    CHECK_EQ(base::bit_cast<uint64_t>(min),                         \
+             base::bit_cast<uint64_t>(results.min_aab_));           \
+    CHECK_EQ(base::bit_cast<uint64_t>(min),                         \
+             base::bit_cast<uint64_t>(results.min_aba_));           \
+    CHECK_EQ(base::bit_cast<uint64_t>(max),                         \
+             base::bit_cast<uint64_t>(results.max_abc_));           \
+    CHECK_EQ(base::bit_cast<uint64_t>(max),                         \
+             base::bit_cast<uint64_t>(results.max_aab_));           \
+    CHECK_EQ(base::bit_cast<uint64_t>(max),                         \
+             base::bit_cast<uint64_t>(results.max_aba_));           \
+    /* Use a base::bit_cast to correctly identify -0.0 and NaNs. */ \
   } while (0)
 
   double nan_a = qnan_d;
diff --git a/test/cctest/test-random-number-generator.cc b/test/cctest/test-random-number-generator.cc
index 00b5224099b..b1ef46465d7 100644
--- a/test/cctest/test-random-number-generator.cc
+++ b/test/cctest/test-random-number-generator.cc
@@ -89,14 +89,14 @@ void RandomBitCorrelation(int random_bit) {
 
       // Enter the new random value into the history
       for (int i = ago; i >= 0; i--) {
-        history[i] = bit_cast<uint32_t>(rng->NextInt());
+        history[i] = base::bit_cast<uint32_t>(rng->NextInt());
       }
 
       // Find out how many of the bits are the same as the prediction bit.
       int m = 0;
       for (int i = 0; i < kRepeats; i++) {
         v8::HandleScope scope(isolate);
-        uint32_t random = bit_cast<uint32_t>(rng->NextInt());
+        uint32_t random = base::bit_cast<uint32_t>(rng->NextInt());
         for (int j = ago - 1; j >= 0; j--) history[j + 1] = history[j];
         history[0] = random;
 
diff --git a/test/cctest/test-utils-arm64.cc b/test/cctest/test-utils-arm64.cc
index 2b9cec90652..ae02d547e58 100644
--- a/test/cctest/test-utils-arm64.cc
+++ b/test/cctest/test-utils-arm64.cc
@@ -72,18 +72,19 @@ bool Equal128(vec128_t expected, const RegisterDump*, vec128_t result) {
 }
 
 bool EqualFP32(float expected, const RegisterDump*, float result) {
-  if (bit_cast<uint32_t>(expected) == bit_cast<uint32_t>(result)) {
+  if (base::bit_cast<uint32_t>(expected) == base::bit_cast<uint32_t>(result)) {
     return true;
   } else {
     if (std::isnan(expected) || (expected == 0.0)) {
       printf("Expected 0x%08" PRIx32 "\t Found 0x%08" PRIx32 "\n",
-             bit_cast<uint32_t>(expected), bit_cast<uint32_t>(result));
+             base::bit_cast<uint32_t>(expected),
+             base::bit_cast<uint32_t>(result));
     } else {
       printf("Expected %.9f (0x%08" PRIx32
              ")\t "
              "Found %.9f (0x%08" PRIx32 ")\n",
-             expected, bit_cast<uint32_t>(expected), result,
-             bit_cast<uint32_t>(result));
+             expected, base::bit_cast<uint32_t>(expected), result,
+             base::bit_cast<uint32_t>(result));
     }
     return false;
   }
@@ -91,19 +92,20 @@ bool EqualFP32(float expected, const RegisterDump*, float result) {
 
 
 bool EqualFP64(double expected, const RegisterDump*, double result) {
-  if (bit_cast<uint64_t>(expected) == bit_cast<uint64_t>(result)) {
+  if (base::bit_cast<uint64_t>(expected) == base::bit_cast<uint64_t>(result)) {
     return true;
   }
 
   if (std::isnan(expected) || (expected == 0.0)) {
     printf("Expected 0x%016" PRIx64 "\t Found 0x%016" PRIx64 "\n",
-           bit_cast<uint64_t>(expected), bit_cast<uint64_t>(result));
+           base::bit_cast<uint64_t>(expected),
+           base::bit_cast<uint64_t>(result));
   } else {
     printf("Expected %.17f (0x%016" PRIx64
            ")\t "
            "Found %.17f (0x%016" PRIx64 ")\n",
-           expected, bit_cast<uint64_t>(expected), result,
-           bit_cast<uint64_t>(result));
+           expected, base::bit_cast<uint64_t>(expected), result,
+           base::bit_cast<uint64_t>(result));
   }
   return false;
 }
@@ -148,7 +150,7 @@ bool EqualFP32(float expected, const RegisterDump* core,
   uint64_t result_64 = core->dreg_bits(fpreg.code());
   if ((result_64 & 0xFFFFFFFF00000000L) != 0) {
     printf("Expected 0x%08" PRIx32 " (%f)\t Found 0x%016" PRIx64 "\n",
-           bit_cast<uint32_t>(expected), expected, result_64);
+           base::bit_cast<uint32_t>(expected), expected, result_64);
     return false;
   }
 
diff --git a/test/cctest/test-utils-arm64.h b/test/cctest/test-utils-arm64.h
index 5143dcf0d86..21b2123eead 100644
--- a/test/cctest/test-utils-arm64.h
+++ b/test/cctest/test-utils-arm64.h
@@ -80,7 +80,7 @@ class RegisterDump {
   }
 
   inline float sreg(unsigned code) const {
-    return bit_cast<float>(sreg_bits(code));
+    return base::bit_cast<float>(sreg_bits(code));
   }
 
   inline uint64_t dreg_bits(unsigned code) const {
@@ -89,7 +89,7 @@ class RegisterDump {
   }
 
   inline double dreg(unsigned code) const {
-    return bit_cast<double>(dreg_bits(code));
+    return base::bit_cast<double>(dreg_bits(code));
   }
 
   inline vec128_t qreg(unsigned code) const { return dump_.q_[code]; }
diff --git a/test/cctest/wasm/test-run-wasm-64.cc b/test/cctest/wasm/test-run-wasm-64.cc
index 510f446f84b..718a0d7aca6 100644
--- a/test/cctest/wasm/test-run-wasm-64.cc
+++ b/test/cctest/wasm/test-run-wasm-64.cc
@@ -628,7 +628,8 @@ WASM_EXEC_TEST(F32UConvertI64) {
   WasmRunner<float, uint64_t> r(execution_tier);
   BUILD(r, WASM_F32_UCONVERT_I64(WASM_LOCAL_GET(0)));
   for (size_t i = 0; i < arraysize(values); i++) {
-    CHECK_EQ(bit_cast<float>(values[i].expected), r.Call(values[i].input));
+    CHECK_EQ(base::bit_cast<float>(values[i].expected),
+             r.Call(values[i].input));
   }
 }
 
@@ -720,7 +721,8 @@ WASM_EXEC_TEST(F64UConvertI64) {
   WasmRunner<double, uint64_t> r(execution_tier);
   BUILD(r, WASM_F64_UCONVERT_I64(WASM_LOCAL_GET(0)));
   for (size_t i = 0; i < arraysize(values); i++) {
-    CHECK_EQ(bit_cast<double>(values[i].expected), r.Call(values[i].input));
+    CHECK_EQ(base::bit_cast<double>(values[i].expected),
+             r.Call(values[i].input));
   }
 }
 
diff --git a/test/cctest/wasm/test-run-wasm-relaxed-simd.cc b/test/cctest/wasm/test-run-wasm-relaxed-simd.cc
index b1be2d8e026..59d4fb5c0ba 100644
--- a/test/cctest/wasm/test-run-wasm-relaxed-simd.cc
+++ b/test/cctest/wasm/test-run-wasm-relaxed-simd.cc
@@ -238,7 +238,7 @@ template <typename T, size_t N = kSimd128Size / sizeof(T)>
 std::array<uint8_t, kSimd128Size> as_uint8(const T* src) {
   std::array<uint8_t, kSimd128Size> arr;
   for (size_t i = 0; i < N; i++) {
-    WriteLittleEndianValue<T>(bit_cast<T*>(&arr[0]) + i, src[i]);
+    WriteLittleEndianValue<T>(base::bit_cast<T*>(&arr[0]) + i, src[i]);
   }
   return arr;
 }
diff --git a/test/cctest/wasm/test-run-wasm-simd.cc b/test/cctest/wasm/test-run-wasm-simd.cc
index 5b69031d9f3..9bac10fb1a6 100644
--- a/test/cctest/wasm/test-run-wasm-simd.cc
+++ b/test/cctest/wasm/test-run-wasm-simd.cc
@@ -358,7 +358,7 @@ void RunF128CompareOpConstImmTest(
     uint8_t const_buffer[kSimd128Size];
     for (size_t i = 0; i < kSimd128Size / sizeof(FloatType); i++) {
       WriteLittleEndianValue<FloatType>(
-          bit_cast<FloatType*>(&const_buffer[0]) + i, x);
+          base::bit_cast<FloatType*>(&const_buffer[0]) + i, x);
     }
     BUILD(r,
           WASM_LOCAL_SET(temp,
@@ -665,7 +665,7 @@ void RunICompareOpConstImmTest(TestExecutionTier execution_tier,
     uint8_t const_buffer[kSimd128Size];
     for (size_t i = 0; i < kSimd128Size / sizeof(ScalarType); i++) {
       WriteLittleEndianValue<ScalarType>(
-          bit_cast<ScalarType*>(&const_buffer[0]) + i, x);
+          base::bit_cast<ScalarType*>(&const_buffer[0]) + i, x);
     }
     BUILD(r,
           WASM_LOCAL_SET(temp,
@@ -1563,7 +1563,7 @@ void RunS128ConstBinOpTest(TestExecutionTier execution_tier,
     uint8_t const_buffer[16];
     for (size_t i = 0; i < kSimd128Size / sizeof(ScalarType); i++) {
       WriteLittleEndianValue<ScalarType>(
-          bit_cast<ScalarType*>(&const_buffer[0]) + i, x);
+          base::bit_cast<ScalarType*>(&const_buffer[0]) + i, x);
     }
     BUILD(
         r,
diff --git a/test/cctest/wasm/test-run-wasm.cc b/test/cctest/wasm/test-run-wasm.cc
index 05cca1be136..81d089db9f5 100644
--- a/test/cctest/wasm/test-run-wasm.cc
+++ b/test/cctest/wasm/test-run-wasm.cc
@@ -628,7 +628,8 @@ WASM_EXEC_TEST(Float32Neg) {
   BUILD(r, WASM_F32_NEG(WASM_LOCAL_GET(0)));
 
   FOR_FLOAT32_INPUTS(i) {
-    CHECK_EQ(0x80000000, bit_cast<uint32_t>(i) ^ bit_cast<uint32_t>(r.Call(i)));
+    CHECK_EQ(0x80000000,
+             base::bit_cast<uint32_t>(i) ^ base::bit_cast<uint32_t>(r.Call(i)));
   }
 }
 
@@ -638,7 +639,7 @@ WASM_EXEC_TEST(Float64Neg) {
 
   FOR_FLOAT64_INPUTS(i) {
     CHECK_EQ(0x8000000000000000,
-             bit_cast<uint64_t>(i) ^ bit_cast<uint64_t>(r.Call(i)));
+             base::bit_cast<uint64_t>(i) ^ base::bit_cast<uint64_t>(r.Call(i)));
   }
 }
 
@@ -1118,7 +1119,7 @@ WASM_EXEC_TEST(I32ReinterpretF32) {
 
   FOR_FLOAT32_INPUTS(i) {
     float input = i;
-    int32_t expected = bit_cast<int32_t, float>(input);
+    int32_t expected = base::bit_cast<int32_t, float>(input);
     r.builder().WriteMemory(&memory[0], input);
     CHECK_EQ(expected, r.Call());
   }
@@ -1134,7 +1135,7 @@ WASM_EXEC_TEST(F32ReinterpretI32) {
 
   FOR_INT32_INPUTS(i) {
     int32_t input = i;
-    float expected = bit_cast<float, int32_t>(input);
+    float expected = base::bit_cast<float, int32_t>(input);
     r.builder().WriteMemory(&memory[0], input);
     float result = r.Call();
     if (std::isnan(expected)) {
@@ -2283,8 +2284,8 @@ WASM_EXEC_TEST(MixedGlobals) {
 
   CHECK_EQ(static_cast<int32_t>(0xEE55CCAA), *var_int32);
   CHECK_EQ(static_cast<uint32_t>(0xEE55CCAA), *var_uint32);
-  CHECK_EQ(bit_cast<float>(0xEE55CCAA), *var_float);
-  CHECK_EQ(bit_cast<double>(0x99112233EE55CCAAULL), *var_double);
+  CHECK_EQ(base::bit_cast<float>(0xEE55CCAA), *var_float);
+  CHECK_EQ(base::bit_cast<double>(0x99112233EE55CCAAULL), *var_double);
 
   USE(unused);
 }
diff --git a/test/cctest/wasm/wasm-run-utils.cc b/test/cctest/wasm/wasm-run-utils.cc
index 70de345e53e..42f3f0e7d07 100644
--- a/test/cctest/wasm/wasm-run-utils.cc
+++ b/test/cctest/wasm/wasm-run-utils.cc
@@ -25,8 +25,8 @@ namespace wasm {
 // Helper Functions.
 bool IsSameNan(float expected, float actual) {
   // Sign is non-deterministic.
-  uint32_t expected_bits = bit_cast<uint32_t>(expected) & ~0x80000000;
-  uint32_t actual_bits = bit_cast<uint32_t>(actual) & ~0x80000000;
+  uint32_t expected_bits = base::bit_cast<uint32_t>(expected) & ~0x80000000;
+  uint32_t actual_bits = base::bit_cast<uint32_t>(actual) & ~0x80000000;
   // Some implementations convert signaling NaNs to quiet NaNs.
   return (expected_bits == actual_bits) ||
          ((expected_bits | 0x00400000) == actual_bits);
@@ -34,8 +34,9 @@ bool IsSameNan(float expected, float actual) {
 
 bool IsSameNan(double expected, double actual) {
   // Sign is non-deterministic.
-  uint64_t expected_bits = bit_cast<uint64_t>(expected) & ~0x8000000000000000;
-  uint64_t actual_bits = bit_cast<uint64_t>(actual) & ~0x8000000000000000;
+  uint64_t expected_bits =
+      base::bit_cast<uint64_t>(expected) & ~0x8000000000000000;
+  uint64_t actual_bits = base::bit_cast<uint64_t>(actual) & ~0x8000000000000000;
   // Some implementations convert signaling NaNs to quiet NaNs.
   return (expected_bits == actual_bits) ||
          ((expected_bits | 0x0008000000000000) == actual_bits);
diff --git a/test/cctest/wasm/wasm-run-utils.h b/test/cctest/wasm/wasm-run-utils.h
index 5adfe39f848..69926f8fbcd 100644
--- a/test/cctest/wasm/wasm-run-utils.h
+++ b/test/cctest/wasm/wasm-run-utils.h
@@ -77,9 +77,10 @@ using compiler::Node;
 // the trap occurs if the runtime context is not available to throw a JavaScript
 // exception.
 #define CHECK_TRAP32(x) \
-  CHECK_EQ(0xDEADBEEF, (bit_cast<uint32_t>(x)) & 0xFFFFFFFF)
-#define CHECK_TRAP64(x) \
-  CHECK_EQ(0xDEADBEEFDEADBEEF, (bit_cast<uint64_t>(x)) & 0xFFFFFFFFFFFFFFFF)
+  CHECK_EQ(0xDEADBEEF, (base::bit_cast<uint32_t>(x)) & 0xFFFFFFFF)
+#define CHECK_TRAP64(x)        \
+  CHECK_EQ(0xDEADBEEFDEADBEEF, \
+           (base::bit_cast<uint64_t>(x)) & 0xFFFFFFFFFFFFFFFF)
 #define CHECK_TRAP(x) CHECK_TRAP32(x)
 
 #define WASM_WRAPPER_RETURN_VALUE 8754
diff --git a/test/cctest/wasm/wasm-simd-utils.cc b/test/cctest/wasm/wasm-simd-utils.cc
index be0635ba115..c85a4f21792 100644
--- a/test/cctest/wasm/wasm-simd-utils.cc
+++ b/test/cctest/wasm/wasm-simd-utils.cc
@@ -404,7 +404,7 @@ bool IsExtreme(float x) {
 }
 
 bool IsCanonical(float actual) {
-  uint32_t actual_bits = bit_cast<uint32_t>(actual);
+  uint32_t actual_bits = base::bit_cast<uint32_t>(actual);
   // Canonical NaN has quiet bit and no payload.
   return (actual_bits & 0xFFC00000) == actual_bits;
 }
@@ -418,7 +418,8 @@ void CheckFloatResult(float x, float y, float expected, float actual,
     if (IsSameNan(expected, actual)) return;
     if (IsCanonical(actual)) return;
     // This is expected to assert; it's useful for debugging.
-    CHECK_EQ(bit_cast<uint32_t>(expected), bit_cast<uint32_t>(actual));
+    CHECK_EQ(base::bit_cast<uint32_t>(expected),
+             base::bit_cast<uint32_t>(actual));
   } else {
     if (exact) {
       CHECK_EQ(expected, actual);
@@ -469,7 +470,7 @@ void RunF32x4UnOpTest(TestExecutionTier execution_tier, WasmOpcode opcode,
   }
 
   FOR_FLOAT32_NAN_INPUTS(f) {
-    float x = bit_cast<float>(nan_test_array[f]);
+    float x = base::bit_cast<float>(nan_test_array[f]);
     if (!PlatformCanRepresent(x)) continue;
     // Extreme values have larger errors so skip them for approximation tests.
     if (!exact && IsExtreme(x)) continue;
@@ -529,10 +530,10 @@ void RunF32x4BinOpTest(TestExecutionTier execution_tier, WasmOpcode opcode,
   }
 
   FOR_FLOAT32_NAN_INPUTS(f) {
-    float x = bit_cast<float>(nan_test_array[f]);
+    float x = base::bit_cast<float>(nan_test_array[f]);
     if (!PlatformCanRepresent(x)) continue;
     FOR_FLOAT32_NAN_INPUTS(j) {
-      float y = bit_cast<float>(nan_test_array[j]);
+      float y = base::bit_cast<float>(nan_test_array[j]);
       if (!PlatformCanRepresent(y)) continue;
       if (ShouldSkipTestingConstants(opcode, x, y)) continue;
       float expected = expected_op(x, y);
@@ -585,7 +586,7 @@ bool IsExtreme(double x) {
 }
 
 bool IsCanonical(double actual) {
-  uint64_t actual_bits = bit_cast<uint64_t>(actual);
+  uint64_t actual_bits = base::bit_cast<uint64_t>(actual);
   // Canonical NaN has quiet bit and no payload.
   return (actual_bits & 0xFFF8000000000000) == actual_bits;
 }
@@ -599,7 +600,8 @@ void CheckDoubleResult(double x, double y, double expected, double actual,
     if (IsSameNan(expected, actual)) return;
     if (IsCanonical(actual)) return;
     // This is expected to assert; it's useful for debugging.
-    CHECK_EQ(bit_cast<uint64_t>(expected), bit_cast<uint64_t>(actual));
+    CHECK_EQ(base::bit_cast<uint64_t>(expected),
+             base::bit_cast<uint64_t>(actual));
   } else {
     if (exact) {
       CHECK_EQ(expected, actual);
@@ -650,7 +652,7 @@ void RunF64x2UnOpTest(TestExecutionTier execution_tier, WasmOpcode opcode,
   }
 
   FOR_FLOAT64_NAN_INPUTS(d) {
-    double x = bit_cast<double>(double_nan_test_array[d]);
+    double x = base::bit_cast<double>(double_nan_test_array[d]);
     if (!PlatformCanRepresent(x)) continue;
     // Extreme values have larger errors so skip them for approximation tests.
     if (!exact && IsExtreme(x)) continue;
@@ -695,10 +697,10 @@ void RunF64x2BinOpTest(TestExecutionTier execution_tier, WasmOpcode opcode,
   }
 
   FOR_FLOAT64_NAN_INPUTS(d) {
-    double x = bit_cast<double>(double_nan_test_array[d]);
+    double x = base::bit_cast<double>(double_nan_test_array[d]);
     if (!PlatformCanRepresent(x)) continue;
     FOR_FLOAT64_NAN_INPUTS(j) {
-      double y = bit_cast<double>(double_nan_test_array[j]);
+      double y = base::bit_cast<double>(double_nan_test_array[j]);
       double expected = expected_op(x, y);
       if (!PlatformCanRepresent(expected)) continue;
       if (ShouldSkipTestingConstants(opcode, x, y)) continue;
diff --git a/test/common/wasm/wasm-macro-gen.h b/test/common/wasm/wasm-macro-gen.h
index ca7e2b172de..e38c669d69e 100644
--- a/test/common/wasm/wasm-macro-gen.h
+++ b/test/common/wasm/wasm-macro-gen.h
@@ -416,22 +416,32 @@ inline WasmOpcode LoadStoreOpcodeOf(MachineType type, bool store) {
       static_cast<byte>(((static_cast<int64_t>(val) >> 56) & MASK_7) | 0x80), \
       static_cast<byte>((static_cast<int64_t>(val) >> 63) & MASK_7)
 
-#define WASM_F32(val)                                                       \
-  kExprF32Const,                                                            \
-      static_cast<byte>(bit_cast<int32_t>(static_cast<float>(val))),        \
-      static_cast<byte>(bit_cast<uint32_t>(static_cast<float>(val)) >> 8),  \
-      static_cast<byte>(bit_cast<uint32_t>(static_cast<float>(val)) >> 16), \
-      static_cast<byte>(bit_cast<uint32_t>(static_cast<float>(val)) >> 24)
-#define WASM_F64(val)                                                        \
-  kExprF64Const,                                                             \
-      static_cast<byte>(bit_cast<uint64_t>(static_cast<double>(val))),       \
-      static_cast<byte>(bit_cast<uint64_t>(static_cast<double>(val)) >> 8),  \
-      static_cast<byte>(bit_cast<uint64_t>(static_cast<double>(val)) >> 16), \
-      static_cast<byte>(bit_cast<uint64_t>(static_cast<double>(val)) >> 24), \
-      static_cast<byte>(bit_cast<uint64_t>(static_cast<double>(val)) >> 32), \
-      static_cast<byte>(bit_cast<uint64_t>(static_cast<double>(val)) >> 40), \
-      static_cast<byte>(bit_cast<uint64_t>(static_cast<double>(val)) >> 48), \
-      static_cast<byte>(bit_cast<uint64_t>(static_cast<double>(val)) >> 56)
+#define WASM_F32(val)                                                        \
+  kExprF32Const,                                                             \
+      static_cast<byte>(base::bit_cast<int32_t>(static_cast<float>(val))),   \
+      static_cast<byte>(base::bit_cast<uint32_t>(static_cast<float>(val)) >> \
+                        8),                                                  \
+      static_cast<byte>(base::bit_cast<uint32_t>(static_cast<float>(val)) >> \
+                        16),                                                 \
+      static_cast<byte>(base::bit_cast<uint32_t>(static_cast<float>(val)) >> \
+                        24)
+#define WASM_F64(val)                                                         \
+  kExprF64Const,                                                              \
+      static_cast<byte>(base::bit_cast<uint64_t>(static_cast<double>(val))),  \
+      static_cast<byte>(base::bit_cast<uint64_t>(static_cast<double>(val)) >> \
+                        8),                                                   \
+      static_cast<byte>(base::bit_cast<uint64_t>(static_cast<double>(val)) >> \
+                        16),                                                  \
+      static_cast<byte>(base::bit_cast<uint64_t>(static_cast<double>(val)) >> \
+                        24),                                                  \
+      static_cast<byte>(base::bit_cast<uint64_t>(static_cast<double>(val)) >> \
+                        32),                                                  \
+      static_cast<byte>(base::bit_cast<uint64_t>(static_cast<double>(val)) >> \
+                        40),                                                  \
+      static_cast<byte>(base::bit_cast<uint64_t>(static_cast<double>(val)) >> \
+                        48),                                                  \
+      static_cast<byte>(base::bit_cast<uint64_t>(static_cast<double>(val)) >> \
+                        56)
 
 #define WASM_LOCAL_GET(index) kExprLocalGet, static_cast<byte>(index)
 #define WASM_LOCAL_SET(index, val) val, kExprLocalSet, static_cast<byte>(index)
diff --git a/test/unittests/base/platform/platform-unittest.cc b/test/unittests/base/platform/platform-unittest.cc
index cd55ddbfa51..13000308f05 100644
--- a/test/unittests/base/platform/platform-unittest.cc
+++ b/test/unittests/base/platform/platform-unittest.cc
@@ -202,7 +202,7 @@ class ThreadLocalStorageTest : public Thread, public ::testing::Test {
 
  private:
   static void* GetValue(size_t x) {
-    return bit_cast<void*>(static_cast<uintptr_t>(x + 1));
+    return base::bit_cast<void*>(static_cast<uintptr_t>(x + 1));
   }
 
   // Older versions of Android have fewer TLS slots (nominally 64, but the
diff --git a/test/unittests/compiler/arm64/instruction-selector-arm64-unittest.cc b/test/unittests/compiler/arm64/instruction-selector-arm64-unittest.cc
index 5fbf8aa5f6d..fb2d46a21e0 100644
--- a/test/unittests/compiler/arm64/instruction-selector-arm64-unittest.cc
+++ b/test/unittests/compiler/arm64/instruction-selector-arm64-unittest.cc
@@ -5218,7 +5218,7 @@ TEST_F(InstructionSelectorTest, ExternalReferenceLoad1) {
   TRACED_FOREACH(int64_t, offset, kOffsets) {
     StreamBuilder m(this, MachineType::Int64());
     ExternalReference reference =
-        bit_cast<ExternalReference>(isolate()->isolate_root() + offset);
+        base::bit_cast<ExternalReference>(isolate()->isolate_root() + offset);
     Node* const value =
         m.Load(MachineType::Int64(), m.ExternalConstant(reference));
     m.Return(value);
@@ -5239,7 +5239,7 @@ TEST_F(InstructionSelectorTest, ExternalReferenceLoad2) {
   StreamBuilder m(this, MachineType::Int64());
   int64_t offset = 0x100000000;
   ExternalReference reference =
-      bit_cast<ExternalReference>(isolate()->isolate_root() + offset);
+      base::bit_cast<ExternalReference>(isolate()->isolate_root() + offset);
   Node* const value =
       m.Load(MachineType::Int64(), m.ExternalConstant(reference));
   m.Return(value);
diff --git a/test/unittests/compiler/common-operator-unittest.cc b/test/unittests/compiler/common-operator-unittest.cc
index 1c9369cb342..2881c33f653 100644
--- a/test/unittests/compiler/common-operator-unittest.cc
+++ b/test/unittests/compiler/common-operator-unittest.cc
@@ -298,7 +298,7 @@ TEST_F(CommonOperatorTest, Float32Constant) {
     TRACED_FOREACH(float, v2, kFloatValues) {
       const Operator* op1 = common()->Float32Constant(v1);
       const Operator* op2 = common()->Float32Constant(v2);
-      EXPECT_EQ(bit_cast<uint32_t>(v1) == bit_cast<uint32_t>(v2),
+      EXPECT_EQ(base::bit_cast<uint32_t>(v1) == base::bit_cast<uint32_t>(v2),
                 op1->Equals(op2));
     }
   }
@@ -319,7 +319,7 @@ TEST_F(CommonOperatorTest, Float64Constant) {
     TRACED_FOREACH(double, v2, kFloatValues) {
       const Operator* op1 = common()->Float64Constant(v1);
       const Operator* op2 = common()->Float64Constant(v2);
-      EXPECT_EQ(bit_cast<uint64_t>(v1) == bit_cast<uint64_t>(v2),
+      EXPECT_EQ(base::bit_cast<uint64_t>(v1) == base::bit_cast<uint64_t>(v2),
                 op1->Equals(op2));
     }
   }
@@ -340,7 +340,7 @@ TEST_F(CommonOperatorTest, NumberConstant) {
     TRACED_FOREACH(double, v2, kFloatValues) {
       const Operator* op1 = common()->NumberConstant(v1);
       const Operator* op2 = common()->NumberConstant(v2);
-      EXPECT_EQ(bit_cast<uint64_t>(v1) == bit_cast<uint64_t>(v2),
+      EXPECT_EQ(base::bit_cast<uint64_t>(v1) == base::bit_cast<uint64_t>(v2),
                 op1->Equals(op2));
     }
   }
diff --git a/test/unittests/compiler/graph-unittest.h b/test/unittests/compiler/graph-unittest.h
index 60d425b9118..372398b0ee9 100644
--- a/test/unittests/compiler/graph-unittest.h
+++ b/test/unittests/compiler/graph-unittest.h
@@ -40,7 +40,7 @@ class GraphTest : public TestWithNativeContextAndZone {
   Node* Float64Constant(volatile double value);
   Node* Int32Constant(int32_t value);
   Node* Uint32Constant(uint32_t value) {
-    return Int32Constant(bit_cast<int32_t>(value));
+    return Int32Constant(base::bit_cast<int32_t>(value));
   }
   Node* Int64Constant(int64_t value);
   Node* NumberConstant(volatile double value);
diff --git a/test/unittests/compiler/int64-lowering-unittest.cc b/test/unittests/compiler/int64-lowering-unittest.cc
index da23e61b933..7bd8e477e58 100644
--- a/test/unittests/compiler/int64-lowering-unittest.cc
+++ b/test/unittests/compiler/int64-lowering-unittest.cc
@@ -893,9 +893,10 @@ TEST_F(Int64LoweringTest, F64ReinterpretI64) {
 }
 
 TEST_F(Int64LoweringTest, I64ReinterpretF64) {
-  LowerGraph(graph()->NewNode(machine()->BitcastFloat64ToInt64(),
-                              Float64Constant(bit_cast<double>(value(0)))),
-             MachineRepresentation::kWord64);
+  LowerGraph(
+      graph()->NewNode(machine()->BitcastFloat64ToInt64(),
+                       Float64Constant(base::bit_cast<double>(value(0)))),
+      MachineRepresentation::kWord64);
 
   Capture<Node*> stack_slot;
   Matcher<Node*> stack_slot_matcher =
@@ -906,7 +907,7 @@ TEST_F(Int64LoweringTest, I64ReinterpretF64) {
       StoreRepresentation(MachineRepresentation::kFloat64,
                           WriteBarrierKind::kNoWriteBarrier),
       AllOf(CaptureEq(&stack_slot), stack_slot_matcher), IsInt32Constant(0),
-      IsFloat64Constant(bit_cast<double>(value(0))), start(), start());
+      IsFloat64Constant(base::bit_cast<double>(value(0))), start(), start());
 
   EXPECT_THAT(
       graph()->end()->InputAt(1),
diff --git a/test/unittests/compiler/machine-operator-reducer-unittest.cc b/test/unittests/compiler/machine-operator-reducer-unittest.cc
index fa8d45c7823..4e1442cd69e 100644
--- a/test/unittests/compiler/machine-operator-reducer-unittest.cc
+++ b/test/unittests/compiler/machine-operator-reducer-unittest.cc
@@ -53,9 +53,9 @@ class MachineOperatorReducerTest : public GraphTest {
   Matcher<Node*> IsTruncatingDiv(const Matcher<Node*>& dividend_matcher,
                                  const int32_t divisor) {
     base::MagicNumbersForDivision<uint32_t> const mag =
-        base::SignedDivisionByConstant(bit_cast<uint32_t>(divisor));
-    int32_t const multiplier = bit_cast<int32_t>(mag.multiplier);
-    int32_t const shift = bit_cast<int32_t>(mag.shift);
+        base::SignedDivisionByConstant(base::bit_cast<uint32_t>(divisor));
+    int32_t const multiplier = base::bit_cast<int32_t>(mag.multiplier);
+    int32_t const shift = base::bit_cast<int32_t>(mag.shift);
     Matcher<Node*> quotient_matcher =
         IsInt32MulHigh(dividend_matcher, IsInt32Constant(multiplier));
     if (divisor > 0 && multiplier < 0) {
@@ -407,7 +407,8 @@ TEST_F(MachineOperatorReducerTest, ChangeFloat64ToUint32WithConstant) {
     Reduction reduction = Reduce(graph()->NewNode(
         machine()->ChangeFloat64ToUint32(), Float64Constant(FastUI2D(x))));
     ASSERT_TRUE(reduction.Changed());
-    EXPECT_THAT(reduction.replacement(), IsInt32Constant(bit_cast<int32_t>(x)));
+    EXPECT_THAT(reduction.replacement(),
+                IsInt32Constant(base::bit_cast<int32_t>(x)));
   }
 }
 
@@ -469,7 +470,7 @@ TEST_F(MachineOperatorReducerTest, ChangeUint32ToFloat64WithConstant) {
   TRACED_FOREACH(uint32_t, x, kUint32Values) {
     Reduction reduction =
         Reduce(graph()->NewNode(machine()->ChangeUint32ToFloat64(),
-                                Int32Constant(bit_cast<int32_t>(x))));
+                                Int32Constant(base::bit_cast<int32_t>(x))));
     ASSERT_TRUE(reduction.Changed());
     EXPECT_THAT(reduction.replacement(), IsFloat64Constant(BitEq(FastUI2D(x))));
   }
@@ -484,10 +485,11 @@ TEST_F(MachineOperatorReducerTest, ChangeUint32ToUint64WithConstant) {
   TRACED_FOREACH(uint32_t, x, kUint32Values) {
     Reduction reduction =
         Reduce(graph()->NewNode(machine()->ChangeUint32ToUint64(),
-                                Int32Constant(bit_cast<int32_t>(x))));
+                                Int32Constant(base::bit_cast<int32_t>(x))));
     ASSERT_TRUE(reduction.Changed());
-    EXPECT_THAT(reduction.replacement(),
-                IsInt64Constant(bit_cast<int64_t>(static_cast<uint64_t>(x))));
+    EXPECT_THAT(
+        reduction.replacement(),
+        IsInt64Constant(base::bit_cast<int64_t>(static_cast<uint64_t>(x))));
   }
 }
 
@@ -561,8 +563,8 @@ TEST_F(MachineOperatorReducerTest, TruncateInt64ToInt32WithConstant) {
         graph()->NewNode(machine()->TruncateInt64ToInt32(), Int64Constant(x)));
     ASSERT_TRUE(reduction.Changed());
     EXPECT_THAT(reduction.replacement(),
-                IsInt32Constant(bit_cast<int32_t>(
-                    static_cast<uint32_t>(bit_cast<uint64_t>(x)))));
+                IsInt32Constant(base::bit_cast<int32_t>(
+                    static_cast<uint32_t>(base::bit_cast<uint64_t>(x)))));
   }
 }
 
@@ -1513,7 +1515,7 @@ TEST_F(MachineOperatorReducerTest, Uint32DivWithConstant) {
                            Uint32Constant(divisor), graph()->start()));
       ASSERT_TRUE(r.Changed());
       EXPECT_THAT(r.replacement(),
-                  IsInt32Constant(bit_cast<int32_t>(
+                  IsInt32Constant(base::bit_cast<int32_t>(
                       base::bits::UnsignedDiv32(dividend, divisor))));
     }
   }
@@ -1669,7 +1671,7 @@ TEST_F(MachineOperatorReducerTest, Uint32ModWithConstant) {
                            Uint32Constant(divisor), graph()->start()));
       ASSERT_TRUE(r.Changed());
       EXPECT_THAT(r.replacement(),
-                  IsInt32Constant(bit_cast<int32_t>(
+                  IsInt32Constant(base::bit_cast<int32_t>(
                       base::bits::UnsignedMod32(dividend, divisor))));
     }
   }
@@ -2605,8 +2607,9 @@ TEST_F(MachineOperatorReducerTest, Float64InsertLowWord32WithConstant) {
       ASSERT_TRUE(r.Changed());
       EXPECT_THAT(
           r.replacement(),
-          IsFloat64Constant(BitEq(bit_cast<double>(
-              (bit_cast<uint64_t>(x) & uint64_t{0xFFFFFFFF00000000}) | y))));
+          IsFloat64Constant(BitEq(base::bit_cast<double>(
+              (base::bit_cast<uint64_t>(x) & uint64_t{0xFFFFFFFF00000000}) |
+              y))));
     }
   }
 }
@@ -2624,8 +2627,8 @@ TEST_F(MachineOperatorReducerTest, Float64InsertHighWord32WithConstant) {
                                   Float64Constant(x), Uint32Constant(y)));
       ASSERT_TRUE(r.Changed());
       EXPECT_THAT(r.replacement(),
-                  IsFloat64Constant(BitEq(bit_cast<double>(
-                      (bit_cast<uint64_t>(x) & uint64_t{0xFFFFFFFF}) |
+                  IsFloat64Constant(BitEq(base::bit_cast<double>(
+                      (base::bit_cast<uint64_t>(x) & uint64_t{0xFFFFFFFF}) |
                       (static_cast<uint64_t>(y) << 32)))));
     }
   }
diff --git a/test/unittests/compiler/riscv64/instruction-selector-riscv64-unittest.cc b/test/unittests/compiler/riscv64/instruction-selector-riscv64-unittest.cc
index d5781118291..b56149b604f 100644
--- a/test/unittests/compiler/riscv64/instruction-selector-riscv64-unittest.cc
+++ b/test/unittests/compiler/riscv64/instruction-selector-riscv64-unittest.cc
@@ -1609,7 +1609,7 @@ TEST_F(InstructionSelectorTest, ExternalReferenceLoad1) {
   TRACED_FOREACH(int64_t, offset, kOffsets) {
     StreamBuilder m(this, MachineType::Int64());
     ExternalReference reference =
-        bit_cast<ExternalReference>(isolate()->isolate_root() + offset);
+        base::bit_cast<ExternalReference>(isolate()->isolate_root() + offset);
     Node* const value =
         m.Load(MachineType::Int64(), m.ExternalConstant(reference));
     m.Return(value);
@@ -1630,7 +1630,7 @@ TEST_F(InstructionSelectorTest, ExternalReferenceLoad2) {
   StreamBuilder m(this, MachineType::Int64());
   int64_t offset = 0x100000000;
   ExternalReference reference =
-      bit_cast<ExternalReference>(isolate()->isolate_root() + offset);
+      base::bit_cast<ExternalReference>(isolate()->isolate_root() + offset);
   Node* const value =
       m.Load(MachineType::Int64(), m.ExternalConstant(reference));
   m.Return(value);
diff --git a/test/unittests/compiler/simplified-lowering-unittest.cc b/test/unittests/compiler/simplified-lowering-unittest.cc
index 5c85cdd1bfa..6c5c6cad04f 100644
--- a/test/unittests/compiler/simplified-lowering-unittest.cc
+++ b/test/unittests/compiler/simplified-lowering-unittest.cc
@@ -83,7 +83,7 @@ const int kSmiValues[] = {Smi::kMinValue,
 TEST_F(SimplifiedLoweringTest, SmiConstantToIntPtrConstant) {
   TRACED_FOREACH(int, x, kSmiValues) {
     LowerGraph(jsgraph()->Constant(x));
-    intptr_t smi = bit_cast<intptr_t>(Smi::FromInt(x));
+    intptr_t smi = base::bit_cast<intptr_t>(Smi::FromInt(x));
     EXPECT_THAT(graph()->end()->InputAt(1),
                 IsReturn(IsIntPtrConstant(smi), start(), start()));
   }
diff --git a/test/unittests/compiler/simplified-operator-reducer-unittest.cc b/test/unittests/compiler/simplified-operator-reducer-unittest.cc
index 6e839a33046..063fe442ef2 100644
--- a/test/unittests/compiler/simplified-operator-reducer-unittest.cc
+++ b/test/unittests/compiler/simplified-operator-reducer-unittest.cc
@@ -96,8 +96,8 @@ const int32_t kInt32Values[] = {
 
 const double kNaNs[] = {-std::numeric_limits<double>::quiet_NaN(),
                         std::numeric_limits<double>::quiet_NaN(),
-                        bit_cast<double>(uint64_t{0x7FFFFFFFFFFFFFFF}),
-                        bit_cast<double>(uint64_t{0xFFFFFFFFFFFFFFFF})};
+                        base::bit_cast<double>(uint64_t{0x7FFFFFFFFFFFFFFF}),
+                        base::bit_cast<double>(uint64_t{0xFFFFFFFFFFFFFFFF})};
 
 const CheckForMinusZeroMode kCheckForMinusZeroModes[] = {
     CheckForMinusZeroMode::kDontCheckForMinusZero,
diff --git a/test/unittests/wasm/decoder-unittest.cc b/test/unittests/wasm/decoder-unittest.cc
index d693eef1727..7309f8a3bf5 100644
--- a/test/unittests/wasm/decoder-unittest.cc
+++ b/test/unittests/wasm/decoder-unittest.cc
@@ -612,7 +612,8 @@ TEST_F(DecoderTest, ReadI64v_Bits) {
   for (size_t v = 0; v < arraysize(kVals); v++) {
     // foreach length 1...64
     for (int i = 1; i <= 64; i++) {
-      const int64_t val = bit_cast<int64_t>(kVals[v] << (64 - i)) >> (64 - i);
+      const int64_t val =
+          base::bit_cast<int64_t>(kVals[v] << (64 - i)) >> (64 - i);
 
       unsigned length = 1 + i / 7;
       for (unsigned j = 0; j < kMaxSize; j++) {
diff --git a/test/unittests/wasm/leb-helper-unittest.cc b/test/unittests/wasm/leb-helper-unittest.cc
index d1531c4e354..9e17ad50afb 100644
--- a/test/unittests/wasm/leb-helper-unittest.cc
+++ b/test/unittests/wasm/leb-helper-unittest.cc
@@ -143,11 +143,11 @@ TEST_F(LEBHelperTest, WriteAndDecode_i32v) {
   CheckEncodeDecode_i32v(-77377);
 
   for (uint32_t val = 0x3A; val != 0; val = val << 1) {
-    CheckEncodeDecode_i32v(bit_cast<int32_t>(val));
+    CheckEncodeDecode_i32v(base::bit_cast<int32_t>(val));
   }
 
   for (uint32_t val = 0xFFFFFF3B; val != 0; val = val << 1) {
-    CheckEncodeDecode_i32v(bit_cast<int32_t>(val));
+    CheckEncodeDecode_i32v(base::bit_cast<int32_t>(val));
   }
 }
 
@@ -182,11 +182,11 @@ TEST_F(LEBHelperTest, WriteAndDecode_i64v) {
   CheckEncodeDecode_i64v(-77377);
 
   for (uint64_t val = 0x3A; val != 0; val = val << 1) {
-    CheckEncodeDecode_i64v(bit_cast<int64_t>(val));
+    CheckEncodeDecode_i64v(base::bit_cast<int64_t>(val));
   }
 
   for (uint64_t val = 0xFFFFFFFFFFFFFF3B; val != 0; val = val << 1) {
-    CheckEncodeDecode_i64v(bit_cast<int64_t>(val));
+    CheckEncodeDecode_i64v(base::bit_cast<int64_t>(val));
   }
 }
 }  // namespace wasm
-- 
2.35.1

