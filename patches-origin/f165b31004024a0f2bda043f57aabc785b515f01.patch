From f165b31004024a0f2bda043f57aabc785b515f01 Mon Sep 17 00:00:00 2001
From: Deepti Gandluri <gdeepti@chromium.org>
Date: Wed, 31 Aug 2022 14:16:38 -0700
Subject: [PATCH] [wasm-relaxed-simd] Implement dot product instructions for
 ia32/x64

Reference lowering in the corresponding issue:
https://github.com/WebAssembly/relaxed-simd/issues/52

Bug: v8:12284


Change-Id: Ia59419f41ae1e53804b0fdb7169bf6f56f864c53
Reviewed-on: https://chromium-review.googlesource.com/c/v8/v8/+/3862956
Reviewed-by: Thibaud Michaud <thibaudm@chromium.org>
Commit-Queue: Deepti Gandluri <gdeepti@chromium.org>
Cr-Commit-Position: refs/heads/main@{#82923}
---
 .../macro-assembler-shared-ia32-x64.cc            | 15 +++++++++++++++
 .../macro-assembler-shared-ia32-x64.h             |  1 +
 src/compiler/backend/ia32/code-generator-ia32.cc  |  6 ++++++
 .../backend/ia32/instruction-codes-ia32.h         |  1 +
 .../backend/ia32/instruction-scheduler-ia32.cc    |  1 +
 .../backend/ia32/instruction-selector-ia32.cc     |  6 ++++++
 src/compiler/backend/instruction-selector.cc      |  4 +++-
 src/compiler/backend/x64/code-generator-x64.cc    |  6 ++++++
 src/compiler/backend/x64/instruction-codes-x64.h  |  1 +
 .../backend/x64/instruction-scheduler-x64.cc      |  1 +
 .../backend/x64/instruction-selector-x64.cc       |  6 ++++++
 src/wasm/baseline/ia32/liftoff-assembler-ia32.h   |  2 +-
 src/wasm/baseline/x64/liftoff-assembler-x64.h     |  2 +-
 test/cctest/wasm/test-run-wasm-relaxed-simd.cc    |  4 +++-
 14 files changed, 52 insertions(+), 4 deletions(-)

diff --git a/src/codegen/shared-ia32-x64/macro-assembler-shared-ia32-x64.cc b/src/codegen/shared-ia32-x64/macro-assembler-shared-ia32-x64.cc
index 7b6ae44eadd..826e6d02507 100644
--- a/src/codegen/shared-ia32-x64/macro-assembler-shared-ia32-x64.cc
+++ b/src/codegen/shared-ia32-x64/macro-assembler-shared-ia32-x64.cc
@@ -704,6 +704,21 @@ void SharedTurboAssembler::I16x8Q15MulRSatS(XMMRegister dst, XMMRegister src1,
   Pxor(dst, scratch);
 }
 
+void SharedTurboAssembler::I16x8DotI8x16I7x16S(XMMRegister dst,
+                                               XMMRegister src1,
+                                               XMMRegister src2) {
+  ASM_CODE_COMMENT(this);
+  if (CpuFeatures::IsSupported(AVX)) {
+    CpuFeatureScope avx_scope(this, AVX);
+    vpmaddubsw(dst, src2, src1);
+  } else {
+    if (dst != src2) {
+      movdqa(dst, src2);
+    }
+    pmaddubsw(dst, src1);
+  }
+}
+
 void SharedTurboAssembler::I32x4ExtAddPairwiseI16x8U(XMMRegister dst,
                                                      XMMRegister src,
                                                      XMMRegister tmp) {
diff --git a/src/codegen/shared-ia32-x64/macro-assembler-shared-ia32-x64.h b/src/codegen/shared-ia32-x64/macro-assembler-shared-ia32-x64.h
index 300846e7d27..985c154eac9 100644
--- a/src/codegen/shared-ia32-x64/macro-assembler-shared-ia32-x64.h
+++ b/src/codegen/shared-ia32-x64/macro-assembler-shared-ia32-x64.h
@@ -442,6 +442,7 @@ class V8_EXPORT_PRIVATE SharedTurboAssembler : public TurboAssemblerBase {
   // Will move src1 to dst if AVX is not supported.
   void I16x8Q15MulRSatS(XMMRegister dst, XMMRegister src1, XMMRegister src2,
                         XMMRegister scratch);
+  void I16x8DotI8x16I7x16S(XMMRegister dst, XMMRegister src1, XMMRegister src2);
   void I32x4ExtAddPairwiseI16x8U(XMMRegister dst, XMMRegister src,
                                  XMMRegister tmp);
   // Requires that dst == src1 if AVX is not supported.
diff --git a/src/compiler/backend/ia32/code-generator-ia32.cc b/src/compiler/backend/ia32/code-generator-ia32.cc
index 23c3c0abb77..8a53c5cd21a 100644
--- a/src/compiler/backend/ia32/code-generator-ia32.cc
+++ b/src/compiler/backend/ia32/code-generator-ia32.cc
@@ -2089,6 +2089,12 @@ CodeGenerator::CodeGenResult CodeGenerator::AssembleArchInstruction(
                   i.InputSimd128Register(1));
       break;
     }
+    case kIA32I16x8DotI8x16I7x16S: {
+      __ I16x8DotI8x16I7x16S(i.OutputSimd128Register(),
+                             i.InputSimd128Register(0),
+                             i.InputSimd128Register(1));
+      break;
+    }
     case kIA32F32x4Splat: {
       __ F32x4Splat(i.OutputSimd128Register(), i.InputDoubleRegister(0));
       break;
diff --git a/src/compiler/backend/ia32/instruction-codes-ia32.h b/src/compiler/backend/ia32/instruction-codes-ia32.h
index f854bffdcd7..45f967b75da 100644
--- a/src/compiler/backend/ia32/instruction-codes-ia32.h
+++ b/src/compiler/backend/ia32/instruction-codes-ia32.h
@@ -359,6 +359,7 @@ namespace compiler {
   V(IA32I32x4AllTrue)              \
   V(IA32I16x8AllTrue)              \
   V(IA32I8x16AllTrue)              \
+  V(IA32I16x8DotI8x16I7x16S)       \
   V(IA32Word32AtomicPairLoad)      \
   V(IA32Word32ReleasePairStore)    \
   V(IA32Word32SeqCstPairStore)     \
diff --git a/src/compiler/backend/ia32/instruction-scheduler-ia32.cc b/src/compiler/backend/ia32/instruction-scheduler-ia32.cc
index 62e5d5ad04e..a30b4fc6a3d 100644
--- a/src/compiler/backend/ia32/instruction-scheduler-ia32.cc
+++ b/src/compiler/backend/ia32/instruction-scheduler-ia32.cc
@@ -244,6 +244,7 @@ int InstructionScheduler::GetTargetInstructionFlags(
     case kIA32I16x8ExtAddPairwiseI8x16U:
     case kIA32I16x8Q15MulRSatS:
     case kIA32I16x8RelaxedQ15MulRS:
+    case kIA32I16x8DotI8x16I7x16S:
     case kIA32I8x16Splat:
     case kIA32I8x16ExtractLaneS:
     case kIA32Pinsrb:
diff --git a/src/compiler/backend/ia32/instruction-selector-ia32.cc b/src/compiler/backend/ia32/instruction-selector-ia32.cc
index b5a23478e65..0154f90f5c4 100644
--- a/src/compiler/backend/ia32/instruction-selector-ia32.cc
+++ b/src/compiler/backend/ia32/instruction-selector-ia32.cc
@@ -3311,6 +3311,12 @@ void InstructionSelector::VisitF32x4Qfms(Node* node) {
   VisitRRRR(this, node, kIA32F32x4Qfms);
 }
 
+void InstructionSelector::VisitI16x8DotI8x16I7x16S(Node* node) {
+  IA32OperandGenerator g(this);
+  Emit(kIA32I16x8DotI8x16I7x16S, g.DefineAsRegister(node),
+       g.UseUniqueRegister(node->InputAt(0)), g.UseRegister(node->InputAt(1)));
+}
+
 void InstructionSelector::AddOutputToSelectContinuation(OperandGenerator* g,
                                                         int first_input_index,
                                                         Node* node) {
diff --git a/src/compiler/backend/instruction-selector.cc b/src/compiler/backend/instruction-selector.cc
index ed0bf5e5df9..c27774c64e2 100644
--- a/src/compiler/backend/instruction-selector.cc
+++ b/src/compiler/backend/instruction-selector.cc
@@ -2802,11 +2802,13 @@ void InstructionSelector::VisitF32x4Qfms(Node* node) { UNIMPLEMENTED(); }
         // && !V8_TARGET_ARCH_ARM64 && !V8_TARGET_ARCH_IA32 &&
         // !V8_TARGET_ARCH_RISCV64 && !V8_TARGET_ARCH_RISCV32
 
-#if !V8_TARGET_ARCH_ARM64
+#if !V8_TARGET_ARCH_ARM64 && !V8_TARGET_ARCH_X64 && !V8_TARGET_ARCH_IA32
 void InstructionSelector::VisitI16x8DotI8x16I7x16S(Node* node) {
   UNIMPLEMENTED();
 }
+#endif  // !V8_TARGET_ARCH_ARM6 && !V8_TARGET_ARCH_X64 && !V8_TARGET_ARCH_IA32
 
+#if !V8_TARGET_ARCH_ARM64
 void InstructionSelector::VisitI32x4DotI8x16I7x16AddS(Node* node) {
   UNIMPLEMENTED();
 }
diff --git a/src/compiler/backend/x64/code-generator-x64.cc b/src/compiler/backend/x64/code-generator-x64.cc
index 4ee0b5f8c06..acace4f630e 100644
--- a/src/compiler/backend/x64/code-generator-x64.cc
+++ b/src/compiler/backend/x64/code-generator-x64.cc
@@ -3651,6 +3651,12 @@ CodeGenerator::CodeGenResult CodeGenerator::AssembleArchInstruction(
                   i.InputSimd128Register(1));
       break;
     }
+    case kX64I16x8DotI8x16I7x16S: {
+      __ I16x8DotI8x16I7x16S(i.OutputSimd128Register(),
+                             i.InputSimd128Register(0),
+                             i.InputSimd128Register(1));
+      break;
+    }
     case kX64I8x16Splat: {
       XMMRegister dst = i.OutputSimd128Register();
       if (HasRegisterInput(instr, 0)) {
diff --git a/src/compiler/backend/x64/instruction-codes-x64.h b/src/compiler/backend/x64/instruction-codes-x64.h
index 9c0f6dc46f4..ed69ab87619 100644
--- a/src/compiler/backend/x64/instruction-codes-x64.h
+++ b/src/compiler/backend/x64/instruction-codes-x64.h
@@ -335,6 +335,7 @@ namespace compiler {
   V(X64I16x8ExtAddPairwiseI8x16U)                    \
   V(X64I16x8Q15MulRSatS)                             \
   V(X64I16x8RelaxedQ15MulRS)                         \
+  V(X64I16x8DotI8x16I7x16S)                          \
   V(X64I8x16Splat)                                   \
   V(X64I8x16ExtractLaneS)                            \
   V(X64I8x16SConvertI16x8)                           \
diff --git a/src/compiler/backend/x64/instruction-scheduler-x64.cc b/src/compiler/backend/x64/instruction-scheduler-x64.cc
index 92f88f26552..f50fc8f9dcf 100644
--- a/src/compiler/backend/x64/instruction-scheduler-x64.cc
+++ b/src/compiler/backend/x64/instruction-scheduler-x64.cc
@@ -280,6 +280,7 @@ int InstructionScheduler::GetTargetInstructionFlags(
     case kX64I16x8ExtAddPairwiseI8x16U:
     case kX64I16x8Q15MulRSatS:
     case kX64I16x8RelaxedQ15MulRS:
+    case kX64I16x8DotI8x16I7x16S:
     case kX64I8x16Splat:
     case kX64I8x16ExtractLaneS:
     case kX64I8x16SConvertI16x8:
diff --git a/src/compiler/backend/x64/instruction-selector-x64.cc b/src/compiler/backend/x64/instruction-selector-x64.cc
index 91c9f3ec1d7..0558783760e 100644
--- a/src/compiler/backend/x64/instruction-selector-x64.cc
+++ b/src/compiler/backend/x64/instruction-selector-x64.cc
@@ -4320,6 +4320,12 @@ void InstructionSelector::VisitF64x2PromoteLowF32x4(Node* node) {
   VisitRR(this, node, code);
 }
 
+void InstructionSelector::VisitI16x8DotI8x16I7x16S(Node* node) {
+  X64OperandGenerator g(this);
+  Emit(kX64I16x8DotI8x16I7x16S, g.DefineAsRegister(node),
+       g.UseUniqueRegister(node->InputAt(0)), g.UseRegister(node->InputAt(1)));
+}
+
 void InstructionSelector::AddOutputToSelectContinuation(OperandGenerator* g,
                                                         int first_input_index,
                                                         Node* node) {
diff --git a/src/wasm/baseline/ia32/liftoff-assembler-ia32.h b/src/wasm/baseline/ia32/liftoff-assembler-ia32.h
index 4293b226038..83b8ded59f5 100644
--- a/src/wasm/baseline/ia32/liftoff-assembler-ia32.h
+++ b/src/wasm/baseline/ia32/liftoff-assembler-ia32.h
@@ -3670,7 +3670,7 @@ void LiftoffAssembler::emit_i16x8_relaxed_q15mulr_s(LiftoffRegister dst,
 void LiftoffAssembler::emit_i16x8_dot_i8x16_i7x16_s(LiftoffRegister dst,
                                                     LiftoffRegister lhs,
                                                     LiftoffRegister rhs) {
-  bailout(kSimd, "emit_i16x8_dot_i8x16_i7x16_s");
+  I16x8DotI8x16I7x16S(dst.fp(), lhs.fp(), rhs.fp());
 }
 
 void LiftoffAssembler::emit_i32x4_dot_i8x16_i7x16_add_s(LiftoffRegister dst,
diff --git a/src/wasm/baseline/x64/liftoff-assembler-x64.h b/src/wasm/baseline/x64/liftoff-assembler-x64.h
index f183865f00e..544ec670b96 100644
--- a/src/wasm/baseline/x64/liftoff-assembler-x64.h
+++ b/src/wasm/baseline/x64/liftoff-assembler-x64.h
@@ -3255,7 +3255,7 @@ void LiftoffAssembler::emit_i16x8_relaxed_q15mulr_s(LiftoffRegister dst,
 void LiftoffAssembler::emit_i16x8_dot_i8x16_i7x16_s(LiftoffRegister dst,
                                                     LiftoffRegister lhs,
                                                     LiftoffRegister rhs) {
-  bailout(kSimd, "emit_i16x8_dot_i8x16_i7x16_s");
+  I16x8DotI8x16I7x16S(dst.fp(), lhs.fp(), rhs.fp());
 }
 
 void LiftoffAssembler::emit_i32x4_dot_i8x16_i7x16_add_s(LiftoffRegister dst,
diff --git a/test/cctest/wasm/test-run-wasm-relaxed-simd.cc b/test/cctest/wasm/test-run-wasm-relaxed-simd.cc
index 345014de2dd..0493fad74a9 100644
--- a/test/cctest/wasm/test-run-wasm-relaxed-simd.cc
+++ b/test/cctest/wasm/test-run-wasm-relaxed-simd.cc
@@ -435,7 +435,7 @@ WASM_RELAXED_SIMD_TEST(I16x8RelaxedQ15MulRS) {
   }
 }
 
-#if V8_TARGET_ARCH_ARM64
+#if V8_TARGET_ARCH_ARM64 || V8_TARGET_ARCH_X64 || V8_TARGET_ARCH_IA32
 WASM_RELAXED_SIMD_TEST(I16x8DotI8x16I7x16S) {
   WasmRunner<int32_t, int8_t, int8_t> r(execution_tier);
   int16_t* g = r.builder().template AddGlobal<int16_t>(kWasmS128);
@@ -460,7 +460,9 @@ WASM_RELAXED_SIMD_TEST(I16x8DotI8x16I7x16S) {
     }
   }
 }
+#endif  // V8_TARGET_ARCH_ARM64 || V8_TARGET_ARCH_X64 || V8_TARGET_ARCH_IA32
 
+#if V8_TARGET_ARCH_ARM64
 WASM_RELAXED_SIMD_TEST(I32x4DotI8x16I7x16AddS) {
   WasmRunner<int32_t, int8_t, int8_t, int32_t> r(execution_tier);
   int32_t* g = r.builder().template AddGlobal<int32_t>(kWasmS128);
-- 
2.35.1

