From 74955ee1c7ad924af8a486fa0a038c5ddab08e12 Mon Sep 17 00:00:00 2001
From: Lu Yahan <yahan@iscas.ac.cn>
Date: Thu, 30 Jun 2022 10:48:50 +0800
Subject: [PATCH] [riscv64][wasm] Fix and harden all conditional tier-up checks

port commit b9c4a8495560cd3ee14f32aa9f6cf5acee18811a

Change-Id: Id2764f7b37b287a76bd9b22e55f4153b9b619bd6
Reviewed-on: https://chromium-review.googlesource.com/c/v8/v8/+/3736554
Commit-Queue: ji qiu <qiuji@iscas.ac.cn>
Reviewed-by: ji qiu <qiuji@iscas.ac.cn>
Auto-Submit: Yahan Lu <yahan@iscas.ac.cn>
Commit-Queue: Yahan Lu <yahan@iscas.ac.cn>
Cr-Commit-Position: refs/heads/main@{#81454}
---
 src/builtins/riscv64/builtins-riscv64.cc      |  1 -
 .../riscv64/liftoff-assembler-riscv64.h       | 43 +++++++++++++++++--
 2 files changed, 40 insertions(+), 4 deletions(-)

diff --git a/src/builtins/riscv64/builtins-riscv64.cc b/src/builtins/riscv64/builtins-riscv64.cc
index ac5cd09ae5..c36e083b8c 100644
--- a/src/builtins/riscv64/builtins-riscv64.cc
+++ b/src/builtins/riscv64/builtins-riscv64.cc
@@ -1106,7 +1106,6 @@ static void MaybeOptimizeCodeOrTailCallOptimizedCodeSlot(
 
 namespace {
 void ResetBytecodeAge(MacroAssembler* masm, Register bytecode_array) {
-  static_assert(BytecodeArray::kNoAgeBytecodeAge == 0);
   __ Sh(zero_reg,
         FieldMemOperand(bytecode_array, BytecodeArray::kBytecodeAgeOffset));
 }
diff --git a/src/wasm/baseline/riscv64/liftoff-assembler-riscv64.h b/src/wasm/baseline/riscv64/liftoff-assembler-riscv64.h
index 29e4fcfcf3..b7d1910d44 100644
--- a/src/wasm/baseline/riscv64/liftoff-assembler-riscv64.h
+++ b/src/wasm/baseline/riscv64/liftoff-assembler-riscv64.h
@@ -956,9 +956,46 @@ void LiftoffAssembler::LoadReturnStackSlot(LiftoffRegister dst, int offset,
 void LiftoffAssembler::MoveStackValue(uint32_t dst_offset, uint32_t src_offset,
                                       ValueKind kind) {
   DCHECK_NE(dst_offset, src_offset);
-  LiftoffRegister reg = GetUnusedRegister(reg_class_for(kind), {});
-  Fill(reg, src_offset, kind);
-  Spill(dst_offset, reg, kind);
+
+  MemOperand src = liftoff::GetStackSlot(src_offset);
+  MemOperand dst = liftoff::GetStackSlot(dst_offset);
+  switch (kind) {
+    case kI32:
+      Lw(kScratchReg, src);
+      Sw(kScratchReg, dst);
+      break;
+    case kI64:
+    case kRef:
+    case kOptRef:
+    case kRtt:
+      Ld(kScratchReg, src);
+      Sd(kScratchReg, dst);
+      break;
+    case kF32:
+      LoadFloat(kScratchDoubleReg, src);
+      StoreFloat(kScratchDoubleReg, dst);
+      break;
+    case kF64:
+      TurboAssembler::LoadDouble(kScratchDoubleReg, src);
+      TurboAssembler::StoreDouble(kScratchDoubleReg, dst);
+      break;
+    case kS128: {
+      VU.set(kScratchReg, E8, m1);
+      Register src_reg = src.offset() == 0 ? src.rm() : kScratchReg;
+      if (src.offset() != 0) {
+        TurboAssembler::Add64(src_reg, src.rm(), src.offset());
+      }
+      vl(kSimd128ScratchReg, src_reg, 0, E8);
+      Register dst_reg = dst.offset() == 0 ? dst.rm() : kScratchReg;
+      if (dst.offset() != 0) {
+        Add64(kScratchReg, dst.rm(), dst.offset());
+      }
+      vs(kSimd128ScratchReg, dst_reg, 0, VSew::E8);
+      break;
+    }
+    default:
+      UNREACHABLE();
+  }
 }
 
 void LiftoffAssembler::Move(Register dst, Register src, ValueKind kind) {
-- 
2.35.1

