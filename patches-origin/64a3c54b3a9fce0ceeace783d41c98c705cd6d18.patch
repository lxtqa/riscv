From 64a3c54b3a9fce0ceeace783d41c98c705cd6d18 Mon Sep 17 00:00:00 2001
From: Lu Yahan <yahan@iscas.ac.cn>
Date: Fri, 11 Aug 2023 18:58:45 +0800
Subject: [PATCH] [riscv]Reduce number of vector arch code(Part 3).

Change-Id: I2619b230cd81b5bae8ad4cb4afe0dc41e5e17948
Reviewed-on: https://chromium-review.googlesource.com/c/v8/v8/+/4772525
Auto-Submit: Yahan Lu <yahan@iscas.ac.cn>
Reviewed-by: Ji Qiu <qiuji@iscas.ac.cn>
Commit-Queue: Ji Qiu <qiuji@iscas.ac.cn>
Cr-Commit-Position: refs/heads/main@{#89508}
---
 .../backend/riscv/code-generator-riscv.cc     | 171 ++++++++----------
 .../backend/riscv/instruction-codes-riscv.h   |  23 +--
 .../riscv/instruction-scheduler-riscv.cc      |  21 ++-
 .../riscv/instruction-selector-riscv.h        |  59 ++++--
 .../riscv/instruction-selector-riscv32.cc     |  30 +++
 .../riscv/instruction-selector-riscv64.cc     |  26 +++
 6 files changed, 201 insertions(+), 129 deletions(-)

diff --git a/src/compiler/backend/riscv/code-generator-riscv.cc b/src/compiler/backend/riscv/code-generator-riscv.cc
index 2dfdcd0fca2..f885fc9c7a1 100644
--- a/src/compiler/backend/riscv/code-generator-riscv.cc
+++ b/src/compiler/backend/riscv/code-generator-riscv.cc
@@ -3012,18 +3012,6 @@ CodeGenerator::CodeGenResult CodeGenerator::AssembleArchInstruction(
       __ vfabs_vv(i.OutputSimd128Register(), i.InputSimd128Register(0));
       break;
     }
-    case kRiscvF64x2Add: {
-      __ VU.set(kScratchReg, E64, m1);
-      __ vfadd_vv(i.OutputSimd128Register(), i.InputSimd128Register(0),
-                  i.InputSimd128Register(1));
-      break;
-    }
-    case kRiscvF64x2Sub: {
-      __ VU.set(kScratchReg, E64, m1);
-      __ vfsub_vv(i.OutputSimd128Register(), i.InputSimd128Register(0),
-                  i.InputSimd128Register(1));
-      break;
-    }
     case kRiscvF64x2Ceil: {
       __ Ceil_d(i.OutputSimd128Register(), i.InputSimd128Register(0),
                 kScratchReg, kSimd128ScratchReg);
@@ -3085,20 +3073,6 @@ CodeGenerator::CodeGenResult CodeGenerator::AssembleArchInstruction(
       break;
     }
 #if V8_TARGET_ARCH_RISCV64
-    case kRiscvF64x2Min: {
-      __ VU.set(kScratchReg, E64, m1);
-      const int64_t kNaN = 0x7ff8000000000000L;
-      __ vmfeq_vv(v0, i.InputSimd128Register(0), i.InputSimd128Register(0));
-      __ vmfeq_vv(kSimd128ScratchReg, i.InputSimd128Register(1),
-                  i.InputSimd128Register(1));
-      __ vand_vv(v0, v0, kSimd128ScratchReg);
-      __ li(kScratchReg, kNaN);
-      __ vmv_vx(kSimd128ScratchReg, kScratchReg);
-      __ vfmin_vv(kSimd128ScratchReg, i.InputSimd128Register(1),
-                  i.InputSimd128Register(0), Mask);
-      __ vmv_vv(i.OutputSimd128Register(), kSimd128ScratchReg);
-      break;
-    }
     case kRiscvF64x2Max: {
       __ VU.set(kScratchReg, E64, m1);
       const int64_t kNaN = 0x7ff8000000000000L;
@@ -3114,22 +3088,6 @@ CodeGenerator::CodeGenResult CodeGenerator::AssembleArchInstruction(
       break;
     }
 #elif V8_TARGET_ARCH_RISCV32
-    case kRiscvF64x2Min: {
-      __ VU.set(kScratchReg, E64, m1);
-      const int32_t kNaN = 0x7ff80000L, kNaNShift = 32;
-      __ vmfeq_vv(v0, i.InputSimd128Register(0), i.InputSimd128Register(0));
-      __ vmfeq_vv(kSimd128ScratchReg, i.InputSimd128Register(1),
-                  i.InputSimd128Register(1));
-      __ vand_vv(v0, v0, kSimd128ScratchReg);
-      __ li(kScratchReg, kNaN);
-      __ li(kScratchReg2, kNaNShift);
-      __ vmv_vx(kSimd128ScratchReg, kScratchReg);
-      __ vsll_vx(kSimd128ScratchReg, kSimd128ScratchReg, kScratchReg2);
-      __ vfmin_vv(kSimd128ScratchReg, i.InputSimd128Register(1),
-                  i.InputSimd128Register(0), Mask);
-      __ vmv_vv(i.OutputSimd128Register(), kSimd128ScratchReg);
-      break;
-    }
     case kRiscvF64x2Max: {
       __ VU.set(kScratchReg, E64, m1);
       const int32_t kNaN = 0x7ff80000L, kNaNShift = 32;
@@ -3147,19 +3105,6 @@ CodeGenerator::CodeGenResult CodeGenerator::AssembleArchInstruction(
       break;
     }
 #endif
-    case kRiscvF64x2Div: {
-      __ VU.set(kScratchReg, E64, m1);
-      __ vfdiv_vv(i.OutputSimd128Register(), i.InputSimd128Register(0),
-                  i.InputSimd128Register(1));
-      break;
-    }
-    case kRiscvF64x2Mul: {
-      __ VU.set(kScratchReg, E64, m1);
-      __ VU.set(FPURoundingMode::RTZ);
-      __ vfmul_vv(i.OutputSimd128Register(), i.InputSimd128Register(0),
-                  i.InputSimd128Register(1));
-      break;
-    }
     case kRiscvF64x2ExtractLane: {
       __ VU.set(kScratchReg, E64, m1);
       if (is_uint5(i.InputInt8(1))) {
@@ -3251,18 +3196,6 @@ CodeGenerator::CodeGenResult CodeGenerator::AssembleArchInstruction(
       __ vfabs_vv(i.OutputSimd128Register(), i.InputSimd128Register(0));
       break;
     }
-    case kRiscvF32x4Add: {
-      __ VU.set(kScratchReg, E32, m1);
-      __ vfadd_vv(i.OutputSimd128Register(), i.InputSimd128Register(0),
-                  i.InputSimd128Register(1));
-      break;
-    }
-    case kRiscvF32x4Sub: {
-      __ VU.set(kScratchReg, E32, m1);
-      __ vfsub_vv(i.OutputSimd128Register(), i.InputSimd128Register(0),
-                  i.InputSimd128Register(1));
-      break;
-    }
     case kRiscvF32x4Ceil: {
       __ Ceil_f(i.OutputSimd128Register(), i.InputSimd128Register(0),
                 kScratchReg, kSimd128ScratchReg);
@@ -3285,20 +3218,6 @@ CodeGenerator::CodeGenResult CodeGenerator::AssembleArchInstruction(
       __ vfcvt_f_x_v(i.OutputSimd128Register(), i.InputSimd128Register(0));
       break;
     }
-    case kRiscvF32x4Div: {
-      __ VU.set(kScratchReg, E32, m1);
-      __ VU.set(FPURoundingMode::RTZ);
-      __ vfdiv_vv(i.OutputSimd128Register(), i.InputSimd128Register(0),
-                  i.InputSimd128Register(1));
-      break;
-    }
-    case kRiscvF32x4Mul: {
-      __ VU.set(kScratchReg, E32, m1);
-      __ VU.set(FPURoundingMode::RTZ);
-      __ vfmul_vv(i.OutputSimd128Register(), i.InputSimd128Register(1),
-                  i.InputSimd128Register(0));
-      break;
-    }
     case kRiscvF32x4Eq: {
       __ VU.set(kScratchReg, E32, m1);
       __ vmfeq_vv(v0, i.InputSimd128Register(1), i.InputSimd128Register(0));
@@ -3369,20 +3288,6 @@ CodeGenerator::CodeGenResult CodeGenerator::AssembleArchInstruction(
       __ vmv_vv(i.OutputSimd128Register(), kSimd128ScratchReg);
       break;
     }
-    case kRiscvF32x4Min: {
-      __ VU.set(kScratchReg, E32, m1);
-      const int32_t kNaN = 0x7FC00000;
-      __ vmfeq_vv(v0, i.InputSimd128Register(0), i.InputSimd128Register(0));
-      __ vmfeq_vv(kSimd128ScratchReg, i.InputSimd128Register(1),
-                  i.InputSimd128Register(1));
-      __ vand_vv(v0, v0, kSimd128ScratchReg);
-      __ li(kScratchReg, kNaN);
-      __ vmv_vx(kSimd128ScratchReg, kScratchReg);
-      __ vfmin_vv(kSimd128ScratchReg, i.InputSimd128Register(1),
-                  i.InputSimd128Register(0), Mask);
-      __ vmv_vv(i.OutputSimd128Register(), kSimd128ScratchReg);
-      break;
-    }
     case kRiscvF32x4Qfma: {
       __ VU.set(kScratchReg, E32, m1);
       __ vfmadd_vv(i.InputSimd128Register(0), i.InputSimd128Register(1),
@@ -3605,6 +3510,24 @@ CodeGenerator::CodeGenResult CodeGenerator::AssembleArchInstruction(
       }
       break;
     }
+    case kRiscvVsllVi: {
+      __ VU.set(kScratchReg, i.InputInt8(2), i.InputInt8(3));
+      __ vsll_vi(i.OutputSimd128Register(), i.InputSimd128Register(0),
+                 i.InputInt8(1));
+      break;
+    }
+    case kRiscvVsllVx: {
+      __ VU.set(kScratchReg, i.InputInt8(2), i.InputInt8(3));
+      if (instr->InputAt(1)->IsRegister()) {
+        __ vsll_vx(i.OutputSimd128Register(), i.InputSimd128Register(0),
+                   i.InputRegister(1));
+      } else {
+        __ li(kScratchReg, i.InputInt64(1));
+        __ vsll_vx(i.OutputSimd128Register(), i.InputSimd128Register(0),
+                   kScratchReg);
+      }
+      break;
+    }
     case kRiscvVaddVv: {
       __ VU.set(kScratchReg, i.InputInt8(2), i.InputInt8(3));
       __ vadd_vv(i.OutputSimd128Register(), i.InputSimd128Register(0),
@@ -3622,6 +3545,22 @@ CodeGenerator::CodeGenResult CodeGenerator::AssembleArchInstruction(
       __ vmv_vx(i.OutputSimd128Register(), i.InputRegister(0));
       break;
     }
+    case kRiscvVmvVv: {
+      __ VU.set(kScratchReg, i.InputInt8(1), i.InputInt8(2));
+      __ vmv_vv(i.OutputSimd128Register(), i.InputSimd128Register(0));
+      break;
+    }
+    case kRiscvVmvVi: {
+      __ VU.set(kScratchReg, i.InputInt8(1), i.InputInt8(2));
+      if (i.ToConstant(instr->InputAt(0)).FitsInInt32() &&
+          is_int8(i.InputInt32(0))) {
+        __ vmv_vi(i.OutputSimd128Register(), i.InputInt8(0));
+      } else {
+        __ li(kScratchReg, i.InputInt64(0));
+        __ vmv_vx(i.OutputSimd128Register(), kScratchReg);
+      }
+      break;
+    }
     case kRiscvVfmvVf: {
       __ VU.set(kScratchReg, i.InputInt8(1), i.InputInt8(2));
       __ vfmv_vf(i.OutputSimd128Register(), i.InputDoubleRegister(0));
@@ -3727,6 +3666,48 @@ CodeGenerator::CodeGenResult CodeGenerator::AssembleArchInstruction(
                    i.InputSimd128Register(1));
       break;
     }
+    case kRiscvVfaddVv: {
+      __ VU.set(kScratchReg, i.InputInt8(2), i.InputInt8(3));
+      __ vfadd_vv(i.OutputSimd128Register(), i.InputSimd128Register(0),
+                  i.InputSimd128Register(1));
+      break;
+    }
+    case kRiscvVfsubVv: {
+      __ VU.set(kScratchReg, i.InputInt8(2), i.InputInt8(3));
+      __ vfsub_vv(i.OutputSimd128Register(), i.InputSimd128Register(0),
+                  i.InputSimd128Register(1));
+      break;
+    }
+    case kRiscvVfmulVv: {
+      __ VU.set(kScratchReg, i.InputInt8(2), i.InputInt8(3));
+      __ vfmul_vv(i.OutputSimd128Register(), i.InputSimd128Register(0),
+                  i.InputSimd128Register(1));
+      break;
+    }
+    case kRiscvVfdivVv: {
+      __ VU.set(kScratchReg, i.InputInt8(2), i.InputInt8(3));
+      __ vfdiv_vv(i.OutputSimd128Register(), i.InputSimd128Register(0),
+                  i.InputSimd128Register(1));
+      break;
+    }
+    case kRiscvVmfeqVv: {
+      __ VU.set(kScratchReg, i.InputInt8(2), i.InputInt8(3));
+      __ vmfeq_vv(i.OutputSimd128Register(), i.InputSimd128Register(0),
+                  i.InputSimd128Register(1));
+      break;
+    }
+    case kRiscvVfminVv: {
+      __ VU.set(kScratchReg, i.InputInt8(2), i.InputInt8(3));
+      __ vfmin_vv(i.OutputSimd128Register(), i.InputSimd128Register(0),
+                  i.InputSimd128Register(1), MaskType(i.InputInt8(4)));
+      break;
+    }
+    case kRiscvVandVv: {
+      __ VU.set(kScratchReg, i.InputInt8(2), i.InputInt8(3));
+      __ vand_vv(i.OutputSimd128Register(), i.InputSimd128Register(0),
+                 i.InputSimd128Register(1));
+      break;
+    }
     default:
 #ifdef DEBUG
       switch (arch_opcode) {
diff --git a/src/compiler/backend/riscv/instruction-codes-riscv.h b/src/compiler/backend/riscv/instruction-codes-riscv.h
index ae138b1bd3a..7ef1f41c309 100644
--- a/src/compiler/backend/riscv/instruction-codes-riscv.h
+++ b/src/compiler/backend/riscv/instruction-codes-riscv.h
@@ -229,11 +229,6 @@ namespace compiler {
   V(RiscvI32x4ShrS)                       \
   V(RiscvI32x4ShrU)                       \
   V(RiscvF64x2Sqrt)                       \
-  V(RiscvF64x2Add)                        \
-  V(RiscvF64x2Sub)                        \
-  V(RiscvF64x2Mul)                        \
-  V(RiscvF64x2Div)                        \
-  V(RiscvF64x2Min)                        \
   V(RiscvF64x2Max)                        \
   V(RiscvF64x2ConvertLowI32x4S)           \
   V(RiscvF64x2ConvertLowI32x4U)           \
@@ -265,12 +260,7 @@ namespace compiler {
   V(RiscvF32x4Qfms)                       \
   V(RiscvF64x2Qfma)                       \
   V(RiscvF64x2Qfms)                       \
-  V(RiscvF32x4Add)                        \
-  V(RiscvF32x4Sub)                        \
-  V(RiscvF32x4Mul)                        \
-  V(RiscvF32x4Div)                        \
   V(RiscvF32x4Max)                        \
-  V(RiscvF32x4Min)                        \
   V(RiscvF32x4Eq)                         \
   V(RiscvF32x4Ne)                         \
   V(RiscvF32x4Lt)                         \
@@ -366,7 +356,10 @@ namespace compiler {
   V(RiscvI16x8UConvertI8x16High)          \
   V(RiscvI8x16SConvertI16x8)              \
   V(RiscvI8x16UConvertI16x8)              \
+  V(RiscvVmvVv)                           \
+  V(RiscvVandVv)                          \
   V(RiscvVmvVx)                           \
+  V(RiscvVmvVi)                           \
   V(RiscvVwmul)                           \
   V(RiscvVwmulu)                          \
   V(RiscvVmvSx)                           \
@@ -377,6 +370,8 @@ namespace compiler {
   V(RiscvVwaddu)                          \
   V(RiscvVrgather)                        \
   V(RiscvVslidedown)                      \
+  V(RiscvVsllVi)                          \
+  V(RiscvVsllVx)                          \
   V(RiscvVfmvVf)                          \
   V(RiscvVnegVv)                          \
   V(RiscvVfnegVv)                         \
@@ -394,7 +389,13 @@ namespace compiler {
   V(RiscvVaddSatSVv)                      \
   V(RiscvVaddSatUVv)                      \
   V(RiscvVsubSatSVv)                      \
-  V(RiscvVsubSatUVv)
+  V(RiscvVsubSatUVv)                      \
+  V(RiscvVmfeqVv)                         \
+  V(RiscvVfaddVv)                         \
+  V(RiscvVfsubVv)                         \
+  V(RiscvVfmulVv)                         \
+  V(RiscvVfdivVv)                         \
+  V(RiscvVfminVv)
 
 #define TARGET_ARCH_OPCODE_LIST(V)  \
   TARGET_ARCH_OPCODE_LIST_COMMON(V) \
diff --git a/src/compiler/backend/riscv/instruction-scheduler-riscv.cc b/src/compiler/backend/riscv/instruction-scheduler-riscv.cc
index 4966e7ccdaf..0ea657e8461 100644
--- a/src/compiler/backend/riscv/instruction-scheduler-riscv.cc
+++ b/src/compiler/backend/riscv/instruction-scheduler-riscv.cc
@@ -102,11 +102,6 @@ int InstructionScheduler::GetTargetInstructionFlags(
     case kRiscvDivU32:
     case kRiscvF64x2Abs:
     case kRiscvF64x2Sqrt:
-    case kRiscvF64x2Add:
-    case kRiscvF64x2Sub:
-    case kRiscvF64x2Mul:
-    case kRiscvF64x2Div:
-    case kRiscvF64x2Min:
     case kRiscvF64x2Max:
     case kRiscvF64x2Eq:
     case kRiscvF64x2Ne:
@@ -131,15 +126,11 @@ int InstructionScheduler::GetTargetInstructionFlags(
     case kRiscvI64x2ShrU:
     case kRiscvI64x2BitMask:
     case kRiscvF32x4Abs:
-    case kRiscvF32x4Add:
     case kRiscvF32x4Eq:
     case kRiscvF32x4ExtractLane:
     case kRiscvF32x4Lt:
     case kRiscvF32x4Le:
     case kRiscvF32x4Max:
-    case kRiscvF32x4Min:
-    case kRiscvF32x4Mul:
-    case kRiscvF32x4Div:
     case kRiscvF32x4Ne:
     case kRiscvF32x4Sqrt:
     case kRiscvF64x2Qfma:
@@ -148,7 +139,6 @@ int InstructionScheduler::GetTargetInstructionFlags(
     case kRiscvF32x4Qfms:
     case kRiscvF32x4ReplaceLane:
     case kRiscvF32x4SConvertI32x4:
-    case kRiscvF32x4Sub:
     case kRiscvF32x4UConvertI32x4:
     case kRiscvF32x4Pmin:
     case kRiscvF32x4Pmax:
@@ -287,7 +277,10 @@ int InstructionScheduler::GetTargetInstructionFlags(
     case kRiscvI8x16Shuffle:
     case kRiscvVwmul:
     case kRiscvVwmulu:
+    case kRiscvVmvVv:
     case kRiscvVmvVx:
+    case kRiscvVmvVi:
+    case kRiscvVandVv:
     case kRiscvVmvSx:
     case kRiscvVfmvVf:
     case kRiscvVcompress:
@@ -314,6 +307,14 @@ int InstructionScheduler::GetTargetInstructionFlags(
     case kRiscvVsubSatSVv:
     case kRiscvVrgather:
     case kRiscvVslidedown:
+    case kRiscvVsllVi:
+    case kRiscvVsllVx:
+    case kRiscvVfaddVv:
+    case kRiscvVfsubVv:
+    case kRiscvVfmulVv:
+    case kRiscvVfdivVv:
+    case kRiscvVfminVv:
+    case kRiscvVmfeqVv:
     case kRiscvSar32:
     case kRiscvSignExtendByte:
     case kRiscvSignExtendShort:
diff --git a/src/compiler/backend/riscv/instruction-selector-riscv.h b/src/compiler/backend/riscv/instruction-selector-riscv.h
index 9dc4eb01916..d656ed3339a 100644
--- a/src/compiler/backend/riscv/instruction-selector-riscv.h
+++ b/src/compiler/backend/riscv/instruction-selector-riscv.h
@@ -1188,7 +1188,15 @@ void InstructionSelectorT<Adapter>::VisitI16x8ExtAddPairwiseI8x16U(Node* node) {
   V(I16x8SubSatS, kRiscvVsubSatSVv, E16, m1) \
   V(I8x16SubSatS, kRiscvVsubSatSVv, E8, m1)  \
   V(I16x8SubSatU, kRiscvVsubSatUVv, E16, m1) \
-  V(I8x16SubSatU, kRiscvVsubSatUVv, E8, m1)
+  V(I8x16SubSatU, kRiscvVsubSatUVv, E8, m1)  \
+  V(F64x2Add, kRiscvVfaddVv, E64, m1)        \
+  V(F32x4Add, kRiscvVfaddVv, E32, m1)        \
+  V(F64x2Sub, kRiscvVfsubVv, E64, m1)        \
+  V(F32x4Sub, kRiscvVfsubVv, E32, m1)        \
+  V(F64x2Mul, kRiscvVfmulVv, E64, m1)        \
+  V(F32x4Mul, kRiscvVfmulVv, E32, m1)        \
+  V(F64x2Div, kRiscvVfdivVv, E64, m1)        \
+  V(F32x4Div, kRiscvVfdivVv, E32, m1)
 
 #define SIMD_UNOP_INT_LIST(V) \
   V(Neg, kRiscvVnegVv)        \
@@ -1199,29 +1207,17 @@ void InstructionSelectorT<Adapter>::VisitI16x8ExtAddPairwiseI8x16U(Node* node) {
   V(Splat, kRiscvVfmvVf)
 
 #define SIMD_BINOP_LIST(V)                              \
-  V(F64x2Add, kRiscvF64x2Add)                           \
-  V(F64x2Sub, kRiscvF64x2Sub)                           \
-  V(F64x2Mul, kRiscvF64x2Mul)                           \
-  V(F64x2Div, kRiscvF64x2Div)                           \
-  V(F64x2Min, kRiscvF64x2Min)                           \
   V(F64x2Max, kRiscvF64x2Max)                           \
   V(F64x2Eq, kRiscvF64x2Eq)                             \
   V(F64x2Ne, kRiscvF64x2Ne)                             \
   V(F64x2Lt, kRiscvF64x2Lt)                             \
   V(F64x2Le, kRiscvF64x2Le)                             \
-  V(F32x4Add, kRiscvF32x4Add)                           \
-  V(F32x4Sub, kRiscvF32x4Sub)                           \
-  V(F32x4Mul, kRiscvF32x4Mul)                           \
-  V(F32x4Div, kRiscvF32x4Div)                           \
   V(F32x4Max, kRiscvF32x4Max)                           \
-  V(F32x4Min, kRiscvF32x4Min)                           \
   V(F32x4Eq, kRiscvF32x4Eq)                             \
   V(F32x4Ne, kRiscvF32x4Ne)                             \
   V(F32x4Lt, kRiscvF32x4Lt)                             \
   V(F32x4Le, kRiscvF32x4Le)                             \
-  V(F32x4RelaxedMin, kRiscvF32x4Min)                    \
   V(F32x4RelaxedMax, kRiscvF32x4Max)                    \
-  V(F64x2RelaxedMin, kRiscvF64x2Min)                    \
   V(F64x2RelaxedMax, kRiscvF64x2Max)                    \
   V(I16x8RoundingAverageU, kRiscvI16x8RoundingAverageU) \
   V(I16x8Q15MulRSatS, kRiscvI16x8Q15MulRSatS)           \
@@ -1405,6 +1401,43 @@ VISIT_SIMD_QFMOP(F32x4Qfma, kRiscvF32x4Qfma)
 VISIT_SIMD_QFMOP(F32x4Qfms, kRiscvF32x4Qfms)
 #undef VISIT_SIMD_QFMOP
 
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitF32x4Min(Node* node) {
+  RiscvOperandGeneratorT<Adapter> g(this);
+  InstructionOperand temp1 = g.TempFpRegister(v0);
+  InstructionOperand mask_reg = g.TempFpRegister(v0);
+  InstructionOperand temp2 = g.TempFpRegister(kSimd128ScratchReg);
+
+  this->Emit(kRiscvVmfeqVv, temp1, g.UseRegister(node->InputAt(0)),
+             g.UseRegister(node->InputAt(0)), g.UseImmediate(E32),
+             g.UseImmediate(m1));
+  this->Emit(kRiscvVmfeqVv, temp2, g.UseRegister(node->InputAt(1)),
+             g.UseRegister(node->InputAt(1)), g.UseImmediate(E32),
+             g.UseImmediate(m1));
+  this->Emit(kRiscvVandVv, mask_reg, temp2, temp1, g.UseImmediate(E32),
+             g.UseImmediate(m1));
+
+  InstructionOperand NaN = g.TempFpRegister(kSimd128ScratchReg);
+  InstructionOperand result = g.TempFpRegister(kSimd128ScratchReg);
+  this->Emit(kRiscvVmvVi, NaN, g.UseImmediate(0x7FC00000), g.UseImmediate(E32),
+             g.UseImmediate(m1));
+  this->Emit(kRiscvVfminVv, result, g.UseRegister(node->InputAt(1)),
+             g.UseRegister(node->InputAt(0)), g.UseImmediate(E32),
+             g.UseImmediate(m1), g.UseImmediate(MaskType::Mask));
+  this->Emit(kRiscvVmvVv, g.DefineAsRegister(node), result, g.UseImmediate(E32),
+             g.UseImmediate(m1));
+}
+
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitF32x4RelaxedMin(Node* node) {
+  VisitF32x4Min(node);
+}
+
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitF64x2RelaxedMin(Node* node) {
+  VisitF64x2Min(node);
+}
+
 template <typename Adapter>
 void InstructionSelectorT<Adapter>::VisitI32x4DotI16x8S(Node* node) {
   constexpr int32_t FIRST_INDEX = 0b01010101;
diff --git a/src/compiler/backend/riscv/instruction-selector-riscv32.cc b/src/compiler/backend/riscv/instruction-selector-riscv32.cc
index abafd910676..a54c8159fd2 100644
--- a/src/compiler/backend/riscv/instruction-selector-riscv32.cc
+++ b/src/compiler/backend/riscv/instruction-selector-riscv32.cc
@@ -1664,6 +1664,36 @@ void InstructionSelectorT<Adapter>::VisitWord32AtomicPairCompareExchange(
   Emit(code, output_count, outputs, arraysize(inputs), inputs, temp_count,
        temps);
 }
+
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitF64x2Min(Node* node) {
+  RiscvOperandGeneratorT<Adapter> g(this);
+  InstructionOperand temp1 = g.TempFpRegister(v0);
+  InstructionOperand mask_reg = g.TempFpRegister(v0);
+  InstructionOperand temp2 = g.TempFpRegister(kSimd128ScratchReg);
+  const int32_t kNaN = 0x7ff80000L, kNaNShift = 32;
+  this->Emit(kRiscvVmfeqVv, temp1, g.UseRegister(node->InputAt(0)),
+             g.UseRegister(node->InputAt(0)), g.UseImmediate(E64),
+             g.UseImmediate(m1));
+  this->Emit(kRiscvVmfeqVv, temp2, g.UseRegister(node->InputAt(1)),
+             g.UseRegister(node->InputAt(1)), g.UseImmediate(E64),
+             g.UseImmediate(m1));
+  this->Emit(kRiscvVandVv, mask_reg, temp2, temp1, g.UseImmediate(E64),
+             g.UseImmediate(m1));
+
+  InstructionOperand temp3 = g.TempFpRegister(kSimd128ScratchReg);
+  InstructionOperand temp4 = g.TempFpRegister(kSimd128ScratchReg);
+  InstructionOperand temp5 = g.TempFpRegister(kSimd128ScratchReg);
+  this->Emit(kRiscvVmvVi, temp3, g.UseImmediate(kNaN), g.UseImmediate(E64),
+             g.UseImmediate(m1));
+  this->Emit(kRiscvVsllVx, temp4, temp3, g.UseImmediate(kNaNShift),
+             g.UseImmediate(E64), g.UseImmediate(m1));
+  this->Emit(kRiscvVfminVv, temp5, g.UseRegister(node->InputAt(1)),
+             g.UseRegister(node->InputAt(0)), g.UseImmediate(E64),
+             g.UseImmediate(m1), g.UseImmediate(Mask));
+  this->Emit(kRiscvVmvVv, g.DefineAsRegister(node), temp5, g.UseImmediate(E64),
+             g.UseImmediate(m1));
+}
 // static
 MachineOperatorBuilder::Flags
 InstructionSelector::SupportedMachineOperatorFlags() {
diff --git a/src/compiler/backend/riscv/instruction-selector-riscv64.cc b/src/compiler/backend/riscv/instruction-selector-riscv64.cc
index 2dd1597bb7d..8a2cb516aab 100644
--- a/src/compiler/backend/riscv/instruction-selector-riscv64.cc
+++ b/src/compiler/backend/riscv/instruction-selector-riscv64.cc
@@ -2810,6 +2810,32 @@ void InstructionSelectorT<Adapter>::VisitSignExtendWord32ToInt64(Node* node) {
   }
 }
 
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitF64x2Min(Node* node) {
+  RiscvOperandGeneratorT<Adapter> g(this);
+  InstructionOperand temp1 = g.TempFpRegister(v0);
+  InstructionOperand temp2 = g.TempFpRegister(kSimd128ScratchReg);
+  InstructionOperand mask_reg = g.TempFpRegister(v0);
+  this->Emit(kRiscvVmfeqVv, temp1, g.UseRegister(node->InputAt(0)),
+             g.UseRegister(node->InputAt(0)), g.UseImmediate(E64),
+             g.UseImmediate(m1));
+  this->Emit(kRiscvVmfeqVv, temp2, g.UseRegister(node->InputAt(1)),
+             g.UseRegister(node->InputAt(1)), g.UseImmediate(E64),
+             g.UseImmediate(m1));
+  this->Emit(kRiscvVandVv, mask_reg, temp2, temp1, g.UseImmediate(E64),
+             g.UseImmediate(m1));
+
+  InstructionOperand NaN = g.TempFpRegister(kSimd128ScratchReg);
+  InstructionOperand result = g.TempFpRegister(kSimd128ScratchReg);
+  this->Emit(kRiscvVmvVi, NaN, g.UseImmediate64(0x7ff8000000000000L),
+             g.UseImmediate(E64), g.UseImmediate(m1));
+  this->Emit(kRiscvVfminVv, result, g.UseRegister(node->InputAt(1)),
+             g.UseRegister(node->InputAt(0)), g.UseImmediate(E64),
+             g.UseImmediate(m1), g.UseImmediate(MaskType::Mask));
+  this->Emit(kRiscvVmvVv, g.DefineAsRegister(node), result, g.UseImmediate(E64),
+             g.UseImmediate(m1));
+}
+
 // static
 MachineOperatorBuilder::Flags
 InstructionSelector::SupportedMachineOperatorFlags() {
-- 
2.35.1

