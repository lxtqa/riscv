From 567587afcec7bae0fe5854e62ad21093dbd9984d Mon Sep 17 00:00:00 2001
From: Liu Yu <liuyu@loongson.cn>
Date: Wed, 16 Aug 2023 10:18:22 +0800
Subject: [PATCH] [loong64][wasm] Enable OOB trap handler

Change-Id: I4712f7ab7153a671abaf0ed98def4a6e88c09f72
Reviewed-on: https://chromium-review.googlesource.com/c/v8/v8/+/4876584
Reviewed-by: Clemens Backes <clemensb@chromium.org>
Reviewed-by: Zhao Jiazhong <zhaojiazhong-hf@loongson.cn>
Auto-Submit: Liu Yu <liuyu@loongson.cn>
Commit-Queue: Clemens Backes <clemensb@chromium.org>
Cr-Commit-Position: refs/heads/main@{#90181}
---
 BUILD.gn                                      |  25 +
 src/base/platform/platform-posix.cc           |   6 +-
 .../loong64/macro-assembler-loong64.cc        |   4 +
 src/codegen/loong64/macro-assembler-loong64.h |   4 +
 .../backend/loong64/code-generator-loong64.cc | 155 +++-
 .../loong64/instruction-codes-loong64.h       | 756 +++++++++---------
 .../loong64/instruction-selector-loong64.cc   | 181 +++--
 src/execution/loong64/simulator-loong64.cc    | 198 ++---
 src/execution/loong64/simulator-loong64.h     |  12 +
 src/trap-handler/handler-inside-posix.cc      |   4 +
 src/trap-handler/trap-handler.h               |   7 +
 .../loong64/liftoff-assembler-loong64.h       |  14 +-
 test/unittests/BUILD.gn                       |  10 +-
 .../instruction-selector-loong64-unittest.cc  |  45 +-
 ...est.cc => trap-handler-native-unittest.cc} |  77 ++
 .../wasm/trap-handler-simulator-unittest.cc   |  16 +
 16 files changed, 914 insertions(+), 600 deletions(-)
 rename test/unittests/wasm/{trap-handler-x64-arm64-unittest.cc => trap-handler-native-unittest.cc} (87%)

diff --git a/BUILD.gn b/BUILD.gn
index c76f36cd487..d1e245a4813 100644
--- a/BUILD.gn
+++ b/BUILD.gn
@@ -4399,6 +4399,17 @@ v8_header_set("v8_internal_headers") {
       "src/regexp/loong64/regexp-macro-assembler-loong64.h",
       "src/wasm/baseline/loong64/liftoff-assembler-loong64.h",
     ]
+    if (v8_enable_webassembly) {
+      # Trap handling is enabled on loong64 Linux and in simulators on
+      # x64 on Linux.
+      if ((current_cpu == "loong64" && is_linux) ||
+          (current_cpu == "x64" && is_linux)) {
+        sources += [ "src/trap-handler/handler-inside-posix.h" ]
+      }
+      if (current_cpu == "x64" && is_linux) {
+        sources += [ "src/trap-handler/trap-handler-simulator.h" ]
+      }
+    }
   } else if (v8_current_cpu == "ppc") {
     sources += [
       ### gcmole(ppc) ###
@@ -5668,6 +5679,20 @@ v8_source_set("v8_base_without_compiler") {
       "src/execution/loong64/simulator-loong64.cc",
       "src/regexp/loong64/regexp-macro-assembler-loong64.cc",
     ]
+    if (v8_enable_webassembly) {
+      # Trap handling is enabled on loong64 Linux and in simulators on
+      # x64 on Linux.
+      if ((current_cpu == "loong64" && is_linux) ||
+          (current_cpu == "x64" && is_linux)) {
+        sources += [
+          "src/trap-handler/handler-inside-posix.cc",
+          "src/trap-handler/handler-outside-posix.cc",
+        ]
+      }
+      if (current_cpu == "x64" && is_linux) {
+        sources += [ "src/trap-handler/handler-outside-simulator.cc" ]
+      }
+    }
   } else if (v8_current_cpu == "ppc") {
     sources += [
       ### gcmole(ppc) ###
diff --git a/src/base/platform/platform-posix.cc b/src/base/platform/platform-posix.cc
index 93c6e91b36d..421070d5d08 100644
--- a/src/base/platform/platform-posix.cc
+++ b/src/base/platform/platform-posix.cc
@@ -370,9 +370,9 @@ void* OS::GetRandomMmapAddr() {
   // this address for RISC-V. https://github.com/v8-riscv/v8/issues/375
   raw_addr &= 0x3FFFF000;
 #elif V8_TARGET_ARCH_LOONG64
-  // 42 bits of virtual addressing. Truncate to 40 bits to allow kernel chance
-  // to fulfill request.
-  raw_addr &= uint64_t{0xFFFFFF0000};
+  // 40 or 47 bits of virtual addressing. Truncate to 38 bits to allow kernel
+  // chance to fulfill request.
+  raw_addr &= uint64_t{0x3FFFFF0000};
 #else
   raw_addr &= 0x3FFFF000;
 
diff --git a/src/codegen/loong64/macro-assembler-loong64.cc b/src/codegen/loong64/macro-assembler-loong64.cc
index 531464faf89..5f97c00fe82 100644
--- a/src/codegen/loong64/macro-assembler-loong64.cc
+++ b/src/codegen/loong64/macro-assembler-loong64.cc
@@ -4055,6 +4055,10 @@ void MacroAssembler::AssertGeneratorObject(Register object) {
       Operand(LAST_JS_GENERATOR_OBJECT_TYPE - FIRST_JS_GENERATOR_OBJECT_TYPE));
 }
 
+void MacroAssembler::AssertUnreachable(AbortReason reason) {
+  if (v8_flags.debug_code) Abort(reason);
+}
+
 void MacroAssembler::AssertUndefinedOrAllocationSite(Register object,
                                                      Register scratch) {
   if (v8_flags.debug_code) {
diff --git a/src/codegen/loong64/macro-assembler-loong64.h b/src/codegen/loong64/macro-assembler-loong64.h
index a5cf6640660..41fb5377e18 100644
--- a/src/codegen/loong64/macro-assembler-loong64.h
+++ b/src/codegen/loong64/macro-assembler-loong64.h
@@ -1086,6 +1086,10 @@ class V8_EXPORT_PRIVATE MacroAssembler : public MacroAssemblerBase {
   // enabled via --debug-code.
   void AssertGeneratorObject(Register object) NOOP_UNLESS_DEBUG_CODE;
 
+  // Like Assert(), but without condition.
+  // Use --debug_code to enable.
+  void AssertUnreachable(AbortReason reason) NOOP_UNLESS_DEBUG_CODE;
+
   // Abort execution if argument is not undefined or an AllocationSite, enabled
   // via --debug-code.
   void AssertUndefinedOrAllocationSite(Register object,
diff --git a/src/compiler/backend/loong64/code-generator-loong64.cc b/src/compiler/backend/loong64/code-generator-loong64.cc
index 8167abf74be..b86bd1930f5 100644
--- a/src/compiler/backend/loong64/code-generator-loong64.cc
+++ b/src/compiler/backend/loong64/code-generator-loong64.cc
@@ -229,6 +229,73 @@ CREATE_OOL_CLASS(OutOfLineFloat64Min, Float64MinOutOfLine, FPURegister);
 
 #undef CREATE_OOL_CLASS
 
+#if V8_ENABLE_WEBASSEMBLY
+class WasmOutOfLineTrap : public OutOfLineCode {
+ public:
+  WasmOutOfLineTrap(CodeGenerator* gen, Instruction* instr)
+      : OutOfLineCode(gen), gen_(gen), instr_(instr) {}
+  void Generate() override {
+    Loong64OperandConverter i(gen_, instr_);
+    TrapId trap_id =
+        static_cast<TrapId>(i.InputInt32(instr_->InputCount() - 1));
+    GenerateCallToTrap(trap_id);
+  }
+
+ protected:
+  CodeGenerator* gen_;
+
+  void GenerateWithTrapId(TrapId trap_id) { GenerateCallToTrap(trap_id); }
+
+ private:
+  void GenerateCallToTrap(TrapId trap_id) {
+    gen_->AssembleSourcePosition(instr_);
+    // A direct call to a wasm runtime stub defined in this module.
+    // Just encode the stub index. This will be patched when the code
+    // is added to the native module and copied into wasm code space.
+    __ Call(static_cast<Address>(trap_id), RelocInfo::WASM_STUB_CALL);
+    ReferenceMap* reference_map = gen_->zone()->New<ReferenceMap>(gen_->zone());
+    gen_->RecordSafepoint(reference_map);
+    __ AssertUnreachable(AbortReason::kUnexpectedReturnFromWasmTrap);
+  }
+
+  Instruction* instr_;
+};
+
+class WasmProtectedInstructionTrap final : public WasmOutOfLineTrap {
+ public:
+  WasmProtectedInstructionTrap(CodeGenerator* gen, int pc, Instruction* instr,
+                               TrapId trap_id)
+      : WasmOutOfLineTrap(gen, instr), pc_(pc), trap_id_(trap_id) {}
+
+  void Generate() override {
+    DCHECK(v8_flags.wasm_bounds_checks && !v8_flags.wasm_enforce_bounds_checks);
+    gen_->AddProtectedInstructionLanding(pc_, __ pc_offset());
+    GenerateWithTrapId(trap_id_);
+  }
+
+ private:
+  int pc_;
+  TrapId trap_id_;
+};
+
+void EmitOOLTrapIfNeeded(Zone* zone, CodeGenerator* codegen,
+                         InstructionCode opcode, Instruction* instr, int pc) {
+  const MemoryAccessMode access_mode = AccessModeField::decode(opcode);
+  if (access_mode == kMemoryAccessProtectedMemOutOfBounds) {
+    zone->New<WasmProtectedInstructionTrap>(codegen, pc, instr,
+                                            TrapId::kTrapMemOutOfBounds);
+  } else if (access_mode == kMemoryAccessProtectedNullDereference) {
+    zone->New<WasmProtectedInstructionTrap>(codegen, pc, instr,
+                                            TrapId::kTrapNullDereference);
+  }
+}
+#else
+void EmitOOLTrapIfNeeded(Zone* zone, CodeGenerator* codegen,
+                         InstructionCode opcode, Instruction* instr, int pc) {
+  DCHECK_EQ(kMemoryAccessDirect, AccessModeField::decode(opcode));
+}
+#endif  // V8_ENABLE_WEBASSEMBLY
+
 Condition FlagsConditionToConditionCmp(FlagsCondition condition) {
   switch (condition) {
     case kEqual:
@@ -318,18 +385,20 @@ FPUCondition FlagsConditionToConditionCmpFPU(bool* predicate,
 
 }  // namespace
 
-#define ASSEMBLE_ATOMIC_LOAD_INTEGER(asm_instr)          \
-  do {                                                   \
-    __ asm_instr(i.OutputRegister(), i.MemoryOperand()); \
-    __ dbar(0);                                          \
+#define ASSEMBLE_ATOMIC_LOAD_INTEGER(asm_instr)                       \
+  do {                                                                \
+    EmitOOLTrapIfNeeded(zone(), this, opcode, instr, __ pc_offset()); \
+    __ asm_instr(i.OutputRegister(), i.MemoryOperand());              \
+    __ dbar(0);                                                       \
   } while (0)
 
 // TODO(LOONG_dev): remove second dbar?
-#define ASSEMBLE_ATOMIC_STORE_INTEGER(asm_instr)               \
-  do {                                                         \
-    __ dbar(0);                                                \
-    __ asm_instr(i.InputOrZeroRegister(2), i.MemoryOperand()); \
-    __ dbar(0);                                                \
+#define ASSEMBLE_ATOMIC_STORE_INTEGER(asm_instr)                      \
+  do {                                                                \
+    __ dbar(0);                                                       \
+    EmitOOLTrapIfNeeded(zone(), this, opcode, instr, __ pc_offset()); \
+    __ asm_instr(i.InputOrZeroRegister(2), i.MemoryOperand());        \
+    __ dbar(0);                                                       \
   } while (0)
 
 // only use for sub_w and sub_d
@@ -339,6 +408,7 @@ FPUCondition FlagsConditionToConditionCmpFPU(bool* predicate,
     __ Add_d(i.TempRegister(0), i.InputRegister(0), i.InputRegister(1));       \
     __ dbar(0);                                                                \
     __ bind(&binop);                                                           \
+    EmitOOLTrapIfNeeded(zone(), this, opcode, instr, __ pc_offset());          \
     __ load_linked(i.OutputRegister(0), MemOperand(i.TempRegister(0), 0));     \
     __ bin_instr(i.TempRegister(1), i.OutputRegister(0),                       \
                  Operand(i.InputRegister(2)));                                 \
@@ -364,6 +434,7 @@ FPUCondition FlagsConditionToConditionCmpFPU(bool* predicate,
     __ slli_w(i.TempRegister(3), i.TempRegister(3), 3);                        \
     __ dbar(0);                                                                \
     __ bind(&binop);                                                           \
+    EmitOOLTrapIfNeeded(zone(), this, opcode, instr, __ pc_offset());          \
     __ load_linked(i.TempRegister(1), MemOperand(i.TempRegister(0), 0));       \
     __ ExtractBits(i.OutputRegister(0), i.TempRegister(1), i.TempRegister(3),  \
                    size, sign_extend);                                         \
@@ -393,6 +464,7 @@ FPUCondition FlagsConditionToConditionCmpFPU(bool* predicate,
     __ slli_w(i.TempRegister(1), i.TempRegister(1), 3);                        \
     __ dbar(0);                                                                \
     __ bind(&exchange);                                                        \
+    EmitOOLTrapIfNeeded(zone(), this, opcode, instr, __ pc_offset());          \
     __ load_linked(i.TempRegister(2), MemOperand(i.TempRegister(0), 0));       \
     __ ExtractBits(i.OutputRegister(0), i.TempRegister(2), i.TempRegister(1),  \
                    size, sign_extend);                                         \
@@ -412,6 +484,7 @@ FPUCondition FlagsConditionToConditionCmpFPU(bool* predicate,
     __ add_d(i.TempRegister(0), i.InputRegister(0), i.InputRegister(1));       \
     __ dbar(0);                                                                \
     __ bind(&compareExchange);                                                 \
+    EmitOOLTrapIfNeeded(zone(), this, opcode, instr, __ pc_offset());          \
     __ load_linked(i.OutputRegister(0), MemOperand(i.TempRegister(0), 0));     \
     __ BranchShort(&exit, ne, i.InputRegister(2),                              \
                    Operand(i.OutputRegister(0)));                              \
@@ -441,6 +514,7 @@ FPUCondition FlagsConditionToConditionCmpFPU(bool* predicate,
     __ slli_w(i.TempRegister(1), i.TempRegister(1), 3);                        \
     __ dbar(0);                                                                \
     __ bind(&compareExchange);                                                 \
+    EmitOOLTrapIfNeeded(zone(), this, opcode, instr, __ pc_offset());          \
     __ load_linked(i.TempRegister(2), MemOperand(i.TempRegister(0), 0));       \
     __ ExtractBits(i.OutputRegister(0), i.TempRegister(2), i.TempRegister(1),  \
                    size, sign_extend);                                         \
@@ -827,8 +901,8 @@ CodeGenerator::CodeGenResult CodeGenerator::AssembleArchInstruction(
         auto ool = zone()->New<OutOfLineRecordWrite>(
             this, object, Operand(i.InputInt64(1)), value, mode,
             DetermineStubCallMode());
+        EmitOOLTrapIfNeeded(zone(), this, opcode, instr, __ pc_offset());
         __ StoreTaggedField(value, MemOperand(object, i.InputInt64(1)));
-
         if (mode > RecordWriteMode::kValueIsPointer) {
           __ JumpIfSmi(value, ool->exit());
         }
@@ -841,6 +915,7 @@ CodeGenerator::CodeGenResult CodeGenerator::AssembleArchInstruction(
         auto ool = zone()->New<OutOfLineRecordWrite>(
             this, object, Operand(i.InputRegister(1)), value, mode,
             DetermineStubCallMode());
+        EmitOOLTrapIfNeeded(zone(), this, opcode, instr, __ pc_offset());
         __ StoreTaggedField(value, MemOperand(object, i.InputRegister(1)));
         if (mode > RecordWriteMode::kValueIsPointer) {
           __ JumpIfSmi(value, ool->exit());
@@ -1518,59 +1593,73 @@ CodeGenerator::CodeGenResult CodeGenerator::AssembleArchInstruction(
       __ ext_w_h(i.OutputRegister(), i.InputRegister(0));
       break;
     case kLoong64Ld_bu:
+      EmitOOLTrapIfNeeded(zone(), this, opcode, instr, __ pc_offset());
       __ Ld_bu(i.OutputRegister(), i.MemoryOperand());
       break;
     case kLoong64Ld_b:
+      EmitOOLTrapIfNeeded(zone(), this, opcode, instr, __ pc_offset());
       __ Ld_b(i.OutputRegister(), i.MemoryOperand());
       break;
     case kLoong64St_b: {
       size_t index = 0;
       MemOperand mem = i.MemoryOperand(&index);
+      EmitOOLTrapIfNeeded(zone(), this, opcode, instr, __ pc_offset());
       __ St_b(i.InputOrZeroRegister(index), mem);
       break;
     }
     case kLoong64Ld_hu:
+      EmitOOLTrapIfNeeded(zone(), this, opcode, instr, __ pc_offset());
       __ Ld_hu(i.OutputRegister(), i.MemoryOperand());
       break;
     case kLoong64Ld_h:
+      EmitOOLTrapIfNeeded(zone(), this, opcode, instr, __ pc_offset());
       __ Ld_h(i.OutputRegister(), i.MemoryOperand());
       break;
     case kLoong64St_h: {
       size_t index = 0;
       MemOperand mem = i.MemoryOperand(&index);
+      EmitOOLTrapIfNeeded(zone(), this, opcode, instr, __ pc_offset());
       __ St_h(i.InputOrZeroRegister(index), mem);
       break;
     }
     case kLoong64Ld_w:
+      EmitOOLTrapIfNeeded(zone(), this, opcode, instr, __ pc_offset());
       __ Ld_w(i.OutputRegister(), i.MemoryOperand());
       break;
     case kLoong64Ld_wu:
+      EmitOOLTrapIfNeeded(zone(), this, opcode, instr, __ pc_offset());
       __ Ld_wu(i.OutputRegister(), i.MemoryOperand());
       break;
     case kLoong64Ld_d:
+      EmitOOLTrapIfNeeded(zone(), this, opcode, instr, __ pc_offset());
       __ Ld_d(i.OutputRegister(), i.MemoryOperand());
       break;
     case kLoong64St_w: {
       size_t index = 0;
       MemOperand mem = i.MemoryOperand(&index);
+      EmitOOLTrapIfNeeded(zone(), this, opcode, instr, __ pc_offset());
       __ St_w(i.InputOrZeroRegister(index), mem);
       break;
     }
     case kLoong64St_d: {
       size_t index = 0;
       MemOperand mem = i.MemoryOperand(&index);
+      EmitOOLTrapIfNeeded(zone(), this, opcode, instr, __ pc_offset());
       __ St_d(i.InputOrZeroRegister(index), mem);
       break;
     }
     case kLoong64LoadDecompressTaggedSigned:
+      EmitOOLTrapIfNeeded(zone(), this, opcode, instr, __ pc_offset());
       __ DecompressTaggedSigned(i.OutputRegister(), i.MemoryOperand());
       break;
     case kLoong64LoadDecompressTagged:
+      EmitOOLTrapIfNeeded(zone(), this, opcode, instr, __ pc_offset());
       __ DecompressTagged(i.OutputRegister(), i.MemoryOperand());
       break;
     case kLoong64StoreCompressTagged: {
       size_t index = 0;
       MemOperand mem = i.MemoryOperand(&index);
+      EmitOOLTrapIfNeeded(zone(), this, opcode, instr, __ pc_offset());
       __ StoreTaggedField(i.InputOrZeroRegister(index), mem);
       break;
     }
@@ -1596,6 +1685,7 @@ CodeGenerator::CodeGenResult CodeGenerator::AssembleArchInstruction(
       break;
     }
     case kLoong64Fld_s: {
+      EmitOOLTrapIfNeeded(zone(), this, opcode, instr, __ pc_offset());
       __ Fld_s(i.OutputSingleRegister(), i.MemoryOperand());
       break;
     }
@@ -1606,11 +1696,12 @@ CodeGenerator::CodeGenResult CodeGenerator::AssembleArchInstruction(
       if (ft == kDoubleRegZero && !__ IsDoubleZeroRegSet()) {
         __ Move(kDoubleRegZero, 0.0);
       }
-
+      EmitOOLTrapIfNeeded(zone(), this, opcode, instr, __ pc_offset());
       __ Fst_s(ft, operand);
       break;
     }
     case kLoong64Fld_d:
+      EmitOOLTrapIfNeeded(zone(), this, opcode, instr, __ pc_offset());
       __ Fld_d(i.OutputDoubleRegister(), i.MemoryOperand());
       break;
     case kLoong64Fst_d: {
@@ -1620,7 +1711,7 @@ CodeGenerator::CodeGenResult CodeGenerator::AssembleArchInstruction(
       if (ft == kDoubleRegZero && !__ IsDoubleZeroRegSet()) {
         __ Move(kDoubleRegZero, 0.0);
       }
-
+      EmitOOLTrapIfNeeded(zone(), this, opcode, instr, __ pc_offset());
       __ Fst_d(ft, operand);
       break;
     }
@@ -1746,6 +1837,7 @@ CodeGenerator::CodeGenResult CodeGenerator::AssembleArchInstruction(
       switch (AtomicWidthField::decode(opcode)) {
         case AtomicWidth::kWord32:
           __ add_d(i.TempRegister(0), i.InputRegister(0), i.InputRegister(1));
+          EmitOOLTrapIfNeeded(zone(), this, opcode, instr, __ pc_offset());
           __ amswap_db_w(i.OutputRegister(0), i.InputRegister(2),
                          i.TempRegister(0));
           break;
@@ -1756,6 +1848,7 @@ CodeGenerator::CodeGenResult CodeGenerator::AssembleArchInstruction(
       break;
     case kLoong64Word64AtomicExchangeUint64:
       __ add_d(i.TempRegister(0), i.InputRegister(0), i.InputRegister(1));
+      EmitOOLTrapIfNeeded(zone(), this, opcode, instr, __ pc_offset());
       __ amswap_db_d(i.OutputRegister(0), i.InputRegister(2),
                      i.TempRegister(0));
       break;
@@ -1810,6 +1903,7 @@ CodeGenerator::CodeGenResult CodeGenerator::AssembleArchInstruction(
       switch (AtomicWidthField::decode(opcode)) {
         case AtomicWidth::kWord32:
           __ Add_d(i.TempRegister(0), i.InputRegister(0), i.InputRegister(1));
+          EmitOOLTrapIfNeeded(zone(), this, opcode, instr, __ pc_offset());
           __ amadd_db_w(i.OutputRegister(0), i.InputRegister(2),
                         i.TempRegister(0));
           break;
@@ -1832,6 +1926,7 @@ CodeGenerator::CodeGenResult CodeGenerator::AssembleArchInstruction(
       switch (AtomicWidthField::decode(opcode)) {
         case AtomicWidth::kWord32:
           __ Add_d(i.TempRegister(0), i.InputRegister(0), i.InputRegister(1));
+          EmitOOLTrapIfNeeded(zone(), this, opcode, instr, __ pc_offset());
           __ amand_db_w(i.OutputRegister(0), i.InputRegister(2),
                         i.TempRegister(0));
           break;
@@ -1844,6 +1939,7 @@ CodeGenerator::CodeGenResult CodeGenerator::AssembleArchInstruction(
       switch (AtomicWidthField::decode(opcode)) {
         case AtomicWidth::kWord32:
           __ Add_d(i.TempRegister(0), i.InputRegister(0), i.InputRegister(1));
+          EmitOOLTrapIfNeeded(zone(), this, opcode, instr, __ pc_offset());
           __ amor_db_w(i.OutputRegister(0), i.InputRegister(2),
                        i.TempRegister(0));
           break;
@@ -1856,6 +1952,7 @@ CodeGenerator::CodeGenResult CodeGenerator::AssembleArchInstruction(
       switch (AtomicWidthField::decode(opcode)) {
         case AtomicWidth::kWord32:
           __ Add_d(i.TempRegister(0), i.InputRegister(0), i.InputRegister(1));
+          EmitOOLTrapIfNeeded(zone(), this, opcode, instr, __ pc_offset());
           __ amxor_db_w(i.OutputRegister(0), i.InputRegister(2),
                         i.TempRegister(0));
           break;
@@ -1902,6 +1999,7 @@ CodeGenerator::CodeGenResult CodeGenerator::AssembleArchInstruction(
 
     case kLoong64Word64AtomicAddUint64:
       __ Add_d(i.TempRegister(0), i.InputRegister(0), i.InputRegister(1));
+      EmitOOLTrapIfNeeded(zone(), this, opcode, instr, __ pc_offset());
       __ amadd_db_d(i.OutputRegister(0), i.InputRegister(2), i.TempRegister(0));
       break;
     case kLoong64Word64AtomicSubUint64:
@@ -1909,14 +2007,17 @@ CodeGenerator::CodeGenResult CodeGenerator::AssembleArchInstruction(
       break;
     case kLoong64Word64AtomicAndUint64:
       __ Add_d(i.TempRegister(0), i.InputRegister(0), i.InputRegister(1));
+      EmitOOLTrapIfNeeded(zone(), this, opcode, instr, __ pc_offset());
       __ amand_db_d(i.OutputRegister(0), i.InputRegister(2), i.TempRegister(0));
       break;
     case kLoong64Word64AtomicOrUint64:
       __ Add_d(i.TempRegister(0), i.InputRegister(0), i.InputRegister(1));
+      EmitOOLTrapIfNeeded(zone(), this, opcode, instr, __ pc_offset());
       __ amor_db_d(i.OutputRegister(0), i.InputRegister(2), i.TempRegister(0));
       break;
     case kLoong64Word64AtomicXorUint64:
       __ Add_d(i.TempRegister(0), i.InputRegister(0), i.InputRegister(1));
+      EmitOOLTrapIfNeeded(zone(), this, opcode, instr, __ pc_offset());
       __ amxor_db_d(i.OutputRegister(0), i.InputRegister(2), i.TempRegister(0));
       break;
 #undef ATOMIC_BINOP_CASE
@@ -2078,35 +2179,7 @@ void CodeGenerator::AssembleArchJumpRegardlessOfAssemblyOrder(
 #if V8_ENABLE_WEBASSEMBLY
 void CodeGenerator::AssembleArchTrap(Instruction* instr,
                                      FlagsCondition condition) {
-  class OutOfLineTrap final : public OutOfLineCode {
-   public:
-    OutOfLineTrap(CodeGenerator* gen, Instruction* instr)
-        : OutOfLineCode(gen), instr_(instr), gen_(gen) {}
-    void Generate() final {
-      Loong64OperandConverter i(gen_, instr_);
-      TrapId trap_id =
-          static_cast<TrapId>(i.InputInt32(instr_->InputCount() - 1));
-      GenerateCallToTrap(trap_id);
-    }
-
-   private:
-    void GenerateCallToTrap(TrapId trap_id) {
-      gen_->AssembleSourcePosition(instr_);
-      // A direct call to a wasm runtime stub defined in this module.
-      // Just encode the stub index. This will be patched when the code
-      // is added to the native module and copied into wasm code space.
-      __ Call(static_cast<Address>(trap_id), RelocInfo::WASM_STUB_CALL);
-      ReferenceMap* reference_map =
-          gen_->zone()->New<ReferenceMap>(gen_->zone());
-      gen_->RecordSafepoint(reference_map);
-      if (v8_flags.debug_code) {
-        __ stop();
-      }
-    }
-    Instruction* instr_;
-    CodeGenerator* gen_;
-  };
-  auto ool = zone()->New<OutOfLineTrap>(this, instr);
+  auto ool = zone()->New<WasmOutOfLineTrap>(this, instr);
   Label* tlabel = ool->entry();
   AssembleBranchToLabels(this, masm(), instr, condition, tlabel, nullptr, true);
 }
diff --git a/src/compiler/backend/loong64/instruction-codes-loong64.h b/src/compiler/backend/loong64/instruction-codes-loong64.h
index 0b812c9b16e..3b3d7ef2dbb 100644
--- a/src/compiler/backend/loong64/instruction-codes-loong64.h
+++ b/src/compiler/backend/loong64/instruction-codes-loong64.h
@@ -12,382 +12,386 @@ namespace compiler {
 // LOONG64-specific opcodes that specify which assembly sequence to emit.
 // Most opcodes specify a single instruction.
 
-#define TARGET_ARCH_OPCODE_LIST(V)           \
-  V(Loong64Add_d)                            \
-  V(Loong64Add_w)                            \
-  V(Loong64AddOvf_d)                         \
-  V(Loong64Sub_d)                            \
-  V(Loong64Sub_w)                            \
-  V(Loong64SubOvf_d)                         \
-  V(Loong64Mul_d)                            \
-  V(Loong64MulOvf_w)                         \
-  V(Loong64MulOvf_d)                         \
-  V(Loong64Mulh_d)                           \
-  V(Loong64Mulh_w)                           \
-  V(Loong64Mulh_du)                          \
-  V(Loong64Mulh_wu)                          \
-  V(Loong64Mul_w)                            \
-  V(Loong64Div_d)                            \
-  V(Loong64Div_w)                            \
-  V(Loong64Div_du)                           \
-  V(Loong64Div_wu)                           \
-  V(Loong64Mod_d)                            \
-  V(Loong64Mod_w)                            \
-  V(Loong64Mod_du)                           \
-  V(Loong64Mod_wu)                           \
-  V(Loong64And)                              \
-  V(Loong64And32)                            \
-  V(Loong64Or)                               \
-  V(Loong64Or32)                             \
-  V(Loong64Nor)                              \
-  V(Loong64Nor32)                            \
-  V(Loong64Xor)                              \
-  V(Loong64Xor32)                            \
-  V(Loong64Alsl_d)                           \
-  V(Loong64Alsl_w)                           \
-  V(Loong64Sll_d)                            \
-  V(Loong64Sll_w)                            \
-  V(Loong64Srl_d)                            \
-  V(Loong64Srl_w)                            \
-  V(Loong64Sra_d)                            \
-  V(Loong64Sra_w)                            \
-  V(Loong64Rotr_d)                           \
-  V(Loong64Rotr_w)                           \
-  V(Loong64Bstrpick_d)                       \
-  V(Loong64Bstrpick_w)                       \
-  V(Loong64Bstrins_d)                        \
-  V(Loong64Bstrins_w)                        \
-  V(Loong64ByteSwap64)                       \
-  V(Loong64ByteSwap32)                       \
-  V(Loong64Clz_d)                            \
-  V(Loong64Clz_w)                            \
-  V(Loong64Mov)                              \
-  V(Loong64Tst)                              \
-  V(Loong64Cmp32)                            \
-  V(Loong64Cmp64)                            \
-  V(Loong64Float32Cmp)                       \
-  V(Loong64Float32Add)                       \
-  V(Loong64Float32Sub)                       \
-  V(Loong64Float32Mul)                       \
-  V(Loong64Float32Div)                       \
-  V(Loong64Float32Abs)                       \
-  V(Loong64Float32Neg)                       \
-  V(Loong64Float32Sqrt)                      \
-  V(Loong64Float32Max)                       \
-  V(Loong64Float32Min)                       \
-  V(Loong64Float32ToFloat64)                 \
-  V(Loong64Float32RoundDown)                 \
-  V(Loong64Float32RoundUp)                   \
-  V(Loong64Float32RoundTruncate)             \
-  V(Loong64Float32RoundTiesEven)             \
-  V(Loong64Float32ToInt32)                   \
-  V(Loong64Float32ToInt64)                   \
-  V(Loong64Float32ToUint32)                  \
-  V(Loong64Float32ToUint64)                  \
-  V(Loong64Float64Cmp)                       \
-  V(Loong64Float64Add)                       \
-  V(Loong64Float64Sub)                       \
-  V(Loong64Float64Mul)                       \
-  V(Loong64Float64Div)                       \
-  V(Loong64Float64Mod)                       \
-  V(Loong64Float64Abs)                       \
-  V(Loong64Float64Neg)                       \
-  V(Loong64Float64Sqrt)                      \
-  V(Loong64Float64Max)                       \
-  V(Loong64Float64Min)                       \
-  V(Loong64Float64ToFloat32)                 \
-  V(Loong64Float64RoundDown)                 \
-  V(Loong64Float64RoundUp)                   \
-  V(Loong64Float64RoundTruncate)             \
-  V(Loong64Float64RoundTiesEven)             \
-  V(Loong64Float64ToInt32)                   \
-  V(Loong64Float64ToInt64)                   \
-  V(Loong64Float64ToUint32)                  \
-  V(Loong64Float64ToUint64)                  \
-  V(Loong64Int32ToFloat32)                   \
-  V(Loong64Int32ToFloat64)                   \
-  V(Loong64Int64ToFloat32)                   \
-  V(Loong64Int64ToFloat64)                   \
-  V(Loong64Uint32ToFloat32)                  \
-  V(Loong64Uint32ToFloat64)                  \
-  V(Loong64Uint64ToFloat32)                  \
-  V(Loong64Uint64ToFloat64)                  \
-  V(Loong64Float64ExtractLowWord32)          \
-  V(Loong64Float64ExtractHighWord32)         \
-  V(Loong64Float64InsertLowWord32)           \
-  V(Loong64Float64InsertHighWord32)          \
-  V(Loong64BitcastDL)                        \
-  V(Loong64BitcastLD)                        \
-  V(Loong64Float64SilenceNaN)                \
-  V(Loong64Ld_b)                             \
-  V(Loong64Ld_bu)                            \
-  V(Loong64St_b)                             \
-  V(Loong64Ld_h)                             \
-  V(Loong64Ld_hu)                            \
-  V(Loong64St_h)                             \
-  V(Loong64Ld_w)                             \
-  V(Loong64Ld_wu)                            \
-  V(Loong64St_w)                             \
-  V(Loong64Ld_d)                             \
-  V(Loong64St_d)                             \
-  V(Loong64LoadDecompressTaggedSigned)       \
-  V(Loong64LoadDecompressTagged)             \
-  V(Loong64StoreCompressTagged)              \
-  V(Loong64LoadDecodeSandboxedPointer)       \
-  V(Loong64StoreEncodeSandboxedPointer)      \
-  V(Loong64Fld_s)                            \
-  V(Loong64Fst_s)                            \
-  V(Loong64Fld_d)                            \
-  V(Loong64Fst_d)                            \
-  V(Loong64Push)                             \
-  V(Loong64Peek)                             \
-  V(Loong64Poke)                             \
-  V(Loong64StackClaim)                       \
-  V(Loong64Ext_w_b)                          \
-  V(Loong64Ext_w_h)                          \
-  V(Loong64Dbar)                             \
-  V(Loong64S128Const)                        \
-  V(Loong64S128Zero)                         \
-  V(Loong64S128AllOnes)                      \
-  V(Loong64I32x4Splat)                       \
-  V(Loong64I32x4ExtractLane)                 \
-  V(Loong64I32x4ReplaceLane)                 \
-  V(Loong64I32x4Add)                         \
-  V(Loong64I32x4Sub)                         \
-  V(Loong64F64x2Abs)                         \
-  V(Loong64F64x2Neg)                         \
-  V(Loong64F32x4Splat)                       \
-  V(Loong64F32x4ExtractLane)                 \
-  V(Loong64F32x4ReplaceLane)                 \
-  V(Loong64F32x4SConvertI32x4)               \
-  V(Loong64F32x4UConvertI32x4)               \
-  V(Loong64I32x4Mul)                         \
-  V(Loong64I32x4MaxS)                        \
-  V(Loong64I32x4MinS)                        \
-  V(Loong64I32x4Eq)                          \
-  V(Loong64I32x4Ne)                          \
-  V(Loong64I32x4Shl)                         \
-  V(Loong64I32x4ShrS)                        \
-  V(Loong64I32x4ShrU)                        \
-  V(Loong64I32x4MaxU)                        \
-  V(Loong64I32x4MinU)                        \
-  V(Loong64F64x2Sqrt)                        \
-  V(Loong64F64x2Add)                         \
-  V(Loong64F64x2Sub)                         \
-  V(Loong64F64x2Mul)                         \
-  V(Loong64F64x2Div)                         \
-  V(Loong64F64x2Min)                         \
-  V(Loong64F64x2Max)                         \
-  V(Loong64F64x2Eq)                          \
-  V(Loong64F64x2Ne)                          \
-  V(Loong64F64x2Lt)                          \
-  V(Loong64F64x2Le)                          \
-  V(Loong64F64x2Splat)                       \
-  V(Loong64F64x2ExtractLane)                 \
-  V(Loong64F64x2ReplaceLane)                 \
-  V(Loong64F64x2Pmin)                        \
-  V(Loong64F64x2Pmax)                        \
-  V(Loong64F64x2Ceil)                        \
-  V(Loong64F64x2Floor)                       \
-  V(Loong64F64x2Trunc)                       \
-  V(Loong64F64x2NearestInt)                  \
-  V(Loong64F64x2ConvertLowI32x4S)            \
-  V(Loong64F64x2ConvertLowI32x4U)            \
-  V(Loong64F64x2PromoteLowF32x4)             \
-  V(Loong64F64x2RelaxedMin)                  \
-  V(Loong64F64x2RelaxedMax)                  \
-  V(Loong64I64x2Splat)                       \
-  V(Loong64I64x2ExtractLane)                 \
-  V(Loong64I64x2ReplaceLane)                 \
-  V(Loong64I64x2Add)                         \
-  V(Loong64I64x2Sub)                         \
-  V(Loong64I64x2Mul)                         \
-  V(Loong64I64x2Neg)                         \
-  V(Loong64I64x2Shl)                         \
-  V(Loong64I64x2ShrS)                        \
-  V(Loong64I64x2ShrU)                        \
-  V(Loong64I64x2BitMask)                     \
-  V(Loong64I64x2Eq)                          \
-  V(Loong64I64x2Ne)                          \
-  V(Loong64I64x2GtS)                         \
-  V(Loong64I64x2GeS)                         \
-  V(Loong64I64x2Abs)                         \
-  V(Loong64I64x2SConvertI32x4Low)            \
-  V(Loong64I64x2SConvertI32x4High)           \
-  V(Loong64I64x2UConvertI32x4Low)            \
-  V(Loong64I64x2UConvertI32x4High)           \
-  V(Loong64ExtMulLow)                        \
-  V(Loong64ExtMulHigh)                       \
-  V(Loong64ExtAddPairwise)                   \
-  V(Loong64F32x4Abs)                         \
-  V(Loong64F32x4Neg)                         \
-  V(Loong64F32x4Sqrt)                        \
-  V(Loong64F32x4Add)                         \
-  V(Loong64F32x4Sub)                         \
-  V(Loong64F32x4Mul)                         \
-  V(Loong64F32x4Div)                         \
-  V(Loong64F32x4Max)                         \
-  V(Loong64F32x4Min)                         \
-  V(Loong64F32x4Eq)                          \
-  V(Loong64F32x4Ne)                          \
-  V(Loong64F32x4Lt)                          \
-  V(Loong64F32x4Le)                          \
-  V(Loong64F32x4Pmin)                        \
-  V(Loong64F32x4Pmax)                        \
-  V(Loong64F32x4Ceil)                        \
-  V(Loong64F32x4Floor)                       \
-  V(Loong64F32x4Trunc)                       \
-  V(Loong64F32x4NearestInt)                  \
-  V(Loong64F32x4DemoteF64x2Zero)             \
-  V(Loong64F32x4RelaxedMin)                  \
-  V(Loong64F32x4RelaxedMax)                  \
-  V(Loong64I32x4SConvertF32x4)               \
-  V(Loong64I32x4UConvertF32x4)               \
-  V(Loong64I32x4Neg)                         \
-  V(Loong64I32x4GtS)                         \
-  V(Loong64I32x4GeS)                         \
-  V(Loong64I32x4GtU)                         \
-  V(Loong64I32x4GeU)                         \
-  V(Loong64I32x4Abs)                         \
-  V(Loong64I32x4BitMask)                     \
-  V(Loong64I32x4DotI16x8S)                   \
-  V(Loong64I32x4TruncSatF64x2SZero)          \
-  V(Loong64I32x4TruncSatF64x2UZero)          \
-  V(Loong64I32x4RelaxedTruncF32x4S)          \
-  V(Loong64I32x4RelaxedTruncF32x4U)          \
-  V(Loong64I32x4RelaxedTruncF64x2SZero)      \
-  V(Loong64I32x4RelaxedTruncF64x2UZero)      \
-  V(Loong64I16x8Splat)                       \
-  V(Loong64I16x8ExtractLaneU)                \
-  V(Loong64I16x8ExtractLaneS)                \
-  V(Loong64I16x8ReplaceLane)                 \
-  V(Loong64I16x8Neg)                         \
-  V(Loong64I16x8Shl)                         \
-  V(Loong64I16x8ShrS)                        \
-  V(Loong64I16x8ShrU)                        \
-  V(Loong64I16x8Add)                         \
-  V(Loong64I16x8AddSatS)                     \
-  V(Loong64I16x8Sub)                         \
-  V(Loong64I16x8SubSatS)                     \
-  V(Loong64I16x8Mul)                         \
-  V(Loong64I16x8MaxS)                        \
-  V(Loong64I16x8MinS)                        \
-  V(Loong64I16x8Eq)                          \
-  V(Loong64I16x8Ne)                          \
-  V(Loong64I16x8GtS)                         \
-  V(Loong64I16x8GeS)                         \
-  V(Loong64I16x8AddSatU)                     \
-  V(Loong64I16x8SubSatU)                     \
-  V(Loong64I16x8MaxU)                        \
-  V(Loong64I16x8MinU)                        \
-  V(Loong64I16x8GtU)                         \
-  V(Loong64I16x8GeU)                         \
-  V(Loong64I16x8RoundingAverageU)            \
-  V(Loong64I16x8Abs)                         \
-  V(Loong64I16x8BitMask)                     \
-  V(Loong64I16x8Q15MulRSatS)                 \
-  V(Loong64I16x8RelaxedQ15MulRS)             \
-  V(Loong64I8x16Splat)                       \
-  V(Loong64I8x16ExtractLaneU)                \
-  V(Loong64I8x16ExtractLaneS)                \
-  V(Loong64I8x16ReplaceLane)                 \
-  V(Loong64I8x16Neg)                         \
-  V(Loong64I8x16Shl)                         \
-  V(Loong64I8x16ShrS)                        \
-  V(Loong64I8x16Add)                         \
-  V(Loong64I8x16AddSatS)                     \
-  V(Loong64I8x16Sub)                         \
-  V(Loong64I8x16SubSatS)                     \
-  V(Loong64I8x16MaxS)                        \
-  V(Loong64I8x16MinS)                        \
-  V(Loong64I8x16Eq)                          \
-  V(Loong64I8x16Ne)                          \
-  V(Loong64I8x16GtS)                         \
-  V(Loong64I8x16GeS)                         \
-  V(Loong64I8x16ShrU)                        \
-  V(Loong64I8x16AddSatU)                     \
-  V(Loong64I8x16SubSatU)                     \
-  V(Loong64I8x16MaxU)                        \
-  V(Loong64I8x16MinU)                        \
-  V(Loong64I8x16GtU)                         \
-  V(Loong64I8x16GeU)                         \
-  V(Loong64I8x16RoundingAverageU)            \
-  V(Loong64I8x16Abs)                         \
-  V(Loong64I8x16Popcnt)                      \
-  V(Loong64I8x16BitMask)                     \
-  V(Loong64S128And)                          \
-  V(Loong64S128Or)                           \
-  V(Loong64S128Xor)                          \
-  V(Loong64S128Not)                          \
-  V(Loong64S128Select)                       \
-  V(Loong64S128AndNot)                       \
-  V(Loong64I64x2AllTrue)                     \
-  V(Loong64I32x4AllTrue)                     \
-  V(Loong64I16x8AllTrue)                     \
-  V(Loong64I8x16AllTrue)                     \
-  V(Loong64V128AnyTrue)                      \
-  V(Loong64S32x4InterleaveRight)             \
-  V(Loong64S32x4InterleaveLeft)              \
-  V(Loong64S32x4PackEven)                    \
-  V(Loong64S32x4PackOdd)                     \
-  V(Loong64S32x4InterleaveEven)              \
-  V(Loong64S32x4InterleaveOdd)               \
-  V(Loong64S32x4Shuffle)                     \
-  V(Loong64S16x8InterleaveRight)             \
-  V(Loong64S16x8InterleaveLeft)              \
-  V(Loong64S16x8PackEven)                    \
-  V(Loong64S16x8PackOdd)                     \
-  V(Loong64S16x8InterleaveEven)              \
-  V(Loong64S16x8InterleaveOdd)               \
-  V(Loong64S16x4Reverse)                     \
-  V(Loong64S16x2Reverse)                     \
-  V(Loong64S8x16InterleaveRight)             \
-  V(Loong64S8x16InterleaveLeft)              \
-  V(Loong64S8x16PackEven)                    \
-  V(Loong64S8x16PackOdd)                     \
-  V(Loong64S8x16InterleaveEven)              \
-  V(Loong64S8x16InterleaveOdd)               \
-  V(Loong64I8x16Shuffle)                     \
-  V(Loong64I8x16Swizzle)                     \
-  V(Loong64S8x16Concat)                      \
-  V(Loong64S8x8Reverse)                      \
-  V(Loong64S8x4Reverse)                      \
-  V(Loong64S8x2Reverse)                      \
-  V(Loong64S128LoadSplat)                    \
-  V(Loong64S128Load8x8S)                     \
-  V(Loong64S128Load8x8U)                     \
-  V(Loong64S128Load16x4S)                    \
-  V(Loong64S128Load16x4U)                    \
-  V(Loong64S128Load32x2S)                    \
-  V(Loong64S128Load32x2U)                    \
-  V(Loong64S128Load32Zero)                   \
-  V(Loong64S128Load64Zero)                   \
-  V(Loong64LoadLane)                         \
-  V(Loong64StoreLane)                        \
-  V(Loong64I32x4SConvertI16x8Low)            \
-  V(Loong64I32x4SConvertI16x8High)           \
-  V(Loong64I32x4UConvertI16x8Low)            \
-  V(Loong64I32x4UConvertI16x8High)           \
-  V(Loong64I16x8SConvertI8x16Low)            \
-  V(Loong64I16x8SConvertI8x16High)           \
-  V(Loong64I16x8SConvertI32x4)               \
-  V(Loong64I16x8UConvertI32x4)               \
-  V(Loong64I16x8UConvertI8x16Low)            \
-  V(Loong64I16x8UConvertI8x16High)           \
-  V(Loong64I8x16SConvertI16x8)               \
-  V(Loong64I8x16UConvertI16x8)               \
-  V(Loong64Word64AtomicLoadUint32)           \
-  V(Loong64Word64AtomicLoadUint64)           \
-  V(Loong64Word64AtomicStoreWord64)          \
-  V(Loong64AtomicLoadDecompressTaggedSigned) \
-  V(Loong64AtomicLoadDecompressTagged)       \
-  V(Loong64AtomicStoreCompressTagged)        \
-  V(Loong64Word64AtomicAddUint64)            \
-  V(Loong64Word64AtomicSubUint64)            \
-  V(Loong64Word64AtomicAndUint64)            \
-  V(Loong64Word64AtomicOrUint64)             \
-  V(Loong64Word64AtomicXorUint64)            \
-  V(Loong64Word64AtomicExchangeUint64)       \
+// Opcodes that support a MemoryAccessMode.
+#define TARGET_ARCH_OPCODE_WITH_MEMORY_ACCESS_MODE_LIST(V) \
+  V(Loong64Ld_b)                                           \
+  V(Loong64Ld_bu)                                          \
+  V(Loong64St_b)                                           \
+  V(Loong64Ld_h)                                           \
+  V(Loong64Ld_hu)                                          \
+  V(Loong64St_h)                                           \
+  V(Loong64Ld_w)                                           \
+  V(Loong64Ld_wu)                                          \
+  V(Loong64St_w)                                           \
+  V(Loong64Ld_d)                                           \
+  V(Loong64St_d)                                           \
+  V(Loong64LoadDecompressTaggedSigned)                     \
+  V(Loong64LoadDecompressTagged)                           \
+  V(Loong64StoreCompressTagged)                            \
+  V(Loong64Fld_s)                                          \
+  V(Loong64Fst_s)                                          \
+  V(Loong64Fld_d)                                          \
+  V(Loong64Fst_d)                                          \
+  V(Loong64LoadLane)                                       \
+  V(Loong64StoreLane)                                      \
+  V(Loong64S128LoadSplat)                                  \
+  V(Loong64S128Load8x8S)                                   \
+  V(Loong64S128Load8x8U)                                   \
+  V(Loong64S128Load16x4S)                                  \
+  V(Loong64S128Load16x4U)                                  \
+  V(Loong64S128Load32x2S)                                  \
+  V(Loong64S128Load32x2U)                                  \
+  V(Loong64Word64AtomicLoadUint32)                         \
+  V(Loong64Word64AtomicLoadUint64)                         \
+  V(Loong64Word64AtomicStoreWord64)
+
+#define TARGET_ARCH_OPCODE_LIST(V)                   \
+  TARGET_ARCH_OPCODE_WITH_MEMORY_ACCESS_MODE_LIST(V) \
+  V(Loong64Add_d)                                    \
+  V(Loong64Add_w)                                    \
+  V(Loong64AddOvf_d)                                 \
+  V(Loong64Sub_d)                                    \
+  V(Loong64Sub_w)                                    \
+  V(Loong64SubOvf_d)                                 \
+  V(Loong64Mul_d)                                    \
+  V(Loong64MulOvf_w)                                 \
+  V(Loong64MulOvf_d)                                 \
+  V(Loong64Mulh_d)                                   \
+  V(Loong64Mulh_w)                                   \
+  V(Loong64Mulh_du)                                  \
+  V(Loong64Mulh_wu)                                  \
+  V(Loong64Mul_w)                                    \
+  V(Loong64Div_d)                                    \
+  V(Loong64Div_w)                                    \
+  V(Loong64Div_du)                                   \
+  V(Loong64Div_wu)                                   \
+  V(Loong64Mod_d)                                    \
+  V(Loong64Mod_w)                                    \
+  V(Loong64Mod_du)                                   \
+  V(Loong64Mod_wu)                                   \
+  V(Loong64And)                                      \
+  V(Loong64And32)                                    \
+  V(Loong64Or)                                       \
+  V(Loong64Or32)                                     \
+  V(Loong64Nor)                                      \
+  V(Loong64Nor32)                                    \
+  V(Loong64Xor)                                      \
+  V(Loong64Xor32)                                    \
+  V(Loong64Alsl_d)                                   \
+  V(Loong64Alsl_w)                                   \
+  V(Loong64Sll_d)                                    \
+  V(Loong64Sll_w)                                    \
+  V(Loong64Srl_d)                                    \
+  V(Loong64Srl_w)                                    \
+  V(Loong64Sra_d)                                    \
+  V(Loong64Sra_w)                                    \
+  V(Loong64Rotr_d)                                   \
+  V(Loong64Rotr_w)                                   \
+  V(Loong64Bstrpick_d)                               \
+  V(Loong64Bstrpick_w)                               \
+  V(Loong64Bstrins_d)                                \
+  V(Loong64Bstrins_w)                                \
+  V(Loong64ByteSwap64)                               \
+  V(Loong64ByteSwap32)                               \
+  V(Loong64Clz_d)                                    \
+  V(Loong64Clz_w)                                    \
+  V(Loong64Mov)                                      \
+  V(Loong64Tst)                                      \
+  V(Loong64Cmp32)                                    \
+  V(Loong64Cmp64)                                    \
+  V(Loong64Float32Cmp)                               \
+  V(Loong64Float32Add)                               \
+  V(Loong64Float32Sub)                               \
+  V(Loong64Float32Mul)                               \
+  V(Loong64Float32Div)                               \
+  V(Loong64Float32Abs)                               \
+  V(Loong64Float32Neg)                               \
+  V(Loong64Float32Sqrt)                              \
+  V(Loong64Float32Max)                               \
+  V(Loong64Float32Min)                               \
+  V(Loong64Float32ToFloat64)                         \
+  V(Loong64Float32RoundDown)                         \
+  V(Loong64Float32RoundUp)                           \
+  V(Loong64Float32RoundTruncate)                     \
+  V(Loong64Float32RoundTiesEven)                     \
+  V(Loong64Float32ToInt32)                           \
+  V(Loong64Float32ToInt64)                           \
+  V(Loong64Float32ToUint32)                          \
+  V(Loong64Float32ToUint64)                          \
+  V(Loong64Float64Cmp)                               \
+  V(Loong64Float64Add)                               \
+  V(Loong64Float64Sub)                               \
+  V(Loong64Float64Mul)                               \
+  V(Loong64Float64Div)                               \
+  V(Loong64Float64Mod)                               \
+  V(Loong64Float64Abs)                               \
+  V(Loong64Float64Neg)                               \
+  V(Loong64Float64Sqrt)                              \
+  V(Loong64Float64Max)                               \
+  V(Loong64Float64Min)                               \
+  V(Loong64Float64ToFloat32)                         \
+  V(Loong64Float64RoundDown)                         \
+  V(Loong64Float64RoundUp)                           \
+  V(Loong64Float64RoundTruncate)                     \
+  V(Loong64Float64RoundTiesEven)                     \
+  V(Loong64Float64ToInt32)                           \
+  V(Loong64Float64ToInt64)                           \
+  V(Loong64Float64ToUint32)                          \
+  V(Loong64Float64ToUint64)                          \
+  V(Loong64Int32ToFloat32)                           \
+  V(Loong64Int32ToFloat64)                           \
+  V(Loong64Int64ToFloat32)                           \
+  V(Loong64Int64ToFloat64)                           \
+  V(Loong64Uint32ToFloat32)                          \
+  V(Loong64Uint32ToFloat64)                          \
+  V(Loong64Uint64ToFloat32)                          \
+  V(Loong64Uint64ToFloat64)                          \
+  V(Loong64Float64ExtractLowWord32)                  \
+  V(Loong64Float64ExtractHighWord32)                 \
+  V(Loong64Float64InsertLowWord32)                   \
+  V(Loong64Float64InsertHighWord32)                  \
+  V(Loong64BitcastDL)                                \
+  V(Loong64BitcastLD)                                \
+  V(Loong64Float64SilenceNaN)                        \
+  V(Loong64LoadDecodeSandboxedPointer)               \
+  V(Loong64StoreEncodeSandboxedPointer)              \
+  V(Loong64Push)                                     \
+  V(Loong64Peek)                                     \
+  V(Loong64Poke)                                     \
+  V(Loong64StackClaim)                               \
+  V(Loong64Ext_w_b)                                  \
+  V(Loong64Ext_w_h)                                  \
+  V(Loong64Dbar)                                     \
+  V(Loong64S128Const)                                \
+  V(Loong64S128Zero)                                 \
+  V(Loong64S128AllOnes)                              \
+  V(Loong64I32x4Splat)                               \
+  V(Loong64I32x4ExtractLane)                         \
+  V(Loong64I32x4ReplaceLane)                         \
+  V(Loong64I32x4Add)                                 \
+  V(Loong64I32x4Sub)                                 \
+  V(Loong64F64x2Abs)                                 \
+  V(Loong64F64x2Neg)                                 \
+  V(Loong64F32x4Splat)                               \
+  V(Loong64F32x4ExtractLane)                         \
+  V(Loong64F32x4ReplaceLane)                         \
+  V(Loong64F32x4SConvertI32x4)                       \
+  V(Loong64F32x4UConvertI32x4)                       \
+  V(Loong64I32x4Mul)                                 \
+  V(Loong64I32x4MaxS)                                \
+  V(Loong64I32x4MinS)                                \
+  V(Loong64I32x4Eq)                                  \
+  V(Loong64I32x4Ne)                                  \
+  V(Loong64I32x4Shl)                                 \
+  V(Loong64I32x4ShrS)                                \
+  V(Loong64I32x4ShrU)                                \
+  V(Loong64I32x4MaxU)                                \
+  V(Loong64I32x4MinU)                                \
+  V(Loong64F64x2Sqrt)                                \
+  V(Loong64F64x2Add)                                 \
+  V(Loong64F64x2Sub)                                 \
+  V(Loong64F64x2Mul)                                 \
+  V(Loong64F64x2Div)                                 \
+  V(Loong64F64x2Min)                                 \
+  V(Loong64F64x2Max)                                 \
+  V(Loong64F64x2Eq)                                  \
+  V(Loong64F64x2Ne)                                  \
+  V(Loong64F64x2Lt)                                  \
+  V(Loong64F64x2Le)                                  \
+  V(Loong64F64x2Splat)                               \
+  V(Loong64F64x2ExtractLane)                         \
+  V(Loong64F64x2ReplaceLane)                         \
+  V(Loong64F64x2Pmin)                                \
+  V(Loong64F64x2Pmax)                                \
+  V(Loong64F64x2Ceil)                                \
+  V(Loong64F64x2Floor)                               \
+  V(Loong64F64x2Trunc)                               \
+  V(Loong64F64x2NearestInt)                          \
+  V(Loong64F64x2ConvertLowI32x4S)                    \
+  V(Loong64F64x2ConvertLowI32x4U)                    \
+  V(Loong64F64x2PromoteLowF32x4)                     \
+  V(Loong64F64x2RelaxedMin)                          \
+  V(Loong64F64x2RelaxedMax)                          \
+  V(Loong64I64x2Splat)                               \
+  V(Loong64I64x2ExtractLane)                         \
+  V(Loong64I64x2ReplaceLane)                         \
+  V(Loong64I64x2Add)                                 \
+  V(Loong64I64x2Sub)                                 \
+  V(Loong64I64x2Mul)                                 \
+  V(Loong64I64x2Neg)                                 \
+  V(Loong64I64x2Shl)                                 \
+  V(Loong64I64x2ShrS)                                \
+  V(Loong64I64x2ShrU)                                \
+  V(Loong64I64x2BitMask)                             \
+  V(Loong64I64x2Eq)                                  \
+  V(Loong64I64x2Ne)                                  \
+  V(Loong64I64x2GtS)                                 \
+  V(Loong64I64x2GeS)                                 \
+  V(Loong64I64x2Abs)                                 \
+  V(Loong64I64x2SConvertI32x4Low)                    \
+  V(Loong64I64x2SConvertI32x4High)                   \
+  V(Loong64I64x2UConvertI32x4Low)                    \
+  V(Loong64I64x2UConvertI32x4High)                   \
+  V(Loong64ExtMulLow)                                \
+  V(Loong64ExtMulHigh)                               \
+  V(Loong64ExtAddPairwise)                           \
+  V(Loong64F32x4Abs)                                 \
+  V(Loong64F32x4Neg)                                 \
+  V(Loong64F32x4Sqrt)                                \
+  V(Loong64F32x4Add)                                 \
+  V(Loong64F32x4Sub)                                 \
+  V(Loong64F32x4Mul)                                 \
+  V(Loong64F32x4Div)                                 \
+  V(Loong64F32x4Max)                                 \
+  V(Loong64F32x4Min)                                 \
+  V(Loong64F32x4Eq)                                  \
+  V(Loong64F32x4Ne)                                  \
+  V(Loong64F32x4Lt)                                  \
+  V(Loong64F32x4Le)                                  \
+  V(Loong64F32x4Pmin)                                \
+  V(Loong64F32x4Pmax)                                \
+  V(Loong64F32x4Ceil)                                \
+  V(Loong64F32x4Floor)                               \
+  V(Loong64F32x4Trunc)                               \
+  V(Loong64F32x4NearestInt)                          \
+  V(Loong64F32x4DemoteF64x2Zero)                     \
+  V(Loong64F32x4RelaxedMin)                          \
+  V(Loong64F32x4RelaxedMax)                          \
+  V(Loong64I32x4SConvertF32x4)                       \
+  V(Loong64I32x4UConvertF32x4)                       \
+  V(Loong64I32x4Neg)                                 \
+  V(Loong64I32x4GtS)                                 \
+  V(Loong64I32x4GeS)                                 \
+  V(Loong64I32x4GtU)                                 \
+  V(Loong64I32x4GeU)                                 \
+  V(Loong64I32x4Abs)                                 \
+  V(Loong64I32x4BitMask)                             \
+  V(Loong64I32x4DotI16x8S)                           \
+  V(Loong64I32x4TruncSatF64x2SZero)                  \
+  V(Loong64I32x4TruncSatF64x2UZero)                  \
+  V(Loong64I32x4RelaxedTruncF32x4S)                  \
+  V(Loong64I32x4RelaxedTruncF32x4U)                  \
+  V(Loong64I32x4RelaxedTruncF64x2SZero)              \
+  V(Loong64I32x4RelaxedTruncF64x2UZero)              \
+  V(Loong64I16x8Splat)                               \
+  V(Loong64I16x8ExtractLaneU)                        \
+  V(Loong64I16x8ExtractLaneS)                        \
+  V(Loong64I16x8ReplaceLane)                         \
+  V(Loong64I16x8Neg)                                 \
+  V(Loong64I16x8Shl)                                 \
+  V(Loong64I16x8ShrS)                                \
+  V(Loong64I16x8ShrU)                                \
+  V(Loong64I16x8Add)                                 \
+  V(Loong64I16x8AddSatS)                             \
+  V(Loong64I16x8Sub)                                 \
+  V(Loong64I16x8SubSatS)                             \
+  V(Loong64I16x8Mul)                                 \
+  V(Loong64I16x8MaxS)                                \
+  V(Loong64I16x8MinS)                                \
+  V(Loong64I16x8Eq)                                  \
+  V(Loong64I16x8Ne)                                  \
+  V(Loong64I16x8GtS)                                 \
+  V(Loong64I16x8GeS)                                 \
+  V(Loong64I16x8AddSatU)                             \
+  V(Loong64I16x8SubSatU)                             \
+  V(Loong64I16x8MaxU)                                \
+  V(Loong64I16x8MinU)                                \
+  V(Loong64I16x8GtU)                                 \
+  V(Loong64I16x8GeU)                                 \
+  V(Loong64I16x8RoundingAverageU)                    \
+  V(Loong64I16x8Abs)                                 \
+  V(Loong64I16x8BitMask)                             \
+  V(Loong64I16x8Q15MulRSatS)                         \
+  V(Loong64I16x8RelaxedQ15MulRS)                     \
+  V(Loong64I8x16Splat)                               \
+  V(Loong64I8x16ExtractLaneU)                        \
+  V(Loong64I8x16ExtractLaneS)                        \
+  V(Loong64I8x16ReplaceLane)                         \
+  V(Loong64I8x16Neg)                                 \
+  V(Loong64I8x16Shl)                                 \
+  V(Loong64I8x16ShrS)                                \
+  V(Loong64I8x16Add)                                 \
+  V(Loong64I8x16AddSatS)                             \
+  V(Loong64I8x16Sub)                                 \
+  V(Loong64I8x16SubSatS)                             \
+  V(Loong64I8x16MaxS)                                \
+  V(Loong64I8x16MinS)                                \
+  V(Loong64I8x16Eq)                                  \
+  V(Loong64I8x16Ne)                                  \
+  V(Loong64I8x16GtS)                                 \
+  V(Loong64I8x16GeS)                                 \
+  V(Loong64I8x16ShrU)                                \
+  V(Loong64I8x16AddSatU)                             \
+  V(Loong64I8x16SubSatU)                             \
+  V(Loong64I8x16MaxU)                                \
+  V(Loong64I8x16MinU)                                \
+  V(Loong64I8x16GtU)                                 \
+  V(Loong64I8x16GeU)                                 \
+  V(Loong64I8x16RoundingAverageU)                    \
+  V(Loong64I8x16Abs)                                 \
+  V(Loong64I8x16Popcnt)                              \
+  V(Loong64I8x16BitMask)                             \
+  V(Loong64S128And)                                  \
+  V(Loong64S128Or)                                   \
+  V(Loong64S128Xor)                                  \
+  V(Loong64S128Not)                                  \
+  V(Loong64S128Select)                               \
+  V(Loong64S128AndNot)                               \
+  V(Loong64I64x2AllTrue)                             \
+  V(Loong64I32x4AllTrue)                             \
+  V(Loong64I16x8AllTrue)                             \
+  V(Loong64I8x16AllTrue)                             \
+  V(Loong64V128AnyTrue)                              \
+  V(Loong64S32x4InterleaveRight)                     \
+  V(Loong64S32x4InterleaveLeft)                      \
+  V(Loong64S32x4PackEven)                            \
+  V(Loong64S32x4PackOdd)                             \
+  V(Loong64S32x4InterleaveEven)                      \
+  V(Loong64S32x4InterleaveOdd)                       \
+  V(Loong64S32x4Shuffle)                             \
+  V(Loong64S16x8InterleaveRight)                     \
+  V(Loong64S16x8InterleaveLeft)                      \
+  V(Loong64S16x8PackEven)                            \
+  V(Loong64S16x8PackOdd)                             \
+  V(Loong64S16x8InterleaveEven)                      \
+  V(Loong64S16x8InterleaveOdd)                       \
+  V(Loong64S16x4Reverse)                             \
+  V(Loong64S16x2Reverse)                             \
+  V(Loong64S8x16InterleaveRight)                     \
+  V(Loong64S8x16InterleaveLeft)                      \
+  V(Loong64S8x16PackEven)                            \
+  V(Loong64S8x16PackOdd)                             \
+  V(Loong64S8x16InterleaveEven)                      \
+  V(Loong64S8x16InterleaveOdd)                       \
+  V(Loong64I8x16Shuffle)                             \
+  V(Loong64I8x16Swizzle)                             \
+  V(Loong64S8x16Concat)                              \
+  V(Loong64S8x8Reverse)                              \
+  V(Loong64S8x4Reverse)                              \
+  V(Loong64S8x2Reverse)                              \
+  V(Loong64S128Load32Zero)                           \
+  V(Loong64S128Load64Zero)                           \
+  V(Loong64I32x4SConvertI16x8Low)                    \
+  V(Loong64I32x4SConvertI16x8High)                   \
+  V(Loong64I32x4UConvertI16x8Low)                    \
+  V(Loong64I32x4UConvertI16x8High)                   \
+  V(Loong64I16x8SConvertI8x16Low)                    \
+  V(Loong64I16x8SConvertI8x16High)                   \
+  V(Loong64I16x8SConvertI32x4)                       \
+  V(Loong64I16x8UConvertI32x4)                       \
+  V(Loong64I16x8UConvertI8x16Low)                    \
+  V(Loong64I16x8UConvertI8x16High)                   \
+  V(Loong64I8x16SConvertI16x8)                       \
+  V(Loong64I8x16UConvertI16x8)                       \
+  V(Loong64AtomicLoadDecompressTaggedSigned)         \
+  V(Loong64AtomicLoadDecompressTagged)               \
+  V(Loong64AtomicStoreCompressTagged)                \
+  V(Loong64Word64AtomicAddUint64)                    \
+  V(Loong64Word64AtomicSubUint64)                    \
+  V(Loong64Word64AtomicAndUint64)                    \
+  V(Loong64Word64AtomicOrUint64)                     \
+  V(Loong64Word64AtomicXorUint64)                    \
+  V(Loong64Word64AtomicExchangeUint64)               \
   V(Loong64Word64AtomicCompareExchangeUint64)
 
 // Addressing modes represent the "shape" of inputs to an instruction.
diff --git a/src/compiler/backend/loong64/instruction-selector-loong64.cc b/src/compiler/backend/loong64/instruction-selector-loong64.cc
index b951a09009a..f5641d4cbb0 100644
--- a/src/compiler/backend/loong64/instruction-selector-loong64.cc
+++ b/src/compiler/backend/loong64/instruction-selector-loong64.cc
@@ -123,22 +123,16 @@ class Loong64OperandGeneratorT final : public OperandGeneratorT<Adapter> {
       case kLoong64Xor32:
       case kLoong64Tst:
         return is_uint12(value);
-      case kLoong64Ld_b:
-      case kLoong64Ld_bu:
-      case kLoong64St_b:
-      case kLoong64Ld_h:
-      case kLoong64Ld_hu:
-      case kLoong64St_h:
       case kLoong64Ld_w:
-      case kLoong64Ld_wu:
       case kLoong64St_w:
       case kLoong64Ld_d:
       case kLoong64St_d:
-      case kLoong64Fld_s:
-      case kLoong64Fst_s:
-      case kLoong64Fld_d:
-      case kLoong64Fst_d:
-        return is_int16(value);
+      case kAtomicLoadWord32:
+      case kAtomicStoreWord32:
+      case kLoong64Word64AtomicLoadUint64:
+      case kLoong64Word64AtomicStoreWord64:
+      case kLoong64StoreCompressTagged:
+        return (is_int12(value) || (is_int16(value) && ((value & 0b11) == 0)));
       default:
         return is_int12(value);
     }
@@ -555,6 +549,9 @@ void InstructionSelectorT<TurbofanAdapter>::VisitLoadTransform(Node* node) {
     default:
       UNIMPLEMENTED();
   }
+  if (params.kind == MemoryAccessKind::kProtected) {
+    opcode |= AccessModeField::encode(kMemoryAccessProtectedMemOutOfBounds);
+  }
 
   EmitLoad(this, node, opcode);
 }
@@ -616,6 +613,11 @@ void InstructionSelectorT<Adapter>::VisitLoad(node_t node) {
       case MachineRepresentation::kSimd256:
         UNREACHABLE();
     }
+    if (node->opcode() == IrOpcode::kProtectedLoad) {
+      opcode |= AccessModeField::encode(kMemoryAccessProtectedMemOutOfBounds);
+    } else if (node->opcode() == IrOpcode::kLoadTrapOnNull) {
+      opcode |= AccessModeField::encode(kMemoryAccessProtectedNullDereference);
+    }
 
     EmitLoad(this, node, opcode);
   }
@@ -623,8 +625,7 @@ void InstructionSelectorT<Adapter>::VisitLoad(node_t node) {
 
 template <typename Adapter>
 void InstructionSelectorT<Adapter>::VisitProtectedLoad(node_t node) {
-  // TODO(eholk)
-  UNIMPLEMENTED();
+  VisitLoad(node);
 }
 
 template <typename Adapter>
@@ -676,42 +677,45 @@ void InstructionSelectorT<TurbofanAdapter>::VisitStore(Node* node) {
     InstructionCode code = kArchStoreWithWriteBarrier;
     code |= AddressingModeField::encode(addressing_mode);
     code |= RecordWriteModeField::encode(record_write_mode);
+    if (node->opcode() == IrOpcode::kStoreTrapOnNull) {
+      code |= AccessModeField::encode(kMemoryAccessProtectedNullDereference);
+    }
     Emit(code, 0, nullptr, input_count, inputs);
   } else {
-    ArchOpcode opcode;
+    InstructionCode code;
     switch (rep) {
       case MachineRepresentation::kFloat32:
-        opcode = kLoong64Fst_s;
+        code = kLoong64Fst_s;
         break;
       case MachineRepresentation::kFloat64:
-        opcode = kLoong64Fst_d;
+        code = kLoong64Fst_d;
         break;
       case MachineRepresentation::kBit:  // Fall through.
       case MachineRepresentation::kWord8:
-        opcode = kLoong64St_b;
+        code = kLoong64St_b;
         break;
       case MachineRepresentation::kWord16:
-        opcode = kLoong64St_h;
+        code = kLoong64St_h;
         break;
       case MachineRepresentation::kWord32:
-        opcode = kLoong64St_w;
+        code = kLoong64St_w;
         break;
       case MachineRepresentation::kWord64:
-        opcode = kLoong64St_d;
+        code = kLoong64St_d;
         break;
       case MachineRepresentation::kTaggedSigned:   // Fall through.
       case MachineRepresentation::kTaggedPointer:  // Fall through.
       case MachineRepresentation::kTagged:
-        opcode = kLoong64StoreCompressTagged;
+        code = kLoong64StoreCompressTagged;
         break;
       case MachineRepresentation::kCompressedPointer:  // Fall through.
       case MachineRepresentation::kCompressed:
 #ifdef V8_COMPRESS_POINTERS
-        opcode = kLoong64StoreCompressTagged;
+        code = kLoong64StoreCompressTagged;
         break;
 #endif
       case MachineRepresentation::kSandboxedPointer:
-        opcode = kLoong64StoreEncodeSandboxedPointer;
+        code = kLoong64StoreEncodeSandboxedPointer;
         break;
       case MachineRepresentation::kMapWord:  // Fall through.
       case MachineRepresentation::kIndirectPointer:  // Fall through.
@@ -731,7 +735,7 @@ void InstructionSelectorT<TurbofanAdapter>::VisitStore(Node* node) {
       // Check that the delta is a 32-bit integer due to the limitations of
       // immediate operands.
       if (is_int32(delta)) {
-        Emit(opcode | AddressingModeField::encode(kMode_Root), g.NoOutput(),
+        Emit(code | AddressingModeField::encode(kMode_Root), g.NoOutput(),
              g.UseImmediate(static_cast<int32_t>(delta)),
              g.UseRegisterOrImmediateZero(value));
         return;
@@ -740,17 +744,23 @@ void InstructionSelectorT<TurbofanAdapter>::VisitStore(Node* node) {
 
     if (base != nullptr && base->opcode() == IrOpcode::kLoadRootRegister) {
       // This will only work if {index} is a constant.
-      Emit(opcode | AddressingModeField::encode(kMode_Root), g.NoOutput(),
+      Emit(code | AddressingModeField::encode(kMode_Root), g.NoOutput(),
            g.UseImmediate(index), g.UseRegisterOrImmediateZero(value));
       return;
     }
 
-    if (g.CanBeImmediate(index, opcode)) {
-      Emit(opcode | AddressingModeField::encode(kMode_MRI), g.NoOutput(),
+    if (node->opcode() == IrOpcode::kProtectedStore) {
+      code |= AccessModeField::encode(kMemoryAccessProtectedMemOutOfBounds);
+    } else if (node->opcode() == IrOpcode::kStoreTrapOnNull) {
+      code |= AccessModeField::encode(kMemoryAccessProtectedNullDereference);
+    }
+
+    if (g.CanBeImmediate(index, code)) {
+      Emit(code | AddressingModeField::encode(kMode_MRI), g.NoOutput(),
            g.UseRegister(base), g.UseImmediate(index),
            g.UseRegisterOrImmediateZero(value));
     } else {
-      Emit(opcode | AddressingModeField::encode(kMode_MRR), g.NoOutput(),
+      Emit(code | AddressingModeField::encode(kMode_MRR), g.NoOutput(),
            g.UseRegister(base), g.UseRegister(index),
            g.UseRegisterOrImmediateZero(value));
     }
@@ -759,8 +769,7 @@ void InstructionSelectorT<TurbofanAdapter>::VisitStore(Node* node) {
 
 template <typename Adapter>
 void InstructionSelectorT<Adapter>::VisitProtectedStore(node_t node) {
-  // TODO(eholk)
-  UNIMPLEMENTED();
+  VisitStore(node);
 }
 
 template <>
@@ -2595,6 +2604,10 @@ void VisitAtomicLoad(InstructionSelectorT<Adapter>* selector, Node* node,
       UNREACHABLE();
   }
 
+  if (atomic_load_params.kind() == MemoryAccessKind::kProtected) {
+    code |= AccessModeField::encode(kMemoryAccessProtectedMemOutOfBounds);
+  }
+
   if (g.CanBeImmediate(index, code)) {
     selector->Emit(code | AddressingModeField::encode(kMode_MRI) |
                        AtomicWidthField::encode(width),
@@ -2677,6 +2690,10 @@ void VisitAtomicStore(InstructionSelectorT<TurbofanAdapter>* selector,
     }
   }
 
+  if (store_params.kind() == MemoryAccessKind::kProtected) {
+    code |= AccessModeField::encode(kMemoryAccessProtectedMemOutOfBounds);
+  }
+
   if (g.CanBeImmediate(index, code)) {
     selector->Emit(code | AddressingModeField::encode(kMode_MRI) |
                        AtomicWidthField::encode(width),
@@ -2696,7 +2713,8 @@ void VisitAtomicStore(InstructionSelectorT<TurbofanAdapter>* selector,
 
 template <typename Adapter>
 void VisitAtomicExchange(InstructionSelectorT<Adapter>* selector, Node* node,
-                         ArchOpcode opcode, AtomicWidth width) {
+                         ArchOpcode opcode, AtomicWidth width,
+                         MemoryAccessKind access_kind) {
   Loong64OperandGeneratorT<Adapter> g(selector);
   Node* base = node->InputAt(0);
   Node* index = node->InputAt(1);
@@ -2716,13 +2734,17 @@ void VisitAtomicExchange(InstructionSelectorT<Adapter>* selector, Node* node,
   temp[2] = g.TempRegister();
   InstructionCode code = opcode | AddressingModeField::encode(addressing_mode) |
                          AtomicWidthField::encode(width);
+  if (access_kind == MemoryAccessKind::kProtected) {
+    code |= AccessModeField::encode(kMemoryAccessProtectedMemOutOfBounds);
+  }
   selector->Emit(code, 1, outputs, input_count, inputs, 3, temp);
 }
 
 template <typename Adapter>
 void VisitAtomicCompareExchange(InstructionSelectorT<Adapter>* selector,
                                 Node* node, ArchOpcode opcode,
-                                AtomicWidth width) {
+                                AtomicWidth width,
+                                MemoryAccessKind access_kind) {
   Loong64OperandGeneratorT<Adapter> g(selector);
   Node* base = node->InputAt(0);
   Node* index = node->InputAt(1);
@@ -2744,12 +2766,16 @@ void VisitAtomicCompareExchange(InstructionSelectorT<Adapter>* selector,
   temp[2] = g.TempRegister();
   InstructionCode code = opcode | AddressingModeField::encode(addressing_mode) |
                          AtomicWidthField::encode(width);
+  if (access_kind == MemoryAccessKind::kProtected) {
+    code |= AccessModeField::encode(kMemoryAccessProtectedMemOutOfBounds);
+  }
   selector->Emit(code, 1, outputs, input_count, inputs, 3, temp);
 }
 
 template <typename Adapter>
 void VisitAtomicBinop(InstructionSelectorT<Adapter>* selector, Node* node,
-                      ArchOpcode opcode, AtomicWidth width) {
+                      ArchOpcode opcode, AtomicWidth width,
+                      MemoryAccessKind access_kind) {
   Loong64OperandGeneratorT<Adapter> g(selector);
   Node* base = node->InputAt(0);
   Node* index = node->InputAt(1);
@@ -2770,6 +2796,9 @@ void VisitAtomicBinop(InstructionSelectorT<Adapter>* selector, Node* node,
   temps[3] = g.TempRegister();
   InstructionCode code = opcode | AddressingModeField::encode(addressing_mode) |
                          AtomicWidthField::encode(width);
+  if (access_kind == MemoryAccessKind::kProtected) {
+    code |= AccessModeField::encode(kMemoryAccessProtectedMemOutOfBounds);
+  }
   selector->Emit(code, 1, outputs, input_count, inputs, 4, temps);
 }
 
@@ -3303,22 +3332,23 @@ template <>
 void InstructionSelectorT<TurbofanAdapter>::VisitWord32AtomicExchange(
     Node* node) {
   ArchOpcode opcode;
-  MachineType type = AtomicOpType(node->op());
-  if (type == MachineType::Int8()) {
+  AtomicOpParameters params = AtomicOpParametersOf(node->op());
+  if (params.type() == MachineType::Int8()) {
     opcode = kAtomicExchangeInt8;
-  } else if (type == MachineType::Uint8()) {
+  } else if (params.type() == MachineType::Uint8()) {
     opcode = kAtomicExchangeUint8;
-  } else if (type == MachineType::Int16()) {
+  } else if (params.type() == MachineType::Int16()) {
     opcode = kAtomicExchangeInt16;
-  } else if (type == MachineType::Uint16()) {
+  } else if (params.type() == MachineType::Uint16()) {
     opcode = kAtomicExchangeUint16;
-  } else if (type == MachineType::Int32() || type == MachineType::Uint32()) {
+  } else if (params.type() == MachineType::Int32() ||
+             params.type() == MachineType::Uint32()) {
     opcode = kAtomicExchangeWord32;
   } else {
     UNREACHABLE();
   }
 
-  VisitAtomicExchange(this, node, opcode, AtomicWidth::kWord32);
+  VisitAtomicExchange(this, node, opcode, AtomicWidth::kWord32, params.kind());
 }
 
 template <>
@@ -3331,19 +3361,19 @@ template <>
 void InstructionSelectorT<TurbofanAdapter>::VisitWord64AtomicExchange(
     Node* node) {
   ArchOpcode opcode;
-  MachineType type = AtomicOpType(node->op());
-  if (type == MachineType::Uint8()) {
+  AtomicOpParameters params = AtomicOpParametersOf(node->op());
+  if (params.type() == MachineType::Uint8()) {
     opcode = kAtomicExchangeUint8;
-  } else if (type == MachineType::Uint16()) {
+  } else if (params.type() == MachineType::Uint16()) {
     opcode = kAtomicExchangeUint16;
-  } else if (type == MachineType::Uint32()) {
+  } else if (params.type() == MachineType::Uint32()) {
     opcode = kAtomicExchangeWord32;
-  } else if (type == MachineType::Uint64()) {
+  } else if (params.type() == MachineType::Uint64()) {
     opcode = kLoong64Word64AtomicExchangeUint64;
   } else {
     UNREACHABLE();
   }
-  VisitAtomicExchange(this, node, opcode, AtomicWidth::kWord64);
+  VisitAtomicExchange(this, node, opcode, AtomicWidth::kWord64, params.kind());
 }
 
 template <>
@@ -3356,21 +3386,24 @@ template <>
 void InstructionSelectorT<TurbofanAdapter>::VisitWord32AtomicCompareExchange(
     Node* node) {
   ArchOpcode opcode;
-  MachineType type = AtomicOpType(node->op());
-  if (type == MachineType::Int8()) {
+  AtomicOpParameters params = AtomicOpParametersOf(node->op());
+  if (params.type() == MachineType::Int8()) {
     opcode = kAtomicCompareExchangeInt8;
-  } else if (type == MachineType::Uint8()) {
+  } else if (params.type() == MachineType::Uint8()) {
     opcode = kAtomicCompareExchangeUint8;
-  } else if (type == MachineType::Int16()) {
+  } else if (params.type() == MachineType::Int16()) {
     opcode = kAtomicCompareExchangeInt16;
-  } else if (type == MachineType::Uint16()) {
+  } else if (params.type() == MachineType::Uint16()) {
     opcode = kAtomicCompareExchangeUint16;
-  } else if (type == MachineType::Int32() || type == MachineType::Uint32()) {
+  } else if (params.type() == MachineType::Int32() ||
+             params.type() == MachineType::Uint32()) {
     opcode = kAtomicCompareExchangeWord32;
   } else {
     UNREACHABLE();
   }
-  VisitAtomicCompareExchange(this, node, opcode, AtomicWidth::kWord32);
+
+  VisitAtomicCompareExchange(this, node, opcode, AtomicWidth::kWord32,
+                             params.kind());
 }
 
 template <>
@@ -3383,19 +3416,20 @@ template <>
 void InstructionSelectorT<TurbofanAdapter>::VisitWord64AtomicCompareExchange(
     Node* node) {
   ArchOpcode opcode;
-  MachineType type = AtomicOpType(node->op());
-  if (type == MachineType::Uint8()) {
+  AtomicOpParameters params = AtomicOpParametersOf(node->op());
+  if (params.type() == MachineType::Uint8()) {
     opcode = kAtomicCompareExchangeUint8;
-  } else if (type == MachineType::Uint16()) {
+  } else if (params.type() == MachineType::Uint16()) {
     opcode = kAtomicCompareExchangeUint16;
-  } else if (type == MachineType::Uint32()) {
+  } else if (params.type() == MachineType::Uint32()) {
     opcode = kAtomicCompareExchangeWord32;
-  } else if (type == MachineType::Uint64()) {
+  } else if (params.type() == MachineType::Uint64()) {
     opcode = kLoong64Word64AtomicCompareExchangeUint64;
   } else {
     UNREACHABLE();
   }
-  VisitAtomicCompareExchange(this, node, opcode, AtomicWidth::kWord64);
+  VisitAtomicCompareExchange(this, node, opcode, AtomicWidth::kWord64,
+                             params.kind());
 }
 
 template <typename Adapter>
@@ -3406,22 +3440,23 @@ void InstructionSelectorT<Adapter>::VisitWord32AtomicBinaryOperation(
     UNIMPLEMENTED();
   } else {
     ArchOpcode opcode;
-    MachineType type = AtomicOpType(node->op());
-    if (type == MachineType::Int8()) {
+    AtomicOpParameters params = AtomicOpParametersOf(node->op());
+    if (params.type() == MachineType::Int8()) {
       opcode = int8_op;
-    } else if (type == MachineType::Uint8()) {
+    } else if (params.type() == MachineType::Uint8()) {
       opcode = uint8_op;
-    } else if (type == MachineType::Int16()) {
+    } else if (params.type() == MachineType::Int16()) {
       opcode = int16_op;
-    } else if (type == MachineType::Uint16()) {
+    } else if (params.type() == MachineType::Uint16()) {
       opcode = uint16_op;
-    } else if (type == MachineType::Int32() || type == MachineType::Uint32()) {
+    } else if (params.type() == MachineType::Int32() ||
+               params.type() == MachineType::Uint32()) {
       opcode = word32_op;
     } else {
       UNREACHABLE();
     }
 
-    VisitAtomicBinop(this, node, opcode, AtomicWidth::kWord32);
+    VisitAtomicBinop(this, node, opcode, AtomicWidth::kWord32, params.kind());
   }
 }
 
@@ -3447,19 +3482,19 @@ void InstructionSelectorT<Adapter>::VisitWord64AtomicBinaryOperation(
     UNIMPLEMENTED();
   } else {
     ArchOpcode opcode;
-    MachineType type = AtomicOpType(node->op());
-    if (type == MachineType::Uint8()) {
+    AtomicOpParameters params = AtomicOpParametersOf(node->op());
+    if (params.type() == MachineType::Uint8()) {
       opcode = uint8_op;
-    } else if (type == MachineType::Uint16()) {
+    } else if (params.type() == MachineType::Uint16()) {
       opcode = uint16_op;
-    } else if (type == MachineType::Uint32()) {
+    } else if (params.type() == MachineType::Uint32()) {
       opcode = uint32_op;
-    } else if (type == MachineType::Uint64()) {
+    } else if (params.type() == MachineType::Uint64()) {
       opcode = uint64_op;
     } else {
       UNREACHABLE();
     }
-    VisitAtomicBinop(this, node, opcode, AtomicWidth::kWord64);
+    VisitAtomicBinop(this, node, opcode, AtomicWidth::kWord64, params.kind());
   }
 }
 
diff --git a/src/execution/loong64/simulator-loong64.cc b/src/execution/loong64/simulator-loong64.cc
index 2b414558551..44957491f36 100644
--- a/src/execution/loong64/simulator-loong64.cc
+++ b/src/execution/loong64/simulator-loong64.cc
@@ -26,6 +26,10 @@
 #include "src/runtime/runtime-utils.h"
 #include "src/utils/ostreams.h"
 
+#if V8_ENABLE_WEBASSEMBLY
+#include "src/trap-handler/trap-handler-simulator.h"
+#endif  // V8_ENABLE_WEBASSEMBLY
+
 namespace v8 {
 namespace internal {
 
@@ -1662,8 +1666,20 @@ void Simulator::TraceMemWr(int64_t addr, T value) {
   }
 }
 
-// TODO(plind): sign-extend and zero-extend not implmented properly
-// on all the ReadXX functions, I don't think re-interpret cast does it.
+bool Simulator::ProbeMemory(uintptr_t address, uintptr_t access_size) {
+#if V8_ENABLE_WEBASSEMBLY && V8_TRAP_HANDLER_SUPPORTED
+  uintptr_t last_accessed_byte = address + access_size - 1;
+  uintptr_t current_pc = registers_[pc];
+  uintptr_t landing_pad =
+      trap_handler::ProbeMemory(last_accessed_byte, current_pc);
+  if (!landing_pad) return true;
+  set_pc(landing_pad);
+  return false;
+#else
+  return true;
+#endif
+}
+
 int32_t Simulator::ReadW(int64_t addr, Instruction* instr, TraceType t) {
   if (addr >= 0 && addr < 0x400) {
     // This has to be a nullptr-dereference, drop into debugger.
@@ -1672,17 +1688,13 @@ int32_t Simulator::ReadW(int64_t addr, Instruction* instr, TraceType t) {
            addr, reinterpret_cast<intptr_t>(instr));
     DieOrDebug();
   }
-  /* if ((addr & 0x3) == 0)*/ {
+
+  {
     local_monitor_.NotifyLoad();
     int32_t* ptr = reinterpret_cast<int32_t*>(addr);
     TraceMemRd(addr, static_cast<int64_t>(*ptr), t);
     return *ptr;
   }
-  //  PrintF("Unaligned read at 0x%08" PRIx64 " , pc=0x%08" V8PRIxPTR "\n",
-  //  addr,
-  //         reinterpret_cast<intptr_t>(instr));
-  //  DieOrDebug();
-  //  return 0;
 }
 
 uint32_t Simulator::ReadWU(int64_t addr, Instruction* instr) {
@@ -1693,16 +1705,13 @@ uint32_t Simulator::ReadWU(int64_t addr, Instruction* instr) {
            addr, reinterpret_cast<intptr_t>(instr));
     DieOrDebug();
   }
-  // if ((addr & 0x3) == 0) {
-  local_monitor_.NotifyLoad();
-  uint32_t* ptr = reinterpret_cast<uint32_t*>(addr);
-  TraceMemRd(addr, static_cast<int64_t>(*ptr), WORD);
-  return *ptr;
-  // }
-  // PrintF("Unaligned read at 0x%08" PRIx64 " , pc=0x%08" V8PRIxPTR "\n", addr,
-  //        reinterpret_cast<intptr_t>(instr));
-  // DieOrDebug();
-  // return 0;
+
+  {
+    local_monitor_.NotifyLoad();
+    uint32_t* ptr = reinterpret_cast<uint32_t*>(addr);
+    TraceMemRd(addr, static_cast<int64_t>(*ptr), WORD);
+    return *ptr;
+  }
 }
 
 void Simulator::WriteW(int64_t addr, int32_t value, Instruction* instr) {
@@ -1713,7 +1722,8 @@ void Simulator::WriteW(int64_t addr, int32_t value, Instruction* instr) {
            addr, reinterpret_cast<intptr_t>(instr));
     DieOrDebug();
   }
-  /*if ((addr & 0x3) == 0)*/ {
+
+  {
     local_monitor_.NotifyStore();
     base::MutexGuard lock_guard(&GlobalMonitor::Get()->mutex);
     GlobalMonitor::Get()->NotifyStore_Locked(&global_monitor_thread_);
@@ -1722,10 +1732,6 @@ void Simulator::WriteW(int64_t addr, int32_t value, Instruction* instr) {
     *ptr = value;
     return;
   }
-  //  PrintF("Unaligned write at 0x%08" PRIx64 " , pc=0x%08" V8PRIxPTR "\n",
-  //  addr,
-  //         reinterpret_cast<intptr_t>(instr));
-  //  DieOrDebug();
 }
 
 void Simulator::WriteConditionalW(int64_t addr, int32_t value,
@@ -1737,6 +1743,7 @@ void Simulator::WriteConditionalW(int64_t addr, int32_t value,
            addr, reinterpret_cast<intptr_t>(instr));
     DieOrDebug();
   }
+
   if ((addr & 0x3) == 0) {
     base::MutexGuard lock_guard(&GlobalMonitor::Get()->mutex);
     if (local_monitor_.NotifyStoreConditional(addr, TransactionSize::Word) &&
@@ -1766,17 +1773,13 @@ int64_t Simulator::Read2W(int64_t addr, Instruction* instr) {
            addr, reinterpret_cast<intptr_t>(instr));
     DieOrDebug();
   }
-  /*  if ((addr & kPointerAlignmentMask) == 0)*/ {
+
+  {
     local_monitor_.NotifyLoad();
     int64_t* ptr = reinterpret_cast<int64_t*>(addr);
     TraceMemRd(addr, *ptr);
     return *ptr;
   }
-  //  PrintF("Unaligned read at 0x%08" PRIx64 " , pc=0x%08" V8PRIxPTR "\n",
-  //  addr,
-  //         reinterpret_cast<intptr_t>(instr));
-  //  DieOrDebug();
-  //  return 0;
 }
 
 void Simulator::Write2W(int64_t addr, int64_t value, Instruction* instr) {
@@ -1787,7 +1790,8 @@ void Simulator::Write2W(int64_t addr, int64_t value, Instruction* instr) {
            addr, reinterpret_cast<intptr_t>(instr));
     DieOrDebug();
   }
-  /*if ((addr & kPointerAlignmentMask) == 0)*/ {
+
+  {
     local_monitor_.NotifyStore();
     base::MutexGuard lock_guard(&GlobalMonitor::Get()->mutex);
     GlobalMonitor::Get()->NotifyStore_Locked(&global_monitor_thread_);
@@ -1796,10 +1800,6 @@ void Simulator::Write2W(int64_t addr, int64_t value, Instruction* instr) {
     *ptr = value;
     return;
   }
-  //  PrintF("Unaligned write at 0x%08" PRIx64 " , pc=0x%08" V8PRIxPTR "\n",
-  //  addr,
-  //         reinterpret_cast<intptr_t>(instr));
-  //  DieOrDebug();
 }
 
 void Simulator::WriteConditional2W(int64_t addr, int64_t value,
@@ -1811,6 +1811,7 @@ void Simulator::WriteConditional2W(int64_t addr, int64_t value,
            addr, reinterpret_cast<intptr_t>(instr));
     DieOrDebug();
   }
+
   if ((addr & kPointerAlignmentMask) == 0) {
     base::MutexGuard lock_guard(&GlobalMonitor::Get()->mutex);
     if (local_monitor_.NotifyStoreConditional(addr,
@@ -1834,63 +1835,35 @@ void Simulator::WriteConditional2W(int64_t addr, int64_t value,
 }
 
 double Simulator::ReadD(int64_t addr, Instruction* instr) {
-  /*if ((addr & kDoubleAlignmentMask) == 0)*/ {
-    local_monitor_.NotifyLoad();
-    double* ptr = reinterpret_cast<double*>(addr);
-    return *ptr;
-  }
-  // PrintF("Unaligned (double) read at 0x%08" PRIx64 " , pc=0x%08" V8PRIxPTR
-  // "\n",
-  //       addr, reinterpret_cast<intptr_t>(instr));
-  // base::OS::Abort();
-  // return 0;
+  local_monitor_.NotifyLoad();
+  double* ptr = reinterpret_cast<double*>(addr);
+  return *ptr;
 }
 
 void Simulator::WriteD(int64_t addr, double value, Instruction* instr) {
-  /*if ((addr & kDoubleAlignmentMask) == 0)*/ {
-    local_monitor_.NotifyStore();
-    base::MutexGuard lock_guard(&GlobalMonitor::Get()->mutex);
-    GlobalMonitor::Get()->NotifyStore_Locked(&global_monitor_thread_);
-    double* ptr = reinterpret_cast<double*>(addr);
-    *ptr = value;
-    return;
-  }
-  // PrintF("Unaligned (double) write at 0x%08" PRIx64 " , pc=0x%08" V8PRIxPTR
-  //       "\n",
-  //       addr, reinterpret_cast<intptr_t>(instr));
-  // DieOrDebug();
+  local_monitor_.NotifyStore();
+  base::MutexGuard lock_guard(&GlobalMonitor::Get()->mutex);
+  GlobalMonitor::Get()->NotifyStore_Locked(&global_monitor_thread_);
+  double* ptr = reinterpret_cast<double*>(addr);
+  *ptr = value;
+  return;
 }
 
 uint16_t Simulator::ReadHU(int64_t addr, Instruction* instr) {
-  // if ((addr & 1) == 0) {
   local_monitor_.NotifyLoad();
   uint16_t* ptr = reinterpret_cast<uint16_t*>(addr);
   TraceMemRd(addr, static_cast<int64_t>(*ptr));
   return *ptr;
-  // }
-  // PrintF("Unaligned unsigned halfword read at 0x%08" PRIx64
-  //        " , pc=0x%08" V8PRIxPTR "\n",
-  //        addr, reinterpret_cast<intptr_t>(instr));
-  // DieOrDebug();
-  // return 0;
 }
 
 int16_t Simulator::ReadH(int64_t addr, Instruction* instr) {
-  // if ((addr & 1) == 0) {
   local_monitor_.NotifyLoad();
   int16_t* ptr = reinterpret_cast<int16_t*>(addr);
   TraceMemRd(addr, static_cast<int64_t>(*ptr));
   return *ptr;
-  // }
-  // PrintF("Unaligned signed halfword read at 0x%08" PRIx64
-  //        " , pc=0x%08" V8PRIxPTR "\n",
-  //        addr, reinterpret_cast<intptr_t>(instr));
-  // DieOrDebug();
-  // return 0;
 }
 
 void Simulator::WriteH(int64_t addr, uint16_t value, Instruction* instr) {
-  // if ((addr & 1) == 0) {
   local_monitor_.NotifyStore();
   base::MutexGuard lock_guard(&GlobalMonitor::Get()->mutex);
   GlobalMonitor::Get()->NotifyStore_Locked(&global_monitor_thread_);
@@ -1898,15 +1871,9 @@ void Simulator::WriteH(int64_t addr, uint16_t value, Instruction* instr) {
   uint16_t* ptr = reinterpret_cast<uint16_t*>(addr);
   *ptr = value;
   return;
-  // }
-  // PrintF("Unaligned unsigned halfword write at 0x%08" PRIx64
-  //        " , pc=0x%08" V8PRIxPTR "\n",
-  //        addr, reinterpret_cast<intptr_t>(instr));
-  // DieOrDebug();
 }
 
 void Simulator::WriteH(int64_t addr, int16_t value, Instruction* instr) {
-  // if ((addr & 1) == 0) {
   local_monitor_.NotifyStore();
   base::MutexGuard lock_guard(&GlobalMonitor::Get()->mutex);
   GlobalMonitor::Get()->NotifyStore_Locked(&global_monitor_thread_);
@@ -1914,11 +1881,6 @@ void Simulator::WriteH(int64_t addr, int16_t value, Instruction* instr) {
   int16_t* ptr = reinterpret_cast<int16_t*>(addr);
   *ptr = value;
   return;
-  // }
-  // PrintF("Unaligned halfword write at 0x%08" PRIx64 " , pc=0x%08" V8PRIxPTR
-  //        "\n",
-  //        addr, reinterpret_cast<intptr_t>(instr));
-  // DieOrDebug();
 }
 
 uint32_t Simulator::ReadBU(int64_t addr) {
@@ -2839,36 +2801,43 @@ void Simulator::DecodeTypeOp8() {
       printf_instr("LDPTR_W\t %s: %016lx, %s: %016lx, si14: %016lx\n",
                    Registers::Name(rd_reg()), rd(), Registers::Name(rj_reg()),
                    rj(), si14_se);
+      if (!ProbeMemory(rj() + si14_se, sizeof(int32_t))) return;
       set_register(rd_reg(), ReadW(rj() + si14_se, instr_.instr()));
       break;
     case STPTR_W:
       printf_instr("STPTR_W\t %s: %016lx, %s: %016lx, si14: %016lx\n",
                    Registers::Name(rd_reg()), rd(), Registers::Name(rj_reg()),
                    rj(), si14_se);
+      if (!ProbeMemory(rj() + si14_se, sizeof(int32_t))) return;
       WriteW(rj() + si14_se, static_cast<int32_t>(rd()), instr_.instr());
       break;
     case LDPTR_D:
       printf_instr("LDPTR_D\t %s: %016lx, %s: %016lx, si14: %016lx\n",
                    Registers::Name(rd_reg()), rd(), Registers::Name(rj_reg()),
                    rj(), si14_se);
+      if (!ProbeMemory(rj() + si14_se, sizeof(int64_t))) return;
       set_register(rd_reg(), Read2W(rj() + si14_se, instr_.instr()));
       break;
     case STPTR_D:
       printf_instr("STPTR_D\t %s: %016lx, %s: %016lx, si14: %016lx\n",
                    Registers::Name(rd_reg()), rd(), Registers::Name(rj_reg()),
                    rj(), si14_se);
+      if (!ProbeMemory(rj() + si14_se, sizeof(int64_t))) return;
       Write2W(rj() + si14_se, rd(), instr_.instr());
       break;
     case LL_W: {
       printf_instr("LL_W\t %s: %016lx, %s: %016lx, si14: %016lx\n",
                    Registers::Name(rd_reg()), rd(), Registers::Name(rj_reg()),
                    rj(), si14_se);
-      base::MutexGuard lock_guard(&GlobalMonitor::Get()->mutex);
       addr = si14_se + rj();
-      set_register(rd_reg(), ReadW(addr, instr_.instr()));
-      local_monitor_.NotifyLoadLinked(addr, TransactionSize::Word);
-      GlobalMonitor::Get()->NotifyLoadLinked_Locked(addr,
-                                                    &global_monitor_thread_);
+      if (!ProbeMemory(addr, sizeof(int32_t))) return;
+      {
+        base::MutexGuard lock_guard(&GlobalMonitor::Get()->mutex);
+        set_register(rd_reg(), ReadW(addr, instr_.instr()));
+        local_monitor_.NotifyLoadLinked(addr, TransactionSize::Word);
+        GlobalMonitor::Get()->NotifyLoadLinked_Locked(addr,
+                                                      &global_monitor_thread_);
+      }
       break;
     }
     case SC_W: {
@@ -2876,6 +2845,7 @@ void Simulator::DecodeTypeOp8() {
                    Registers::Name(rd_reg()), rd(), Registers::Name(rj_reg()),
                    rj(), si14_se);
       addr = si14_se + rj();
+      if (!ProbeMemory(addr, sizeof(int32_t))) return;
       int32_t LLbit = 0;
       WriteConditionalW(addr, static_cast<int32_t>(rd()), instr_.instr(),
                         &LLbit);
@@ -2886,12 +2856,15 @@ void Simulator::DecodeTypeOp8() {
       printf_instr("LL_D\t %s: %016lx, %s: %016lx, si14: %016lx\n",
                    Registers::Name(rd_reg()), rd(), Registers::Name(rj_reg()),
                    rj(), si14_se);
-      base::MutexGuard lock_guard(&GlobalMonitor::Get()->mutex);
       addr = si14_se + rj();
-      set_register(rd_reg(), Read2W(addr, instr_.instr()));
-      local_monitor_.NotifyLoadLinked(addr, TransactionSize::DoubleWord);
-      GlobalMonitor::Get()->NotifyLoadLinked_Locked(addr,
-                                                    &global_monitor_thread_);
+      if (!ProbeMemory(addr, sizeof(int64_t))) return;
+      {
+        base::MutexGuard lock_guard(&GlobalMonitor::Get()->mutex);
+        set_register(rd_reg(), Read2W(addr, instr_.instr()));
+        local_monitor_.NotifyLoadLinked(addr, TransactionSize::DoubleWord);
+        GlobalMonitor::Get()->NotifyLoadLinked_Locked(addr,
+                                                      &global_monitor_thread_);
+      }
       break;
     }
     case SC_D: {
@@ -2899,6 +2872,7 @@ void Simulator::DecodeTypeOp8() {
                    Registers::Name(rd_reg()), rd(), Registers::Name(rj_reg()),
                    rj(), si14_se);
       addr = si14_se + rj();
+      if (!ProbeMemory(addr, sizeof(int64_t))) return;
       int32_t LLbit = 0;
       WriteConditional2W(addr, rd(), instr_.instr(), &LLbit);
       set_register(rd_reg(), LLbit);
@@ -3036,72 +3010,84 @@ void Simulator::DecodeTypeOp10() {
       printf_instr("LD_B\t %s: %016lx, %s: %016lx, si12: %016lx\n",
                    Registers::Name(rd_reg()), rd(), Registers::Name(rj_reg()),
                    rj(), si12_ze);
+      if (!ProbeMemory(rj() + si12_se, sizeof(int8_t))) return;
       set_register(rd_reg(), ReadB(rj() + si12_se));
       break;
     case LD_H:
       printf_instr("LD_H\t %s: %016lx, %s: %016lx, si12: %016lx\n",
                    Registers::Name(rd_reg()), rd(), Registers::Name(rj_reg()),
                    rj(), si12_ze);
+      if (!ProbeMemory(rj() + si12_se, sizeof(int16_t))) return;
       set_register(rd_reg(), ReadH(rj() + si12_se, instr_.instr()));
       break;
     case LD_W:
       printf_instr("LD_W\t %s: %016lx, %s: %016lx, si12: %016lx\n",
                    Registers::Name(rd_reg()), rd(), Registers::Name(rj_reg()),
                    rj(), si12_ze);
+      if (!ProbeMemory(rj() + si12_se, sizeof(int32_t))) return;
       set_register(rd_reg(), ReadW(rj() + si12_se, instr_.instr()));
       break;
     case LD_D:
       printf_instr("LD_D\t %s: %016lx, %s: %016lx, si12: %016lx\n",
                    Registers::Name(rd_reg()), rd(), Registers::Name(rj_reg()),
                    rj(), si12_ze);
+      if (!ProbeMemory(rj() + si12_se, sizeof(int64_t))) return;
       set_register(rd_reg(), Read2W(rj() + si12_se, instr_.instr()));
       break;
     case ST_B:
       printf_instr("ST_B\t %s: %016lx, %s: %016lx, si12: %016lx\n",
                    Registers::Name(rd_reg()), rd(), Registers::Name(rj_reg()),
                    rj(), si12_ze);
+      if (!ProbeMemory(rj() + si12_se, sizeof(int8_t))) return;
       WriteB(rj() + si12_se, static_cast<int8_t>(rd()));
       break;
     case ST_H:
       printf_instr("ST_H\t %s: %016lx, %s: %016lx, si12: %016lx\n",
                    Registers::Name(rd_reg()), rd(), Registers::Name(rj_reg()),
                    rj(), si12_ze);
+      if (!ProbeMemory(rj() + si12_se, sizeof(int16_t))) return;
       WriteH(rj() + si12_se, static_cast<int16_t>(rd()), instr_.instr());
       break;
     case ST_W:
       printf_instr("ST_W\t %s: %016lx, %s: %016lx, si12: %016lx\n",
                    Registers::Name(rd_reg()), rd(), Registers::Name(rj_reg()),
                    rj(), si12_ze);
+      if (!ProbeMemory(rj() + si12_se, sizeof(int32_t))) return;
       WriteW(rj() + si12_se, static_cast<int32_t>(rd()), instr_.instr());
       break;
     case ST_D:
       printf_instr("ST_D\t %s: %016lx, %s: %016lx, si12: %016lx\n",
                    Registers::Name(rd_reg()), rd(), Registers::Name(rj_reg()),
                    rj(), si12_ze);
+      if (!ProbeMemory(rj() + si12_se, sizeof(int64_t))) return;
       Write2W(rj() + si12_se, rd(), instr_.instr());
       break;
     case LD_BU:
       printf_instr("LD_BU\t %s: %016lx, %s: %016lx, si12: %016lx\n",
                    Registers::Name(rd_reg()), rd(), Registers::Name(rj_reg()),
                    rj(), si12_ze);
+      if (!ProbeMemory(rj() + si12_se, sizeof(uint8_t))) return;
       set_register(rd_reg(), ReadBU(rj() + si12_se));
       break;
     case LD_HU:
       printf_instr("LD_HU\t %s: %016lx, %s: %016lx, si12: %016lx\n",
                    Registers::Name(rd_reg()), rd(), Registers::Name(rj_reg()),
                    rj(), si12_ze);
+      if (!ProbeMemory(rj() + si12_se, sizeof(uint16_t))) return;
       set_register(rd_reg(), ReadHU(rj() + si12_se, instr_.instr()));
       break;
     case LD_WU:
       printf_instr("LD_WU\t %s: %016lx, %s: %016lx, si12: %016lx\n",
                    Registers::Name(rd_reg()), rd(), Registers::Name(rj_reg()),
                    rj(), si12_ze);
+      if (!ProbeMemory(rj() + si12_se, sizeof(uint32_t))) return;
       set_register(rd_reg(), ReadWU(rj() + si12_se, instr_.instr()));
       break;
     case FLD_S: {
       printf_instr("FLD_S\t %s: %016f, %s: %016lx, si12: %016lx\n",
                    FPURegisters::Name(fd_reg()), fd_float(),
                    Registers::Name(rj_reg()), rj(), si12_ze);
+      if (!ProbeMemory(rj() + si12_se, sizeof(float))) return;
       set_fpu_register(fd_reg(), kFPUInvalidResult);  // Trash upper 32 bits.
       set_fpu_register_word(
           fd_reg(), ReadW(rj() + si12_se, instr_.instr(), FLOAT_DOUBLE));
@@ -3111,6 +3097,7 @@ void Simulator::DecodeTypeOp10() {
       printf_instr("FST_S\t %s: %016f, %s: %016lx, si12: %016lx\n",
                    FPURegisters::Name(fd_reg()), fd_float(),
                    Registers::Name(rj_reg()), rj(), si12_ze);
+      if (!ProbeMemory(rj() + si12_se, sizeof(float))) return;
       int32_t alu_out_32 = static_cast<int32_t>(get_fpu_register(fd_reg()));
       WriteW(rj() + si12_se, alu_out_32, instr_.instr());
       break;
@@ -3119,6 +3106,7 @@ void Simulator::DecodeTypeOp10() {
       printf_instr("FLD_D\t %s: %016f, %s: %016lx, si12: %016lx\n",
                    FPURegisters::Name(fd_reg()), fd_double(),
                    Registers::Name(rj_reg()), rj(), si12_ze);
+      if (!ProbeMemory(rj() + si12_se, sizeof(double))) return;
       set_fpu_register_double(fd_reg(), ReadD(rj() + si12_se, instr_.instr()));
       TraceMemRd(rj() + si12_se, get_fpu_register(fd_reg()), DOUBLE);
       break;
@@ -3127,6 +3115,7 @@ void Simulator::DecodeTypeOp10() {
       printf_instr("FST_D\t %s: %016f, %s: %016lx, si12: %016lx\n",
                    FPURegisters::Name(fd_reg()), fd_double(),
                    Registers::Name(rj_reg()), rj(), si12_ze);
+      if (!ProbeMemory(rj() + si12_se, sizeof(double))) return;
       WriteD(rj() + si12_se, get_fpu_register_double(fd_reg()), instr_.instr());
       TraceMemWr(rj() + si12_se, get_fpu_register(fd_reg()), DWORD);
       break;
@@ -4036,66 +4025,77 @@ void Simulator::DecodeTypeOp17() {
       printf_instr("LDX_B\t %s: %016lx, %s, %016lx, %s, %016lx\n",
                    Registers::Name(rd_reg()), rd(), Registers::Name(rj_reg()),
                    rj(), Registers::Name(rk_reg()), rk());
+      if (!ProbeMemory(rj() + rk(), sizeof(int8_t))) return;
       set_register(rd_reg(), ReadB(rj() + rk()));
       break;
     case LDX_H:
       printf_instr("LDX_H\t %s: %016lx, %s, %016lx, %s, %016lx\n",
                    Registers::Name(rd_reg()), rd(), Registers::Name(rj_reg()),
                    rj(), Registers::Name(rk_reg()), rk());
+      if (!ProbeMemory(rj() + rk(), sizeof(int16_t))) return;
       set_register(rd_reg(), ReadH(rj() + rk(), instr_.instr()));
       break;
     case LDX_W:
       printf_instr("LDX_W\t %s: %016lx, %s, %016lx, %s, %016lx\n",
                    Registers::Name(rd_reg()), rd(), Registers::Name(rj_reg()),
                    rj(), Registers::Name(rk_reg()), rk());
+      if (!ProbeMemory(rj() + rk(), sizeof(int32_t))) return;
       set_register(rd_reg(), ReadW(rj() + rk(), instr_.instr()));
       break;
     case LDX_D:
       printf_instr("LDX_D\t %s: %016lx, %s, %016lx, %s, %016lx\n",
                    Registers::Name(rd_reg()), rd(), Registers::Name(rj_reg()),
                    rj(), Registers::Name(rk_reg()), rk());
+      if (!ProbeMemory(rj() + rk(), sizeof(int64_t))) return;
       set_register(rd_reg(), Read2W(rj() + rk(), instr_.instr()));
       break;
     case STX_B:
       printf_instr("STX_B\t %s: %016lx, %s, %016lx, %s, %016lx\n",
                    Registers::Name(rd_reg()), rd(), Registers::Name(rj_reg()),
                    rj(), Registers::Name(rk_reg()), rk());
+      if (!ProbeMemory(rj() + rk(), sizeof(int8_t))) return;
       WriteB(rj() + rk(), static_cast<int8_t>(rd()));
       break;
     case STX_H:
       printf_instr("STX_H\t %s: %016lx, %s, %016lx, %s, %016lx\n",
                    Registers::Name(rd_reg()), rd(), Registers::Name(rj_reg()),
                    rj(), Registers::Name(rk_reg()), rk());
+      if (!ProbeMemory(rj() + rk(), sizeof(int16_t))) return;
       WriteH(rj() + rk(), static_cast<int16_t>(rd()), instr_.instr());
       break;
     case STX_W:
       printf_instr("STX_W\t %s: %016lx, %s, %016lx, %s, %016lx\n",
                    Registers::Name(rd_reg()), rd(), Registers::Name(rj_reg()),
                    rj(), Registers::Name(rk_reg()), rk());
+      if (!ProbeMemory(rj() + rk(), sizeof(int32_t))) return;
       WriteW(rj() + rk(), static_cast<int32_t>(rd()), instr_.instr());
       break;
     case STX_D:
       printf_instr("STX_D\t %s: %016lx, %s, %016lx, %s, %016lx\n",
                    Registers::Name(rd_reg()), rd(), Registers::Name(rj_reg()),
                    rj(), Registers::Name(rk_reg()), rk());
+      if (!ProbeMemory(rj() + rk(), sizeof(int64_t))) return;
       Write2W(rj() + rk(), rd(), instr_.instr());
       break;
     case LDX_BU:
       printf_instr("LDX_BU\t %s: %016lx, %s, %016lx, %s, %016lx\n",
                    Registers::Name(rd_reg()), rd(), Registers::Name(rj_reg()),
                    rj(), Registers::Name(rk_reg()), rk());
+      if (!ProbeMemory(rj() + rk(), sizeof(uint8_t))) return;
       set_register(rd_reg(), ReadBU(rj() + rk()));
       break;
     case LDX_HU:
       printf_instr("LDX_HU\t %s: %016lx, %s, %016lx, %s, %016lx\n",
                    Registers::Name(rd_reg()), rd(), Registers::Name(rj_reg()),
                    rj(), Registers::Name(rk_reg()), rk());
+      if (!ProbeMemory(rj() + rk(), sizeof(uint16_t))) return;
       set_register(rd_reg(), ReadHU(rj() + rk(), instr_.instr()));
       break;
     case LDX_WU:
       printf_instr("LDX_WU\t %s: %016lx, %s, %016lx, %s, %016lx\n",
                    Registers::Name(rd_reg()), rd(), Registers::Name(rj_reg()),
                    rj(), Registers::Name(rk_reg()), rk());
+      if (!ProbeMemory(rj() + rk(), sizeof(uint32_t))) return;
       set_register(rd_reg(), ReadWU(rj() + rk(), instr_.instr()));
       break;
     case FLDX_S:
@@ -4103,6 +4103,7 @@ void Simulator::DecodeTypeOp17() {
                    FPURegisters::Name(fd_reg()), fd_float(),
                    Registers::Name(rj_reg()), rj(), Registers::Name(rk_reg()),
                    rk());
+      if (!ProbeMemory(rj() + rk(), sizeof(float))) return;
       set_fpu_register(fd_reg(), kFPUInvalidResult);  // Trash upper 32 bits.
       set_fpu_register_word(fd_reg(),
                             ReadW(rj() + rk(), instr_.instr(), FLOAT_DOUBLE));
@@ -4112,6 +4113,7 @@ void Simulator::DecodeTypeOp17() {
                    FPURegisters::Name(fd_reg()), fd_double(),
                    Registers::Name(rj_reg()), rj(), Registers::Name(rk_reg()),
                    rk());
+      if (!ProbeMemory(rj() + rk(), sizeof(double))) return;
       set_fpu_register_double(fd_reg(), ReadD(rj() + rk(), instr_.instr()));
       break;
     case FSTX_S:
@@ -4119,6 +4121,7 @@ void Simulator::DecodeTypeOp17() {
                    FPURegisters::Name(fd_reg()), fd_float(),
                    Registers::Name(rj_reg()), rj(), Registers::Name(rk_reg()),
                    rk());
+      if (!ProbeMemory(rj() + rk(), sizeof(float))) return;
       WriteW(rj() + rk(), static_cast<int32_t>(get_fpu_register(fd_reg())),
              instr_.instr());
       break;
@@ -4127,6 +4130,7 @@ void Simulator::DecodeTypeOp17() {
                    FPURegisters::Name(fd_reg()), fd_double(),
                    Registers::Name(rj_reg()), rj(), Registers::Name(rk_reg()),
                    rk());
+      if (!ProbeMemory(rj() + rk(), sizeof(double))) return;
       WriteD(rj() + rk(), get_fpu_register_double(fd_reg()), instr_.instr());
       break;
     case AMSWAP_W:
@@ -4187,6 +4191,7 @@ void Simulator::DecodeTypeOp17() {
       printf_instr("AMSWAP_DB_W:\t %s: %016lx, %s, %016lx, %s, %016lx\n",
                    Registers::Name(rd_reg()), rd(), Registers::Name(rk_reg()),
                    rk(), Registers::Name(rj_reg()), rj());
+      if (!ProbeMemory(rj(), sizeof(int32_t))) return;
       int32_t success = 0;
       do {
         {
@@ -4204,6 +4209,7 @@ void Simulator::DecodeTypeOp17() {
       printf_instr("AMSWAP_DB_D:\t %s: %016lx, %s, %016lx, %s, %016lx\n",
                    Registers::Name(rd_reg()), rd(), Registers::Name(rk_reg()),
                    rk(), Registers::Name(rj_reg()), rj());
+      if (!ProbeMemory(rj(), sizeof(int64_t))) return;
       int32_t success = 0;
       do {
         {
@@ -4220,6 +4226,7 @@ void Simulator::DecodeTypeOp17() {
       printf_instr("AMADD_DB_W:\t %s: %016lx, %s, %016lx, %s, %016lx\n",
                    Registers::Name(rd_reg()), rd(), Registers::Name(rk_reg()),
                    rk(), Registers::Name(rj_reg()), rj());
+      if (!ProbeMemory(rj(), sizeof(int32_t))) return;
       int32_t success = 0;
       do {
         {
@@ -4239,6 +4246,7 @@ void Simulator::DecodeTypeOp17() {
       printf_instr("AMADD_DB_D:\t %s: %016lx, %s, %016lx, %s, %016lx\n",
                    Registers::Name(rd_reg()), rd(), Registers::Name(rk_reg()),
                    rk(), Registers::Name(rj_reg()), rj());
+      if (!ProbeMemory(rj(), sizeof(int64_t))) return;
       int32_t success = 0;
       do {
         {
@@ -4255,6 +4263,7 @@ void Simulator::DecodeTypeOp17() {
       printf_instr("AMAND_DB_W:\t %s: %016lx, %s, %016lx, %s, %016lx\n",
                    Registers::Name(rd_reg()), rd(), Registers::Name(rk_reg()),
                    rk(), Registers::Name(rj_reg()), rj());
+      if (!ProbeMemory(rj(), sizeof(int32_t))) return;
       int32_t success = 0;
       do {
         {
@@ -4274,6 +4283,7 @@ void Simulator::DecodeTypeOp17() {
       printf_instr("AMAND_DB_D:\t %s: %016lx, %s, %016lx, %s, %016lx\n",
                    Registers::Name(rd_reg()), rd(), Registers::Name(rk_reg()),
                    rk(), Registers::Name(rj_reg()), rj());
+      if (!ProbeMemory(rj(), sizeof(int64_t))) return;
       int32_t success = 0;
       do {
         {
@@ -4290,6 +4300,7 @@ void Simulator::DecodeTypeOp17() {
       printf_instr("AMOR_DB_W:\t %s: %016lx, %s, %016lx, %s, %016lx\n",
                    Registers::Name(rd_reg()), rd(), Registers::Name(rk_reg()),
                    rk(), Registers::Name(rj_reg()), rj());
+      if (!ProbeMemory(rj(), sizeof(int32_t))) return;
       int32_t success = 0;
       do {
         {
@@ -4309,6 +4320,7 @@ void Simulator::DecodeTypeOp17() {
       printf_instr("AMOR_DB_D:\t %s: %016lx, %s, %016lx, %s, %016lx\n",
                    Registers::Name(rd_reg()), rd(), Registers::Name(rk_reg()),
                    rk(), Registers::Name(rj_reg()), rj());
+      if (!ProbeMemory(rj(), sizeof(int64_t))) return;
       int32_t success = 0;
       do {
         {
@@ -4325,6 +4337,7 @@ void Simulator::DecodeTypeOp17() {
       printf_instr("AMXOR_DB_W:\t %s: %016lx, %s, %016lx, %s, %016lx\n",
                    Registers::Name(rd_reg()), rd(), Registers::Name(rk_reg()),
                    rk(), Registers::Name(rj_reg()), rj());
+      if (!ProbeMemory(rj(), sizeof(int32_t))) return;
       int32_t success = 0;
       do {
         {
@@ -4344,6 +4357,7 @@ void Simulator::DecodeTypeOp17() {
       printf_instr("AMXOR_DB_D:\t %s: %016lx, %s, %016lx, %s, %016lx\n",
                    Registers::Name(rd_reg()), rd(), Registers::Name(rk_reg()),
                    rk(), Registers::Name(rj_reg()), rj());
+      if (!ProbeMemory(rj(), sizeof(int64_t))) return;
       int32_t success = 0;
       do {
         {
diff --git a/src/execution/loong64/simulator-loong64.h b/src/execution/loong64/simulator-loong64.h
index c26a7922e71..4d9ff2f0146 100644
--- a/src/execution/loong64/simulator-loong64.h
+++ b/src/execution/loong64/simulator-loong64.h
@@ -399,6 +399,18 @@ class Simulator : public SimulatorBase {
     WORD_DWORD
   };
 
+  // "Probe" if an address range can be read. This is currently implemented
+  // by doing a 1-byte read of the last accessed byte, since the assumption is
+  // that if the last byte is accessible, also all lower bytes are accessible
+  // (which holds true for Wasm).
+  // Returns true if the access was successful, false if the access raised a
+  // signal which was then handled by the trap handler (also see
+  // {trap_handler::ProbeMemory}). If the access raises a signal which is not
+  // handled by the trap handler (e.g. because the current PC is not registered
+  // as a protected instruction), the signal will propagate and make the process
+  // crash. If no trap handler is available, this always returns true.
+  bool ProbeMemory(uintptr_t address, uintptr_t access_size);
+
   // Read and write memory.
   inline uint32_t ReadBU(int64_t addr);
   inline int32_t ReadB(int64_t addr);
diff --git a/src/trap-handler/handler-inside-posix.cc b/src/trap-handler/handler-inside-posix.cc
index 142f6fd3a16..10f80ed0a24 100644
--- a/src/trap-handler/handler-inside-posix.cc
+++ b/src/trap-handler/handler-inside-posix.cc
@@ -53,6 +53,8 @@ namespace trap_handler {
 #define CONTEXT_PC() &uc->uc_mcontext.pc
 #elif V8_OS_DARWIN && V8_HOST_ARCH_ARM64
 #define CONTEXT_PC() &uc->uc_mcontext->__ss.__pc
+#elif V8_OS_LINUX && V8_HOST_ARCH_LOONG64
+#define CONTEXT_PC() &uc->uc_mcontext.__pc
 #elif V8_OS_LINUX
 #define CONTEXT_REG(reg, REG) &uc->uc_mcontext.gregs[REG_##REG]
 #elif V8_OS_DARWIN
@@ -137,6 +139,8 @@ bool TryHandleSignal(int signum, siginfo_t* info, void* context) {
     auto* context_ip = CONTEXT_REG(rip, RIP);
 #elif V8_HOST_ARCH_ARM64
     auto* context_ip = CONTEXT_PC();
+#elif V8_HOST_ARCH_LOONG64
+    auto* context_ip = CONTEXT_PC();
 #else
 #error "Unsupported architecture."
 #endif
diff --git a/src/trap-handler/trap-handler.h b/src/trap-handler/trap-handler.h
index e391bc6e386..396a3f11790 100644
--- a/src/trap-handler/trap-handler.h
+++ b/src/trap-handler/trap-handler.h
@@ -37,6 +37,13 @@ namespace trap_handler {
     (!defined(_MSC_VER) || defined(__clang__))
 #define V8_TRAP_HANDLER_VIA_SIMULATOR
 #define V8_TRAP_HANDLER_SUPPORTED true
+// Loong64 (non-simulator) on Linux.
+#elif V8_TARGET_ARCH_LOONG64 && V8_HOST_ARCH_LOONG64 && V8_OS_LINUX
+#define V8_TRAP_HANDLER_SUPPORTED true
+// Loong64 simulator on x64 on Linux
+#elif V8_TARGET_ARCH_LOONG64 && V8_HOST_ARCH_X64 && V8_OS_LINUX
+#define V8_TRAP_HANDLER_VIA_SIMULATOR
+#define V8_TRAP_HANDLER_SUPPORTED true
 // Everything else is unsupported.
 #else
 #define V8_TRAP_HANDLER_SUPPORTED false
diff --git a/src/wasm/baseline/loong64/liftoff-assembler-loong64.h b/src/wasm/baseline/loong64/liftoff-assembler-loong64.h
index 4f7f4bb3105..d94a60f7abe 100644
--- a/src/wasm/baseline/loong64/liftoff-assembler-loong64.h
+++ b/src/wasm/baseline/loong64/liftoff-assembler-loong64.h
@@ -461,11 +461,11 @@ void LiftoffAssembler::Load(LiftoffRegister dst, Register src_addr,
                             LoadType type, uint32_t* protected_load_pc,
                             bool is_load_mem, bool i64_offset,
                             bool needs_shift) {
+  BlockTrampolinePoolScope block_trampoline_pool(this);
   unsigned shift_amount = needs_shift ? type.size_log_2() : 0;
   MemOperand src_op = liftoff::GetMemOp(this, src_addr, offset_reg, offset_imm,
                                         i64_offset, shift_amount);
 
-  if (protected_load_pc) *protected_load_pc = pc_offset();
   switch (type.value()) {
     case LoadType::kI32Load8U:
     case LoadType::kI64Load8U:
@@ -505,6 +505,10 @@ void LiftoffAssembler::Load(LiftoffRegister dst, Register src_addr,
     default:
       UNREACHABLE();
   }
+  // protected_store_pc should be the address of the load/store instruction.
+  // The MacroAssembler load/store may contain some instructions for adjusting
+  // MemOperand, so use pc_offset-4 to locate.
+  if (protected_load_pc) *protected_load_pc = pc_offset() - 4;
 }
 
 void LiftoffAssembler::Store(Register dst_addr, Register offset_reg,
@@ -512,10 +516,10 @@ void LiftoffAssembler::Store(Register dst_addr, Register offset_reg,
                              StoreType type, LiftoffRegList pinned,
                              uint32_t* protected_store_pc, bool is_store_mem,
                              bool i64_offset) {
+  BlockTrampolinePoolScope block_trampoline_pool(this);
   MemOperand dst_op =
       liftoff::GetMemOp(this, dst_addr, offset_reg, offset_imm, i64_offset);
 
-  if (protected_store_pc) *protected_store_pc = pc_offset();
   switch (type.value()) {
     case StoreType::kI32Store8:
     case StoreType::kI64Store8:
@@ -544,6 +548,10 @@ void LiftoffAssembler::Store(Register dst_addr, Register offset_reg,
     default:
       UNREACHABLE();
   }
+  // protected_store_pc should be the address of the load/store instruction.
+  // The MacroAssembler load/store may contain some instructions for adjusting
+  // MemOperand, so use pc_offset-4 to locate.
+  if (protected_store_pc) *protected_store_pc = pc_offset() - 4;
 }
 
 void LiftoffAssembler::AtomicLoad(LiftoffRegister dst, Register src_addr,
@@ -3037,7 +3045,7 @@ void LiftoffAssembler::StackCheck(Label* ool_code, Register limit_address) {
 }
 
 void LiftoffAssembler::AssertUnreachable(AbortReason reason) {
-  if (v8_flags.debug_code) Abort(reason);
+  MacroAssembler::AssertUnreachable(reason);
 }
 
 void LiftoffAssembler::PushRegisters(LiftoffRegList regs) {
diff --git a/test/unittests/BUILD.gn b/test/unittests/BUILD.gn
index 09d60116bf3..9dabeaece10 100644
--- a/test/unittests/BUILD.gn
+++ b/test/unittests/BUILD.gn
@@ -657,7 +657,7 @@ v8_source_set("v8_unittests_sources") {
       sources += [ "compiler/arm64/instruction-selector-arm64-unittest.cc" ]
     }
     if (v8_enable_webassembly && current_cpu == "arm64") {
-      sources += [ "wasm/trap-handler-x64-arm64-unittest.cc" ]
+      sources += [ "wasm/trap-handler-native-unittest.cc" ]
     }
   } else if (v8_current_cpu == "x86") {
     sources += [
@@ -701,7 +701,7 @@ v8_source_set("v8_unittests_sources") {
       sources += [ "compiler/x64/instruction-selector-x64-unittest.cc" ]
     }
     if (v8_enable_webassembly) {
-      sources += [ "wasm/trap-handler-x64-arm64-unittest.cc" ]
+      sources += [ "wasm/trap-handler-native-unittest.cc" ]
     }
   } else if (v8_current_cpu == "ppc" || v8_current_cpu == "ppc64") {
     sources += [
@@ -727,6 +727,9 @@ v8_source_set("v8_unittests_sources") {
     if (v8_enable_turbofan) {
       sources += [ "compiler/loong64/instruction-selector-loong64-unittest.cc" ]
     }
+    if (v8_enable_webassembly && current_cpu == "loong64") {
+      sources += [ "wasm/trap-handler-native-unittest.cc" ]
+    }
   }
 
   if (v8_enable_webassembly) {
@@ -740,7 +743,8 @@ v8_source_set("v8_unittests_sources") {
 
     # Include this test only on arm64 simulator builds on x64 on Linux, Mac and
     # Windows.
-    if (current_cpu == "x64" && v8_current_cpu == "arm64" &&
+    if (current_cpu == "x64" &&
+        (v8_current_cpu == "arm64" || v8_current_cpu == "loong64") &&
         (is_linux || is_mac || is_win)) {
       sources += [ "wasm/trap-handler-simulator-unittest.cc" ]
     }
diff --git a/test/unittests/compiler/loong64/instruction-selector-loong64-unittest.cc b/test/unittests/compiler/loong64/instruction-selector-loong64-unittest.cc
index 941e9d95ba9..a2dabfb8a57 100644
--- a/test/unittests/compiler/loong64/instruction-selector-loong64-unittest.cc
+++ b/test/unittests/compiler/loong64/instruction-selector-loong64-unittest.cc
@@ -1266,12 +1266,21 @@ TEST_P(InstructionSelectorMemoryAccessImmTest, LoadWithImmediateIndex) {
     StreamBuilder m(this, memacc.type, MachineType::Pointer());
     m.Return(m.Load(memacc.type, m.Parameter(0), m.Int32Constant(index)));
     Stream s = m.Build();
+    MachineRepresentation rep_type = memacc.type.representation();
     ASSERT_EQ(1U, s.size());
     EXPECT_EQ(memacc.load_opcode, s[0]->arch_opcode());
-    EXPECT_EQ(kMode_MRI, s[0]->addressing_mode());
     ASSERT_EQ(2U, s[0]->InputCount());
-    ASSERT_EQ(InstructionOperand::IMMEDIATE, s[0]->InputAt(1)->kind());
-    EXPECT_EQ(index, s.ToInt32(s[0]->InputAt(1)));
+    if (((rep_type == MachineRepresentation::kWord64 ||
+          rep_type == MachineRepresentation::kWord32) &&
+         is_int16(index) && ((index & 0b11) == 0)) ||
+        is_int12(index)) {
+      EXPECT_EQ(kMode_MRI, s[0]->addressing_mode());
+      ASSERT_EQ(InstructionOperand::IMMEDIATE, s[0]->InputAt(1)->kind());
+      EXPECT_EQ(index, s.ToInt32(s[0]->InputAt(1)));
+    } else {
+      EXPECT_EQ(kMode_MRR, s[0]->addressing_mode());
+      ASSERT_EQ(InstructionOperand::UNALLOCATED, s[0]->InputAt(1)->kind());
+    }
     ASSERT_EQ(1U, s[0]->OutputCount());
     EXPECT_TRUE((s.*memacc.val_predicate)(s[0]->Output()));
   }
@@ -1290,12 +1299,21 @@ TEST_P(InstructionSelectorMemoryAccessImmTest, StoreWithImmediateIndex) {
             m.Int32Constant(index), m.Parameter(1), kNoWriteBarrier);
     m.Return(m.Int32Constant(0));
     Stream s = m.Build();
+    MachineRepresentation rep_type = memacc.type.representation();
     ASSERT_EQ(1U, s.size());
     EXPECT_EQ(memacc.store_opcode, s[0]->arch_opcode());
-    EXPECT_EQ(kMode_MRI, s[0]->addressing_mode());
     ASSERT_EQ(3U, s[0]->InputCount());
-    ASSERT_EQ(InstructionOperand::IMMEDIATE, s[0]->InputAt(1)->kind());
-    EXPECT_EQ(index, s.ToInt32(s[0]->InputAt(1)));
+    if (((rep_type == MachineRepresentation::kWord64 ||
+          rep_type == MachineRepresentation::kWord32) &&
+         is_int16(index) && ((index & 0b11) == 0)) ||
+        is_int12(index)) {
+      EXPECT_EQ(kMode_MRI, s[0]->addressing_mode());
+      ASSERT_EQ(InstructionOperand::IMMEDIATE, s[0]->InputAt(1)->kind());
+      EXPECT_EQ(index, s.ToInt32(s[0]->InputAt(1)));
+    } else {
+      EXPECT_EQ(kMode_MRR, s[0]->addressing_mode());
+      ASSERT_EQ(InstructionOperand::UNALLOCATED, s[0]->InputAt(1)->kind());
+    }
     EXPECT_EQ(0U, s[0]->OutputCount());
   }
 }
@@ -1308,12 +1326,21 @@ TEST_P(InstructionSelectorMemoryAccessImmTest, StoreZero) {
             m.Int32Constant(index), m.Int32Constant(0), kNoWriteBarrier);
     m.Return(m.Int32Constant(0));
     Stream s = m.Build();
+    MachineRepresentation rep_type = memacc.type.representation();
     ASSERT_EQ(1U, s.size());
     EXPECT_EQ(memacc.store_opcode, s[0]->arch_opcode());
-    EXPECT_EQ(kMode_MRI, s[0]->addressing_mode());
     ASSERT_EQ(3U, s[0]->InputCount());
-    ASSERT_EQ(InstructionOperand::IMMEDIATE, s[0]->InputAt(1)->kind());
-    EXPECT_EQ(index, s.ToInt32(s[0]->InputAt(1)));
+    if (((rep_type == MachineRepresentation::kWord64 ||
+          rep_type == MachineRepresentation::kWord32) &&
+         is_int16(index) && ((index & 0b11) == 0)) ||
+        is_int12(index)) {
+      ASSERT_EQ(InstructionOperand::IMMEDIATE, s[0]->InputAt(1)->kind());
+      EXPECT_EQ(kMode_MRI, s[0]->addressing_mode());
+      EXPECT_EQ(index, s.ToInt32(s[0]->InputAt(1)));
+    } else {
+      ASSERT_EQ(InstructionOperand::UNALLOCATED, s[0]->InputAt(1)->kind());
+      EXPECT_EQ(kMode_MRR, s[0]->addressing_mode());
+    }
     ASSERT_EQ(InstructionOperand::IMMEDIATE, s[0]->InputAt(2)->kind());
     EXPECT_EQ(0, s.ToInt64(s[0]->InputAt(2)));
     EXPECT_EQ(0U, s[0]->OutputCount());
diff --git a/test/unittests/wasm/trap-handler-x64-arm64-unittest.cc b/test/unittests/wasm/trap-handler-native-unittest.cc
similarity index 87%
rename from test/unittests/wasm/trap-handler-x64-arm64-unittest.cc
rename to test/unittests/wasm/trap-handler-native-unittest.cc
index b5da3687a85..3eac3678298 100644
--- a/test/unittests/wasm/trap-handler-x64-arm64-unittest.cc
+++ b/test/unittests/wasm/trap-handler-native-unittest.cc
@@ -121,6 +121,9 @@ class TrapHandlerTest : public TestWithIsolate,
 #elif V8_HOST_ARCH_ARM64
     // SIGTRAP to simulate crashes which are not handled by the trap handler.
     EXPECT_EQ(0, sigaction(SIGTRAP, &action, &g_old_other_action));
+#elif V8_HOST_ARCH_LOONG64
+    // SIGTRAP to simulate crashes which are not handled by the trap handler.
+    EXPECT_EQ(0, sigaction(SIGTRAP, &action, &g_old_other_action));
 #else
 #error Unsupported platform
 #endif
@@ -149,6 +152,8 @@ class TrapHandlerTest : public TestWithIsolate,
       EXPECT_EQ(0, sigaction(SIGFPE, &g_old_other_action, nullptr));
 #elif V8_HOST_ARCH_ARM64
       EXPECT_EQ(0, sigaction(SIGTRAP, &g_old_other_action, nullptr));
+#elif V8_HOST_ARCH_LOONG64
+      EXPECT_EQ(0, sigaction(SIGTRAP, &g_old_other_action, nullptr));
 #else
 #error Unsupported platform
 #endif
@@ -194,6 +199,8 @@ class TrapHandlerTest : public TestWithIsolate,
     sigaction(SIGFPE, &g_old_other_action, nullptr);
 #elif V8_HOST_ARCH_ARM64
     sigaction(SIGTRAP, &g_old_other_action, nullptr);
+#elif V8_HOST_ARCH_LOONG64
+    sigaction(SIGTRAP, &g_old_other_action, nullptr);
 #else
 #error Unsupported platform
 #endif
@@ -208,6 +215,8 @@ class TrapHandlerTest : public TestWithIsolate,
     uc->uc_mcontext->__ss.__rip = g_recovery_address;
 #elif V8_OS_LINUX && V8_HOST_ARCH_ARM64
     uc->uc_mcontext.pc = g_recovery_address;
+#elif V8_OS_LINUX && V8_HOST_ARCH_LOONG64
+    uc->uc_mcontext.__pc = g_recovery_address;
 #elif V8_OS_LINUX && V8_HOST_ARCH_X64
     uc->uc_mcontext.gregs[REG_RIP] = g_recovery_address;
 #elif V8_OS_FREEBSD
@@ -254,6 +263,16 @@ class TrapHandlerTest : public TestWithIsolate,
     Register one = temps.AcquireX();
     masm->Mov(one, 1);
     masm->Str(one, MemOperand(addr));
+#elif V8_HOST_ARCH_LOONG64
+    UseScratchRegisterScope temps(masm);
+    Register addr = temps.Acquire();
+    masm->li(
+        addr,
+        static_cast<int64_t>(
+            i_isolate()->thread_local_top()->thread_in_wasm_flag_address_));
+    Register one = temps.Acquire();
+    masm->li(one, 1);
+    masm->St_d(one, MemOperand(addr, 0));
 #else
 #error Unsupported platform
 #endif
@@ -271,6 +290,14 @@ class TrapHandlerTest : public TestWithIsolate,
     masm->Mov(addr,
               i_isolate()->thread_local_top()->thread_in_wasm_flag_address_);
     masm->Str(xzr, MemOperand(addr));
+#elif V8_HOST_ARCH_LOONG64
+    UseScratchRegisterScope temps(masm);
+    Register addr = temps.Acquire();
+    masm->li(
+        addr,
+        static_cast<int64_t>(
+            i_isolate()->thread_local_top()->thread_in_wasm_flag_address_));
+    masm->St_d(zero_reg, MemOperand(addr, 0));
 #else
 #error Unsupported platform
 #endif
@@ -348,6 +375,15 @@ TEST_P(TrapHandlerTest, TestTrapHandlerRecovery) {
   __ Ldr(scratch, MemOperand(scratch));
   uint32_t recovery_offset = __ pc_offset();
   GenerateResetThreadInWasmFlagCode(&masm);
+#elif V8_HOST_ARCH_LOONG64
+  GenerateSetThreadInWasmFlagCode(&masm);
+  UseScratchRegisterScope temps(&masm);
+  Register scratch = temps.Acquire();
+  __ li(scratch, static_cast<int64_t>(crash_address_));
+  uint32_t crash_offset = __ pc_offset();
+  __ Ld_d(scratch, MemOperand(scratch, 0));
+  uint32_t recovery_offset = __ pc_offset();
+  GenerateResetThreadInWasmFlagCode(&masm);
 #else
 #error Unsupported platform
 #endif
@@ -386,6 +422,15 @@ TEST_P(TrapHandlerTest, TestReleaseHandlerData) {
   __ Ldr(scratch, MemOperand(scratch));
   uint32_t recovery_offset = __ pc_offset();
   GenerateResetThreadInWasmFlagCode(&masm);
+#elif V8_HOST_ARCH_LOONG64
+  GenerateSetThreadInWasmFlagCode(&masm);
+  UseScratchRegisterScope temps(&masm);
+  Register scratch = temps.Acquire();
+  __ li(scratch, static_cast<int64_t>(crash_address_));
+  uint32_t crash_offset = __ pc_offset();
+  __ Ld_d(scratch, MemOperand(scratch, 0));
+  uint32_t recovery_offset = __ pc_offset();
+  GenerateResetThreadInWasmFlagCode(&masm);
 #else
 #error Unsupported platform
 #endif
@@ -427,6 +472,13 @@ TEST_P(TrapHandlerTest, TestNoThreadInWasmFlag) {
   uint32_t crash_offset = __ pc_offset();
   __ Ldr(scratch, MemOperand(scratch));
   uint32_t recovery_offset = __ pc_offset();
+#elif V8_HOST_ARCH_LOONG64
+  UseScratchRegisterScope temps(&masm);
+  Register scratch = temps.Acquire();
+  __ li(scratch, static_cast<int64_t>(crash_address_));
+  uint32_t crash_offset = __ pc_offset();
+  __ Ld_d(scratch, MemOperand(scratch, 0));
+  uint32_t recovery_offset = __ pc_offset();
 #else
 #error Unsupported platform
 #endif
@@ -467,6 +519,16 @@ TEST_P(TrapHandlerTest, TestCrashInWasmNoProtectedInstruction) {
   // Offset where the crash is not happening.
   uint32_t recovery_offset = __ pc_offset();
   GenerateResetThreadInWasmFlagCode(&masm);
+#elif V8_HOST_ARCH_LOONG64
+  GenerateSetThreadInWasmFlagCode(&masm);
+  UseScratchRegisterScope temps(&masm);
+  Register scratch = temps.Acquire();
+  uint32_t no_crash_offset = __ pc_offset();
+  __ li(scratch, static_cast<int64_t>(crash_address_));
+  __ Ld_d(scratch, MemOperand(scratch, 0));
+  // Offset where the crash is not happening.
+  uint32_t recovery_offset = __ pc_offset();
+  GenerateResetThreadInWasmFlagCode(&masm);
 #else
 #error Unsupported platform
 #endif
@@ -505,6 +567,14 @@ TEST_P(TrapHandlerTest, TestCrashInWasmWrongCrashType) {
   // Offset where the crash is not happening.
   uint32_t recovery_offset = __ pc_offset();
   GenerateResetThreadInWasmFlagCode(&masm);
+#elif V8_HOST_ARCH_LOONG64
+  GenerateSetThreadInWasmFlagCode(&masm);
+  UseScratchRegisterScope temps(&masm);
+  uint32_t crash_offset = __ pc_offset();
+  __ Trap();
+  // Offset where the crash is not happening.
+  uint32_t recovery_offset = __ pc_offset();
+  GenerateResetThreadInWasmFlagCode(&masm);
 #else
 #error Unsupported platform
 #endif
@@ -575,6 +645,13 @@ TEST_P(TrapHandlerTest, TestCrashInOtherThread) {
   uint32_t crash_offset = __ pc_offset();
   __ Ldr(scratch, MemOperand(scratch));
   uint32_t recovery_offset = __ pc_offset();
+#elif V8_HOST_ARCH_LOONG64
+  UseScratchRegisterScope temps(&masm);
+  Register scratch = temps.Acquire();
+  __ li(scratch, static_cast<int64_t>(crash_address_));
+  uint32_t crash_offset = __ pc_offset();
+  __ Ld_d(scratch, MemOperand(scratch, 0));
+  uint32_t recovery_offset = __ pc_offset();
 #else
 #error Unsupported platform
 #endif
diff --git a/test/unittests/wasm/trap-handler-simulator-unittest.cc b/test/unittests/wasm/trap-handler-simulator-unittest.cc
index 74cef45a025..586c72f6806 100644
--- a/test/unittests/wasm/trap-handler-simulator-unittest.cc
+++ b/test/unittests/wasm/trap-handler-simulator-unittest.cc
@@ -109,6 +109,8 @@ TEST_F(SimulatorTrapHandlerTest, ProbeMemoryWithLandingPad) {
   // Test that the trap handler can recover a memory access violation in
   // wasm code (we fake the wasm code and the access violation).
   std::unique_ptr<TestingAssemblerBuffer> buffer = AllocateAssemblerBuffer();
+
+#ifdef V8_TARGET_ARCH_ARM64
   constexpr Register scratch = x0;
   MacroAssembler masm(nullptr, AssemblerOptions{}, CodeObjectRequired::kNo,
                       buffer->CreateView());
@@ -119,6 +121,20 @@ TEST_F(SimulatorTrapHandlerTest, ProbeMemoryWithLandingPad) {
   uint32_t recovery_offset = masm.pc_offset();
   // Return.
   masm.Ret();
+#elif V8_TARGET_ARCH_LOONG64
+  constexpr Register scratch = a0;
+  MacroAssembler masm(nullptr, AssemblerOptions{}, CodeObjectRequired::kNo,
+                      buffer->CreateView());
+  // Generate an illegal memory access.
+  masm.li(scratch, static_cast<int64_t>(InaccessibleMemoryPtr()));
+  uint32_t crash_offset = masm.pc_offset();
+  masm.St_d(scratch, MemOperand(scratch, 0));  // load from inaccessible memory.
+  uint32_t recovery_offset = masm.pc_offset();
+  // Return.
+  masm.Ret();
+#else
+#error Unsupported platform
+#endif
 
   CodeDesc desc;
   masm.GetCode(static_cast<LocalIsolate*>(nullptr), &desc);
-- 
2.35.1

