From c18eac5f68016e2ddfccad4601e41df8df69c621 Mon Sep 17 00:00:00 2001
From: Clemens Backes <clemensb@chromium.org>
Date: Wed, 3 May 2023 16:21:56 +0200
Subject: [PATCH] [codegen][cleanup] Use uint8_t instead of byte

Byte is an alias for the standard uint8_t type (defined in
src/common/globals.h).
For readability, avoid the alias and use the uint8_t directly.

R=tebbi@chromium.org

Change-Id: I91dc97ff0085c3da429183b8b7be893c4c30fc12
Reviewed-on: https://chromium-review.googlesource.com/c/v8/v8/+/4503232
Commit-Queue: Clemens Backes <clemensb@chromium.org>
Reviewed-by: Tobias Tebbi <tebbi@chromium.org>
Cr-Commit-Position: refs/heads/main@{#87438}
---
 src/codegen/arm/assembler-arm.cc              |  20 +-
 src/codegen/arm/assembler-arm.h               |   2 +-
 src/codegen/arm/constants-arm.h               |   2 +-
 src/codegen/arm64/assembler-arm64.cc          |   6 +-
 src/codegen/arm64/assembler-arm64.h           |   4 +-
 src/codegen/arm64/instructions-arm64.cc       |   4 +-
 src/codegen/arm64/macro-assembler-arm64.cc    |   3 +-
 src/codegen/arm64/macro-assembler-arm64.h     |   2 +-
 src/codegen/assembler.cc                      |  10 +-
 src/codegen/assembler.h                       |   8 +-
 src/codegen/code-desc.h                       |   4 +-
 src/codegen/code-reference.cc                 |  16 +-
 src/codegen/code-reference.h                  |   4 +-
 src/codegen/external-reference.cc             |   2 +-
 src/codegen/ia32/assembler-ia32-inl.h         |   4 +-
 src/codegen/ia32/assembler-ia32.cc            |  91 +++---
 src/codegen/ia32/assembler-ia32.h             |  93 +++---
 src/codegen/loong64/assembler-loong64.cc      |   2 +-
 src/codegen/loong64/assembler-loong64.h       |   2 +-
 src/codegen/loong64/constants-loong64.h       |   2 +-
 src/codegen/machine-type.h                    |   2 +-
 src/codegen/mips64/assembler-mips64.cc        |   8 +-
 src/codegen/mips64/assembler-mips64.h         |   2 +-
 src/codegen/mips64/constants-mips64.h         |   2 +-
 src/codegen/ppc/assembler-ppc.cc              |  12 +-
 src/codegen/ppc/assembler-ppc.h               |   2 +-
 src/codegen/ppc/constants-ppc.h               |   4 +-
 src/codegen/ppc/cpu-ppc.cc                    |   8 +-
 src/codegen/reloc-info.cc                     |  19 +-
 src/codegen/reloc-info.h                      |  22 +-
 src/codegen/riscv/assembler-riscv.cc          |  10 +-
 src/codegen/riscv/base-constants-riscv.h      |   2 +-
 src/codegen/s390/assembler-s390-inl.h         |  44 +--
 src/codegen/s390/assembler-s390.cc            |   2 +-
 src/codegen/s390/assembler-s390.h             |   4 +-
 src/codegen/s390/constants-s390.h             |  30 +-
 .../macro-assembler-shared-ia32-x64.cc        |  42 +--
 .../macro-assembler-shared-ia32-x64.h         |   2 +-
 src/codegen/source-position-table.cc          |  28 +-
 src/codegen/source-position-table.h           |   8 +-
 src/codegen/x64/assembler-x64-inl.h           |  19 +-
 src/codegen/x64/assembler-x64.cc              | 229 +++++++--------
 src/codegen/x64/assembler-x64.h               | 269 ++++++++++--------
 src/codegen/x64/macro-assembler-x64.cc        |  14 +-
 44 files changed, 551 insertions(+), 514 deletions(-)

diff --git a/src/codegen/arm/assembler-arm.cc b/src/codegen/arm/assembler-arm.cc
index 415ce7d3c92..d5ac947f6e4 100644
--- a/src/codegen/arm/assembler-arm.cc
+++ b/src/codegen/arm/assembler-arm.cc
@@ -838,7 +838,7 @@ void Assembler::target_at_put(int pos, int target_pos) {
       // If the target fits in a byte then only patch with a mov
       // instruction.
       PatchingAssembler patcher(
-          options(), reinterpret_cast<byte*>(buffer_start_ + pos), 1);
+          options(), reinterpret_cast<uint8_t*>(buffer_start_ + pos), 1);
       patcher.mov(dst, Operand(target24));
     } else {
       uint16_t target16_0 = target24 & kImm16Mask;
@@ -847,12 +847,12 @@ void Assembler::target_at_put(int pos, int target_pos) {
         // Patch with movw/movt.
         if (target16_1 == 0) {
           PatchingAssembler patcher(
-              options(), reinterpret_cast<byte*>(buffer_start_ + pos), 1);
+              options(), reinterpret_cast<uint8_t*>(buffer_start_ + pos), 1);
           CpuFeatureScope scope(&patcher, ARMv7);
           patcher.movw(dst, target16_0);
         } else {
           PatchingAssembler patcher(
-              options(), reinterpret_cast<byte*>(buffer_start_ + pos), 2);
+              options(), reinterpret_cast<uint8_t*>(buffer_start_ + pos), 2);
           CpuFeatureScope scope(&patcher, ARMv7);
           patcher.movw(dst, target16_0);
           patcher.movt(dst, target16_1);
@@ -864,12 +864,12 @@ void Assembler::target_at_put(int pos, int target_pos) {
         uint8_t target8_2 = target16_1 & kImm8Mask;
         if (target8_2 == 0) {
           PatchingAssembler patcher(
-              options(), reinterpret_cast<byte*>(buffer_start_ + pos), 2);
+              options(), reinterpret_cast<uint8_t*>(buffer_start_ + pos), 2);
           patcher.mov(dst, Operand(target8_0));
           patcher.orr(dst, dst, Operand(target8_1 << 8));
         } else {
           PatchingAssembler patcher(
-              options(), reinterpret_cast<byte*>(buffer_start_ + pos), 3);
+              options(), reinterpret_cast<uint8_t*>(buffer_start_ + pos), 3);
           patcher.mov(dst, Operand(target8_0));
           patcher.orr(dst, dst, Operand(target8_1 << 8));
           patcher.orr(dst, dst, Operand(target8_2 << 16));
@@ -5192,22 +5192,22 @@ void Assembler::GrowBuffer() {
   // Set up new buffer.
   std::unique_ptr<AssemblerBuffer> new_buffer = buffer_->Grow(new_size);
   DCHECK_EQ(new_size, new_buffer->size());
-  byte* new_start = new_buffer->start();
+  uint8_t* new_start = new_buffer->start();
 
   // Copy the data.
   int pc_delta = new_start - buffer_start_;
   int rc_delta = (new_start + new_size) - (buffer_start_ + old_size);
   size_t reloc_size = (buffer_start_ + old_size) - reloc_info_writer.pos();
   MemMove(new_start, buffer_start_, pc_offset());
-  byte* new_reloc_start = reinterpret_cast<byte*>(
+  uint8_t* new_reloc_start = reinterpret_cast<uint8_t*>(
       reinterpret_cast<Address>(reloc_info_writer.pos()) + rc_delta);
   MemMove(new_reloc_start, reloc_info_writer.pos(), reloc_size);
 
   // Switch buffers.
   buffer_ = std::move(new_buffer);
   buffer_start_ = new_start;
-  pc_ = reinterpret_cast<byte*>(reinterpret_cast<Address>(pc_) + pc_delta);
-  byte* new_last_pc = reinterpret_cast<byte*>(
+  pc_ = reinterpret_cast<uint8_t*>(reinterpret_cast<Address>(pc_) + pc_delta);
+  uint8_t* new_last_pc = reinterpret_cast<uint8_t*>(
       reinterpret_cast<Address>(reloc_info_writer.last_pc()) + pc_delta);
   reloc_info_writer.Reposition(new_reloc_start, new_last_pc);
 
@@ -5456,7 +5456,7 @@ void Assembler::CheckConstPool(bool force_emit, bool require_jump) {
 }
 
 PatchingAssembler::PatchingAssembler(const AssemblerOptions& options,
-                                     byte* address, int instructions)
+                                     uint8_t* address, int instructions)
     : Assembler(options, ExternalAssemblerBuffer(
                              address, instructions * kInstrSize + kGap)) {
   DCHECK_EQ(reloc_info_writer.pos(), buffer_start_ + buffer_->size());
diff --git a/src/codegen/arm/assembler-arm.h b/src/codegen/arm/assembler-arm.h
index ea728ef5df0..0f51903fb54 100644
--- a/src/codegen/arm/assembler-arm.h
+++ b/src/codegen/arm/assembler-arm.h
@@ -1358,7 +1358,7 @@ class EnsureSpace {
 
 class PatchingAssembler : public Assembler {
  public:
-  PatchingAssembler(const AssemblerOptions& options, byte* address,
+  PatchingAssembler(const AssemblerOptions& options, uint8_t* address,
                     int instructions);
   ~PatchingAssembler();
 
diff --git a/src/codegen/arm/constants-arm.h b/src/codegen/arm/constants-arm.h
index 5b8636d3b9d..71ff34f30a2 100644
--- a/src/codegen/arm/constants-arm.h
+++ b/src/codegen/arm/constants-arm.h
@@ -436,7 +436,7 @@ inline Hint NegateHint(Hint ignored) { return no_hint; }
 // Example: Test whether the instruction at ptr does set the condition code
 // bits.
 //
-// bool InstructionSetsConditionCodes(byte* ptr) {
+// bool InstructionSetsConditionCodes(uint8_t* ptr) {
 //   Instruction* instr = Instruction::At(ptr);
 //   int type = instr->TypeValue();
 //   return ((type == 0) || (type == 1)) && instr->HasS();
diff --git a/src/codegen/arm64/assembler-arm64.cc b/src/codegen/arm64/assembler-arm64.cc
index 9d606bec5ec..65e7bc6dbda 100644
--- a/src/codegen/arm64/assembler-arm64.cc
+++ b/src/codegen/arm64/assembler-arm64.cc
@@ -519,8 +519,8 @@ void Assembler::RemoveBranchFromLabelLinkChain(Instruction* branch,
       // currently referring to this label.
       label->Unuse();
     } else {
-      label->link_to(
-          static_cast<int>(reinterpret_cast<byte*>(next_link) - buffer_start_));
+      label->link_to(static_cast<int>(reinterpret_cast<uint8_t*>(next_link) -
+                                      buffer_start_));
     }
 
   } else if (branch == next_link) {
@@ -4457,7 +4457,7 @@ void Assembler::GrowBuffer() {
   // Set up new buffer.
   std::unique_ptr<AssemblerBuffer> new_buffer = buffer_->Grow(new_size);
   DCHECK_EQ(new_size, new_buffer->size());
-  byte* new_start = new_buffer->start();
+  uint8_t* new_start = new_buffer->start();
 
   // Copy the data.
   intptr_t pc_delta = new_start - buffer_start_;
diff --git a/src/codegen/arm64/assembler-arm64.h b/src/codegen/arm64/assembler-arm64.h
index 658a927089a..589300ec631 100644
--- a/src/codegen/arm64/assembler-arm64.h
+++ b/src/codegen/arm64/assembler-arm64.h
@@ -2713,7 +2713,7 @@ class V8_EXPORT_PRIVATE Assembler : public AssemblerBase {
   }
 
   ptrdiff_t InstructionOffset(Instruction* instr) const {
-    return reinterpret_cast<byte*>(instr) - buffer_start_;
+    return reinterpret_cast<uint8_t*>(instr) - buffer_start_;
   }
 
   // Register encoding.
@@ -3391,7 +3391,7 @@ class PatchingAssembler : public Assembler {
   // relocation information takes space in the buffer, the PatchingAssembler
   // will crash trying to grow the buffer.
   // Note that the instruction cache will not be flushed.
-  PatchingAssembler(const AssemblerOptions& options, byte* start,
+  PatchingAssembler(const AssemblerOptions& options, uint8_t* start,
                     unsigned count)
       : Assembler(options,
                   ExternalAssemblerBuffer(start, count * kInstrSize + kGap)),
diff --git a/src/codegen/arm64/instructions-arm64.cc b/src/codegen/arm64/instructions-arm64.cc
index 7d986f286d9..3369333f2f1 100644
--- a/src/codegen/arm64/instructions-arm64.cc
+++ b/src/codegen/arm64/instructions-arm64.cc
@@ -245,7 +245,7 @@ void Instruction::SetPCRelImmTarget(const AssemblerOptions& options,
     imm = Assembler::ImmPCRelAddress(static_cast<int>(target_offset));
     SetInstructionBits(Mask(~ImmPCRel_mask) | imm);
   } else {
-    PatchingAssembler patcher(options, reinterpret_cast<byte*>(this),
+    PatchingAssembler patcher(options, reinterpret_cast<uint8_t*>(this),
                               PatchingAssembler::kAdrFarPatchableNInstrs);
     patcher.PatchAdrFar(target_offset);
   }
@@ -294,7 +294,7 @@ void Instruction::SetUnresolvedInternalReferenceImmTarget(
   uint32_t high16 = unsigned_bitextract_32(31, 16, target_offset);
   uint32_t low16 = unsigned_bitextract_32(15, 0, target_offset);
 
-  PatchingAssembler patcher(options, reinterpret_cast<byte*>(this), 2);
+  PatchingAssembler patcher(options, reinterpret_cast<uint8_t*>(this), 2);
   patcher.brk(high16);
   patcher.brk(low16);
 }
diff --git a/src/codegen/arm64/macro-assembler-arm64.cc b/src/codegen/arm64/macro-assembler-arm64.cc
index aded378f202..000b22ac61f 100644
--- a/src/codegen/arm64/macro-assembler-arm64.cc
+++ b/src/codegen/arm64/macro-assembler-arm64.cc
@@ -2192,7 +2192,8 @@ void MacroAssembler::JumpHelper(int64_t offset, RelocInfo::Mode rmode,
 // * the offset of the target from the current PC, in instructions, for any
 //   other type of call.
 int64_t MacroAssembler::CalculateTargetOffset(Address target,
-                                              RelocInfo::Mode rmode, byte* pc) {
+                                              RelocInfo::Mode rmode,
+                                              uint8_t* pc) {
   int64_t offset = static_cast<int64_t>(target);
   if (rmode == RelocInfo::WASM_CALL || rmode == RelocInfo::WASM_STUB_CALL) {
     // The target of WebAssembly calls is still an index instead of an actual
diff --git a/src/codegen/arm64/macro-assembler-arm64.h b/src/codegen/arm64/macro-assembler-arm64.h
index d3e9cde7215..c74c562ba65 100644
--- a/src/codegen/arm64/macro-assembler-arm64.h
+++ b/src/codegen/arm64/macro-assembler-arm64.h
@@ -2217,7 +2217,7 @@ class V8_EXPORT_PRIVATE MacroAssembler : public MacroAssemblerBase {
                           const MemOperand& addr, LoadStorePairOp op);
 
   int64_t CalculateTargetOffset(Address target, RelocInfo::Mode rmode,
-                                byte* pc);
+                                uint8_t* pc);
 
   void JumpHelper(int64_t offset, RelocInfo::Mode rmode, Condition cond = al);
 
diff --git a/src/codegen/assembler.cc b/src/codegen/assembler.cc
index 1ff8ad10ca6..03989f5bf13 100644
--- a/src/codegen/assembler.cc
+++ b/src/codegen/assembler.cc
@@ -97,7 +97,7 @@ class DefaultAssemblerBuffer : public AssemblerBuffer {
 #endif
   }
 
-  byte* start() const override { return buffer_.begin(); }
+  uint8_t* start() const override { return buffer_.begin(); }
 
   int size() const override { return static_cast<int>(buffer_.size()); }
 
@@ -112,10 +112,10 @@ class DefaultAssemblerBuffer : public AssemblerBuffer {
 
 class ExternalAssemblerBufferImpl : public AssemblerBuffer {
  public:
-  ExternalAssemblerBufferImpl(byte* start, int size)
+  ExternalAssemblerBufferImpl(uint8_t* start, int size)
       : start_(start), size_(size) {}
 
-  byte* start() const override { return start_; }
+  uint8_t* start() const override { return start_; }
 
   int size() const override { return size_; }
 
@@ -127,7 +127,7 @@ class ExternalAssemblerBufferImpl : public AssemblerBuffer {
   void operator delete(void* ptr) noexcept;
 
  private:
-  byte* const start_;
+  uint8_t* const start_;
   const int size_;
 };
 
@@ -160,7 +160,7 @@ void ExternalAssemblerBufferImpl::operator delete(void* ptr) noexcept {
 std::unique_ptr<AssemblerBuffer> ExternalAssemblerBuffer(void* start,
                                                          int size) {
   return std::make_unique<ExternalAssemblerBufferImpl>(
-      reinterpret_cast<byte*>(start), size);
+      reinterpret_cast<uint8_t*>(start), size);
 }
 
 std::unique_ptr<AssemblerBuffer> NewAssemblerBuffer(int size) {
diff --git a/src/codegen/assembler.h b/src/codegen/assembler.h
index 553fe9004fc..73b96407411 100644
--- a/src/codegen/assembler.h
+++ b/src/codegen/assembler.h
@@ -255,7 +255,7 @@ struct V8_EXPORT_PRIVATE AssemblerOptions {
 class AssemblerBuffer {
  public:
   virtual ~AssemblerBuffer() = default;
-  virtual byte* start() const = 0;
+  virtual uint8_t* start() const = 0;
   virtual int size() const = 0;
   // Return a grown copy of this buffer. The contained data is uninitialized.
   // The data in {this} will still be read afterwards (until {this} is
@@ -336,7 +336,7 @@ class V8_EXPORT_PRIVATE AssemblerBase : public Malloced {
 #endif
   }
 
-  byte* buffer_start() const { return buffer_->start(); }
+  uint8_t* buffer_start() const { return buffer_->start(); }
   int buffer_size() const { return buffer_->size(); }
   int instruction_size() const { return pc_offset(); }
 
@@ -423,11 +423,11 @@ class V8_EXPORT_PRIVATE AssemblerBase : public Malloced {
   // The buffer into which code and relocation info are generated.
   std::unique_ptr<AssemblerBuffer> buffer_;
   // Cached from {buffer_->start()}, for faster access.
-  byte* buffer_start_;
+  uint8_t* buffer_start_;
   std::forward_list<HeapNumberRequest> heap_number_requests_;
   // The program counter, which points into the buffer above and moves forward.
   // TODO(jkummerow): This should probably have type {Address}.
-  byte* pc_;
+  uint8_t* pc_;
 
   void set_constant_pool_available(bool available) {
     if (V8_EMBEDDED_CONSTANT_POOL_BOOL) {
diff --git a/src/codegen/code-desc.h b/src/codegen/code-desc.h
index 7aed2eb9621..2f74cdb9c7c 100644
--- a/src/codegen/code-desc.h
+++ b/src/codegen/code-desc.h
@@ -41,7 +41,7 @@ class CodeDesc {
 #endif
 
  public:
-  byte* buffer = nullptr;
+  uint8_t* buffer = nullptr;
   int buffer_size = 0;
 
   // The instruction area contains executable code plus inlined metadata.
@@ -88,7 +88,7 @@ class CodeDesc {
 
   // Unwinding information.
 
-  byte* unwinding_info = nullptr;
+  uint8_t* unwinding_info = nullptr;
   int unwinding_info_size = 0;
   int unwinding_info_offset_relative() const {
     // TODO(jgruber,v8:11036): Remove this function once unwinding_info setup
diff --git a/src/codegen/code-reference.cc b/src/codegen/code-reference.cc
index 702a85e06dc..7f3893e3940 100644
--- a/src/codegen/code-reference.cc
+++ b/src/codegen/code-reference.cc
@@ -25,8 +25,8 @@ struct CodeOps {
   Address instruction_start() const { return code->instruction_start(); }
   Address instruction_end() const { return code->instruction_end(); }
   int instruction_size() const { return code->instruction_size(); }
-  const byte* relocation_start() const { return code->relocation_start(); }
-  const byte* relocation_end() const { return code->relocation_end(); }
+  const uint8_t* relocation_start() const { return code->relocation_start(); }
+  const uint8_t* relocation_end() const { return code->relocation_end(); }
   int relocation_size() const { return code->relocation_size(); }
   Address code_comments() const { return code->code_comments(); }
   int code_comments_size() const { return code->code_comments_size(); }
@@ -45,8 +45,8 @@ struct WasmCodeOps {
                                      code->instructions().size());
   }
   int instruction_size() const { return code->instructions().length(); }
-  const byte* relocation_start() const { return code->reloc_info().begin(); }
-  const byte* relocation_end() const {
+  const uint8_t* relocation_start() const { return code->reloc_info().begin(); }
+  const uint8_t* relocation_end() const {
     return code->reloc_info().begin() + code->reloc_info().length();
   }
   int relocation_size() const { return code->reloc_info().length(); }
@@ -68,10 +68,10 @@ struct CodeDescOps {
     return instruction_start() + code_desc->instr_size;
   }
   int instruction_size() const { return code_desc->instr_size; }
-  const byte* relocation_start() const {
+  const uint8_t* relocation_start() const {
     return code_desc->buffer + code_desc->reloc_offset;
   }
-  const byte* relocation_end() const {
+  const uint8_t* relocation_end() const {
     return code_desc->buffer + code_desc->buffer_size;
   }
   int relocation_size() const { return code_desc->reloc_size; }
@@ -107,8 +107,8 @@ DISPATCH(Address, constant_pool)
 DISPATCH(Address, instruction_start)
 DISPATCH(Address, instruction_end)
 DISPATCH(int, instruction_size)
-DISPATCH(const byte*, relocation_start)
-DISPATCH(const byte*, relocation_end)
+DISPATCH(const uint8_t*, relocation_start)
+DISPATCH(const uint8_t*, relocation_end)
 DISPATCH(int, relocation_size)
 DISPATCH(Address, code_comments)
 DISPATCH(int, code_comments_size)
diff --git a/src/codegen/code-reference.h b/src/codegen/code-reference.h
index 8ba313aec14..c44ec54252e 100644
--- a/src/codegen/code-reference.h
+++ b/src/codegen/code-reference.h
@@ -33,8 +33,8 @@ class CodeReference {
   Address instruction_start() const;
   Address instruction_end() const;
   int instruction_size() const;
-  const byte* relocation_start() const;
-  const byte* relocation_end() const;
+  const uint8_t* relocation_start() const;
+  const uint8_t* relocation_end() const;
   int relocation_size() const;
   Address code_comments() const;
   int code_comments_size() const;
diff --git a/src/codegen/external-reference.cc b/src/codegen/external-reference.cc
index f45ac6ead71..f04618989e0 100644
--- a/src/codegen/external-reference.cc
+++ b/src/codegen/external-reference.cc
@@ -946,7 +946,7 @@ void* libc_memmove(void* dest, const void* src, size_t n) {
 FUNCTION_REFERENCE(libc_memmove_function, libc_memmove)
 
 void* libc_memset(void* dest, int value, size_t n) {
-  DCHECK_EQ(static_cast<byte>(value), value);
+  DCHECK_EQ(static_cast<uint8_t>(value), value);
   return memset(dest, value, n);
 }
 
diff --git a/src/codegen/ia32/assembler-ia32-inl.h b/src/codegen/ia32/assembler-ia32-inl.h
index c7c13cc7ce2..18a3b069bea 100644
--- a/src/codegen/ia32/assembler-ia32-inl.h
+++ b/src/codegen/ia32/assembler-ia32-inl.h
@@ -246,11 +246,11 @@ void Assembler::emit_disp(Label* L, Displacement::Type type) {
 }
 
 void Assembler::emit_near_disp(Label* L) {
-  byte disp = 0x00;
+  uint8_t disp = 0x00;
   if (L->is_near_linked()) {
     int offset = L->near_link_pos() - pc_offset();
     DCHECK(is_int8(offset));
-    disp = static_cast<byte>(offset & 0xFF);
+    disp = static_cast<uint8_t>(offset & 0xFF);
   }
   L->link_to(pc_offset(), Label::kNear);
   *pc_++ = disp;
diff --git a/src/codegen/ia32/assembler-ia32.cc b/src/codegen/ia32/assembler-ia32.cc
index fd56e914dcf..c7867969483 100644
--- a/src/codegen/ia32/assembler-ia32.cc
+++ b/src/codegen/ia32/assembler-ia32.cc
@@ -391,7 +391,7 @@ void Assembler::Align(int m) {
 }
 
 bool Assembler::IsNop(Address addr) {
-  byte* a = reinterpret_cast<byte*>(addr);
+  uint8_t* a = reinterpret_cast<uint8_t*>(addr);
   while (*a == 0x66) a++;
   if (*a == 0x90) return true;
   if (a[0] == 0xF && a[1] == 0x1F) return true;
@@ -1801,7 +1801,7 @@ void Assembler::j(Condition cc, Label* L, Label::Distance distance) {
   }
 }
 
-void Assembler::j(Condition cc, byte* entry, RelocInfo::Mode rmode) {
+void Assembler::j(Condition cc, uint8_t* entry, RelocInfo::Mode rmode) {
   EnsureSpace ensure_space(this);
   DCHECK((0 <= cc) && (static_cast<int>(cc) < 16));
   // 0000 1111 1000 tttn #32-bit disp.
@@ -2285,7 +2285,7 @@ void Assembler::roundps(XMMRegister dst, XMMRegister src, RoundingMode mode) {
   EMIT(0x08);
   emit_sse_operand(dst, src);
   // Mask precision exeption.
-  EMIT(static_cast<byte>(mode) | 0x8);
+  EMIT(static_cast<uint8_t>(mode) | 0x8);
 }
 
 void Assembler::roundpd(XMMRegister dst, XMMRegister src, RoundingMode mode) {
@@ -2297,7 +2297,7 @@ void Assembler::roundpd(XMMRegister dst, XMMRegister src, RoundingMode mode) {
   EMIT(0x09);
   emit_sse_operand(dst, src);
   // Mask precision exeption.
-  EMIT(static_cast<byte>(mode) | 0x8);
+  EMIT(static_cast<uint8_t>(mode) | 0x8);
 }
 
 void Assembler::roundss(XMMRegister dst, XMMRegister src, RoundingMode mode) {
@@ -2309,7 +2309,7 @@ void Assembler::roundss(XMMRegister dst, XMMRegister src, RoundingMode mode) {
   EMIT(0x0A);
   emit_sse_operand(dst, src);
   // Mask precision exeption.
-  EMIT(static_cast<byte>(mode) | 0x8);
+  EMIT(static_cast<uint8_t>(mode) | 0x8);
 }
 
 void Assembler::roundsd(XMMRegister dst, XMMRegister src, RoundingMode mode) {
@@ -2321,7 +2321,7 @@ void Assembler::roundsd(XMMRegister dst, XMMRegister src, RoundingMode mode) {
   EMIT(0x0B);
   emit_sse_operand(dst, src);
   // Mask precision exeption.
-  EMIT(static_cast<byte>(mode) | 0x8);
+  EMIT(static_cast<uint8_t>(mode) | 0x8);
 }
 
 void Assembler::movmskpd(Register dst, XMMRegister src) {
@@ -2395,7 +2395,7 @@ void Assembler::movshdup(XMMRegister dst, XMMRegister src) {
   emit_sse_operand(dst, src);
 }
 
-void Assembler::shufps(XMMRegister dst, XMMRegister src, byte imm8) {
+void Assembler::shufps(XMMRegister dst, XMMRegister src, uint8_t imm8) {
   DCHECK(is_uint8(imm8));
   EnsureSpace ensure_space(this);
   EMIT(0x0F);
@@ -2404,7 +2404,7 @@ void Assembler::shufps(XMMRegister dst, XMMRegister src, byte imm8) {
   EMIT(imm8);
 }
 
-void Assembler::shufpd(XMMRegister dst, XMMRegister src, byte imm8) {
+void Assembler::shufpd(XMMRegister dst, XMMRegister src, uint8_t imm8) {
   DCHECK(is_uint8(imm8));
   EnsureSpace ensure_space(this);
   EMIT(0x66);
@@ -2562,7 +2562,7 @@ void Assembler::movd(Operand dst, XMMRegister src) {
   emit_sse_operand(src, dst);
 }
 
-void Assembler::extractps(Operand dst, XMMRegister src, byte imm8) {
+void Assembler::extractps(Operand dst, XMMRegister src, uint8_t imm8) {
   DCHECK(IsEnabled(SSE4_1));
   DCHECK(is_uint8(imm8));
   EnsureSpace ensure_space(this);
@@ -2574,7 +2574,7 @@ void Assembler::extractps(Operand dst, XMMRegister src, byte imm8) {
   EMIT(imm8);
 }
 
-void Assembler::extractps(Register dst, XMMRegister src, byte imm8) {
+void Assembler::extractps(Register dst, XMMRegister src, uint8_t imm8) {
   DCHECK(IsEnabled(SSE4_1));
   DCHECK(is_uint8(imm8));
   EnsureSpace ensure_space(this);
@@ -2857,7 +2857,7 @@ void Assembler::minss(XMMRegister dst, Operand src) {
 }
 
 // Packed single-precision floating-point SSE instructions.
-void Assembler::ps(byte opcode, XMMRegister dst, Operand src) {
+void Assembler::ps(uint8_t opcode, XMMRegister dst, Operand src) {
   EnsureSpace ensure_space(this);
   EMIT(0x0F);
   EMIT(opcode);
@@ -2865,7 +2865,7 @@ void Assembler::ps(byte opcode, XMMRegister dst, Operand src) {
 }
 
 // Packed double-precision floating-point SSE instructions.
-void Assembler::pd(byte opcode, XMMRegister dst, Operand src) {
+void Assembler::pd(uint8_t opcode, XMMRegister dst, Operand src) {
   EnsureSpace ensure_space(this);
   EMIT(0x66);
   EMIT(0x0F);
@@ -2875,20 +2875,23 @@ void Assembler::pd(byte opcode, XMMRegister dst, Operand src) {
 
 // AVX instructions
 
-void Assembler::vss(byte op, XMMRegister dst, XMMRegister src1, Operand src2) {
+void Assembler::vss(uint8_t op, XMMRegister dst, XMMRegister src1,
+                    Operand src2) {
   vinstr(op, dst, src1, src2, kF3, k0F, kWIG);
 }
 
-void Assembler::vps(byte op, XMMRegister dst, XMMRegister src1, Operand src2) {
+void Assembler::vps(uint8_t op, XMMRegister dst, XMMRegister src1,
+                    Operand src2) {
   vinstr(op, dst, src1, src2, kNoPrefix, k0F, kWIG);
 }
 
-void Assembler::vpd(byte op, XMMRegister dst, XMMRegister src1, Operand src2) {
+void Assembler::vpd(uint8_t op, XMMRegister dst, XMMRegister src1,
+                    Operand src2) {
   vinstr(op, dst, src1, src2, k66, k0F, kWIG);
 }
 
 void Assembler::vshufpd(XMMRegister dst, XMMRegister src1, Operand src2,
-                        byte imm8) {
+                        uint8_t imm8) {
   DCHECK(is_uint8(imm8));
   vpd(0xC6, dst, src1, src2);
   EMIT(imm8);
@@ -2931,7 +2934,7 @@ void Assembler::vcmppd(XMMRegister dst, XMMRegister src1, Operand src2,
 }
 
 void Assembler::vshufps(XMMRegister dst, XMMRegister src1, Operand src2,
-                        byte imm8) {
+                        uint8_t imm8) {
   DCHECK(is_uint8(imm8));
   vps(0xC6, dst, src1, src2);
   EMIT(imm8);
@@ -3072,20 +3075,20 @@ void Assembler::vpinsrd(XMMRegister dst, XMMRegister src1, Operand src2,
 void Assembler::vroundsd(XMMRegister dst, XMMRegister src1, XMMRegister src2,
                          RoundingMode mode) {
   vinstr(0x0b, dst, src1, src2, k66, k0F3A, kWIG);
-  EMIT(static_cast<byte>(mode) | 0x8);  // Mask precision exception.
+  EMIT(static_cast<uint8_t>(mode) | 0x8);  // Mask precision exception.
 }
 void Assembler::vroundss(XMMRegister dst, XMMRegister src1, XMMRegister src2,
                          RoundingMode mode) {
   vinstr(0x0a, dst, src1, src2, k66, k0F3A, kWIG);
-  EMIT(static_cast<byte>(mode) | 0x8);  // Mask precision exception.
+  EMIT(static_cast<uint8_t>(mode) | 0x8);  // Mask precision exception.
 }
 void Assembler::vroundps(XMMRegister dst, XMMRegister src, RoundingMode mode) {
   vinstr(0x08, dst, xmm0, Operand(src), k66, k0F3A, kWIG);
-  EMIT(static_cast<byte>(mode) | 0x8);  // Mask precision exception.
+  EMIT(static_cast<uint8_t>(mode) | 0x8);  // Mask precision exception.
 }
 void Assembler::vroundpd(XMMRegister dst, XMMRegister src, RoundingMode mode) {
   vinstr(0x09, dst, xmm0, Operand(src), k66, k0F3A, kWIG);
-  EMIT(static_cast<byte>(mode) | 0x8);  // Mask precision exception.
+  EMIT(static_cast<uint8_t>(mode) | 0x8);  // Mask precision exception.
 }
 
 void Assembler::vmovmskpd(Register dst, XMMRegister src) {
@@ -3112,7 +3115,7 @@ void Assembler::vpmovmskb(Register dst, XMMRegister src) {
   emit_sse_operand(dst, src);
 }
 
-void Assembler::vextractps(Operand dst, XMMRegister src, byte imm8) {
+void Assembler::vextractps(Operand dst, XMMRegister src, uint8_t imm8) {
   vinstr(0x17, src, xmm0, dst, k66, k0F3A, VexW::kWIG);
   EMIT(imm8);
 }
@@ -3121,7 +3124,7 @@ void Assembler::vpcmpgtq(XMMRegister dst, XMMRegister src1, XMMRegister src2) {
   vinstr(0x37, dst, src1, src2, k66, k0F38, VexW::kWIG);
 }
 
-void Assembler::bmi1(byte op, Register reg, Register vreg, Operand rm) {
+void Assembler::bmi1(uint8_t op, Register reg, Register vreg, Operand rm) {
   DCHECK(IsEnabled(BMI1));
   EnsureSpace ensure_space(this);
   emit_vex_prefix(vreg, kLZ, kNoPrefix, k0F38, kW0);
@@ -3156,7 +3159,7 @@ void Assembler::popcnt(Register dst, Operand src) {
   emit_operand(dst, src);
 }
 
-void Assembler::bmi2(SIMDPrefix pp, byte op, Register reg, Register vreg,
+void Assembler::bmi2(SIMDPrefix pp, uint8_t op, Register reg, Register vreg,
                      Operand rm) {
   DCHECK(IsEnabled(BMI2));
   EnsureSpace ensure_space(this);
@@ -3165,7 +3168,7 @@ void Assembler::bmi2(SIMDPrefix pp, byte op, Register reg, Register vreg,
   emit_operand(reg, rm);
 }
 
-void Assembler::rorx(Register dst, Operand src, byte imm8) {
+void Assembler::rorx(Register dst, Operand src, uint8_t imm8) {
   DCHECK(IsEnabled(BMI2));
   DCHECK(is_uint8(imm8));
   Register vreg = Register::from_code(0);  // VEX.vvvv unused
@@ -3176,16 +3179,16 @@ void Assembler::rorx(Register dst, Operand src, byte imm8) {
   EMIT(imm8);
 }
 
-void Assembler::sse_instr(XMMRegister dst, Operand src, byte escape,
-                          byte opcode) {
+void Assembler::sse_instr(XMMRegister dst, Operand src, uint8_t escape,
+                          uint8_t opcode) {
   EnsureSpace ensure_space(this);
   EMIT(escape);
   EMIT(opcode);
   emit_sse_operand(dst, src);
 }
 
-void Assembler::sse2_instr(XMMRegister dst, Operand src, byte prefix,
-                           byte escape, byte opcode) {
+void Assembler::sse2_instr(XMMRegister dst, Operand src, uint8_t prefix,
+                           uint8_t escape, uint8_t opcode) {
   EnsureSpace ensure_space(this);
   EMIT(prefix);
   EMIT(escape);
@@ -3193,8 +3196,8 @@ void Assembler::sse2_instr(XMMRegister dst, Operand src, byte prefix,
   emit_sse_operand(dst, src);
 }
 
-void Assembler::ssse3_instr(XMMRegister dst, Operand src, byte prefix,
-                            byte escape1, byte escape2, byte opcode) {
+void Assembler::ssse3_instr(XMMRegister dst, Operand src, uint8_t prefix,
+                            uint8_t escape1, uint8_t escape2, uint8_t opcode) {
   DCHECK(IsEnabled(SSSE3));
   EnsureSpace ensure_space(this);
   EMIT(prefix);
@@ -3204,8 +3207,8 @@ void Assembler::ssse3_instr(XMMRegister dst, Operand src, byte prefix,
   emit_sse_operand(dst, src);
 }
 
-void Assembler::sse4_instr(XMMRegister dst, Operand src, byte prefix,
-                           byte escape1, byte escape2, byte opcode) {
+void Assembler::sse4_instr(XMMRegister dst, Operand src, uint8_t prefix,
+                           uint8_t escape1, uint8_t escape2, uint8_t opcode) {
   DCHECK(IsEnabled(SSE4_1));
   EnsureSpace ensure_space(this);
   EMIT(prefix);
@@ -3215,19 +3218,19 @@ void Assembler::sse4_instr(XMMRegister dst, Operand src, byte prefix,
   emit_sse_operand(dst, src);
 }
 
-void Assembler::vinstr(byte op, XMMRegister dst, XMMRegister src1,
+void Assembler::vinstr(uint8_t op, XMMRegister dst, XMMRegister src1,
                        XMMRegister src2, SIMDPrefix pp, LeadingOpcode m, VexW w,
                        CpuFeature feature) {
   vinstr(op, dst, src1, src2, kL128, pp, m, w, feature);
 }
 
-void Assembler::vinstr(byte op, XMMRegister dst, XMMRegister src1, Operand src2,
-                       SIMDPrefix pp, LeadingOpcode m, VexW w,
+void Assembler::vinstr(uint8_t op, XMMRegister dst, XMMRegister src1,
+                       Operand src2, SIMDPrefix pp, LeadingOpcode m, VexW w,
                        CpuFeature feature) {
   vinstr(op, dst, src1, src2, kL128, pp, m, w, feature);
 }
 
-void Assembler::vinstr(byte op, XMMRegister dst, XMMRegister src1,
+void Assembler::vinstr(uint8_t op, XMMRegister dst, XMMRegister src1,
                        XMMRegister src2, VectorLength l, SIMDPrefix pp,
                        LeadingOpcode m, VexW w, CpuFeature feature) {
   DCHECK(IsEnabled(feature));
@@ -3237,9 +3240,9 @@ void Assembler::vinstr(byte op, XMMRegister dst, XMMRegister src1,
   emit_sse_operand(dst, src2);
 }
 
-void Assembler::vinstr(byte op, XMMRegister dst, XMMRegister src1, Operand src2,
-                       VectorLength l, SIMDPrefix pp, LeadingOpcode m, VexW w,
-                       CpuFeature feature) {
+void Assembler::vinstr(uint8_t op, XMMRegister dst, XMMRegister src1,
+                       Operand src2, VectorLength l, SIMDPrefix pp,
+                       LeadingOpcode m, VexW w, CpuFeature feature) {
   DCHECK(IsEnabled(feature));
   EnsureSpace ensure_space(this);
   emit_vex_prefix(src1, l, pp, m, w);
@@ -3300,7 +3303,7 @@ void Assembler::GrowBuffer() {
   // Set up new buffer.
   std::unique_ptr<AssemblerBuffer> new_buffer = buffer_->Grow(new_size);
   DCHECK_EQ(new_size, new_buffer->size());
-  byte* new_start = new_buffer->start();
+  uint8_t* new_start = new_buffer->start();
 
   // Copy the data.
   intptr_t pc_delta = new_start - buffer_start_;
@@ -3326,9 +3329,9 @@ void Assembler::GrowBuffer() {
   // Relocate pc-relative references.
   int mode_mask = RelocInfo::ModeMask(RelocInfo::OFF_HEAP_TARGET);
   DCHECK_EQ(mode_mask, RelocInfo::kApplyMask & mode_mask);
-  base::Vector<byte> instructions{buffer_start_,
-                                  static_cast<size_t>(pc_offset())};
-  base::Vector<const byte> reloc_info{reloc_info_writer.pos(), reloc_size};
+  base::Vector<uint8_t> instructions{buffer_start_,
+                                     static_cast<size_t>(pc_offset())};
+  base::Vector<const uint8_t> reloc_info{reloc_info_writer.pos(), reloc_size};
   for (RelocIterator it(instructions, reloc_info, 0, mode_mask); !it.done();
        it.next()) {
     it.rinfo()->apply(pc_delta);
diff --git a/src/codegen/ia32/assembler-ia32.h b/src/codegen/ia32/assembler-ia32.h
index 1c1cf863930..8251a5d5874 100644
--- a/src/codegen/ia32/assembler-ia32.h
+++ b/src/codegen/ia32/assembler-ia32.h
@@ -281,7 +281,7 @@ class V8_EXPORT_PRIVATE Operand {
   // register.
   Register reg() const;
 
-  base::Vector<const byte> encoded_bytes() const { return {buf_, len_}; }
+  base::Vector<const uint8_t> encoded_bytes() const { return {buf_, len_}; }
   RelocInfo::Mode rmode() { return rmode_; }
 
  private:
@@ -308,7 +308,7 @@ class V8_EXPORT_PRIVATE Operand {
            && ((buf_[0] & 0x07) == reg_code);  // register codes match.
   }
 
-  byte buf_[6];
+  uint8_t buf_[6];
   // The number of bytes in buf_.
   uint8_t len_ = 0;
   // Only valid if len_ > 4.
@@ -435,18 +435,18 @@ class V8_EXPORT_PRIVATE Assembler : public AssemblerBase {
   static constexpr int kSpecialTargetSize = kSystemPointerSize;
 
   // One byte opcode for test al, 0xXX.
-  static constexpr byte kTestAlByte = 0xA8;
+  static constexpr uint8_t kTestAlByte = 0xA8;
   // One byte opcode for nop.
-  static constexpr byte kNopByte = 0x90;
+  static constexpr uint8_t kNopByte = 0x90;
 
   // One byte opcode for a short unconditional jump.
-  static constexpr byte kJmpShortOpcode = 0xEB;
+  static constexpr uint8_t kJmpShortOpcode = 0xEB;
   // One byte prefix for a short conditional jump.
-  static constexpr byte kJccShortPrefix = 0x70;
-  static constexpr byte kJncShortOpcode = kJccShortPrefix | not_carry;
-  static constexpr byte kJcShortOpcode = kJccShortPrefix | carry;
-  static constexpr byte kJnzShortOpcode = kJccShortPrefix | not_zero;
-  static constexpr byte kJzShortOpcode = kJccShortPrefix | zero;
+  static constexpr uint8_t kJccShortPrefix = 0x70;
+  static constexpr uint8_t kJncShortOpcode = kJccShortPrefix | not_carry;
+  static constexpr uint8_t kJcShortOpcode = kJccShortPrefix | carry;
+  static constexpr uint8_t kJnzShortOpcode = kJccShortPrefix | not_zero;
+  static constexpr uint8_t kJzShortOpcode = kJccShortPrefix | zero;
 
   // ---------------------------------------------------------------------------
   // InstructionStream generation
@@ -778,7 +778,7 @@ class V8_EXPORT_PRIVATE Assembler : public AssemblerBase {
 
   // Conditional jumps
   void j(Condition cc, Label* L, Label::Distance distance = Label::kFar);
-  void j(Condition cc, byte* entry, RelocInfo::Mode rmode);
+  void j(Condition cc, uint8_t* entry, RelocInfo::Mode rmode);
   void j(Condition cc, Handle<Code> code,
          RelocInfo::Mode rmode = RelocInfo::CODE_TARGET);
 
@@ -880,8 +880,8 @@ class V8_EXPORT_PRIVATE Assembler : public AssemblerBase {
   void movups(XMMRegister dst, XMMRegister src) { movups(dst, Operand(src)); }
   void movups(XMMRegister dst, Operand src);
   void movups(Operand dst, XMMRegister src);
-  void shufps(XMMRegister dst, XMMRegister src, byte imm8);
-  void shufpd(XMMRegister dst, XMMRegister src, byte imm8);
+  void shufps(XMMRegister dst, XMMRegister src, uint8_t imm8);
+  void shufpd(XMMRegister dst, XMMRegister src, uint8_t imm8);
 
   void movhlps(XMMRegister dst, XMMRegister src);
   void movlhps(XMMRegister dst, XMMRegister src);
@@ -1006,8 +1006,8 @@ class V8_EXPORT_PRIVATE Assembler : public AssemblerBase {
   void movss(Operand dst, XMMRegister src);
   void movss(XMMRegister dst, XMMRegister src) { movss(dst, Operand(src)); }
 
-  void extractps(Operand dst, XMMRegister src, byte imm8);
-  void extractps(Register dst, XMMRegister src, byte imm8);
+  void extractps(Operand dst, XMMRegister src, uint8_t imm8);
+  void extractps(Register dst, XMMRegister src, uint8_t imm8);
 
   void pcmpgtq(XMMRegister dst, XMMRegister src);
 
@@ -1125,7 +1125,7 @@ class V8_EXPORT_PRIVATE Assembler : public AssemblerBase {
   void vsqrtss(XMMRegister dst, XMMRegister src1, Operand src2) {
     vss(0x51, dst, src1, src2);
   }
-  void vss(byte op, XMMRegister dst, XMMRegister src1, Operand src2);
+  void vss(uint8_t op, XMMRegister dst, XMMRegister src1, Operand src2);
 
   void vhaddps(XMMRegister dst, XMMRegister src1, XMMRegister src2) {
     vhaddps(dst, src1, Operand(src2));
@@ -1156,7 +1156,7 @@ class V8_EXPORT_PRIVATE Assembler : public AssemblerBase {
     vinstr(0x10, dst, xmm0, src, kF2, k0F, kWIG);
   }
 
-  void vextractps(Operand dst, XMMRegister src, byte imm8);
+  void vextractps(Operand dst, XMMRegister src, uint8_t imm8);
 
   void vpcmpgtq(XMMRegister dst, XMMRegister src1, XMMRegister src2);
 
@@ -1168,14 +1168,16 @@ class V8_EXPORT_PRIVATE Assembler : public AssemblerBase {
   void vmovups(XMMRegister dst, XMMRegister src) { vmovups(dst, Operand(src)); }
   void vmovups(XMMRegister dst, Operand src) { vps(0x10, dst, xmm0, src); }
   void vmovupd(XMMRegister dst, Operand src) { vpd(0x10, dst, xmm0, src); }
-  void vshufps(XMMRegister dst, XMMRegister src1, XMMRegister src2, byte imm8) {
+  void vshufps(XMMRegister dst, XMMRegister src1, XMMRegister src2,
+               uint8_t imm8) {
     vshufps(dst, src1, Operand(src2), imm8);
   }
-  void vshufps(XMMRegister dst, XMMRegister src1, Operand src2, byte imm8);
-  void vshufpd(XMMRegister dst, XMMRegister src1, XMMRegister src2, byte imm8) {
+  void vshufps(XMMRegister dst, XMMRegister src1, Operand src2, uint8_t imm8);
+  void vshufpd(XMMRegister dst, XMMRegister src1, XMMRegister src2,
+               uint8_t imm8) {
     vshufpd(dst, src1, Operand(src2), imm8);
   }
-  void vshufpd(XMMRegister dst, XMMRegister src1, Operand src2, byte imm8);
+  void vshufpd(XMMRegister dst, XMMRegister src1, Operand src2, uint8_t imm8);
 
   void vmovhlps(XMMRegister dst, XMMRegister src1, XMMRegister src2);
   void vmovlhps(XMMRegister dst, XMMRegister src1, XMMRegister src2);
@@ -1429,15 +1431,15 @@ class V8_EXPORT_PRIVATE Assembler : public AssemblerBase {
   void shrx(Register dst, Operand src1, Register src2) {
     bmi2(kF2, 0xf7, dst, src2, src1);
   }
-  void rorx(Register dst, Register src, byte imm8) {
+  void rorx(Register dst, Register src, uint8_t imm8) {
     rorx(dst, Operand(src), imm8);
   }
-  void rorx(Register dst, Operand src, byte imm8);
+  void rorx(Register dst, Operand src, uint8_t imm8);
 
   // Implementation of packed single-precision floating-point SSE instructions.
-  void ps(byte op, XMMRegister dst, Operand src);
+  void ps(uint8_t op, XMMRegister dst, Operand src);
   // Implementation of packed double-precision floating-point SSE instructions.
-  void pd(byte op, XMMRegister dst, Operand src);
+  void pd(uint8_t op, XMMRegister dst, Operand src);
 
 #define PACKED_OP_LIST(V) \
   V(unpckl, 0x14)         \
@@ -1483,8 +1485,8 @@ class V8_EXPORT_PRIVATE Assembler : public AssemblerBase {
 #undef AVX_PACKED_OP_DECLARE
 #undef PACKED_OP_LIST
 
-  void vps(byte op, XMMRegister dst, XMMRegister src1, Operand src2);
-  void vpd(byte op, XMMRegister dst, XMMRegister src1, Operand src2);
+  void vps(uint8_t op, XMMRegister dst, XMMRegister src1, Operand src2);
+  void vpd(uint8_t op, XMMRegister dst, XMMRegister src1, Operand src2);
 
   void vcmpps(XMMRegister dst, XMMRegister src1, Operand src2, uint8_t cmp);
   void vcmppd(XMMRegister dst, XMMRegister src1, Operand src2, uint8_t cmp);
@@ -1674,8 +1676,8 @@ class V8_EXPORT_PRIVATE Assembler : public AssemblerBase {
   // Avoid overflows for displacements etc.
   static constexpr int kMaximalBufferSize = 512 * MB;
 
-  byte byte_at(int pos) { return buffer_start_[pos]; }
-  void set_byte_at(int pos, byte value) { buffer_start_[pos] = value; }
+  uint8_t byte_at(int pos) { return buffer_start_[pos]; }
+  void set_byte_at(int pos, uint8_t value) { buffer_start_[pos] = value; }
 
  protected:
   void emit_sse_operand(XMMRegister reg, Operand adr);
@@ -1748,29 +1750,30 @@ class V8_EXPORT_PRIVATE Assembler : public AssemblerBase {
   inline void emit_disp(Label* L, Displacement::Type type);
   inline void emit_near_disp(Label* L);
 
-  void sse_instr(XMMRegister dst, Operand src, byte prefix, byte opcode);
-  void sse2_instr(XMMRegister dst, Operand src, byte prefix, byte escape,
-                  byte opcode);
-  void ssse3_instr(XMMRegister dst, Operand src, byte prefix, byte escape1,
-                   byte escape2, byte opcode);
-  void sse4_instr(XMMRegister dst, Operand src, byte prefix, byte escape1,
-                  byte escape2, byte opcode);
-  void vinstr(byte op, XMMRegister dst, XMMRegister src1, XMMRegister src2,
+  void sse_instr(XMMRegister dst, Operand src, uint8_t prefix, uint8_t opcode);
+  void sse2_instr(XMMRegister dst, Operand src, uint8_t prefix, uint8_t escape,
+                  uint8_t opcode);
+  void ssse3_instr(XMMRegister dst, Operand src, uint8_t prefix,
+                   uint8_t escape1, uint8_t escape2, uint8_t opcode);
+  void sse4_instr(XMMRegister dst, Operand src, uint8_t prefix, uint8_t escape1,
+                  uint8_t escape2, uint8_t opcode);
+  void vinstr(uint8_t op, XMMRegister dst, XMMRegister src1, XMMRegister src2,
               SIMDPrefix pp, LeadingOpcode m, VexW w, CpuFeature = AVX);
-  void vinstr(byte op, XMMRegister dst, XMMRegister src1, Operand src2,
+  void vinstr(uint8_t op, XMMRegister dst, XMMRegister src1, Operand src2,
               SIMDPrefix pp, LeadingOpcode m, VexW w, CpuFeature = AVX);
-  void vinstr(byte op, XMMRegister dst, XMMRegister src1, XMMRegister src2,
+  void vinstr(uint8_t op, XMMRegister dst, XMMRegister src1, XMMRegister src2,
               VectorLength l, SIMDPrefix pp, LeadingOpcode m, VexW w,
               CpuFeature = AVX);
-  void vinstr(byte op, XMMRegister dst, XMMRegister src1, Operand src2,
+  void vinstr(uint8_t op, XMMRegister dst, XMMRegister src1, Operand src2,
               VectorLength l, SIMDPrefix pp, LeadingOpcode m, VexW w,
               CpuFeature = AVX);
   // Most BMI instructions are similar.
-  void bmi1(byte op, Register reg, Register vreg, Operand rm);
-  void bmi2(SIMDPrefix pp, byte op, Register reg, Register vreg, Operand rm);
-  void fma_instr(byte op, XMMRegister dst, XMMRegister src1, XMMRegister src2,
-                 VectorLength l, SIMDPrefix pp, LeadingOpcode m, VexW w);
-  void fma_instr(byte op, XMMRegister dst, XMMRegister src1, Operand src2,
+  void bmi1(uint8_t op, Register reg, Register vreg, Operand rm);
+  void bmi2(SIMDPrefix pp, uint8_t op, Register reg, Register vreg, Operand rm);
+  void fma_instr(uint8_t op, XMMRegister dst, XMMRegister src1,
+                 XMMRegister src2, VectorLength l, SIMDPrefix pp,
+                 LeadingOpcode m, VexW w);
+  void fma_instr(uint8_t op, XMMRegister dst, XMMRegister src1, Operand src2,
                  VectorLength l, SIMDPrefix pp, LeadingOpcode m, VexW w);
 
   // record reloc info for current pc_
diff --git a/src/codegen/loong64/assembler-loong64.cc b/src/codegen/loong64/assembler-loong64.cc
index ea49190271c..cf0f88a8eea 100644
--- a/src/codegen/loong64/assembler-loong64.cc
+++ b/src/codegen/loong64/assembler-loong64.cc
@@ -2117,7 +2117,7 @@ void Assembler::GrowBuffer() {
   // Set up new buffer.
   std::unique_ptr<AssemblerBuffer> new_buffer = buffer_->Grow(new_size);
   DCHECK_EQ(new_size, new_buffer->size());
-  byte* new_start = new_buffer->start();
+  uint8_t* new_start = new_buffer->start();
 
   // Copy the data.
   intptr_t pc_delta = new_start - buffer_start_;
diff --git a/src/codegen/loong64/assembler-loong64.h b/src/codegen/loong64/assembler-loong64.h
index 2e26a6ded92..4d4d2e83c2e 100644
--- a/src/codegen/loong64/assembler-loong64.h
+++ b/src/codegen/loong64/assembler-loong64.h
@@ -1082,7 +1082,7 @@ class V8_EXPORT_PRIVATE Assembler : public AssemblerBase {
   // Keep track of the last Call's position to ensure that safepoint can get the
   // correct information even if there is a trampoline immediately after the
   // Call.
-  byte* pc_for_safepoint_;
+  uint8_t* pc_for_safepoint_;
 
   RegList scratch_register_list_;
 
diff --git a/src/codegen/loong64/constants-loong64.h b/src/codegen/loong64/constants-loong64.h
index 42c6b48a309..df20f07307c 100644
--- a/src/codegen/loong64/constants-loong64.h
+++ b/src/codegen/loong64/constants-loong64.h
@@ -920,7 +920,7 @@ class Instruction : public InstructionGetters<InstructionBase> {
   // reference to an instruction is to convert a pointer. There is no way
   // to allocate or create instances of class Instruction.
   // Use the At(pc) function to create references to Instruction.
-  static Instruction* At(byte* pc) {
+  static Instruction* At(uint8_t* pc) {
     return reinterpret_cast<Instruction*>(pc);
   }
 
diff --git a/src/codegen/machine-type.h b/src/codegen/machine-type.h
index 286ce8e033c..7765f109d0b 100644
--- a/src/codegen/machine-type.h
+++ b/src/codegen/machine-type.h
@@ -327,7 +327,7 @@ class MachineType {
     return ElementSizeLog2Of(this->representation()) <= kSystemPointerSizeLog2;
   }
 
-  constexpr byte MemSize() const {
+  constexpr uint8_t MemSize() const {
     return 1 << i::ElementSizeLog2Of(this->representation());
   }
 
diff --git a/src/codegen/mips64/assembler-mips64.cc b/src/codegen/mips64/assembler-mips64.cc
index a64da7c8d10..155bd4b881d 100644
--- a/src/codegen/mips64/assembler-mips64.cc
+++ b/src/codegen/mips64/assembler-mips64.cc
@@ -3737,7 +3737,7 @@ void Assembler::GrowBuffer() {
   // Set up new buffer.
   std::unique_ptr<AssemblerBuffer> new_buffer = buffer_->Grow(new_size);
   DCHECK_EQ(new_size, new_buffer->size());
-  byte* new_start = new_buffer->start();
+  uint8_t* new_start = new_buffer->start();
 
   // Copy the data.
   intptr_t pc_delta = new_start - buffer_start_;
@@ -3756,9 +3756,9 @@ void Assembler::GrowBuffer() {
                                reloc_info_writer.last_pc() + pc_delta);
 
   // Relocate runtime entries.
-  base::Vector<byte> instructions{buffer_start_,
-                                  static_cast<size_t>(pc_offset())};
-  base::Vector<const byte> reloc_info{reloc_info_writer.pos(), reloc_size};
+  base::Vector<uint8_t> instructions{buffer_start_,
+                                     static_cast<size_t>(pc_offset())};
+  base::Vector<const uint8_t> reloc_info{reloc_info_writer.pos(), reloc_size};
   for (RelocIterator it(instructions, reloc_info, 0); !it.done(); it.next()) {
     RelocInfo::Mode rmode = it.rinfo()->rmode();
     if (rmode == RelocInfo::INTERNAL_REFERENCE) {
diff --git a/src/codegen/mips64/assembler-mips64.h b/src/codegen/mips64/assembler-mips64.h
index a9a0bcf80e5..094506523e4 100644
--- a/src/codegen/mips64/assembler-mips64.h
+++ b/src/codegen/mips64/assembler-mips64.h
@@ -1900,7 +1900,7 @@ class V8_EXPORT_PRIVATE Assembler : public AssemblerBase {
   // Keep track of the last Call's position to ensure that safepoint can get the
   // correct information even if there is a trampoline immediately after the
   // Call.
-  byte* pc_for_safepoint_;
+  uint8_t* pc_for_safepoint_;
 
   RegList scratch_register_list_;
 
diff --git a/src/codegen/mips64/constants-mips64.h b/src/codegen/mips64/constants-mips64.h
index 1b8790d8442..4c6ff50e692 100644
--- a/src/codegen/mips64/constants-mips64.h
+++ b/src/codegen/mips64/constants-mips64.h
@@ -1747,7 +1747,7 @@ class Instruction : public InstructionGetters<InstructionBase> {
   // reference to an instruction is to convert a pointer. There is no way
   // to allocate or create instances of class Instruction.
   // Use the At(pc) function to create references to Instruction.
-  static Instruction* At(byte* pc) {
+  static Instruction* At(uint8_t* pc) {
     return reinterpret_cast<Instruction*>(pc);
   }
 
diff --git a/src/codegen/ppc/assembler-ppc.cc b/src/codegen/ppc/assembler-ppc.cc
index 3e164452d89..07c02dd71fc 100644
--- a/src/codegen/ppc/assembler-ppc.cc
+++ b/src/codegen/ppc/assembler-ppc.cc
@@ -483,7 +483,7 @@ void Assembler::target_at_put(int pos, int target_pos, bool* is_branch) {
       int32_t offset =
           target_pos + (InstructionStream::kHeaderSize - kHeapObjectTag);
       PatchingAssembler patcher(
-          options(), reinterpret_cast<byte*>(buffer_start_ + pos), 2);
+          options(), reinterpret_cast<uint8_t*>(buffer_start_ + pos), 2);
       patcher.bitwise_mov32(dst, offset);
       break;
     }
@@ -498,7 +498,7 @@ void Assembler::target_at_put(int pos, int target_pos, bool* is_branch) {
                           : (SIGN_EXT_IMM22(operands & kImm22Mask));
       int32_t offset = target_pos + delta;
       PatchingAssembler patcher(
-          options(), reinterpret_cast<byte*>(buffer_start_ + pos),
+          options(), reinterpret_cast<uint8_t*>(buffer_start_ + pos),
           2 + static_cast<int32_t>(opcode == kUnboundAddLabelLongOffsetOpcode));
       patcher.bitwise_add32(dst, base, offset);
       if (opcode == kUnboundAddLabelLongOffsetOpcode) patcher.nop();
@@ -508,7 +508,7 @@ void Assembler::target_at_put(int pos, int target_pos, bool* is_branch) {
       // Load the address of the label in a register.
       Register dst = Register::from_code(instr_at(pos + kInstrSize));
       PatchingAssembler patcher(options(),
-                                reinterpret_cast<byte*>(buffer_start_ + pos),
+                                reinterpret_cast<uint8_t*>(buffer_start_ + pos),
                                 kMovInstructionsNoConstantPool);
       // Keep internal references relative until EmitRelocations.
       patcher.bitwise_mov(dst, target_pos);
@@ -516,7 +516,7 @@ void Assembler::target_at_put(int pos, int target_pos, bool* is_branch) {
     }
     case kUnboundJumpTableEntryOpcode: {
       PatchingAssembler patcher(options(),
-                                reinterpret_cast<byte*>(buffer_start_ + pos),
+                                reinterpret_cast<uint8_t*>(buffer_start_ + pos),
                                 kSystemPointerSize / kInstrSize);
       // Keep internal references relative until EmitRelocations.
       patcher.dp(target_pos);
@@ -2135,7 +2135,7 @@ void Assembler::GrowBuffer(int needed) {
   // Set up new buffer.
   std::unique_ptr<AssemblerBuffer> new_buffer = buffer_->Grow(new_size);
   DCHECK_EQ(new_size, new_buffer->size());
-  byte* new_start = new_buffer->start();
+  uint8_t* new_start = new_buffer->start();
 
   // Copy the data.
   intptr_t pc_delta = new_start - buffer_start_;
@@ -2249,7 +2249,7 @@ void Assembler::CheckTrampolinePool() {
 }
 
 PatchingAssembler::PatchingAssembler(const AssemblerOptions& options,
-                                     byte* address, int instructions)
+                                     uint8_t* address, int instructions)
     : Assembler(options, ExternalAssemblerBuffer(
                              address, instructions * kInstrSize + kGap)) {
   DCHECK_EQ(reloc_info_writer.pos(), buffer_start_ + buffer_->size());
diff --git a/src/codegen/ppc/assembler-ppc.h b/src/codegen/ppc/assembler-ppc.h
index 30b5d3a2bdb..fed9693d1a6 100644
--- a/src/codegen/ppc/assembler-ppc.h
+++ b/src/codegen/ppc/assembler-ppc.h
@@ -1551,7 +1551,7 @@ class EnsureSpace {
 
 class PatchingAssembler : public Assembler {
  public:
-  PatchingAssembler(const AssemblerOptions& options, byte* address,
+  PatchingAssembler(const AssemblerOptions& options, uint8_t* address,
                     int instructions);
   ~PatchingAssembler();
 };
diff --git a/src/codegen/ppc/constants-ppc.h b/src/codegen/ppc/constants-ppc.h
index 6ddb3da4112..f841dc07a69 100644
--- a/src/codegen/ppc/constants-ppc.h
+++ b/src/codegen/ppc/constants-ppc.h
@@ -2979,7 +2979,7 @@ const Instr rtCallRedirInstr = TWI;
 // Example: Test whether the instruction at ptr does set the condition code
 // bits.
 //
-// bool InstructionSetsConditionCodes(byte* ptr) {
+// bool InstructionSetsConditionCodes(uint8_t* ptr) {
 //   Instruction* instr = Instruction::At(ptr);
 //   int type = instr->TypeValue();
 //   return ((type == 0) || (type == 1)) && instr->HasS();
@@ -3212,7 +3212,7 @@ class Instruction {
   // reference to an instruction is to convert a pointer. There is no way
   // to allocate or create instances of class Instruction.
   // Use the At(pc) function to create references to Instruction.
-  static Instruction* At(byte* pc) {
+  static Instruction* At(uint8_t* pc) {
     return reinterpret_cast<Instruction*>(pc);
   }
 
diff --git a/src/codegen/ppc/cpu-ppc.cc b/src/codegen/ppc/cpu-ppc.cc
index 1ded190f054..a5f1e32c907 100644
--- a/src/codegen/ppc/cpu-ppc.cc
+++ b/src/codegen/ppc/cpu-ppc.cc
@@ -28,10 +28,10 @@ void CpuFeatures::FlushICache(void* buffer, size_t size) {
 
   const int kCacheLineSize = CpuFeatures::icache_line_size();
   intptr_t mask = kCacheLineSize - 1;
-  byte* start =
-      reinterpret_cast<byte*>(reinterpret_cast<intptr_t>(buffer) & ~mask);
-  byte* end = static_cast<byte*>(buffer) + size;
-  for (byte* pointer = start; pointer < end; pointer += kCacheLineSize) {
+  uint8_t* start =
+      reinterpret_cast<uint8_t*>(reinterpret_cast<intptr_t>(buffer) & ~mask);
+  uint8_t* end = static_cast<uint8_t*>(buffer) + size;
+  for (uint8_t* pointer = start; pointer < end; pointer += kCacheLineSize) {
     __asm__(
         "dcbf 0, %0  \n"
         "sync        \n"
diff --git a/src/codegen/reloc-info.cc b/src/codegen/reloc-info.cc
index f7b48fd1f8f..1bbcb36355a 100644
--- a/src/codegen/reloc-info.cc
+++ b/src/codegen/reloc-info.cc
@@ -28,7 +28,7 @@ uint32_t RelocInfoWriter::WriteLongPCJump(uint32_t pc_delta) {
   uint32_t pc_jump = pc_delta >> kSmallPCDeltaBits;
   DCHECK_GT(pc_jump, 0);
   base::VLQEncodeUnsigned(
-      [this](byte byte) {
+      [this](uint8_t byte) {
         *--pos_ = byte;
         return pos_;
       },
@@ -44,7 +44,7 @@ void RelocInfoWriter::WriteShortTaggedPC(uint32_t pc_delta, int tag) {
 }
 
 void RelocInfoWriter::WriteShortData(intptr_t data_delta) {
-  *--pos_ = static_cast<byte>(data_delta);
+  *--pos_ = static_cast<uint8_t>(data_delta);
 }
 
 void RelocInfoWriter::WriteMode(RelocInfo::Mode rmode) {
@@ -61,7 +61,7 @@ void RelocInfoWriter::WriteModeAndPC(uint32_t pc_delta, RelocInfo::Mode rmode) {
 
 void RelocInfoWriter::WriteIntData(int number) {
   for (int i = 0; i < kIntSize; i++) {
-    *--pos_ = static_cast<byte>(number);
+    *--pos_ = static_cast<uint8_t>(number);
     // Signed right shift is arithmetic shift.  Tested in test-utils.cc.
     number = number >> kBitsPerByte;
   }
@@ -70,7 +70,7 @@ void RelocInfoWriter::WriteIntData(int number) {
 void RelocInfoWriter::Write(const RelocInfo* rinfo) {
   RelocInfo::Mode rmode = rinfo->rmode();
 #ifdef DEBUG
-  byte* begin_pos = pos_;
+  uint8_t* begin_pos = pos_;
 #endif
   DCHECK(rinfo->rmode() < RelocInfo::NUMBER_OF_MODES);
   DCHECK_GE(rinfo->pc() - reinterpret_cast<Address>(last_pc_), 0);
@@ -98,7 +98,7 @@ void RelocInfoWriter::Write(const RelocInfo* rinfo) {
       WriteIntData(static_cast<int>(rinfo->data()));
     }
   }
-  last_pc_ = reinterpret_cast<byte*>(rinfo->pc());
+  last_pc_ = reinterpret_cast<uint8_t*>(rinfo->pc());
 #ifdef DEBUG
   DCHECK_LE(begin_pos - pos_, kMaxSize);
 #endif
@@ -202,15 +202,16 @@ RelocIterator::RelocIterator(EmbeddedData* embedded_data, Code code,
                     code.constant_pool(), code.relocation_end(),
                     code.relocation_start(), mode_mask) {}
 
-RelocIterator::RelocIterator(base::Vector<byte> instructions,
-                             base::Vector<const byte> reloc_info,
+RelocIterator::RelocIterator(base::Vector<uint8_t> instructions,
+                             base::Vector<const uint8_t> reloc_info,
                              Address const_pool, int mode_mask)
     : RelocIterator(reinterpret_cast<Address>(instructions.begin()), const_pool,
                     reloc_info.begin() + reloc_info.size(), reloc_info.begin(),
                     mode_mask) {}
 
-RelocIterator::RelocIterator(Address pc, Address constant_pool, const byte* pos,
-                             const byte* end, int mode_mask)
+RelocIterator::RelocIterator(Address pc, Address constant_pool,
+                             const uint8_t* pos, const uint8_t* end,
+                             int mode_mask)
     : pos_(pos),
       end_(end),
       rinfo_(pc, RelocInfo::NO_INFO, 0, constant_pool),
diff --git a/src/codegen/reloc-info.h b/src/codegen/reloc-info.h
index 064854de8aa..035e54be7d3 100644
--- a/src/codegen/reloc-info.h
+++ b/src/codegen/reloc-info.h
@@ -436,14 +436,14 @@ class RelocInfoWriter {
   RelocInfoWriter(const RelocInfoWriter&) = delete;
   RelocInfoWriter& operator=(const RelocInfoWriter&) = delete;
 
-  byte* pos() const { return pos_; }
-  byte* last_pc() const { return last_pc_; }
+  uint8_t* pos() const { return pos_; }
+  uint8_t* last_pc() const { return last_pc_; }
 
   void Write(const RelocInfo* rinfo);
 
   // Update the state of the stream after reloc info buffer
   // and/or code is moved while the stream is active.
-  void Reposition(byte* pos, byte* pc) {
+  void Reposition(uint8_t* pos, uint8_t* pc) {
     pos_ = pos;
     last_pc_ = pc;
   }
@@ -462,8 +462,8 @@ class RelocInfoWriter {
   inline void WriteModeAndPC(uint32_t pc_delta, RelocInfo::Mode rmode);
   inline void WriteIntData(int data_delta);
 
-  byte* pos_;
-  byte* last_pc_;
+  uint8_t* pos_;
+  uint8_t* last_pc_;
 };
 
 // A RelocIterator iterates over relocation information.
@@ -488,8 +488,8 @@ class V8_EXPORT_PRIVATE RelocIterator {
   explicit RelocIterator(Code code, InstructionStream instruction_stream,
                          ByteArray relocation_info, int mode_mask);
   // For Wasm.
-  explicit RelocIterator(base::Vector<byte> instructions,
-                         base::Vector<const byte> reloc_info,
+  explicit RelocIterator(base::Vector<uint8_t> instructions,
+                         base::Vector<const uint8_t> reloc_info,
                          Address const_pool, int mode_mask = kAllModesMask);
   // For the disassembler.
   explicit RelocIterator(const CodeReference code_reference);
@@ -510,8 +510,8 @@ class V8_EXPORT_PRIVATE RelocIterator {
   }
 
  private:
-  RelocIterator(Address pc, Address constant_pool, const byte* pos,
-                const byte* end, int mode_mask);
+  RelocIterator(Address pc, Address constant_pool, const uint8_t* pos,
+                const uint8_t* end, int mode_mask);
 
   // Used for efficiently skipping unwanted modes.
   bool SetMode(RelocInfo::Mode mode) {
@@ -534,8 +534,8 @@ class V8_EXPORT_PRIVATE RelocIterator {
   void ReadShortTaggedPC() { rinfo_.pc_ += *pos_ >> detail::kTagBits; }
   void ReadShortData();
 
-  const byte* pos_;
-  const byte* const end_;
+  const uint8_t* pos_;
+  const uint8_t* const end_;
   RelocInfo rinfo_;
   bool done_ = false;
   const int mode_mask_;
diff --git a/src/codegen/riscv/assembler-riscv.cc b/src/codegen/riscv/assembler-riscv.cc
index f0a8ac16d95..7e66b509dc2 100644
--- a/src/codegen/riscv/assembler-riscv.cc
+++ b/src/codegen/riscv/assembler-riscv.cc
@@ -489,7 +489,7 @@ void Assembler::disassembleInstr(Instr instr) {
   disasm::Disassembler disasm(converter);
   base::EmbeddedVector<char, 128> disasm_buffer;
 
-  disasm.InstructionDecode(disasm_buffer, reinterpret_cast<byte*>(&instr));
+  disasm.InstructionDecode(disasm_buffer, reinterpret_cast<uint8_t*>(&instr));
   DEBUG_PRINTF("%s\n", disasm_buffer.begin());
 }
 
@@ -1278,7 +1278,7 @@ void Assembler::GrowBuffer() {
   // Set up new buffer.
   std::unique_ptr<AssemblerBuffer> new_buffer = buffer_->Grow(new_size);
   DCHECK_EQ(new_size, new_buffer->size());
-  byte* new_start = new_buffer->start();
+  uint8_t* new_start = new_buffer->start();
 
   // Copy the data.
   intptr_t pc_delta = new_start - buffer_start_;
@@ -1297,9 +1297,9 @@ void Assembler::GrowBuffer() {
                                reloc_info_writer.last_pc() + pc_delta);
 
   // Relocate runtime entries.
-  base::Vector<byte> instructions{buffer_start_,
-                                  static_cast<size_t>(pc_offset())};
-  base::Vector<const byte> reloc_info{reloc_info_writer.pos(), reloc_size};
+  base::Vector<uint8_t> instructions{buffer_start_,
+                                     static_cast<size_t>(pc_offset())};
+  base::Vector<const uint8_t> reloc_info{reloc_info_writer.pos(), reloc_size};
   for (RelocIterator it(instructions, reloc_info, 0); !it.done(); it.next()) {
     RelocInfo::Mode rmode = it.rinfo()->rmode();
     if (rmode == RelocInfo::INTERNAL_REFERENCE) {
diff --git a/src/codegen/riscv/base-constants-riscv.h b/src/codegen/riscv/base-constants-riscv.h
index 9acbf86f153..0c1018c118f 100644
--- a/src/codegen/riscv/base-constants-riscv.h
+++ b/src/codegen/riscv/base-constants-riscv.h
@@ -1223,7 +1223,7 @@ class Instruction : public InstructionGetters<InstructionBase> {
   // reference to an instruction is to convert a pointer. There is no way
   // to allocate or create instances of class Instruction.
   // Use the At(pc) function to create references to Instruction.
-  static Instruction* At(byte* pc) {
+  static Instruction* At(uint8_t* pc) {
     return reinterpret_cast<Instruction*>(pc);
   }
 
diff --git a/src/codegen/s390/assembler-s390-inl.h b/src/codegen/s390/assembler-s390-inl.h
index 6b48c28394c..585b59739d0 100644
--- a/src/codegen/s390/assembler-s390-inl.h
+++ b/src/codegen/s390/assembler-s390-inl.h
@@ -56,14 +56,14 @@ void RelocInfo::apply(intptr_t delta) {
     Memory<Address>(pc_) = target + delta;
   } else if (IsCodeTarget(rmode_)) {
     SixByteInstr instr =
-        Instruction::InstructionBits(reinterpret_cast<const byte*>(pc_));
+        Instruction::InstructionBits(reinterpret_cast<const uint8_t*>(pc_));
     int32_t dis = static_cast<int32_t>(instr & 0xFFFFFFFF) * 2  // halfwords
                   - static_cast<int32_t>(delta);
     instr >>= 32;  // Clear the 4-byte displacement field.
     instr <<= 32;
     instr |= static_cast<uint32_t>(dis / 2);
-    Instruction::SetInstructionBits<SixByteInstr>(reinterpret_cast<byte*>(pc_),
-                                                  instr);
+    Instruction::SetInstructionBits<SixByteInstr>(
+        reinterpret_cast<uint8_t*>(pc_), instr);
   } else {
     // mov sequence
     DCHECK(IsInternalReferenceEncoded(rmode_));
@@ -134,7 +134,7 @@ Tagged_t Assembler::target_compressed_address_at(Address pc,
 
 Handle<Object> Assembler::code_target_object_handle_at(Address pc) {
   SixByteInstr instr =
-      Instruction::InstructionBits(reinterpret_cast<const byte*>(pc));
+      Instruction::InstructionBits(reinterpret_cast<const uint8_t*>(pc));
   int index = instr & 0xFFFFFFFF;
   return GetCodeTarget(index);
 }
@@ -231,9 +231,10 @@ Operand::Operand(Register rm) : rm_(rm), rmode_(RelocInfo::NO_INFO) {}
 Address Assembler::target_address_at(Address pc, Address constant_pool) {
   // S390 Instruction!
   // We want to check for instructions generated by Asm::mov()
-  Opcode op1 = Instruction::S390OpcodeValue(reinterpret_cast<const byte*>(pc));
+  Opcode op1 =
+      Instruction::S390OpcodeValue(reinterpret_cast<const uint8_t*>(pc));
   SixByteInstr instr_1 =
-      Instruction::InstructionBits(reinterpret_cast<const byte*>(pc));
+      Instruction::InstructionBits(reinterpret_cast<const uint8_t*>(pc));
 
   if (BRASL == op1 || BRCL == op1) {
     int32_t dis = static_cast<int32_t>(instr_1 & 0xFFFFFFFF) * 2;
@@ -242,11 +243,11 @@ Address Assembler::target_address_at(Address pc, Address constant_pool) {
 
 #if V8_TARGET_ARCH_S390X
   int instr1_length =
-      Instruction::InstructionLength(reinterpret_cast<const byte*>(pc));
+      Instruction::InstructionLength(reinterpret_cast<const uint8_t*>(pc));
   Opcode op2 = Instruction::S390OpcodeValue(
-      reinterpret_cast<const byte*>(pc + instr1_length));
+      reinterpret_cast<const uint8_t*>(pc + instr1_length));
   SixByteInstr instr_2 = Instruction::InstructionBits(
-      reinterpret_cast<const byte*>(pc + instr1_length));
+      reinterpret_cast<const uint8_t*>(pc + instr1_length));
   // IIHF for hi_32, IILF for lo_32
   if (IIHF == op1 && IILF == op2) {
     return static_cast<Address>(((instr_1 & 0xFFFFFFFF) << 32) |
@@ -293,9 +294,10 @@ void Assembler::set_target_address_at(Address pc, Address constant_pool,
                                       Address target,
                                       ICacheFlushMode icache_flush_mode) {
   // Check for instructions generated by Asm::mov()
-  Opcode op1 = Instruction::S390OpcodeValue(reinterpret_cast<const byte*>(pc));
+  Opcode op1 =
+      Instruction::S390OpcodeValue(reinterpret_cast<const uint8_t*>(pc));
   SixByteInstr instr_1 =
-      Instruction::InstructionBits(reinterpret_cast<const byte*>(pc));
+      Instruction::InstructionBits(reinterpret_cast<const uint8_t*>(pc));
   bool patched = false;
 
   if (BRASL == op1 || BRCL == op1) {
@@ -303,8 +305,8 @@ void Assembler::set_target_address_at(Address pc, Address constant_pool,
     instr_1 <<= 32;
     int32_t halfwords = (target - pc) / 2;  // number of halfwords
     instr_1 |= static_cast<uint32_t>(halfwords);
-    Instruction::SetInstructionBits<SixByteInstr>(reinterpret_cast<byte*>(pc),
-                                                  instr_1);
+    Instruction::SetInstructionBits<SixByteInstr>(
+        reinterpret_cast<uint8_t*>(pc), instr_1);
     if (icache_flush_mode != SKIP_ICACHE_FLUSH) {
       FlushInstructionCache(pc, 6);
     }
@@ -312,11 +314,11 @@ void Assembler::set_target_address_at(Address pc, Address constant_pool,
   } else {
 #if V8_TARGET_ARCH_S390X
     int instr1_length =
-        Instruction::InstructionLength(reinterpret_cast<const byte*>(pc));
+        Instruction::InstructionLength(reinterpret_cast<const uint8_t*>(pc));
     Opcode op2 = Instruction::S390OpcodeValue(
-        reinterpret_cast<const byte*>(pc + instr1_length));
+        reinterpret_cast<const uint8_t*>(pc + instr1_length));
     SixByteInstr instr_2 = Instruction::InstructionBits(
-        reinterpret_cast<const byte*>(pc + instr1_length));
+        reinterpret_cast<const uint8_t*>(pc + instr1_length));
     // IIHF for hi_32, IILF for lo_32
     if (IIHF == op1 && IILF == op2) {
       // IIHF
@@ -324,8 +326,8 @@ void Assembler::set_target_address_at(Address pc, Address constant_pool,
       instr_1 <<= 32;
       instr_1 |= reinterpret_cast<uint64_t>(target) >> 32;
 
-      Instruction::SetInstructionBits<SixByteInstr>(reinterpret_cast<byte*>(pc),
-                                                    instr_1);
+      Instruction::SetInstructionBits<SixByteInstr>(
+          reinterpret_cast<uint8_t*>(pc), instr_1);
 
       // IILF
       instr_2 >>= 32;
@@ -333,7 +335,7 @@ void Assembler::set_target_address_at(Address pc, Address constant_pool,
       instr_2 |= reinterpret_cast<uint64_t>(target) & 0xFFFFFFFF;
 
       Instruction::SetInstructionBits<SixByteInstr>(
-          reinterpret_cast<byte*>(pc + instr1_length), instr_2);
+          reinterpret_cast<uint8_t*>(pc + instr1_length), instr_2);
       if (icache_flush_mode != SKIP_ICACHE_FLUSH) {
         FlushInstructionCache(pc, 12);
       }
@@ -346,8 +348,8 @@ void Assembler::set_target_address_at(Address pc, Address constant_pool,
       instr_1 <<= 32;
       instr_1 |= reinterpret_cast<uint32_t>(target);
 
-      Instruction::SetInstructionBits<SixByteInstr>(reinterpret_cast<byte*>(pc),
-                                                    instr_1);
+      Instruction::SetInstructionBits<SixByteInstr>(
+          reinterpret_cast<uint8_t*>(pc), instr_1);
       if (icache_flush_mode != SKIP_ICACHE_FLUSH) {
         FlushInstructionCache(pc, 6);
       }
diff --git a/src/codegen/s390/assembler-s390.cc b/src/codegen/s390/assembler-s390.cc
index 7435f9a6147..fc238bfcb4f 100644
--- a/src/codegen/s390/assembler-s390.cc
+++ b/src/codegen/s390/assembler-s390.cc
@@ -753,7 +753,7 @@ void Assembler::GrowBuffer(int needed) {
   // Set up new buffer.
   std::unique_ptr<AssemblerBuffer> new_buffer = buffer_->Grow(new_size);
   DCHECK_EQ(new_size, new_buffer->size());
-  byte* new_start = new_buffer->start();
+  uint8_t* new_start = new_buffer->start();
 
   // Copy the data.
   intptr_t pc_delta = new_start - buffer_start_;
diff --git a/src/codegen/s390/assembler-s390.h b/src/codegen/s390/assembler-s390.h
index 64aa353e856..914ec9c6c6b 100644
--- a/src/codegen/s390/assembler-s390.h
+++ b/src/codegen/s390/assembler-s390.h
@@ -1329,7 +1329,7 @@ class V8_EXPORT_PRIVATE Assembler : public AssemblerBase {
     return Instruction::InstructionLength(buffer_start_ + pos);
   }
 
-  static SixByteInstr instr_at(byte* pc) {
+  static SixByteInstr instr_at(uint8_t* pc) {
     return Instruction::InstructionBits(pc);
   }
 
@@ -1357,7 +1357,7 @@ class V8_EXPORT_PRIVATE Assembler : public AssemblerBase {
   void emit_label_addr(Label* label);
 
  public:
-  byte* buffer_pos() const { return buffer_start_; }
+  uint8_t* buffer_pos() const { return buffer_start_; }
 
   // InstructionStream generation
   // The relocation writer's position is at least kGap bytes below the end of
diff --git a/src/codegen/s390/constants-s390.h b/src/codegen/s390/constants-s390.h
index 3de1a2f3728..1ad001c7dfa 100644
--- a/src/codegen/s390/constants-s390.h
+++ b/src/codegen/s390/constants-s390.h
@@ -1908,7 +1908,8 @@ class Instruction {
   // Get the raw instruction bits.
   template <typename T>
   inline T InstructionBits() const {
-    return Instruction::InstructionBits<T>(reinterpret_cast<const byte*>(this));
+    return Instruction::InstructionBits<T>(
+        reinterpret_cast<const uint8_t*>(this));
   }
   inline Instr InstructionBits() const {
     return *reinterpret_cast<const Instr*>(this);
@@ -1917,7 +1918,7 @@ class Instruction {
   // Set the raw instruction bits to value.
   template <typename T>
   inline void SetInstructionBits(T value) const {
-    Instruction::SetInstructionBits<T>(reinterpret_cast<const byte*>(this),
+    Instruction::SetInstructionBits<T>(reinterpret_cast<const uint8_t*>(this),
                                        value);
   }
   inline void SetInstructionBits(Instr value) {
@@ -1945,11 +1946,12 @@ class Instruction {
 
   // Determine the instruction length
   inline int InstructionLength() {
-    return Instruction::InstructionLength(reinterpret_cast<const byte*>(this));
+    return Instruction::InstructionLength(
+        reinterpret_cast<const uint8_t*>(this));
   }
   // Extract the Instruction Opcode
   inline Opcode S390OpcodeValue() {
-    return Instruction::S390OpcodeValue(reinterpret_cast<const byte*>(this));
+    return Instruction::S390OpcodeValue(reinterpret_cast<const uint8_t*>(this));
   }
 
   // Static support.
@@ -1968,12 +1970,12 @@ class Instruction {
   }
 
   // Determine the instruction length of the given instruction
-  static inline int InstructionLength(const byte* instr) {
+  static inline int InstructionLength(const uint8_t* instr) {
     // Length can be determined by the first nibble.
     // 0x0 to 0x3 => 2-bytes
     // 0x4 to 0xB => 4-bytes
     // 0xC to 0xF => 6-bytes
-    byte topNibble = (*instr >> 4) & 0xF;
+    uint8_t topNibble = (*instr >> 4) & 0xF;
     if (topNibble <= 3)
       return 2;
     else if (topNibble <= 0xB)
@@ -1982,7 +1984,7 @@ class Instruction {
   }
 
   // Returns the instruction bits of the given instruction
-  static inline uint64_t InstructionBits(const byte* instr) {
+  static inline uint64_t InstructionBits(const uint8_t* instr) {
     int length = InstructionLength(instr);
     if (2 == length)
       return static_cast<uint64_t>(InstructionBits<TwoByteInstr>(instr));
@@ -1994,7 +1996,7 @@ class Instruction {
 
   // Extract the raw instruction bits
   template <typename T>
-  static inline T InstructionBits(const byte* instr) {
+  static inline T InstructionBits(const uint8_t* instr) {
 #if !V8_TARGET_LITTLE_ENDIAN
     if (sizeof(T) <= 4) {
       return *reinterpret_cast<const T*>(instr);
@@ -2025,7 +2027,7 @@ class Instruction {
 
   // Set the Instruction Bits to value
   template <typename T>
-  static inline void SetInstructionBits(byte* instr, T value) {
+  static inline void SetInstructionBits(uint8_t* instr, T value) {
 #if V8_TARGET_LITTLE_ENDIAN
     // The instruction bits are stored in big endian format even on little
     // endian hosts, in order to decode instruction length and opcode.
@@ -2067,18 +2069,18 @@ class Instruction {
   }
 
   // Get Instruction Format Type
-  static OpcodeFormatType getOpcodeFormatType(const byte* instr) {
-    const byte firstByte = *instr;
+  static OpcodeFormatType getOpcodeFormatType(const uint8_t* instr) {
+    const uint8_t firstByte = *instr;
     return OpcodeFormatTable[firstByte];
   }
 
   // Extract the full opcode from the instruction.
-  static inline Opcode S390OpcodeValue(const byte* instr) {
+  static inline Opcode S390OpcodeValue(const uint8_t* instr) {
     OpcodeFormatType opcodeType = getOpcodeFormatType(instr);
 
     // The native instructions are encoded in big-endian format
     // even if running on little-endian host.  Hence, we need
-    // to ensure we use byte* based bit-wise logic.
+    // to ensure we use uint8_t* based bit-wise logic.
     switch (opcodeType) {
       case ONE_BYTE_OPCODE:
         // One Byte - Bits 0 to 7
@@ -2107,7 +2109,7 @@ class Instruction {
   // reference to an instruction is to convert a pointer. There is no way
   // to allocate or create instances of class Instruction.
   // Use the At(pc) function to create references to Instruction.
-  static Instruction* At(byte* pc) {
+  static Instruction* At(uint8_t* pc) {
     return reinterpret_cast<Instruction*>(pc);
   }
 
diff --git a/src/codegen/shared-ia32-x64/macro-assembler-shared-ia32-x64.cc b/src/codegen/shared-ia32-x64/macro-assembler-shared-ia32-x64.cc
index fb7fb8d5823..3e4997efc03 100644
--- a/src/codegen/shared-ia32-x64/macro-assembler-shared-ia32-x64.cc
+++ b/src/codegen/shared-ia32-x64/macro-assembler-shared-ia32-x64.cc
@@ -224,7 +224,7 @@ void SharedMacroAssemblerBase::F32x4Min(XMMRegister dst, XMMRegister lhs,
   // Canonicalize NaNs by quieting and clearing the payload.
   Cmpunordps(dst, dst, scratch);
   Orps(scratch, dst);
-  Psrld(dst, dst, byte{10});
+  Psrld(dst, dst, uint8_t{10});
   Andnps(dst, dst, scratch);
 }
 
@@ -256,7 +256,7 @@ void SharedMacroAssemblerBase::F32x4Max(XMMRegister dst, XMMRegister lhs,
   Subps(scratch, scratch, dst);
   // Canonicalize NaNs by clearing the payload. Sign is non-deterministic.
   Cmpunordps(dst, dst, scratch);
-  Psrld(dst, dst, byte{10});
+  Psrld(dst, dst, uint8_t{10});
   Andnps(dst, dst, scratch);
 }
 
@@ -274,7 +274,7 @@ void SharedMacroAssemblerBase::F64x2Min(XMMRegister dst, XMMRegister lhs,
     // Canonicalize NaNs by quieting and clearing the payload.
     vcmpunordpd(dst, dst, scratch);
     vorpd(scratch, scratch, dst);
-    vpsrlq(dst, dst, byte{13});
+    vpsrlq(dst, dst, uint8_t{13});
     vandnpd(dst, dst, scratch);
   } else {
     // Compare lhs with rhs, and rhs with lhs, and have the results in scratch
@@ -293,7 +293,7 @@ void SharedMacroAssemblerBase::F64x2Min(XMMRegister dst, XMMRegister lhs,
     orpd(scratch, dst);
     cmpunordpd(dst, scratch);
     orpd(scratch, dst);
-    psrlq(dst, byte{13});
+    psrlq(dst, uint8_t{13});
     andnpd(dst, scratch);
   }
 }
@@ -315,7 +315,7 @@ void SharedMacroAssemblerBase::F64x2Max(XMMRegister dst, XMMRegister lhs,
     vsubpd(scratch, scratch, dst);
     // Canonicalize NaNs by clearing the payload. Sign is non-deterministic.
     vcmpunordpd(dst, dst, scratch);
-    vpsrlq(dst, dst, byte{13});
+    vpsrlq(dst, dst, uint8_t{13});
     vandnpd(dst, dst, scratch);
   } else {
     if (dst == lhs || dst == rhs) {
@@ -333,7 +333,7 @@ void SharedMacroAssemblerBase::F64x2Max(XMMRegister dst, XMMRegister lhs,
     orpd(scratch, dst);
     subpd(scratch, dst);
     cmpunordpd(dst, scratch);
-    psrlq(dst, byte{13});
+    psrlq(dst, uint8_t{13});
     andnpd(dst, scratch);
   }
 }
@@ -436,7 +436,7 @@ void SharedMacroAssemblerBase::I8x16Shl(XMMRegister dst, XMMRegister src1,
   }
 
   uint8_t shift = truncate_to_int3(src2);
-  Psllw(dst, src1, byte{shift});
+  Psllw(dst, src1, uint8_t{shift});
 
   uint8_t bmask = static_cast<uint8_t>(0xff << shift);
   uint32_t mask = bmask << 24 | bmask << 16 | bmask << 8 | bmask;
@@ -526,7 +526,7 @@ void SharedMacroAssemblerBase::I8x16ShrU(XMMRegister dst, XMMRegister src1,
   uint32_t mask = bmask << 24 | bmask << 16 | bmask << 8 | bmask;
   Move(tmp1, mask);
   Movd(tmp2, tmp1);
-  Pshufd(tmp2, tmp2, byte{0});
+  Pshufd(tmp2, tmp2, uint8_t{0});
   Pand(dst, tmp2);
 }
 
@@ -723,7 +723,7 @@ void SharedMacroAssemblerBase::I16x8Q15MulRSatS(XMMRegister dst,
   ASM_CODE_COMMENT(this);
   // k = i16x8.splat(0x8000)
   Pcmpeqd(scratch, scratch);
-  Psllw(scratch, scratch, byte{15});
+  Psllw(scratch, scratch, uint8_t{15});
 
   if (!CpuFeatures::IsSupported(AVX) && (dst != src1)) {
     movaps(dst, src1);
@@ -756,7 +756,7 @@ void SharedMacroAssemblerBase::I32x4DotI8x16I7x16AddS(
   ASM_CODE_COMMENT(this);
   // k = i16x8.splat(1)
   Pcmpeqd(splat_reg, splat_reg);
-  Psrlw(splat_reg, splat_reg, byte{15});
+  Psrlw(splat_reg, splat_reg, uint8_t{15});
 
   if (CpuFeatures::IsSupported(AVX)) {
     CpuFeatureScope avx_scope(this, AVX);
@@ -802,14 +802,14 @@ void SharedMacroAssemblerBase::I32x4ExtAddPairwiseI16x8U(XMMRegister dst,
     // src = |a|b|c|d|e|f|g|h|
     // tmp = i32x4.splat(0x0000FFFF)
     pcmpeqd(tmp, tmp);
-    psrld(tmp, byte{16});
+    psrld(tmp, uint8_t{16});
     // tmp =|0|b|0|d|0|f|0|h|
     andps(tmp, src);
     // dst = |0|a|0|c|0|e|0|g|
     if (dst != src) {
       movaps(dst, src);
     }
-    psrld(dst, byte{16});
+    psrld(dst, uint8_t{16});
     // dst = |a+b|c+d|e+f|g+h|
     paddd(dst, tmp);
   }
@@ -1010,7 +1010,7 @@ void SharedMacroAssemblerBase::I64x2ShrS(XMMRegister dst, XMMRegister src,
 
   // xmm_tmp = wasm_i64x2_const(0x80000000'00000000).
   Pcmpeqd(xmm_tmp, xmm_tmp);
-  Psllq(xmm_tmp, byte{63});
+  Psllq(xmm_tmp, uint8_t{63});
 
   if (!CpuFeatures::IsSupported(AVX) && (dst != src)) {
     movaps(dst, src);
@@ -1039,7 +1039,7 @@ void SharedMacroAssemblerBase::I64x2ShrS(XMMRegister dst, XMMRegister src,
 
   // See I64x2ShrS with constant shift for explanation of this algorithm.
   Pcmpeqd(xmm_tmp, xmm_tmp);
-  Psllq(xmm_tmp, byte{63});
+  Psllq(xmm_tmp, uint8_t{63});
 
   // Shift modulo 64.
   Move(tmp_shift, shift);
@@ -1067,14 +1067,14 @@ void SharedMacroAssemblerBase::I64x2Mul(XMMRegister dst, XMMRegister lhs,
   if (CpuFeatures::IsSupported(AVX)) {
     CpuFeatureScope avx_scope(this, AVX);
     // 1. Multiply high dword of each qword of left with right.
-    vpsrlq(tmp1, lhs, byte{32});
+    vpsrlq(tmp1, lhs, uint8_t{32});
     vpmuludq(tmp1, tmp1, rhs);
     // 2. Multiply high dword of each qword of right with left.
-    vpsrlq(tmp2, rhs, byte{32});
+    vpsrlq(tmp2, rhs, uint8_t{32});
     vpmuludq(tmp2, tmp2, lhs);
     // 3. Add 1 and 2, then shift left by 32 (this is the high dword of result).
     vpaddq(tmp2, tmp2, tmp1);
-    vpsllq(tmp2, tmp2, byte{32});
+    vpsllq(tmp2, tmp2, uint8_t{32});
     // 4. Multiply low dwords (this is the low dword of result).
     vpmuludq(dst, lhs, rhs);
     // 5. Add 3 and 4.
@@ -1083,12 +1083,12 @@ void SharedMacroAssemblerBase::I64x2Mul(XMMRegister dst, XMMRegister lhs,
     // Same algorithm as AVX version, but with moves to not overwrite inputs.
     movaps(tmp1, lhs);
     movaps(tmp2, rhs);
-    psrlq(tmp1, byte{32});
+    psrlq(tmp1, uint8_t{32});
     pmuludq(tmp1, rhs);
-    psrlq(tmp2, byte{32});
+    psrlq(tmp2, uint8_t{32});
     pmuludq(tmp2, lhs);
     paddq(tmp2, tmp1);
-    psllq(tmp2, byte{32});
+    psllq(tmp2, uint8_t{32});
     if (dst == rhs) {
       // pmuludq is commutative
       pmuludq(dst, lhs);
@@ -1266,7 +1266,7 @@ void SharedMacroAssemblerBase::S128Load32Splat(XMMRegister dst, Operand src) {
     vbroadcastss(dst, src);
   } else {
     movss(dst, src);
-    shufps(dst, dst, byte{0});
+    shufps(dst, dst, uint8_t{0});
   }
 }
 
diff --git a/src/codegen/shared-ia32-x64/macro-assembler-shared-ia32-x64.h b/src/codegen/shared-ia32-x64/macro-assembler-shared-ia32-x64.h
index ae97572783f..7778fdfacae 100644
--- a/src/codegen/shared-ia32-x64/macro-assembler-shared-ia32-x64.h
+++ b/src/codegen/shared-ia32-x64/macro-assembler-shared-ia32-x64.h
@@ -804,7 +804,7 @@ class V8_EXPORT_PRIVATE SharedMacroAssembler : public SharedMacroAssemblerBase {
     // the exponent, which means multiply by 2 (or addps to itself).
     Addps(dst, dst, dst);
     // Then shift to get the bit representation of the int.
-    Pslld(dst, byte{8});
+    Pslld(dst, uint8_t{8});
     // Merge the converted lanes and bit shifted lanes.
     Paddd(dst, tmp);
   }
diff --git a/src/codegen/source-position-table.cc b/src/codegen/source-position-table.cc
index efa3e9d8b14..829bd140f2f 100644
--- a/src/codegen/source-position-table.cc
+++ b/src/codegen/source-position-table.cc
@@ -54,7 +54,7 @@ void SubtractFromEntry(PositionTableEntry* value,
 
 // Helper: Encode an integer.
 template <typename T>
-void EncodeInt(ZoneVector<byte>* bytes, T value) {
+void EncodeInt(ZoneVector<uint8_t>* bytes, T value) {
   using unsigned_type = typename std::make_unsigned<T>::type;
   // Zig-zag encoding.
   static constexpr int kShift = sizeof(T) * kBitsPerByte - 1;
@@ -64,7 +64,7 @@ void EncodeInt(ZoneVector<byte>* bytes, T value) {
   bool more;
   do {
     more = encoded > ValueBits::kMax;
-    byte current =
+    uint8_t current =
         MoreBit::encode(more) | ValueBits::encode(encoded & ValueBits::kMask);
     bytes->push_back(current);
     encoded >>= ValueBits::kSize;
@@ -72,7 +72,7 @@ void EncodeInt(ZoneVector<byte>* bytes, T value) {
 }
 
 // Encode a PositionTableEntry.
-void EncodeEntry(ZoneVector<byte>* bytes, const PositionTableEntry& entry) {
+void EncodeEntry(ZoneVector<uint8_t>* bytes, const PositionTableEntry& entry) {
   // We only accept ascending code offsets.
   DCHECK_LE(0, entry.code_offset);
   // All but the first entry must be *strictly* ascending (no two entries for
@@ -87,8 +87,8 @@ void EncodeEntry(ZoneVector<byte>* bytes, const PositionTableEntry& entry) {
 
 // Helper: Decode an integer.
 template <typename T>
-T DecodeInt(base::Vector<const byte> bytes, int* index) {
-  byte current;
+T DecodeInt(base::Vector<const uint8_t> bytes, int* index) {
+  uint8_t current;
   int shift = 0;
   T decoded = 0;
   bool more;
@@ -105,7 +105,7 @@ T DecodeInt(base::Vector<const byte> bytes, int* index) {
   return decoded;
 }
 
-void DecodeEntry(base::Vector<const byte> bytes, int* index,
+void DecodeEntry(base::Vector<const uint8_t> bytes, int* index,
                  PositionTableEntry* entry) {
   int tmp = DecodeInt<int>(bytes, index);
   if (tmp >= 0) {
@@ -118,9 +118,9 @@ void DecodeEntry(base::Vector<const byte> bytes, int* index,
   entry->source_position = DecodeInt<int64_t>(bytes, index);
 }
 
-base::Vector<const byte> VectorFromByteArray(ByteArray byte_array) {
-  return base::Vector<const byte>(byte_array.GetDataStartAddress(),
-                                  byte_array.length());
+base::Vector<const uint8_t> VectorFromByteArray(ByteArray byte_array) {
+  return base::Vector<const uint8_t>(byte_array.GetDataStartAddress(),
+                                     byte_array.length());
 }
 
 #ifdef ENABLE_SLOW_DCHECKS
@@ -201,12 +201,12 @@ template EXPORT_TEMPLATE_DEFINE(V8_EXPORT_PRIVATE)
     Handle<ByteArray> SourcePositionTableBuilder::ToSourcePositionTable(
         LocalIsolate* isolate);
 
-base::OwnedVector<byte>
+base::OwnedVector<uint8_t>
 SourcePositionTableBuilder::ToSourcePositionTableVector() {
-  if (bytes_.empty()) return base::OwnedVector<byte>();
+  if (bytes_.empty()) return base::OwnedVector<uint8_t>();
   DCHECK(!Omit());
 
-  base::OwnedVector<byte> table = base::OwnedVector<byte>::Of(bytes_);
+  base::OwnedVector<uint8_t> table = base::OwnedVector<uint8_t>::Of(bytes_);
 
 #ifdef ENABLE_SLOW_DCHECKS
   // Brute force testing: Record all positions and decode
@@ -252,7 +252,7 @@ SourcePositionTableIterator::SourcePositionTableIterator(
 }
 
 SourcePositionTableIterator::SourcePositionTableIterator(
-    base::Vector<const byte> bytes, IterationFilter iteration_filter,
+    base::Vector<const uint8_t> bytes, IterationFilter iteration_filter,
     FunctionEntryFilter function_entry_filter)
     : raw_table_(bytes),
       iteration_filter_(iteration_filter),
@@ -265,7 +265,7 @@ SourcePositionTableIterator::SourcePositionTableIterator(
 }
 
 void SourcePositionTableIterator::Advance() {
-  base::Vector<const byte> bytes =
+  base::Vector<const uint8_t> bytes =
       table_.is_null() ? raw_table_ : VectorFromByteArray(*table_);
   DCHECK(!done());
   DCHECK(index_ >= 0 && index_ <= bytes.length());
diff --git a/src/codegen/source-position-table.h b/src/codegen/source-position-table.h
index 13bf2adf5f3..439b20e8850 100644
--- a/src/codegen/source-position-table.h
+++ b/src/codegen/source-position-table.h
@@ -57,7 +57,7 @@ class V8_EXPORT_PRIVATE SourcePositionTableBuilder {
   template <typename IsolateT>
   EXPORT_TEMPLATE_DECLARE(V8_EXPORT_PRIVATE)
   Handle<ByteArray> ToSourcePositionTable(IsolateT* isolate);
-  base::OwnedVector<byte> ToSourcePositionTableVector();
+  base::OwnedVector<uint8_t> ToSourcePositionTableVector();
 
   inline bool Omit() const { return mode_ != RECORD_SOURCE_POSITIONS; }
   inline bool Lazy() const { return mode_ == LAZY_SOURCE_POSITIONS; }
@@ -66,7 +66,7 @@ class V8_EXPORT_PRIVATE SourcePositionTableBuilder {
   void AddEntry(const PositionTableEntry& entry);
 
   RecordingMode mode_;
-  ZoneVector<byte> bytes_;
+  ZoneVector<uint8_t> bytes_;
 #ifdef ENABLE_SLOW_DCHECKS
   ZoneVector<PositionTableEntry> raw_entries_;
 #endif
@@ -114,7 +114,7 @@ class V8_EXPORT_PRIVATE SourcePositionTableIterator {
   // Handle-safe iterator based on an a vector located outside the garbage
   // collected heap, allows allocation during its lifetime.
   explicit SourcePositionTableIterator(
-      base::Vector<const byte> bytes,
+      base::Vector<const uint8_t> bytes,
       IterationFilter iteration_filter = kJavaScriptOnly,
       FunctionEntryFilter function_entry_filter = kSkipFunctionEntry);
 
@@ -152,7 +152,7 @@ class V8_EXPORT_PRIVATE SourcePositionTableIterator {
 
   static const int kDone = -1;
 
-  base::Vector<const byte> raw_table_;
+  base::Vector<const uint8_t> raw_table_;
   Handle<ByteArray> table_;
   int index_ = 0;
   PositionTableEntry current_;
diff --git a/src/codegen/x64/assembler-x64-inl.h b/src/codegen/x64/assembler-x64-inl.h
index bc514c0af4e..0d169e083e1 100644
--- a/src/codegen/x64/assembler-x64-inl.h
+++ b/src/codegen/x64/assembler-x64-inl.h
@@ -64,32 +64,32 @@ void Assembler::emit_rex_32(Register rm_reg) { emit(0x40 | rm_reg.high_bit()); }
 void Assembler::emit_rex_32(Operand op) { emit(0x40 | op.rex()); }
 
 void Assembler::emit_optional_rex_32(Register reg, Register rm_reg) {
-  byte rex_bits = reg.high_bit() << 2 | rm_reg.high_bit();
+  uint8_t rex_bits = reg.high_bit() << 2 | rm_reg.high_bit();
   if (rex_bits != 0) emit(0x40 | rex_bits);
 }
 
 void Assembler::emit_optional_rex_32(Register reg, Operand op) {
-  byte rex_bits = reg.high_bit() << 2 | op.rex();
+  uint8_t rex_bits = reg.high_bit() << 2 | op.rex();
   if (rex_bits != 0) emit(0x40 | rex_bits);
 }
 
 void Assembler::emit_optional_rex_32(XMMRegister reg, Operand op) {
-  byte rex_bits = (reg.code() & 0x8) >> 1 | op.rex();
+  uint8_t rex_bits = (reg.code() & 0x8) >> 1 | op.rex();
   if (rex_bits != 0) emit(0x40 | rex_bits);
 }
 
 void Assembler::emit_optional_rex_32(XMMRegister reg, XMMRegister base) {
-  byte rex_bits = (reg.code() & 0x8) >> 1 | (base.code() & 0x8) >> 3;
+  uint8_t rex_bits = (reg.code() & 0x8) >> 1 | (base.code() & 0x8) >> 3;
   if (rex_bits != 0) emit(0x40 | rex_bits);
 }
 
 void Assembler::emit_optional_rex_32(XMMRegister reg, Register base) {
-  byte rex_bits = (reg.code() & 0x8) >> 1 | (base.code() & 0x8) >> 3;
+  uint8_t rex_bits = (reg.code() & 0x8) >> 1 | (base.code() & 0x8) >> 3;
   if (rex_bits != 0) emit(0x40 | rex_bits);
 }
 
 void Assembler::emit_optional_rex_32(Register reg, XMMRegister base) {
-  byte rex_bits = (reg.code() & 0x8) >> 1 | (base.code() & 0x8) >> 3;
+  uint8_t rex_bits = (reg.code() & 0x8) >> 1 | (base.code() & 0x8) >> 3;
   if (rex_bits != 0) emit(0x40 | rex_bits);
 }
 
@@ -124,20 +124,21 @@ void Assembler::emit_optional_rex_8(Register reg, Operand op) {
 // byte 1 of 3-byte VEX
 void Assembler::emit_vex3_byte1(XMMRegister reg, XMMRegister rm,
                                 LeadingOpcode m) {
-  byte rxb = static_cast<byte>(~((reg.high_bit() << 2) | rm.high_bit())) << 5;
+  uint8_t rxb = static_cast<uint8_t>(~((reg.high_bit() << 2) | rm.high_bit()))
+                << 5;
   emit(rxb | m);
 }
 
 // byte 1 of 3-byte VEX
 void Assembler::emit_vex3_byte1(XMMRegister reg, Operand rm, LeadingOpcode m) {
-  byte rxb = static_cast<byte>(~((reg.high_bit() << 2) | rm.rex())) << 5;
+  uint8_t rxb = static_cast<uint8_t>(~((reg.high_bit() << 2) | rm.rex())) << 5;
   emit(rxb | m);
 }
 
 // byte 1 of 2-byte VEX
 void Assembler::emit_vex2_byte1(XMMRegister reg, XMMRegister v, VectorLength l,
                                 SIMDPrefix pp) {
-  byte rv = static_cast<byte>(~((reg.high_bit() << 4) | v.code())) << 3;
+  uint8_t rv = static_cast<uint8_t>(~((reg.high_bit() << 4) | v.code())) << 3;
   emit(rv | l | pp);
 }
 
diff --git a/src/codegen/x64/assembler-x64.cc b/src/codegen/x64/assembler-x64.cc
index d9996ea13b0..4b6a5f54886 100644
--- a/src/codegen/x64/assembler-x64.cc
+++ b/src/codegen/x64/assembler-x64.cc
@@ -170,10 +170,10 @@ uint32_t RelocInfo::wasm_call_tag() const {
 Operand::Operand(Operand operand, int32_t offset) {
   DCHECK_GE(operand.memory().len, 1);
   // Operand encodes REX ModR/M [SIB] [Disp].
-  byte modrm = operand.memory().buf[0];
+  uint8_t modrm = operand.memory().buf[0];
   DCHECK_LT(modrm, 0xC0);  // Disallow mode 3 (register target).
   bool has_sib = ((modrm & 0x07) == 0x04);
-  byte mode = modrm & 0xC0;
+  uint8_t mode = modrm & 0xC0;
   int disp_offset = has_sib ? 2 : 1;
   int base_reg = (has_sib ? operand.memory().buf[1] : modrm) & 0x07;
   // Mode 0 with rbp/r13 as ModR/M or SIB base register always has a 32-bit
@@ -204,7 +204,7 @@ Operand::Operand(Operand operand, int32_t offset) {
     // Need 8 bits of displacement.
     memory_.buf[0] = (modrm & 0x3F) | 0x40;  // Mode 1.
     memory_.len = disp_offset + 1;
-    memory_.buf[disp_offset] = static_cast<byte>(disp_value);
+    memory_.buf[disp_offset] = static_cast<uint8_t>(disp_value);
   } else {
     // Need no displacement.
     memory_.buf[0] = (modrm & 0x3F);  // Mode 0.
@@ -468,7 +468,7 @@ void Assembler::LoopHeaderAlign() {
 }
 
 bool Assembler::IsNop(Address addr) {
-  byte* a = reinterpret_cast<byte*>(addr);
+  uint8_t* a = reinterpret_cast<uint8_t*>(addr);
   while (*a == 0x66) a++;
   if (*a == 0x90) return true;
   if (a[0] == 0xF && a[1] == 0x1F) return true;
@@ -608,7 +608,7 @@ void Assembler::GrowBuffer() {
   // Set up new buffer.
   std::unique_ptr<AssemblerBuffer> new_buffer = buffer_->Grow(new_size);
   DCHECK_EQ(new_size, new_buffer->size());
-  byte* new_start = new_buffer->start();
+  uint8_t* new_start = new_buffer->start();
 
   // Copy the data.
   intptr_t pc_delta = new_start - buffer_start_;
@@ -699,14 +699,15 @@ void Assembler::emit_label_operand(int code, Label* label, int addend) {
 
 // Assembler Instruction implementations.
 
-void Assembler::arithmetic_op(byte opcode, Register reg, Operand op, int size) {
+void Assembler::arithmetic_op(uint8_t opcode, Register reg, Operand op,
+                              int size) {
   EnsureSpace ensure_space(this);
   emit_rex(reg, op, size);
   emit(opcode);
   emit_operand(reg, op);
 }
 
-void Assembler::arithmetic_op(byte opcode, Register reg, Register rm_reg,
+void Assembler::arithmetic_op(uint8_t opcode, Register reg, Register rm_reg,
                               int size) {
   EnsureSpace ensure_space(this);
   DCHECK_EQ(opcode & 0xC6, 2);
@@ -722,7 +723,8 @@ void Assembler::arithmetic_op(byte opcode, Register reg, Register rm_reg,
   }
 }
 
-void Assembler::arithmetic_op_16(byte opcode, Register reg, Register rm_reg) {
+void Assembler::arithmetic_op_16(uint8_t opcode, Register reg,
+                                 Register rm_reg) {
   EnsureSpace ensure_space(this);
   DCHECK_EQ(opcode & 0xC6, 2);
   if (rm_reg.low_bits() == 4) {  // Forces SIB byte.
@@ -739,7 +741,7 @@ void Assembler::arithmetic_op_16(byte opcode, Register reg, Register rm_reg) {
   }
 }
 
-void Assembler::arithmetic_op_16(byte opcode, Register reg, Operand rm_reg) {
+void Assembler::arithmetic_op_16(uint8_t opcode, Register reg, Operand rm_reg) {
   EnsureSpace ensure_space(this);
   emit(0x66);
   emit_optional_rex_32(reg, rm_reg);
@@ -747,7 +749,7 @@ void Assembler::arithmetic_op_16(byte opcode, Register reg, Operand rm_reg) {
   emit_operand(reg, rm_reg);
 }
 
-void Assembler::arithmetic_op_8(byte opcode, Register reg, Operand op) {
+void Assembler::arithmetic_op_8(uint8_t opcode, Register reg, Operand op) {
   EnsureSpace ensure_space(this);
   if (!reg.is_byte_register()) {
     emit_rex_32(reg, op);
@@ -758,7 +760,7 @@ void Assembler::arithmetic_op_8(byte opcode, Register reg, Operand op) {
   emit_operand(reg, op);
 }
 
-void Assembler::arithmetic_op_8(byte opcode, Register reg, Register rm_reg) {
+void Assembler::arithmetic_op_8(uint8_t opcode, Register reg, Register rm_reg) {
   EnsureSpace ensure_space(this);
   DCHECK_EQ(opcode & 0xC6, 2);
   if (rm_reg.low_bits() == 4) {  // Forces SIB byte.
@@ -779,7 +781,7 @@ void Assembler::arithmetic_op_8(byte opcode, Register reg, Register rm_reg) {
   }
 }
 
-void Assembler::immediate_arithmetic_op(byte subcode, Register dst,
+void Assembler::immediate_arithmetic_op(uint8_t subcode, Register dst,
                                         Immediate src, int size) {
   EnsureSpace ensure_space(this);
   emit_rex(dst, size);
@@ -797,7 +799,7 @@ void Assembler::immediate_arithmetic_op(byte subcode, Register dst,
   }
 }
 
-void Assembler::immediate_arithmetic_op(byte subcode, Operand dst,
+void Assembler::immediate_arithmetic_op(uint8_t subcode, Operand dst,
                                         Immediate src, int size) {
   EnsureSpace ensure_space(this);
   emit_rex(dst, size);
@@ -812,7 +814,7 @@ void Assembler::immediate_arithmetic_op(byte subcode, Operand dst,
   }
 }
 
-void Assembler::immediate_arithmetic_op_16(byte subcode, Register dst,
+void Assembler::immediate_arithmetic_op_16(uint8_t subcode, Register dst,
                                            Immediate src) {
   EnsureSpace ensure_space(this);
   emit(0x66);  // Operand size override prefix.
@@ -831,7 +833,7 @@ void Assembler::immediate_arithmetic_op_16(byte subcode, Register dst,
   }
 }
 
-void Assembler::immediate_arithmetic_op_16(byte subcode, Operand dst,
+void Assembler::immediate_arithmetic_op_16(uint8_t subcode, Operand dst,
                                            Immediate src) {
   EnsureSpace ensure_space(this);
   emit(0x66);  // Operand size override prefix.
@@ -847,7 +849,7 @@ void Assembler::immediate_arithmetic_op_16(byte subcode, Operand dst,
   }
 }
 
-void Assembler::immediate_arithmetic_op_8(byte subcode, Operand dst,
+void Assembler::immediate_arithmetic_op_8(uint8_t subcode, Operand dst,
                                           Immediate src) {
   EnsureSpace ensure_space(this);
   emit_optional_rex_32(dst);
@@ -857,7 +859,7 @@ void Assembler::immediate_arithmetic_op_8(byte subcode, Operand dst,
   emit(src.value_);
 }
 
-void Assembler::immediate_arithmetic_op_8(byte subcode, Register dst,
+void Assembler::immediate_arithmetic_op_8(uint8_t subcode, Register dst,
                                           Immediate src) {
   EnsureSpace ensure_space(this);
   if (!dst.is_byte_register()) {
@@ -1432,11 +1434,11 @@ void Assembler::j(Condition cc, Label* L, Label::Distance distance) {
   } else if (distance == Label::kNear) {
     // 0111 tttn #8-bit disp
     emit(0x70 | cc);
-    byte disp = 0x00;
+    uint8_t disp = 0x00;
     if (L->is_near_linked()) {
       int offset = L->near_link_pos() - pc_offset();
       DCHECK(is_int8(offset));
-      disp = static_cast<byte>(offset & 0xFF);
+      disp = static_cast<uint8_t>(offset & 0xFF);
     }
     L->link_to(pc_offset(), Label::kNear);
     emit(disp);
@@ -1527,11 +1529,11 @@ void Assembler::jmp(Label* L, Label::Distance distance) {
   EnsureSpace ensure_space(this);
   if (distance == Label::kNear) {
     emit(0xEB);
-    byte disp = 0x00;
+    uint8_t disp = 0x00;
     if (L->is_near_linked()) {
       int offset = L->near_link_pos() - pc_offset();
       DCHECK(is_int8(offset));
-      disp = static_cast<byte>(offset & 0xFF);
+      disp = static_cast<uint8_t>(offset & 0xFF);
     }
     L->link_to(pc_offset(), Label::kNear);
     emit(disp);
@@ -1656,7 +1658,7 @@ void Assembler::movb(Operand dst, Immediate imm) {
   emit_optional_rex_32(dst);
   emit(0xC6);
   emit_operand(0x0, dst);
-  emit(static_cast<byte>(imm.value_));
+  emit(static_cast<uint8_t>(imm.value_));
 }
 
 void Assembler::movw(Register dst, Operand src) {
@@ -1681,8 +1683,8 @@ void Assembler::movw(Operand dst, Immediate imm) {
   emit_optional_rex_32(dst);
   emit(0xC7);
   emit_operand(0x0, dst);
-  emit(static_cast<byte>(imm.value_ & 0xFF));
-  emit(static_cast<byte>(imm.value_ >> 8));
+  emit(static_cast<uint8_t>(imm.value_ & 0xFF));
+  emit(static_cast<uint8_t>(imm.value_ >> 8));
 }
 
 void Assembler::emit_mov(Register dst, Operand src, int size) {
@@ -2978,13 +2980,13 @@ void Assembler::pinsrb(XMMRegister dst, Operand src, uint8_t imm8) {
   emit(imm8);
 }
 
-void Assembler::insertps(XMMRegister dst, XMMRegister src, byte imm8) {
+void Assembler::insertps(XMMRegister dst, XMMRegister src, uint8_t imm8) {
   DCHECK(is_uint8(imm8));
   sse4_instr(dst, src, 0x66, 0x0F, 0x3A, 0x21);
   emit(imm8);
 }
 
-void Assembler::insertps(XMMRegister dst, Operand src, byte imm8) {
+void Assembler::insertps(XMMRegister dst, Operand src, uint8_t imm8) {
   DCHECK(is_uint8(imm8));
   sse4_instr(dst, src, 0x66, 0x0F, 0x3A, 0x21);
   emit(imm8);
@@ -3046,7 +3048,7 @@ void Assembler::movaps(XMMRegister dst, Operand src) {
   emit_sse_operand(dst, src);
 }
 
-void Assembler::shufps(XMMRegister dst, XMMRegister src, byte imm8) {
+void Assembler::shufps(XMMRegister dst, XMMRegister src, uint8_t imm8) {
   DCHECK(is_uint8(imm8));
   EnsureSpace ensure_space(this);
   emit_optional_rex_32(dst, src);
@@ -3472,42 +3474,42 @@ void Assembler::roundss(XMMRegister dst, XMMRegister src, RoundingMode mode) {
   DCHECK(!IsEnabled(AVX));
   sse4_instr(dst, src, 0x66, 0x0F, 0x3A, 0x0A);
   // Mask precision exception.
-  emit(static_cast<byte>(mode) | 0x8);
+  emit(static_cast<uint8_t>(mode) | 0x8);
 }
 
 void Assembler::roundss(XMMRegister dst, Operand src, RoundingMode mode) {
   DCHECK(!IsEnabled(AVX));
   sse4_instr(dst, src, 0x66, 0x0F, 0x3A, 0x0A);
   // Mask precision exception.
-  emit(static_cast<byte>(mode) | 0x8);
+  emit(static_cast<uint8_t>(mode) | 0x8);
 }
 
 void Assembler::roundsd(XMMRegister dst, XMMRegister src, RoundingMode mode) {
   DCHECK(!IsEnabled(AVX));
   sse4_instr(dst, src, 0x66, 0x0F, 0x3A, 0x0B);
   // Mask precision exception.
-  emit(static_cast<byte>(mode) | 0x8);
+  emit(static_cast<uint8_t>(mode) | 0x8);
 }
 
 void Assembler::roundsd(XMMRegister dst, Operand src, RoundingMode mode) {
   DCHECK(!IsEnabled(AVX));
   sse4_instr(dst, src, 0x66, 0x0F, 0x3A, 0x0B);
   // Mask precision exception.
-  emit(static_cast<byte>(mode) | 0x8);
+  emit(static_cast<uint8_t>(mode) | 0x8);
 }
 
 void Assembler::roundps(XMMRegister dst, XMMRegister src, RoundingMode mode) {
   DCHECK(!IsEnabled(AVX));
   sse4_instr(dst, src, 0x66, 0x0F, 0x3A, 0x08);
   // Mask precision exception.
-  emit(static_cast<byte>(mode) | 0x8);
+  emit(static_cast<uint8_t>(mode) | 0x8);
 }
 
 void Assembler::roundpd(XMMRegister dst, XMMRegister src, RoundingMode mode) {
   DCHECK(!IsEnabled(AVX));
   sse4_instr(dst, src, 0x66, 0x0F, 0x3A, 0x09);
   // Mask precision exception.
-  emit(static_cast<byte>(mode) | 0x8);
+  emit(static_cast<uint8_t>(mode) | 0x8);
 }
 
 void Assembler::movmskpd(Register dst, XMMRegister src) {
@@ -3584,7 +3586,7 @@ BROADCASTSS(XMMRegister, L128)
 BROADCASTSS(YMMRegister, L256)
 #undef BROADCASTSS
 
-void Assembler::fma_instr(byte op, XMMRegister dst, XMMRegister src1,
+void Assembler::fma_instr(uint8_t op, XMMRegister dst, XMMRegister src1,
                           XMMRegister src2, VectorLength l, SIMDPrefix pp,
                           LeadingOpcode m, VexW w) {
   DCHECK(IsEnabled(FMA3));
@@ -3594,7 +3596,7 @@ void Assembler::fma_instr(byte op, XMMRegister dst, XMMRegister src1,
   emit_sse_operand(dst, src2);
 }
 
-void Assembler::fma_instr(byte op, XMMRegister dst, XMMRegister src1,
+void Assembler::fma_instr(uint8_t op, XMMRegister dst, XMMRegister src1,
                           Operand src2, VectorLength l, SIMDPrefix pp,
                           LeadingOpcode m, VexW w) {
   DCHECK(IsEnabled(FMA3));
@@ -3768,7 +3770,7 @@ void Assembler::vmovhps(Operand dst, XMMRegister src) {
   emit_sse_operand(src, dst);
 }
 
-void Assembler::vinstr(byte op, XMMRegister dst, XMMRegister src1,
+void Assembler::vinstr(uint8_t op, XMMRegister dst, XMMRegister src1,
                        XMMRegister src2, SIMDPrefix pp, LeadingOpcode m, VexW w,
                        CpuFeature feature) {
   DCHECK(IsEnabled(feature));
@@ -3779,8 +3781,8 @@ void Assembler::vinstr(byte op, XMMRegister dst, XMMRegister src1,
   emit_sse_operand(dst, src2);
 }
 
-void Assembler::vinstr(byte op, XMMRegister dst, XMMRegister src1, Operand src2,
-                       SIMDPrefix pp, LeadingOpcode m, VexW w,
+void Assembler::vinstr(uint8_t op, XMMRegister dst, XMMRegister src1,
+                       Operand src2, SIMDPrefix pp, LeadingOpcode m, VexW w,
                        CpuFeature feature) {
   DCHECK(IsEnabled(feature));
   DCHECK(feature == AVX || feature == AVX2);
@@ -3791,7 +3793,7 @@ void Assembler::vinstr(byte op, XMMRegister dst, XMMRegister src1, Operand src2,
 }
 
 template <typename Reg1, typename Reg2, typename Op>
-void Assembler::vinstr(byte op, Reg1 dst, Reg2 src1, Op src2, SIMDPrefix pp,
+void Assembler::vinstr(uint8_t op, Reg1 dst, Reg2 src1, Op src2, SIMDPrefix pp,
                        LeadingOpcode m, VexW w, CpuFeature feature) {
   DCHECK(IsEnabled(feature));
   DCHECK(feature == AVX || feature == AVX2);
@@ -3804,22 +3806,22 @@ void Assembler::vinstr(byte op, Reg1 dst, Reg2 src1, Op src2, SIMDPrefix pp,
 }
 
 template EXPORT_TEMPLATE_DEFINE(V8_EXPORT_PRIVATE) void Assembler::vinstr(
-    byte op, YMMRegister dst, YMMRegister src1, YMMRegister src2, SIMDPrefix pp,
-    LeadingOpcode m, VexW w, CpuFeature feature);
+    uint8_t op, YMMRegister dst, YMMRegister src1, YMMRegister src2,
+    SIMDPrefix pp, LeadingOpcode m, VexW w, CpuFeature feature);
 template EXPORT_TEMPLATE_DEFINE(V8_EXPORT_PRIVATE) void Assembler::vinstr(
-    byte op, YMMRegister dst, XMMRegister src1, XMMRegister src2, SIMDPrefix pp,
-    LeadingOpcode m, VexW w, CpuFeature feature);
+    uint8_t op, YMMRegister dst, XMMRegister src1, XMMRegister src2,
+    SIMDPrefix pp, LeadingOpcode m, VexW w, CpuFeature feature);
 template EXPORT_TEMPLATE_DEFINE(V8_EXPORT_PRIVATE) void Assembler::vinstr(
-    byte op, YMMRegister dst, YMMRegister src1, Operand src2, SIMDPrefix pp,
+    uint8_t op, YMMRegister dst, YMMRegister src1, Operand src2, SIMDPrefix pp,
     LeadingOpcode m, VexW w, CpuFeature feature);
 template EXPORT_TEMPLATE_DEFINE(V8_EXPORT_PRIVATE) void Assembler::vinstr(
-    byte op, YMMRegister dst, YMMRegister src1, XMMRegister src2, SIMDPrefix pp,
-    LeadingOpcode m, VexW w, CpuFeature feature);
+    uint8_t op, YMMRegister dst, YMMRegister src1, XMMRegister src2,
+    SIMDPrefix pp, LeadingOpcode m, VexW w, CpuFeature feature);
 template EXPORT_TEMPLATE_DEFINE(V8_EXPORT_PRIVATE) void Assembler::vinstr(
-    byte op, YMMRegister dst, XMMRegister src1, Operand src2, SIMDPrefix pp,
+    uint8_t op, YMMRegister dst, XMMRegister src1, Operand src2, SIMDPrefix pp,
     LeadingOpcode m, VexW w, CpuFeature feature);
 
-void Assembler::vps(byte op, XMMRegister dst, XMMRegister src1,
+void Assembler::vps(uint8_t op, XMMRegister dst, XMMRegister src1,
                     XMMRegister src2) {
   DCHECK(IsEnabled(AVX));
   EnsureSpace ensure_space(this);
@@ -3828,7 +3830,7 @@ void Assembler::vps(byte op, XMMRegister dst, XMMRegister src1,
   emit_sse_operand(dst, src2);
 }
 
-void Assembler::vps(byte op, YMMRegister dst, YMMRegister src1,
+void Assembler::vps(uint8_t op, YMMRegister dst, YMMRegister src1,
                     YMMRegister src2) {
   DCHECK(IsEnabled(AVX));
   EnsureSpace ensure_space(this);
@@ -3837,7 +3839,8 @@ void Assembler::vps(byte op, YMMRegister dst, YMMRegister src1,
   emit_sse_operand(dst, src2);
 }
 
-void Assembler::vps(byte op, XMMRegister dst, XMMRegister src1, Operand src2) {
+void Assembler::vps(uint8_t op, XMMRegister dst, XMMRegister src1,
+                    Operand src2) {
   DCHECK(IsEnabled(AVX));
   EnsureSpace ensure_space(this);
   emit_vex_prefix(dst, src1, src2, kL128, kNoPrefix, k0F, kWIG);
@@ -3845,7 +3848,8 @@ void Assembler::vps(byte op, XMMRegister dst, XMMRegister src1, Operand src2) {
   emit_sse_operand(dst, src2);
 }
 
-void Assembler::vps(byte op, YMMRegister dst, YMMRegister src1, Operand src2) {
+void Assembler::vps(uint8_t op, YMMRegister dst, YMMRegister src1,
+                    Operand src2) {
   DCHECK(IsEnabled(AVX));
   EnsureSpace ensure_space(this);
   emit_vex_prefix(dst, src1, src2, kL256, kNoPrefix, k0F, kWIG);
@@ -3853,8 +3857,8 @@ void Assembler::vps(byte op, YMMRegister dst, YMMRegister src1, Operand src2) {
   emit_sse_operand(dst, src2);
 }
 
-void Assembler::vps(byte op, XMMRegister dst, XMMRegister src1,
-                    XMMRegister src2, byte imm8) {
+void Assembler::vps(uint8_t op, XMMRegister dst, XMMRegister src1,
+                    XMMRegister src2, uint8_t imm8) {
   DCHECK(IsEnabled(AVX));
   EnsureSpace ensure_space(this);
   emit_vex_prefix(dst, src1, src2, kL128, kNoPrefix, k0F, kWIG);
@@ -3863,8 +3867,8 @@ void Assembler::vps(byte op, XMMRegister dst, XMMRegister src1,
   emit(imm8);
 }
 
-void Assembler::vps(byte op, YMMRegister dst, YMMRegister src1,
-                    YMMRegister src2, byte imm8) {
+void Assembler::vps(uint8_t op, YMMRegister dst, YMMRegister src1,
+                    YMMRegister src2, uint8_t imm8) {
   DCHECK(IsEnabled(AVX));
   EnsureSpace ensure_space(this);
   emit_vex_prefix(dst, src1, src2, kL256, kNoPrefix, k0F, kWIG);
@@ -3873,23 +3877,23 @@ void Assembler::vps(byte op, YMMRegister dst, YMMRegister src1,
   emit(imm8);
 }
 
-#define VPD(DSTRegister, SRCRegister, length)                     \
-  void Assembler::vpd(byte op, DSTRegister dst, SRCRegister src1, \
-                      SRCRegister src2) {                         \
-    DCHECK(IsEnabled(AVX));                                       \
-    EnsureSpace ensure_space(this);                               \
-    emit_vex_prefix(dst, src1, src2, k##length, k66, k0F, kWIG);  \
-    emit(op);                                                     \
-    emit_sse_operand(dst, src2);                                  \
-  }                                                               \
-                                                                  \
-  void Assembler::vpd(byte op, DSTRegister dst, SRCRegister src1, \
-                      Operand src2) {                             \
-    DCHECK(IsEnabled(AVX));                                       \
-    EnsureSpace ensure_space(this);                               \
-    emit_vex_prefix(dst, src1, src2, k##length, k66, k0F, kWIG);  \
-    emit(op);                                                     \
-    emit_sse_operand(dst, src2);                                  \
+#define VPD(DSTRegister, SRCRegister, length)                        \
+  void Assembler::vpd(uint8_t op, DSTRegister dst, SRCRegister src1, \
+                      SRCRegister src2) {                            \
+    DCHECK(IsEnabled(AVX));                                          \
+    EnsureSpace ensure_space(this);                                  \
+    emit_vex_prefix(dst, src1, src2, k##length, k66, k0F, kWIG);     \
+    emit(op);                                                        \
+    emit_sse_operand(dst, src2);                                     \
+  }                                                                  \
+                                                                     \
+  void Assembler::vpd(uint8_t op, DSTRegister dst, SRCRegister src1, \
+                      Operand src2) {                                \
+    DCHECK(IsEnabled(AVX));                                          \
+    EnsureSpace ensure_space(this);                                  \
+    emit_vex_prefix(dst, src1, src2, k##length, k66, k0F, kWIG);     \
+    emit(op);                                                        \
+    emit_sse_operand(dst, src2);                                     \
   }
 VPD(XMMRegister, XMMRegister, L128)
 VPD(XMMRegister, YMMRegister, L256)
@@ -3921,7 +3925,7 @@ void Assembler::vpmovmskb(Register dst, XMMRegister src) {
   emit_sse_operand(idst, src);
 }
 
-void Assembler::vss(byte op, XMMRegister dst, XMMRegister src1,
+void Assembler::vss(uint8_t op, XMMRegister dst, XMMRegister src1,
                     XMMRegister src2) {
   DCHECK(IsEnabled(AVX));
   EnsureSpace ensure_space(this);
@@ -3930,7 +3934,8 @@ void Assembler::vss(byte op, XMMRegister dst, XMMRegister src1,
   emit_sse_operand(dst, src2);
 }
 
-void Assembler::vss(byte op, XMMRegister dst, XMMRegister src1, Operand src2) {
+void Assembler::vss(uint8_t op, XMMRegister dst, XMMRegister src1,
+                    Operand src2) {
   DCHECK(IsEnabled(AVX));
   EnsureSpace ensure_space(this);
   emit_vex_prefix(dst, src1, src2, kLIG, kF3, k0F, kWIG);
@@ -3938,7 +3943,7 @@ void Assembler::vss(byte op, XMMRegister dst, XMMRegister src1, Operand src2) {
   emit_sse_operand(dst, src2);
 }
 
-void Assembler::bmi1q(byte op, Register reg, Register vreg, Register rm) {
+void Assembler::bmi1q(uint8_t op, Register reg, Register vreg, Register rm) {
   DCHECK(IsEnabled(BMI1));
   EnsureSpace ensure_space(this);
   emit_vex_prefix(reg, vreg, rm, kLZ, kNoPrefix, k0F38, kW1);
@@ -3946,7 +3951,7 @@ void Assembler::bmi1q(byte op, Register reg, Register vreg, Register rm) {
   emit_modrm(reg, rm);
 }
 
-void Assembler::bmi1q(byte op, Register reg, Register vreg, Operand rm) {
+void Assembler::bmi1q(uint8_t op, Register reg, Register vreg, Operand rm) {
   DCHECK(IsEnabled(BMI1));
   EnsureSpace ensure_space(this);
   emit_vex_prefix(reg, vreg, rm, kLZ, kNoPrefix, k0F38, kW1);
@@ -3954,7 +3959,7 @@ void Assembler::bmi1q(byte op, Register reg, Register vreg, Operand rm) {
   emit_operand(reg, rm);
 }
 
-void Assembler::bmi1l(byte op, Register reg, Register vreg, Register rm) {
+void Assembler::bmi1l(uint8_t op, Register reg, Register vreg, Register rm) {
   DCHECK(IsEnabled(BMI1));
   EnsureSpace ensure_space(this);
   emit_vex_prefix(reg, vreg, rm, kLZ, kNoPrefix, k0F38, kW0);
@@ -3962,7 +3967,7 @@ void Assembler::bmi1l(byte op, Register reg, Register vreg, Register rm) {
   emit_modrm(reg, rm);
 }
 
-void Assembler::bmi1l(byte op, Register reg, Register vreg, Operand rm) {
+void Assembler::bmi1l(uint8_t op, Register reg, Register vreg, Operand rm) {
   DCHECK(IsEnabled(BMI1));
   EnsureSpace ensure_space(this);
   emit_vex_prefix(reg, vreg, rm, kLZ, kNoPrefix, k0F38, kW0);
@@ -4090,7 +4095,7 @@ void Assembler::popcntl(Register dst, Operand src) {
   emit_operand(dst, src);
 }
 
-void Assembler::bmi2q(SIMDPrefix pp, byte op, Register reg, Register vreg,
+void Assembler::bmi2q(SIMDPrefix pp, uint8_t op, Register reg, Register vreg,
                       Register rm) {
   DCHECK(IsEnabled(BMI2));
   EnsureSpace ensure_space(this);
@@ -4099,7 +4104,7 @@ void Assembler::bmi2q(SIMDPrefix pp, byte op, Register reg, Register vreg,
   emit_modrm(reg, rm);
 }
 
-void Assembler::bmi2q(SIMDPrefix pp, byte op, Register reg, Register vreg,
+void Assembler::bmi2q(SIMDPrefix pp, uint8_t op, Register reg, Register vreg,
                       Operand rm) {
   DCHECK(IsEnabled(BMI2));
   EnsureSpace ensure_space(this);
@@ -4108,7 +4113,7 @@ void Assembler::bmi2q(SIMDPrefix pp, byte op, Register reg, Register vreg,
   emit_operand(reg, rm);
 }
 
-void Assembler::bmi2l(SIMDPrefix pp, byte op, Register reg, Register vreg,
+void Assembler::bmi2l(SIMDPrefix pp, uint8_t op, Register reg, Register vreg,
                       Register rm) {
   DCHECK(IsEnabled(BMI2));
   EnsureSpace ensure_space(this);
@@ -4117,7 +4122,7 @@ void Assembler::bmi2l(SIMDPrefix pp, byte op, Register reg, Register vreg,
   emit_modrm(reg, rm);
 }
 
-void Assembler::bmi2l(SIMDPrefix pp, byte op, Register reg, Register vreg,
+void Assembler::bmi2l(SIMDPrefix pp, uint8_t op, Register reg, Register vreg,
                       Operand rm) {
   DCHECK(IsEnabled(BMI2));
   EnsureSpace ensure_space(this);
@@ -4126,7 +4131,7 @@ void Assembler::bmi2l(SIMDPrefix pp, byte op, Register reg, Register vreg,
   emit_operand(reg, rm);
 }
 
-void Assembler::rorxq(Register dst, Register src, byte imm8) {
+void Assembler::rorxq(Register dst, Register src, uint8_t imm8) {
   DCHECK(IsEnabled(BMI2));
   DCHECK(is_uint8(imm8));
   Register vreg = Register::from_code(0);  // VEX.vvvv unused
@@ -4137,7 +4142,7 @@ void Assembler::rorxq(Register dst, Register src, byte imm8) {
   emit(imm8);
 }
 
-void Assembler::rorxq(Register dst, Operand src, byte imm8) {
+void Assembler::rorxq(Register dst, Operand src, uint8_t imm8) {
   DCHECK(IsEnabled(BMI2));
   DCHECK(is_uint8(imm8));
   Register vreg = Register::from_code(0);  // VEX.vvvv unused
@@ -4148,7 +4153,7 @@ void Assembler::rorxq(Register dst, Operand src, byte imm8) {
   emit(imm8);
 }
 
-void Assembler::rorxl(Register dst, Register src, byte imm8) {
+void Assembler::rorxl(Register dst, Register src, uint8_t imm8) {
   DCHECK(IsEnabled(BMI2));
   DCHECK(is_uint8(imm8));
   Register vreg = Register::from_code(0);  // VEX.vvvv unused
@@ -4159,7 +4164,7 @@ void Assembler::rorxl(Register dst, Register src, byte imm8) {
   emit(imm8);
 }
 
-void Assembler::rorxl(Register dst, Operand src, byte imm8) {
+void Assembler::rorxl(Register dst, Operand src, uint8_t imm8) {
   DCHECK(IsEnabled(BMI2));
   DCHECK(is_uint8(imm8));
   Register vreg = Register::from_code(0);  // VEX.vvvv unused
@@ -4207,8 +4212,8 @@ void Assembler::movups(Operand dst, XMMRegister src) {
   emit_sse_operand(src, dst);
 }
 
-void Assembler::sse_instr(XMMRegister dst, XMMRegister src, byte escape,
-                          byte opcode) {
+void Assembler::sse_instr(XMMRegister dst, XMMRegister src, uint8_t escape,
+                          uint8_t opcode) {
   EnsureSpace ensure_space(this);
   emit_optional_rex_32(dst, src);
   emit(escape);
@@ -4216,8 +4221,8 @@ void Assembler::sse_instr(XMMRegister dst, XMMRegister src, byte escape,
   emit_sse_operand(dst, src);
 }
 
-void Assembler::sse_instr(XMMRegister dst, Operand src, byte escape,
-                          byte opcode) {
+void Assembler::sse_instr(XMMRegister dst, Operand src, uint8_t escape,
+                          uint8_t opcode) {
   EnsureSpace ensure_space(this);
   emit_optional_rex_32(dst, src);
   emit(escape);
@@ -4225,8 +4230,8 @@ void Assembler::sse_instr(XMMRegister dst, Operand src, byte escape,
   emit_sse_operand(dst, src);
 }
 
-void Assembler::sse2_instr(XMMRegister dst, XMMRegister src, byte prefix,
-                           byte escape, byte opcode) {
+void Assembler::sse2_instr(XMMRegister dst, XMMRegister src, uint8_t prefix,
+                           uint8_t escape, uint8_t opcode) {
   EnsureSpace ensure_space(this);
   emit(prefix);
   emit_optional_rex_32(dst, src);
@@ -4235,8 +4240,8 @@ void Assembler::sse2_instr(XMMRegister dst, XMMRegister src, byte prefix,
   emit_sse_operand(dst, src);
 }
 
-void Assembler::sse2_instr(XMMRegister dst, Operand src, byte prefix,
-                           byte escape, byte opcode) {
+void Assembler::sse2_instr(XMMRegister dst, Operand src, uint8_t prefix,
+                           uint8_t escape, uint8_t opcode) {
   EnsureSpace ensure_space(this);
   emit(prefix);
   emit_optional_rex_32(dst, src);
@@ -4245,8 +4250,8 @@ void Assembler::sse2_instr(XMMRegister dst, Operand src, byte prefix,
   emit_sse_operand(dst, src);
 }
 
-void Assembler::ssse3_instr(XMMRegister dst, XMMRegister src, byte prefix,
-                            byte escape1, byte escape2, byte opcode) {
+void Assembler::ssse3_instr(XMMRegister dst, XMMRegister src, uint8_t prefix,
+                            uint8_t escape1, uint8_t escape2, uint8_t opcode) {
   DCHECK(IsEnabled(SSSE3));
   EnsureSpace ensure_space(this);
   emit(prefix);
@@ -4257,8 +4262,8 @@ void Assembler::ssse3_instr(XMMRegister dst, XMMRegister src, byte prefix,
   emit_sse_operand(dst, src);
 }
 
-void Assembler::ssse3_instr(XMMRegister dst, Operand src, byte prefix,
-                            byte escape1, byte escape2, byte opcode) {
+void Assembler::ssse3_instr(XMMRegister dst, Operand src, uint8_t prefix,
+                            uint8_t escape1, uint8_t escape2, uint8_t opcode) {
   DCHECK(IsEnabled(SSSE3));
   EnsureSpace ensure_space(this);
   emit(prefix);
@@ -4269,8 +4274,8 @@ void Assembler::ssse3_instr(XMMRegister dst, Operand src, byte prefix,
   emit_sse_operand(dst, src);
 }
 
-void Assembler::sse4_instr(XMMRegister dst, Register src, byte prefix,
-                           byte escape1, byte escape2, byte opcode,
+void Assembler::sse4_instr(XMMRegister dst, Register src, uint8_t prefix,
+                           uint8_t escape1, uint8_t escape2, uint8_t opcode,
                            int8_t imm8) {
   DCHECK(is_uint8(imm8));
   DCHECK(IsEnabled(SSE4_1));
@@ -4284,8 +4289,8 @@ void Assembler::sse4_instr(XMMRegister dst, Register src, byte prefix,
   emit(imm8);
 }
 
-void Assembler::sse4_instr(XMMRegister dst, XMMRegister src, byte prefix,
-                           byte escape1, byte escape2, byte opcode) {
+void Assembler::sse4_instr(XMMRegister dst, XMMRegister src, uint8_t prefix,
+                           uint8_t escape1, uint8_t escape2, uint8_t opcode) {
   DCHECK(IsEnabled(SSE4_1));
   EnsureSpace ensure_space(this);
   emit(prefix);
@@ -4296,8 +4301,8 @@ void Assembler::sse4_instr(XMMRegister dst, XMMRegister src, byte prefix,
   emit_sse_operand(dst, src);
 }
 
-void Assembler::sse4_instr(XMMRegister dst, Operand src, byte prefix,
-                           byte escape1, byte escape2, byte opcode) {
+void Assembler::sse4_instr(XMMRegister dst, Operand src, uint8_t prefix,
+                           uint8_t escape1, uint8_t escape2, uint8_t opcode) {
   DCHECK(IsEnabled(SSE4_1));
   EnsureSpace ensure_space(this);
   emit(prefix);
@@ -4308,8 +4313,8 @@ void Assembler::sse4_instr(XMMRegister dst, Operand src, byte prefix,
   emit_sse_operand(dst, src);
 }
 
-void Assembler::sse4_instr(Register dst, XMMRegister src, byte prefix,
-                           byte escape1, byte escape2, byte opcode,
+void Assembler::sse4_instr(Register dst, XMMRegister src, uint8_t prefix,
+                           uint8_t escape1, uint8_t escape2, uint8_t opcode,
                            int8_t imm8) {
   DCHECK(is_uint8(imm8));
   DCHECK(IsEnabled(SSE4_1));
@@ -4323,8 +4328,8 @@ void Assembler::sse4_instr(Register dst, XMMRegister src, byte prefix,
   emit(imm8);
 }
 
-void Assembler::sse4_instr(Operand dst, XMMRegister src, byte prefix,
-                           byte escape1, byte escape2, byte opcode,
+void Assembler::sse4_instr(Operand dst, XMMRegister src, uint8_t prefix,
+                           uint8_t escape1, uint8_t escape2, uint8_t opcode,
                            int8_t imm8) {
   DCHECK(is_uint8(imm8));
   DCHECK(IsEnabled(SSE4_1));
@@ -4338,8 +4343,8 @@ void Assembler::sse4_instr(Operand dst, XMMRegister src, byte prefix,
   emit(imm8);
 }
 
-void Assembler::sse4_2_instr(XMMRegister dst, XMMRegister src, byte prefix,
-                             byte escape1, byte escape2, byte opcode) {
+void Assembler::sse4_2_instr(XMMRegister dst, XMMRegister src, uint8_t prefix,
+                             uint8_t escape1, uint8_t escape2, uint8_t opcode) {
   DCHECK(IsEnabled(SSE4_2));
   EnsureSpace ensure_space(this);
   emit(prefix);
@@ -4350,8 +4355,8 @@ void Assembler::sse4_2_instr(XMMRegister dst, XMMRegister src, byte prefix,
   emit_sse_operand(dst, src);
 }
 
-void Assembler::sse4_2_instr(XMMRegister dst, Operand src, byte prefix,
-                             byte escape1, byte escape2, byte opcode) {
+void Assembler::sse4_2_instr(XMMRegister dst, Operand src, uint8_t prefix,
+                             uint8_t escape1, uint8_t escape2, uint8_t opcode) {
   DCHECK(IsEnabled(SSE4_2));
   EnsureSpace ensure_space(this);
   emit(prefix);
diff --git a/src/codegen/x64/assembler-x64.h b/src/codegen/x64/assembler-x64.h
index 935897e0fbf..db146edf967 100644
--- a/src/codegen/x64/assembler-x64.h
+++ b/src/codegen/x64/assembler-x64.h
@@ -182,7 +182,7 @@ class V8_EXPORT_PRIVATE Operand {
     // introduces additional padding between them and the union, increasing the
     // size unnecessarily.
     bool is_label_operand = true;
-    byte rex = 0;  // REX prefix, always zero for label operands.
+    uint8_t rex = 0;  // REX prefix, always zero for label operands.
 
     int8_t addend;  // Used for rip + offset + addend operands.
     Label* label;
@@ -190,10 +190,10 @@ class V8_EXPORT_PRIVATE Operand {
 
   struct MemoryOperand {
     bool is_label_operand = false;
-    byte rex = 0;  // REX prefix.
+    uint8_t rex = 0;  // REX prefix.
 
     // Register (1 byte) + SIB (0 or 1 byte) + displacement (0, 1, or 4 byte).
-    byte buf[6] = {0};
+    uint8_t buf[6] = {0};
     // Number of bytes of buf in use.
     // We must keep {len} and {buf} together for the compiler to elide the
     // stack canary protection code.
@@ -283,7 +283,7 @@ class V8_EXPORT_PRIVATE Operand {
     return memory_.is_label_operand;
   }
 
-  V8_INLINE constexpr byte rex() const {
+  V8_INLINE constexpr uint8_t rex() const {
     // Since both fields are in the common initial sequence of {label_} and
     // {memory_}, the access is valid regardless of the active union member.
     // Label operands always have a REX prefix of zero.
@@ -548,18 +548,18 @@ class V8_EXPORT_PRIVATE Assembler : public AssemblerBase {
   static constexpr int kSpecialTargetSize = 4;  // 32-bit displacement.
 
   // One byte opcode for test eax,0xXXXXXXXX.
-  static constexpr byte kTestEaxByte = 0xA9;
+  static constexpr uint8_t kTestEaxByte = 0xA9;
   // One byte opcode for test al, 0xXX.
-  static constexpr byte kTestAlByte = 0xA8;
+  static constexpr uint8_t kTestAlByte = 0xA8;
   // One byte opcode for nop.
-  static constexpr byte kNopByte = 0x90;
+  static constexpr uint8_t kNopByte = 0x90;
 
   // One byte prefix for a short conditional jump.
-  static constexpr byte kJccShortPrefix = 0x70;
-  static constexpr byte kJncShortOpcode = kJccShortPrefix | not_carry;
-  static constexpr byte kJcShortOpcode = kJccShortPrefix | carry;
-  static constexpr byte kJnzShortOpcode = kJccShortPrefix | not_zero;
-  static constexpr byte kJzShortOpcode = kJccShortPrefix | zero;
+  static constexpr uint8_t kJccShortPrefix = 0x70;
+  static constexpr uint8_t kJncShortOpcode = kJccShortPrefix | not_carry;
+  static constexpr uint8_t kJcShortOpcode = kJccShortPrefix | carry;
+  static constexpr uint8_t kJnzShortOpcode = kJccShortPrefix | not_zero;
+  static constexpr uint8_t kJzShortOpcode = kJccShortPrefix | zero;
 
   // VEX prefix encodings.
   enum SIMDPrefix { kNoPrefix = 0x0, k66 = 0x1, kF3 = 0x2, kF2 = 0x3 };
@@ -1007,7 +1007,7 @@ class V8_EXPORT_PRIVATE Assembler : public AssemblerBase {
   void movhps(XMMRegister dst, Operand src);
   void movhps(Operand dst, XMMRegister src);
 
-  void shufps(XMMRegister dst, XMMRegister src, byte imm8);
+  void shufps(XMMRegister dst, XMMRegister src, uint8_t imm8);
 
   void cvttss2si(Register dst, Operand src);
   void cvttss2si(Register dst, XMMRegister src);
@@ -1016,18 +1016,19 @@ class V8_EXPORT_PRIVATE Assembler : public AssemblerBase {
 
   void movmskps(Register dst, XMMRegister src);
 
-  void vinstr(byte op, XMMRegister dst, XMMRegister src1, XMMRegister src2,
+  void vinstr(uint8_t op, XMMRegister dst, XMMRegister src1, XMMRegister src2,
               SIMDPrefix pp, LeadingOpcode m, VexW w, CpuFeature feature = AVX);
-  void vinstr(byte op, XMMRegister dst, XMMRegister src1, Operand src2,
+  void vinstr(uint8_t op, XMMRegister dst, XMMRegister src1, Operand src2,
               SIMDPrefix pp, LeadingOpcode m, VexW w, CpuFeature feature = AVX);
 
   template <typename Reg1, typename Reg2, typename Op>
-  void vinstr(byte op, Reg1 dst, Reg2 src1, Op src2, SIMDPrefix pp,
+  void vinstr(uint8_t op, Reg1 dst, Reg2 src1, Op src2, SIMDPrefix pp,
               LeadingOpcode m, VexW w, CpuFeature feature = AVX2);
 
   // SSE instructions
-  void sse_instr(XMMRegister dst, XMMRegister src, byte escape, byte opcode);
-  void sse_instr(XMMRegister dst, Operand src, byte escape, byte opcode);
+  void sse_instr(XMMRegister dst, XMMRegister src, uint8_t escape,
+                 uint8_t opcode);
+  void sse_instr(XMMRegister dst, Operand src, uint8_t escape, uint8_t opcode);
 #define DECLARE_SSE_INSTRUCTION(instruction, escape, opcode) \
   void instruction(XMMRegister dst, XMMRegister src) {       \
     sse_instr(dst, src, 0x##escape, 0x##opcode);             \
@@ -1041,10 +1042,10 @@ class V8_EXPORT_PRIVATE Assembler : public AssemblerBase {
 #undef DECLARE_SSE_INSTRUCTION
 
   // SSE instructions with prefix and SSE2 instructions
-  void sse2_instr(XMMRegister dst, XMMRegister src, byte prefix, byte escape,
-                  byte opcode);
-  void sse2_instr(XMMRegister dst, Operand src, byte prefix, byte escape,
-                  byte opcode);
+  void sse2_instr(XMMRegister dst, XMMRegister src, uint8_t prefix,
+                  uint8_t escape, uint8_t opcode);
+  void sse2_instr(XMMRegister dst, Operand src, uint8_t prefix, uint8_t escape,
+                  uint8_t opcode);
 #define DECLARE_SSE2_INSTRUCTION(instruction, prefix, escape, opcode) \
   void instruction(XMMRegister dst, XMMRegister src) {                \
     sse2_instr(dst, src, 0x##prefix, 0x##escape, 0x##opcode);         \
@@ -1060,15 +1061,15 @@ class V8_EXPORT_PRIVATE Assembler : public AssemblerBase {
   SSE2_UNOP_INSTRUCTION_LIST(DECLARE_SSE2_INSTRUCTION)
 #undef DECLARE_SSE2_INSTRUCTION
 
-  void sse2_instr(XMMRegister reg, byte imm8, byte prefix, byte escape,
-                  byte opcode, int extension) {
+  void sse2_instr(XMMRegister reg, uint8_t imm8, uint8_t prefix, uint8_t escape,
+                  uint8_t opcode, int extension) {
     XMMRegister ext_reg = XMMRegister::from_code(extension);
     sse2_instr(ext_reg, reg, prefix, escape, opcode);
     emit(imm8);
   }
 
 #define DECLARE_SSE2_SHIFT_IMM(instruction, prefix, escape, opcode, extension) \
-  void instruction(XMMRegister reg, byte imm8) {                               \
+  void instruction(XMMRegister reg, uint8_t imm8) {                            \
     sse2_instr(reg, imm8, 0x##prefix, 0x##escape, 0x##opcode, 0x##extension);  \
   }
   SSE2_INSTRUCTION_LIST_SHIFT_IMM(DECLARE_SSE2_SHIFT_IMM)
@@ -1156,10 +1157,10 @@ class V8_EXPORT_PRIVATE Assembler : public AssemblerBase {
   void movshdup(XMMRegister dst, XMMRegister src);
 
   // SSSE3
-  void ssse3_instr(XMMRegister dst, XMMRegister src, byte prefix, byte escape1,
-                   byte escape2, byte opcode);
-  void ssse3_instr(XMMRegister dst, Operand src, byte prefix, byte escape1,
-                   byte escape2, byte opcode);
+  void ssse3_instr(XMMRegister dst, XMMRegister src, uint8_t prefix,
+                   uint8_t escape1, uint8_t escape2, uint8_t opcode);
+  void ssse3_instr(XMMRegister dst, Operand src, uint8_t prefix,
+                   uint8_t escape1, uint8_t escape2, uint8_t opcode);
 
 #define DECLARE_SSSE3_INSTRUCTION(instruction, prefix, escape1, escape2,     \
                                   opcode)                                    \
@@ -1175,16 +1176,18 @@ class V8_EXPORT_PRIVATE Assembler : public AssemblerBase {
 #undef DECLARE_SSSE3_INSTRUCTION
 
   // SSE4
-  void sse4_instr(Register dst, XMMRegister src, byte prefix, byte escape1,
-                  byte escape2, byte opcode, int8_t imm8);
-  void sse4_instr(Operand dst, XMMRegister src, byte prefix, byte escape1,
-                  byte escape2, byte opcode, int8_t imm8);
-  void sse4_instr(XMMRegister dst, Register src, byte prefix, byte escape1,
-                  byte escape2, byte opcode, int8_t imm8);
-  void sse4_instr(XMMRegister dst, XMMRegister src, byte prefix, byte escape1,
-                  byte escape2, byte opcode);
-  void sse4_instr(XMMRegister dst, Operand src, byte prefix, byte escape1,
-                  byte escape2, byte opcode);
+  void sse4_instr(Register dst, XMMRegister src, uint8_t prefix,
+                  uint8_t escape1, uint8_t escape2, uint8_t opcode,
+                  int8_t imm8);
+  void sse4_instr(Operand dst, XMMRegister src, uint8_t prefix, uint8_t escape1,
+                  uint8_t escape2, uint8_t opcode, int8_t imm8);
+  void sse4_instr(XMMRegister dst, Register src, uint8_t prefix,
+                  uint8_t escape1, uint8_t escape2, uint8_t opcode,
+                  int8_t imm8);
+  void sse4_instr(XMMRegister dst, XMMRegister src, uint8_t prefix,
+                  uint8_t escape1, uint8_t escape2, uint8_t opcode);
+  void sse4_instr(XMMRegister dst, Operand src, uint8_t prefix, uint8_t escape1,
+                  uint8_t escape2, uint8_t opcode);
 #define DECLARE_SSE4_INSTRUCTION(instruction, prefix, escape1, escape2,     \
                                  opcode)                                    \
   void instruction(XMMRegister dst, XMMRegister src) {                      \
@@ -1216,10 +1219,10 @@ class V8_EXPORT_PRIVATE Assembler : public AssemblerBase {
 #undef DECLARE_SSE4_EXTRACT_INSTRUCTION
 
   // SSE4.2
-  void sse4_2_instr(XMMRegister dst, XMMRegister src, byte prefix, byte escape1,
-                    byte escape2, byte opcode);
-  void sse4_2_instr(XMMRegister dst, Operand src, byte prefix, byte escape1,
-                    byte escape2, byte opcode);
+  void sse4_2_instr(XMMRegister dst, XMMRegister src, uint8_t prefix,
+                    uint8_t escape1, uint8_t escape2, uint8_t opcode);
+  void sse4_2_instr(XMMRegister dst, Operand src, uint8_t prefix,
+                    uint8_t escape1, uint8_t escape2, uint8_t opcode);
 #define DECLARE_SSE4_2_INSTRUCTION(instruction, prefix, escape1, escape2,     \
                                    opcode)                                    \
   void instruction(XMMRegister dst, XMMRegister src) {                        \
@@ -1403,8 +1406,8 @@ class V8_EXPORT_PRIVATE Assembler : public AssemblerBase {
   void pinsrw(XMMRegister dst, Operand src, uint8_t imm8);
 
   // SSE 4.1 instruction
-  void insertps(XMMRegister dst, XMMRegister src, byte imm8);
-  void insertps(XMMRegister dst, Operand src, byte imm8);
+  void insertps(XMMRegister dst, XMMRegister src, uint8_t imm8);
+  void insertps(XMMRegister dst, Operand src, uint8_t imm8);
   void pextrq(Register dst, XMMRegister src, int8_t imm8);
   void pinsrb(XMMRegister dst, Register src, uint8_t imm8);
   void pinsrb(XMMRegister dst, Operand src, uint8_t imm8);
@@ -1471,9 +1474,10 @@ class V8_EXPORT_PRIVATE Assembler : public AssemblerBase {
   void vbroadcastss(YMMRegister dst, Operand src);
   void vbroadcastss(YMMRegister dst, XMMRegister src);
 
-  void fma_instr(byte op, XMMRegister dst, XMMRegister src1, XMMRegister src2,
-                 VectorLength l, SIMDPrefix pp, LeadingOpcode m, VexW w);
-  void fma_instr(byte op, XMMRegister dst, XMMRegister src1, Operand src2,
+  void fma_instr(uint8_t op, XMMRegister dst, XMMRegister src1,
+                 XMMRegister src2, VectorLength l, SIMDPrefix pp,
+                 LeadingOpcode m, VexW w);
+  void fma_instr(uint8_t op, XMMRegister dst, XMMRegister src1, Operand src2,
                  VectorLength l, SIMDPrefix pp, LeadingOpcode m, VexW w);
 
 #define FMA(instr, length, prefix, escape1, escape2, extension, opcode) \
@@ -1574,13 +1578,13 @@ class V8_EXPORT_PRIVATE Assembler : public AssemblerBase {
 #undef AVX_3
 
 #define AVX_SSE2_SHIFT_IMM(instr, prefix, escape, opcode, extension)   \
-  void v##instr(XMMRegister dst, XMMRegister src, byte imm8) {         \
+  void v##instr(XMMRegister dst, XMMRegister src, uint8_t imm8) {      \
     XMMRegister ext_reg = XMMRegister::from_code(extension);           \
     vinstr(0x##opcode, ext_reg, dst, src, k##prefix, k##escape, kWIG); \
     emit(imm8);                                                        \
   }                                                                    \
                                                                        \
-  void v##instr(YMMRegister dst, YMMRegister src, byte imm8) {         \
+  void v##instr(YMMRegister dst, YMMRegister src, uint8_t imm8) {      \
     YMMRegister ext_reg = YMMRegister::from_code(extension);           \
     vinstr(0x##opcode, ext_reg, dst, src, k##prefix, k##escape, kWIG); \
     emit(imm8);                                                        \
@@ -1679,42 +1683,42 @@ class V8_EXPORT_PRIVATE Assembler : public AssemblerBase {
   void vroundss(XMMRegister dst, XMMRegister src1, XMMRegister src2,
                 RoundingMode mode) {
     vinstr(0x0a, dst, src1, src2, k66, k0F3A, kWIG);
-    emit(static_cast<byte>(mode) | 0x8);  // Mask precision exception.
+    emit(static_cast<uint8_t>(mode) | 0x8);  // Mask precision exception.
   }
   void vroundss(XMMRegister dst, XMMRegister src1, Operand src2,
                 RoundingMode mode) {
     vinstr(0x0a, dst, src1, src2, k66, k0F3A, kWIG);
-    emit(static_cast<byte>(mode) | 0x8);  // Mask precision exception.
+    emit(static_cast<uint8_t>(mode) | 0x8);  // Mask precision exception.
   }
   void vroundsd(XMMRegister dst, XMMRegister src1, XMMRegister src2,
                 RoundingMode mode) {
     vinstr(0x0b, dst, src1, src2, k66, k0F3A, kWIG);
-    emit(static_cast<byte>(mode) | 0x8);  // Mask precision exception.
+    emit(static_cast<uint8_t>(mode) | 0x8);  // Mask precision exception.
   }
   void vroundsd(XMMRegister dst, XMMRegister src1, Operand src2,
                 RoundingMode mode) {
     vinstr(0x0b, dst, src1, src2, k66, k0F3A, kWIG);
-    emit(static_cast<byte>(mode) | 0x8);  // Mask precision exception.
+    emit(static_cast<uint8_t>(mode) | 0x8);  // Mask precision exception.
   }
   void vroundps(XMMRegister dst, XMMRegister src, RoundingMode mode) {
     vinstr(0x08, dst, xmm0, src, k66, k0F3A, kWIG);
-    emit(static_cast<byte>(mode) | 0x8);  // Mask precision exception.
+    emit(static_cast<uint8_t>(mode) | 0x8);  // Mask precision exception.
   }
   void vroundps(YMMRegister dst, YMMRegister src, RoundingMode mode) {
     vinstr(0x08, dst, ymm0, src, k66, k0F3A, kWIG, AVX);
-    emit(static_cast<byte>(mode) | 0x8);  // Mask precision exception.
+    emit(static_cast<uint8_t>(mode) | 0x8);  // Mask precision exception.
   }
   void vroundpd(XMMRegister dst, XMMRegister src, RoundingMode mode) {
     vinstr(0x09, dst, xmm0, src, k66, k0F3A, kWIG);
-    emit(static_cast<byte>(mode) | 0x8);  // Mask precision exception.
+    emit(static_cast<uint8_t>(mode) | 0x8);  // Mask precision exception.
   }
   void vroundpd(YMMRegister dst, YMMRegister src, RoundingMode mode) {
     vinstr(0x09, dst, ymm0, src, k66, k0F3A, kWIG, AVX);
-    emit(static_cast<byte>(mode) | 0x8);  // Mask precision exception.
+    emit(static_cast<uint8_t>(mode) | 0x8);  // Mask precision exception.
   }
 
   template <typename Reg, typename Op>
-  void vsd(byte op, Reg dst, Reg src1, Op src2) {
+  void vsd(uint8_t op, Reg dst, Reg src1, Op src2) {
     vinstr(op, dst, src1, src2, kF2, k0F, kWIG, AVX);
   }
 
@@ -1725,13 +1729,15 @@ class V8_EXPORT_PRIVATE Assembler : public AssemblerBase {
   void vmovss(Operand dst, XMMRegister src) { vss(0x11, src, xmm0, dst); }
   void vucomiss(XMMRegister dst, XMMRegister src);
   void vucomiss(XMMRegister dst, Operand src);
-  void vss(byte op, XMMRegister dst, XMMRegister src1, XMMRegister src2);
-  void vss(byte op, XMMRegister dst, XMMRegister src1, Operand src2);
+  void vss(uint8_t op, XMMRegister dst, XMMRegister src1, XMMRegister src2);
+  void vss(uint8_t op, XMMRegister dst, XMMRegister src1, Operand src2);
 
-  void vshufps(XMMRegister dst, XMMRegister src1, XMMRegister src2, byte imm8) {
+  void vshufps(XMMRegister dst, XMMRegister src1, XMMRegister src2,
+               uint8_t imm8) {
     vps(0xC6, dst, src1, src2, imm8);
   }
-  void vshufps(YMMRegister dst, YMMRegister src1, YMMRegister src2, byte imm8) {
+  void vshufps(YMMRegister dst, YMMRegister src1, YMMRegister src2,
+               uint8_t imm8) {
     vps(0xC6, dst, src1, src2, imm8);
   }
 
@@ -1837,11 +1843,12 @@ class V8_EXPORT_PRIVATE Assembler : public AssemblerBase {
     vinstr(0xF0, dst, xmm0, src, kF2, k0F, kWIG);
   }
   void vinsertps(XMMRegister dst, XMMRegister src1, XMMRegister src2,
-                 byte imm8) {
+                 uint8_t imm8) {
     vinstr(0x21, dst, src1, src2, k66, k0F3A, kWIG);
     emit(imm8);
   }
-  void vinsertps(XMMRegister dst, XMMRegister src1, Operand src2, byte imm8) {
+  void vinsertps(XMMRegister dst, XMMRegister src1, Operand src2,
+                 uint8_t imm8) {
     vinstr(0x21, dst, src1, src2, k66, k0F3A, kWIG);
     emit(imm8);
   }
@@ -1974,20 +1981,20 @@ class V8_EXPORT_PRIVATE Assembler : public AssemblerBase {
     emit(imm8);
   }
 
-  void vps(byte op, XMMRegister dst, XMMRegister src1, XMMRegister src2);
-  void vps(byte op, YMMRegister dst, YMMRegister src1, YMMRegister src2);
-  void vps(byte op, XMMRegister dst, XMMRegister src1, Operand src2);
-  void vps(byte op, YMMRegister dst, YMMRegister src1, Operand src2);
-  void vps(byte op, XMMRegister dst, XMMRegister src1, XMMRegister src2,
-           byte imm8);
-  void vps(byte op, YMMRegister dst, YMMRegister src1, YMMRegister src2,
-           byte imm8);
-  void vpd(byte op, XMMRegister dst, XMMRegister src1, XMMRegister src2);
-  void vpd(byte op, YMMRegister dst, YMMRegister src1, YMMRegister src2);
-  void vpd(byte op, XMMRegister dst, YMMRegister src1, YMMRegister src2);
-  void vpd(byte op, XMMRegister dst, XMMRegister src1, Operand src2);
-  void vpd(byte op, YMMRegister dst, YMMRegister src1, Operand src2);
-  void vpd(byte op, XMMRegister dst, YMMRegister src1, Operand src2);
+  void vps(uint8_t op, XMMRegister dst, XMMRegister src1, XMMRegister src2);
+  void vps(uint8_t op, YMMRegister dst, YMMRegister src1, YMMRegister src2);
+  void vps(uint8_t op, XMMRegister dst, XMMRegister src1, Operand src2);
+  void vps(uint8_t op, YMMRegister dst, YMMRegister src1, Operand src2);
+  void vps(uint8_t op, XMMRegister dst, XMMRegister src1, XMMRegister src2,
+           uint8_t imm8);
+  void vps(uint8_t op, YMMRegister dst, YMMRegister src1, YMMRegister src2,
+           uint8_t imm8);
+  void vpd(uint8_t op, XMMRegister dst, XMMRegister src1, XMMRegister src2);
+  void vpd(uint8_t op, YMMRegister dst, YMMRegister src1, YMMRegister src2);
+  void vpd(uint8_t op, XMMRegister dst, YMMRegister src1, YMMRegister src2);
+  void vpd(uint8_t op, XMMRegister dst, XMMRegister src1, Operand src2);
+  void vpd(uint8_t op, YMMRegister dst, YMMRegister src1, Operand src2);
+  void vpd(uint8_t op, XMMRegister dst, YMMRegister src1, Operand src2);
 
   // AVX2 instructions
 #define AVX2_INSTRUCTION(instr, prefix, escape1, escape2, opcode)           \
@@ -2135,10 +2142,10 @@ class V8_EXPORT_PRIVATE Assembler : public AssemblerBase {
   void shrxl(Register dst, Operand src1, Register src2) {
     bmi2l(kF2, 0xf7, dst, src2, src1);
   }
-  void rorxq(Register dst, Register src, byte imm8);
-  void rorxq(Register dst, Operand src, byte imm8);
-  void rorxl(Register dst, Register src, byte imm8);
-  void rorxl(Register dst, Operand src, byte imm8);
+  void rorxq(Register dst, Register src, uint8_t imm8);
+  void rorxq(Register dst, Operand src, uint8_t imm8);
+  void rorxl(Register dst, Register src, uint8_t imm8);
+  void rorxl(Register dst, Operand src, uint8_t imm8);
 
   void mfence();
   void lfence();
@@ -2185,8 +2192,8 @@ class V8_EXPORT_PRIVATE Assembler : public AssemblerBase {
   // Avoid overflows for displacements etc.
   static constexpr int kMaximalBufferSize = 512 * MB;
 
-  byte byte_at(int pos) { return buffer_start_[pos]; }
-  void set_byte_at(int pos, byte value) { buffer_start_[pos] = value; }
+  uint8_t byte_at(int pos) { return buffer_start_[pos]; }
+  void set_byte_at(int pos, uint8_t value) { buffer_start_[pos] = value; }
 
 #if defined(V8_OS_WIN_X64)
   win64_unwindinfo::BuiltinUnwindInfo GetUnwindInfo() const;
@@ -2419,23 +2426,23 @@ class V8_EXPORT_PRIVATE Assembler : public AssemblerBase {
   // AND, OR, XOR, or CMP.  The encodings of these operations are all
   // similar, differing just in the opcode or in the reg field of the
   // ModR/M byte.
-  void arithmetic_op_8(byte opcode, Register reg, Register rm_reg);
-  void arithmetic_op_8(byte opcode, Register reg, Operand rm_reg);
-  void arithmetic_op_16(byte opcode, Register reg, Register rm_reg);
-  void arithmetic_op_16(byte opcode, Register reg, Operand rm_reg);
+  void arithmetic_op_8(uint8_t opcode, Register reg, Register rm_reg);
+  void arithmetic_op_8(uint8_t opcode, Register reg, Operand rm_reg);
+  void arithmetic_op_16(uint8_t opcode, Register reg, Register rm_reg);
+  void arithmetic_op_16(uint8_t opcode, Register reg, Operand rm_reg);
   // Operate on operands/registers with pointer size, 32-bit or 64-bit size.
-  void arithmetic_op(byte opcode, Register reg, Register rm_reg, int size);
-  void arithmetic_op(byte opcode, Register reg, Operand rm_reg, int size);
+  void arithmetic_op(uint8_t opcode, Register reg, Register rm_reg, int size);
+  void arithmetic_op(uint8_t opcode, Register reg, Operand rm_reg, int size);
   // Operate on a byte in memory or register.
-  void immediate_arithmetic_op_8(byte subcode, Register dst, Immediate src);
-  void immediate_arithmetic_op_8(byte subcode, Operand dst, Immediate src);
+  void immediate_arithmetic_op_8(uint8_t subcode, Register dst, Immediate src);
+  void immediate_arithmetic_op_8(uint8_t subcode, Operand dst, Immediate src);
   // Operate on a word in memory or register.
-  void immediate_arithmetic_op_16(byte subcode, Register dst, Immediate src);
-  void immediate_arithmetic_op_16(byte subcode, Operand dst, Immediate src);
+  void immediate_arithmetic_op_16(uint8_t subcode, Register dst, Immediate src);
+  void immediate_arithmetic_op_16(uint8_t subcode, Operand dst, Immediate src);
   // Operate on operands/registers with pointer size, 32-bit or 64-bit size.
-  void immediate_arithmetic_op(byte subcode, Register dst, Immediate src,
+  void immediate_arithmetic_op(uint8_t subcode, Register dst, Immediate src,
                                int size);
-  void immediate_arithmetic_op(byte subcode, Operand dst, Immediate src,
+  void immediate_arithmetic_op(uint8_t subcode, Operand dst, Immediate src,
                                int size);
 
   // Emit machine code for a shift operation.
@@ -2645,14 +2652,18 @@ class V8_EXPORT_PRIVATE Assembler : public AssemblerBase {
   }
 
   // Most BMI instructions are similar.
-  void bmi1q(byte op, Register reg, Register vreg, Register rm);
-  void bmi1q(byte op, Register reg, Register vreg, Operand rm);
-  void bmi1l(byte op, Register reg, Register vreg, Register rm);
-  void bmi1l(byte op, Register reg, Register vreg, Operand rm);
-  void bmi2q(SIMDPrefix pp, byte op, Register reg, Register vreg, Register rm);
-  void bmi2q(SIMDPrefix pp, byte op, Register reg, Register vreg, Operand rm);
-  void bmi2l(SIMDPrefix pp, byte op, Register reg, Register vreg, Register rm);
-  void bmi2l(SIMDPrefix pp, byte op, Register reg, Register vreg, Operand rm);
+  void bmi1q(uint8_t op, Register reg, Register vreg, Register rm);
+  void bmi1q(uint8_t op, Register reg, Register vreg, Operand rm);
+  void bmi1l(uint8_t op, Register reg, Register vreg, Register rm);
+  void bmi1l(uint8_t op, Register reg, Register vreg, Operand rm);
+  void bmi2q(SIMDPrefix pp, uint8_t op, Register reg, Register vreg,
+             Register rm);
+  void bmi2q(SIMDPrefix pp, uint8_t op, Register reg, Register vreg,
+             Operand rm);
+  void bmi2l(SIMDPrefix pp, uint8_t op, Register reg, Register vreg,
+             Register rm);
+  void bmi2l(SIMDPrefix pp, uint8_t op, Register reg, Register vreg,
+             Operand rm);
 
   // record the position of jmp/jcc instruction
   void record_farjmp_position(Label* L, int pos);
@@ -2686,26 +2697,34 @@ class V8_EXPORT_PRIVATE Assembler : public AssemblerBase {
 #endif
 };
 
-extern template EXPORT_TEMPLATE_DECLARE(V8_EXPORT_PRIVATE)
-void Assembler::vinstr(byte op, YMMRegister dst, YMMRegister src1,
-                       YMMRegister src2, SIMDPrefix pp,
-                       LeadingOpcode m, VexW w, CpuFeature feature);
-extern template EXPORT_TEMPLATE_DECLARE(V8_EXPORT_PRIVATE)
-void Assembler::vinstr(byte op, YMMRegister dst, XMMRegister src1,
-                       XMMRegister src2, SIMDPrefix pp,
-                       LeadingOpcode m, VexW w, CpuFeature feature);
-extern template EXPORT_TEMPLATE_DECLARE(V8_EXPORT_PRIVATE)
-void Assembler::vinstr(byte op, YMMRegister dst, YMMRegister src1,
-                       Operand src2, SIMDPrefix pp, LeadingOpcode m,
-                       VexW w, CpuFeature feature);
-extern template EXPORT_TEMPLATE_DECLARE(V8_EXPORT_PRIVATE)
-void Assembler::vinstr(byte op, YMMRegister dst, YMMRegister src1,
-                       XMMRegister src2, SIMDPrefix pp,
-                       LeadingOpcode m, VexW w, CpuFeature feature);
-extern template EXPORT_TEMPLATE_DECLARE(V8_EXPORT_PRIVATE)
-void Assembler::vinstr(byte op, YMMRegister dst, XMMRegister src1,
-                       Operand src2, SIMDPrefix pp, LeadingOpcode m,
-                       VexW w, CpuFeature feature);
+extern template EXPORT_TEMPLATE_DECLARE(
+    V8_EXPORT_PRIVATE) void Assembler::vinstr(uint8_t op, YMMRegister dst,
+                                              YMMRegister src1,
+                                              YMMRegister src2, SIMDPrefix pp,
+                                              LeadingOpcode m, VexW w,
+                                              CpuFeature feature);
+extern template EXPORT_TEMPLATE_DECLARE(
+    V8_EXPORT_PRIVATE) void Assembler::vinstr(uint8_t op, YMMRegister dst,
+                                              XMMRegister src1,
+                                              XMMRegister src2, SIMDPrefix pp,
+                                              LeadingOpcode m, VexW w,
+                                              CpuFeature feature);
+extern template EXPORT_TEMPLATE_DECLARE(
+    V8_EXPORT_PRIVATE) void Assembler::vinstr(uint8_t op, YMMRegister dst,
+                                              YMMRegister src1, Operand src2,
+                                              SIMDPrefix pp, LeadingOpcode m,
+                                              VexW w, CpuFeature feature);
+extern template EXPORT_TEMPLATE_DECLARE(
+    V8_EXPORT_PRIVATE) void Assembler::vinstr(uint8_t op, YMMRegister dst,
+                                              YMMRegister src1,
+                                              XMMRegister src2, SIMDPrefix pp,
+                                              LeadingOpcode m, VexW w,
+                                              CpuFeature feature);
+extern template EXPORT_TEMPLATE_DECLARE(
+    V8_EXPORT_PRIVATE) void Assembler::vinstr(uint8_t op, YMMRegister dst,
+                                              XMMRegister src1, Operand src2,
+                                              SIMDPrefix pp, LeadingOpcode m,
+                                              VexW w, CpuFeature feature);
 
 // Helper class that ensures that there is enough space for generating
 // instructions and relocation information.  The constructor makes
diff --git a/src/codegen/x64/macro-assembler-x64.cc b/src/codegen/x64/macro-assembler-x64.cc
index ee65afec42c..8da9ee9dd73 100644
--- a/src/codegen/x64/macro-assembler-x64.cc
+++ b/src/codegen/x64/macro-assembler-x64.cc
@@ -1463,14 +1463,14 @@ void MacroAssembler::I64x4Mul(YMMRegister dst, YMMRegister lhs, YMMRegister rhs,
   DCHECK(CpuFeatures::IsSupported(AVX2));
   CpuFeatureScope avx_scope(this, AVX2);
   // 1. Multiply high dword of each qword of left with right.
-  vpsrlq(tmp1, lhs, byte{32});
+  vpsrlq(tmp1, lhs, uint8_t{32});
   vpmuludq(tmp1, tmp1, rhs);
   // 2. Multiply high dword of each qword of right with left.
-  vpsrlq(tmp2, rhs, byte{32});
+  vpsrlq(tmp2, rhs, uint8_t{32});
   vpmuludq(tmp2, tmp2, lhs);
   // 3. Add 1 and 2, then shift left by 32 (this is the high dword of result).
   vpaddq(tmp2, tmp2, tmp1);
-  vpsllq(tmp2, tmp2, byte{32});
+  vpsllq(tmp2, tmp2, uint8_t{32});
   // 4. Multiply low dwords (this is the low dword of result).
   vpmuludq(dst, lhs, rhs);
   // 5. Add 3 and 4.
@@ -1848,8 +1848,8 @@ void MacroAssembler::Move(XMMRegister dst, uint32_t src) {
     DCHECK_NE(0u, pop);
     if (pop + ntz + nlz == 32) {
       Pcmpeqd(dst, dst);
-      if (ntz) Pslld(dst, static_cast<byte>(ntz + nlz));
-      if (nlz) Psrld(dst, static_cast<byte>(nlz));
+      if (ntz) Pslld(dst, static_cast<uint8_t>(ntz + nlz));
+      if (nlz) Psrld(dst, static_cast<uint8_t>(nlz));
     } else {
       movl(kScratchRegister, Immediate(src));
       Movd(dst, kScratchRegister);
@@ -1867,8 +1867,8 @@ void MacroAssembler::Move(XMMRegister dst, uint64_t src) {
     DCHECK_NE(0u, pop);
     if (pop + ntz + nlz == 64) {
       Pcmpeqd(dst, dst);
-      if (ntz) Psllq(dst, static_cast<byte>(ntz + nlz));
-      if (nlz) Psrlq(dst, static_cast<byte>(nlz));
+      if (ntz) Psllq(dst, static_cast<uint8_t>(ntz + nlz));
+      if (nlz) Psrlq(dst, static_cast<uint8_t>(nlz));
     } else {
       uint32_t lower = static_cast<uint32_t>(src);
       uint32_t upper = static_cast<uint32_t>(src >> 32);
-- 
2.35.1

