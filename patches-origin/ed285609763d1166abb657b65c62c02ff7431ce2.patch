From ed285609763d1166abb657b65c62c02ff7431ce2 Mon Sep 17 00:00:00 2001
From: Lu Yahan <yahan@iscas.ac.cn>
Date: Wed, 16 Aug 2023 17:10:48 +0800
Subject: [PATCH] [riscv] Reduce riscv Vector arch code(Part 5)

Change-Id: I82a29b1de9a43799a7a8846bd19dcc2577ad7ebf
Reviewed-on: https://chromium-review.googlesource.com/c/v8/v8/+/4781962
Reviewed-by: Ji Qiu <qiuji@iscas.ac.cn>
Commit-Queue: Ji Qiu <qiuji@iscas.ac.cn>
Auto-Submit: Yahan Lu <yahan@iscas.ac.cn>
Cr-Commit-Position: refs/heads/main@{#89538}
---
 .../backend/riscv/code-generator-riscv.cc     | 198 ++++-----
 .../backend/riscv/instruction-codes-riscv.h   |  27 +-
 .../riscv/instruction-scheduler-riscv.cc      |  23 +-
 .../riscv/instruction-selector-riscv.h        | 387 ++++++++++--------
 .../riscv/instruction-selector-riscv32.cc     |  12 +-
 .../riscv/instruction-selector-riscv64.cc     |   8 +-
 6 files changed, 361 insertions(+), 294 deletions(-)

diff --git a/src/compiler/backend/riscv/code-generator-riscv.cc b/src/compiler/backend/riscv/code-generator-riscv.cc
index 3142c95e696..833b22e622e 100644
--- a/src/compiler/backend/riscv/code-generator-riscv.cc
+++ b/src/compiler/backend/riscv/code-generator-riscv.cc
@@ -2441,19 +2441,6 @@ CodeGenerator::CodeGenResult CodeGenerator::AssembleArchInstruction(
       }
       break;
     }
-    case kRiscvI8x16RoundingAverageU: {
-      __ VU.set(kScratchReg2, E8, m1);
-      __ vwaddu_vv(kSimd128ScratchReg, i.InputSimd128Register(0),
-                   i.InputSimd128Register(1));
-      __ li(kScratchReg, 1);
-      __ vwaddu_wx(kSimd128ScratchReg3, kSimd128ScratchReg, kScratchReg);
-      __ li(kScratchReg, 2);
-      __ VU.set(kScratchReg2, E16, m2);
-      __ vdivu_vx(kSimd128ScratchReg3, kSimd128ScratchReg3, kScratchReg);
-      __ VU.set(kScratchReg2, E8, m1);
-      __ vnclipu_vi(i.OutputSimd128Register(), kSimd128ScratchReg3, 0);
-      break;
-    }
     case kRiscvI16x8RoundingAverageU: {
       __ VU.set(kScratchReg2, E16, m1);
       __ vwaddu_vv(kSimd128ScratchReg, i.InputSimd128Register(0),
@@ -2467,12 +2454,6 @@ CodeGenerator::CodeGenResult CodeGenerator::AssembleArchInstruction(
       __ vnclipu_vi(i.OutputSimd128Register(), kSimd128ScratchReg3, 0);
       break;
     }
-    case kRiscvI16x8Q15MulRSatS: {
-      __ VU.set(kScratchReg, E16, m1);
-      __ vsmul_vv(i.OutputSimd128Register(), i.InputSimd128Register(0),
-                  i.InputSimd128Register(1));
-      break;
-    }
     case kRiscvI8x16ExtractLaneU: {
       __ VU.set(kScratchReg, E8, m1);
       __ vslidedown_vi(kSimd128ScratchReg, i.InputSimd128Register(0),
@@ -3289,46 +3270,6 @@ CodeGenerator::CodeGenResult CodeGenerator::AssembleArchInstruction(
       __ vzext_vf2(i.OutputSimd128Register(), kSimd128ScratchReg);
       break;
     }
-    case kRiscvI8x16SConvertI16x8: {
-      __ VU.set(kScratchReg, E16, m1);
-      __ vmv_vv(v26, i.InputSimd128Register(0));
-      __ vmv_vv(v27, i.InputSimd128Register(1));
-      __ VU.set(kScratchReg, E8, m1);
-      __ VU.set(FPURoundingMode::RNE);
-      __ vnclip_vi(i.OutputSimd128Register(), v26, 0);
-      break;
-    }
-    case kRiscvI8x16UConvertI16x8: {
-      __ VU.set(kScratchReg, E16, m1);
-      __ vmv_vv(v26, i.InputSimd128Register(0));
-      __ vmv_vv(v27, i.InputSimd128Register(1));
-      __ VU.set(kScratchReg, E16, m2);
-      __ vmax_vx(v26, v26, zero_reg);
-      __ VU.set(kScratchReg, E8, m1);
-      __ VU.set(FPURoundingMode::RNE);
-      __ vnclipu_vi(i.OutputSimd128Register(), v26, 0);
-      break;
-    }
-    case kRiscvI16x8SConvertI32x4: {
-      __ VU.set(kScratchReg, E32, m1);
-      __ vmv_vv(v26, i.InputSimd128Register(0));
-      __ vmv_vv(v27, i.InputSimd128Register(1));
-      __ VU.set(kScratchReg, E16, m1);
-      __ VU.set(FPURoundingMode::RNE);
-      __ vnclip_vi(i.OutputSimd128Register(), v26, 0);
-      break;
-    }
-    case kRiscvI16x8UConvertI32x4: {
-      __ VU.set(kScratchReg, E32, m1);
-      __ vmv_vv(v26, i.InputSimd128Register(0));
-      __ vmv_vv(v27, i.InputSimd128Register(1));
-      __ VU.set(kScratchReg, E32, m2);
-      __ vmax_vx(v26, v26, zero_reg);
-      __ VU.set(kScratchReg, E16, m1);
-      __ VU.set(FPURoundingMode::RNE);
-      __ vnclipu_vi(i.OutputSimd128Register(), v26, 0);
-      break;
-    }
 #if V8_TARGET_ARCH_RISCV32
     case kRiscvI64x2SplatI32Pair: {
       __ VU.set(kScratchReg, E32, m1);
@@ -3339,18 +3280,77 @@ CodeGenerator::CodeGenResult CodeGenerator::AssembleArchInstruction(
       break;
     }
 #endif
-    case kRiscvVwadd: {
+    case kRiscvVwaddVv: {
       __ VU.set(kScratchReg, i.InputInt8(2), i.InputInt8(3));
       __ vwadd_vv(i.OutputSimd128Register(), i.InputSimd128Register(0),
                   i.InputSimd128Register(1));
       break;
     }
-    case kRiscvVwaddu: {
+    case kRiscvVwadduVv: {
       __ VU.set(kScratchReg, i.InputInt8(2), i.InputInt8(3));
       __ vwaddu_vv(i.OutputSimd128Register(), i.InputSimd128Register(0),
                    i.InputSimd128Register(1));
       break;
     }
+    case kRiscvVwadduWx: {
+      __ VU.set(kScratchReg, i.InputInt8(2), i.InputInt8(3));
+      if (instr->InputAt(1)->IsRegister()) {
+        __ vwaddu_wx(i.OutputSimd128Register(), i.InputSimd128Register(0),
+                     i.InputRegister(1));
+      } else {
+        __ li(kScratchReg, i.InputInt64(1));
+        __ vwaddu_wx(i.OutputSimd128Register(), i.InputSimd128Register(0),
+                     kScratchReg);
+      }
+      break;
+    }
+    case kRiscvVdivu: {
+      __ VU.set(kScratchReg, i.InputInt8(2), i.InputInt8(3));
+      if (instr->InputAt(1)->IsSimd128Register()) {
+        __ vdivu_vv(i.OutputSimd128Register(), i.InputSimd128Register(0),
+                    i.InputSimd128Register(1));
+      } else if ((instr->InputAt(1)->IsRegister())) {
+        __ vdivu_vx(i.OutputSimd128Register(), i.InputSimd128Register(0),
+                    i.InputRegister(1));
+      } else {
+        __ li(kScratchReg, i.InputInt64(1));
+        __ vdivu_vx(i.OutputSimd128Register(), i.InputSimd128Register(0),
+                    kScratchReg);
+      }
+      break;
+    }
+    case kRiscvVnclipu: {
+      __ VU.set(kScratchReg, i.InputInt8(2), i.InputInt8(3));
+      __ VU.set(FPURoundingMode(i.InputInt8(4)));
+      if (instr->InputAt(1)->IsSimd128Register()) {
+        __ vnclipu_vv(i.OutputSimd128Register(), i.InputSimd128Register(0),
+                      i.InputSimd128Register(1));
+      } else if (instr->InputAt(1)->IsRegister()) {
+        __ vnclipu_vx(i.OutputSimd128Register(), i.InputSimd128Register(0),
+                      i.InputRegister(1));
+      } else {
+        DCHECK(instr->InputAt(1)->IsImmediate());
+        __ vnclipu_vi(i.OutputSimd128Register(), i.InputSimd128Register(0),
+                      i.InputInt8(1));
+      }
+      break;
+    }
+    case kRiscvVnclip: {
+      __ VU.set(kScratchReg, i.InputInt8(2), i.InputInt8(3));
+      __ VU.set(FPURoundingMode(i.InputInt8(4)));
+      if (instr->InputAt(1)->IsSimd128Register()) {
+        __ vnclip_vv(i.OutputSimd128Register(), i.InputSimd128Register(0),
+                     i.InputSimd128Register(1));
+      } else if (instr->InputAt(1)->IsRegister()) {
+        __ vnclip_vx(i.OutputSimd128Register(), i.InputSimd128Register(0),
+                     i.InputRegister(1));
+      } else {
+        DCHECK(instr->InputAt(1)->IsImmediate());
+        __ vnclip_vi(i.OutputSimd128Register(), i.InputSimd128Register(0),
+                     i.InputInt8(1));
+      }
+      break;
+    }
     case kRiscvVwmul: {
       __ VU.set(kScratchReg, i.InputInt8(2), i.InputInt8(3));
       __ vwmul_vv(i.OutputSimd128Register(), i.InputSimd128Register(0),
@@ -3388,21 +3388,24 @@ CodeGenerator::CodeGenResult CodeGenerator::AssembleArchInstruction(
       }
       break;
     }
-    case kRiscvVsllVi: {
-      __ VU.set(kScratchReg, i.InputInt8(2), i.InputInt8(3));
-      __ vsll_vi(i.OutputSimd128Register(), i.InputSimd128Register(0),
-                 i.InputInt8(1));
-      break;
-    }
-    case kRiscvVsllVx: {
+    case kRiscvVsll: {
       __ VU.set(kScratchReg, i.InputInt8(2), i.InputInt8(3));
       if (instr->InputAt(1)->IsRegister()) {
         __ vsll_vx(i.OutputSimd128Register(), i.InputSimd128Register(0),
                    i.InputRegister(1));
+      } else if (instr->InputAt(1)->IsSimd128Register()) {
+        __ vsll_vv(i.OutputSimd128Register(), i.InputSimd128Register(0),
+                   i.InputSimd128Register(1));
       } else {
-        __ li(kScratchReg, i.InputInt64(1));
-        __ vsll_vx(i.OutputSimd128Register(), i.InputSimd128Register(0),
-                   kScratchReg);
+        DCHECK(instr->InputAt(1)->IsImmediate());
+        if (is_int5(i.InputInt64(1))) {
+          __ vsll_vi(i.OutputSimd128Register(), i.InputSimd128Register(0),
+                     i.InputInt8(1));
+        } else {
+          __ li(kScratchReg, i.InputInt64(1));
+          __ vsll_vx(i.OutputSimd128Register(), i.InputSimd128Register(0),
+                     kScratchReg);
+        }
       }
       break;
     }
@@ -3418,28 +3421,20 @@ CodeGenerator::CodeGenResult CodeGenerator::AssembleArchInstruction(
                  i.InputSimd128Register(1));
       break;
     }
-    case kRiscvVmvVx: {
+    case kRiscvVmv: {
       __ VU.set(kScratchReg, i.InputInt8(1), i.InputInt8(2));
-      if (instr->InputAt(0)->IsRegister()) {
+      if (instr->InputAt(0)->IsSimd128Register()) {
+        __ vmv_vv(i.OutputSimd128Register(), i.InputSimd128Register(0));
+      } else if (instr->InputAt(0)->IsRegister()) {
         __ vmv_vx(i.OutputSimd128Register(), i.InputRegister(0));
       } else {
-        __ vmv_vi(i.OutputSimd128Register(), i.InputInt8(0));
-      }
-      break;
-    }
-    case kRiscvVmvVv: {
-      __ VU.set(kScratchReg, i.InputInt8(1), i.InputInt8(2));
-      __ vmv_vv(i.OutputSimd128Register(), i.InputSimd128Register(0));
-      break;
-    }
-    case kRiscvVmvVi: {
-      __ VU.set(kScratchReg, i.InputInt8(1), i.InputInt8(2));
-      if (i.ToConstant(instr->InputAt(0)).FitsInInt32() &&
-          is_int8(i.InputInt32(0))) {
-        __ vmv_vi(i.OutputSimd128Register(), i.InputInt8(0));
-      } else {
-        __ li(kScratchReg, i.InputInt64(0));
-        __ vmv_vx(i.OutputSimd128Register(), kScratchReg);
+        if (i.ToConstant(instr->InputAt(0)).FitsInInt32() &&
+            is_int8(i.InputInt32(0))) {
+          __ vmv_vi(i.OutputSimd128Register(), i.InputInt8(0));
+        } else {
+          __ li(kScratchReg, i.InputInt64(0));
+          __ vmv_vx(i.OutputSimd128Register(), kScratchReg);
+        }
       }
       break;
     }
@@ -3464,10 +3459,21 @@ CodeGenerator::CodeGenResult CodeGenerator::AssembleArchInstruction(
                   i.InputSimd128Register(1));
       break;
     }
-    case kRiscvVmaxsVv: {
+    case kRiscvVmax: {
       __ VU.set(kScratchReg, i.InputInt8(2), i.InputInt8(3));
-      __ vmax_vv(i.OutputSimd128Register(), i.InputSimd128Register(0),
-                 i.InputSimd128Register(1));
+      if (instr->InputAt(1)->IsSimd128Register()) {
+        __ vmax_vv(i.OutputSimd128Register(), i.InputSimd128Register(0),
+                   i.InputSimd128Register(1));
+      } else if (instr->InputAt(1)->IsRegister()) {
+        __ vmax_vx(i.OutputSimd128Register(), i.InputSimd128Register(0),
+                   i.InputRegister(1));
+
+      } else {
+        DCHECK(instr->InputAt(1)->IsImmediate());
+        __ li(kScratchReg, i.InputInt64(1));
+        __ vmax_vx(i.OutputSimd128Register(), i.InputSimd128Register(0),
+                   kScratchReg);
+      }
       break;
     }
     case kRiscvVminuVv: {
@@ -3643,6 +3649,12 @@ CodeGenerator::CodeGenResult CodeGenerator::AssembleArchInstruction(
       }
       break;
     }
+    case kRiscvVsmulVv: {
+      __ VU.set(kScratchReg, i.InputInt8(2), i.InputInt8(3));
+      __ vsmul_vv(i.OutputSimd128Register(), i.InputSimd128Register(0),
+                  i.InputSimd128Register(1));
+      break;
+    }
     default:
 #ifdef DEBUG
       switch (arch_opcode) {
diff --git a/src/compiler/backend/riscv/instruction-codes-riscv.h b/src/compiler/backend/riscv/instruction-codes-riscv.h
index 42873bf627e..7836e382f92 100644
--- a/src/compiler/backend/riscv/instruction-codes-riscv.h
+++ b/src/compiler/backend/riscv/instruction-codes-riscv.h
@@ -274,8 +274,6 @@ namespace compiler {
   V(RiscvI16x8Shl)                        \
   V(RiscvI16x8ShrS)                       \
   V(RiscvI16x8ShrU)                       \
-  V(RiscvI16x8RoundingAverageU)           \
-  V(RiscvI16x8Q15MulRSatS)                \
   V(RiscvI16x8Abs)                        \
   V(RiscvI16x8BitMask)                    \
   V(RiscvI8x16ExtractLaneU)               \
@@ -336,39 +334,35 @@ namespace compiler {
   V(RiscvI32x4UConvertI16x8High)          \
   V(RiscvI16x8SConvertI8x16Low)           \
   V(RiscvI16x8SConvertI8x16High)          \
-  V(RiscvI16x8SConvertI32x4)              \
-  V(RiscvI16x8UConvertI32x4)              \
   V(RiscvI16x8UConvertI8x16Low)           \
   V(RiscvI16x8UConvertI8x16High)          \
-  V(RiscvI8x16SConvertI16x8)              \
-  V(RiscvI8x16UConvertI16x8)              \
-  V(RiscvVmvVv)                           \
+  V(RiscvI16x8RoundingAverageU)           \
+  V(RiscvVmv)                             \
   V(RiscvVandVv)                          \
   V(RiscvVnotVv)                          \
   V(RiscvVorVv)                           \
   V(RiscvVxorVv)                          \
-  V(RiscvVmvVx)                           \
-  V(RiscvVmvVi)                           \
   V(RiscvVwmul)                           \
   V(RiscvVwmulu)                          \
   V(RiscvVmvSx)                           \
   V(RiscvVcompress)                       \
   V(RiscvVaddVv)                          \
   V(RiscvVsubVv)                          \
-  V(RiscvVwadd)                           \
-  V(RiscvVwaddu)                          \
+  V(RiscvVwaddVv)                         \
+  V(RiscvVwadduVv)                        \
+  V(RiscvVwadduWx)                        \
   V(RiscvVrgather)                        \
   V(RiscvVslidedown)                      \
-  V(RiscvVsllVi)                          \
-  V(RiscvVsllVx)                          \
+  V(RiscvVsll)                            \
   V(RiscvVfmvVf)                          \
   V(RiscvVnegVv)                          \
   V(RiscvVfnegVv)                         \
   V(RiscvVmaxuVv)                         \
-  V(RiscvVmaxsVv)                         \
+  V(RiscvVmax)                            \
   V(RiscvVminuVv)                         \
   V(RiscvVminsVv)                         \
   V(RiscvVmulVv)                          \
+  V(RiscvVdivu)                           \
   V(RiscvVgtsVv)                          \
   V(RiscvVgesVv)                          \
   V(RiscvVgeuVv)                          \
@@ -389,7 +383,10 @@ namespace compiler {
   V(RiscvVfdivVv)                         \
   V(RiscvVfminVv)                         \
   V(RiscvVfmaxVv)                         \
-  V(RiscvVmergeVx)
+  V(RiscvVmergeVx)                        \
+  V(RiscvVsmulVv)                         \
+  V(RiscvVnclipu)                         \
+  V(RiscvVnclip)
 
 #define TARGET_ARCH_OPCODE_LIST(V)  \
   TARGET_ARCH_OPCODE_LIST_COMMON(V) \
diff --git a/src/compiler/backend/riscv/instruction-scheduler-riscv.cc b/src/compiler/backend/riscv/instruction-scheduler-riscv.cc
index fb68dc7ea79..8d2e841234b 100644
--- a/src/compiler/backend/riscv/instruction-scheduler-riscv.cc
+++ b/src/compiler/backend/riscv/instruction-scheduler-riscv.cc
@@ -161,8 +161,6 @@ int InstructionScheduler::GetTargetInstructionFlags(
     case kRiscvI16x8ExtractLaneU:
     case kRiscvI16x8ExtractLaneS:
     case kRiscvI16x8ReplaceLane:
-    case kRiscvI8x16SConvertI16x8:
-    case kRiscvI16x8SConvertI32x4:
     case kRiscvI16x8SConvertI8x16High:
     case kRiscvI16x8SConvertI8x16Low:
     case kRiscvI16x8Shl:
@@ -170,12 +168,9 @@ int InstructionScheduler::GetTargetInstructionFlags(
     case kRiscvI16x8ShrU:
     case kRiscvI32x4TruncSatF64x2SZero:
     case kRiscvI32x4TruncSatF64x2UZero:
-    case kRiscvI8x16UConvertI16x8:
-    case kRiscvI16x8UConvertI32x4:
     case kRiscvI16x8UConvertI8x16High:
     case kRiscvI16x8UConvertI8x16Low:
     case kRiscvI16x8RoundingAverageU:
-    case kRiscvI16x8Q15MulRSatS:
     case kRiscvI16x8Abs:
     case kRiscvI16x8BitMask:
     case kRiscvI32x4ExtractLane:
@@ -263,9 +258,7 @@ int InstructionScheduler::GetTargetInstructionFlags(
     case kRiscvI8x16Shuffle:
     case kRiscvVwmul:
     case kRiscvVwmulu:
-    case kRiscvVmvVv:
-    case kRiscvVmvVx:
-    case kRiscvVmvVi:
+    case kRiscvVmv:
     case kRiscvVandVv:
     case kRiscvVorVv:
     case kRiscvVnotVv:
@@ -274,16 +267,19 @@ int InstructionScheduler::GetTargetInstructionFlags(
     case kRiscvVfmvVf:
     case kRiscvVcompress:
     case kRiscvVaddVv:
-    case kRiscvVwadd:
+    case kRiscvVwaddVv:
+    case kRiscvVwadduVv:
+    case kRiscvVwadduWx:
     case kRiscvVsubVv:
     case kRiscvVnegVv:
     case kRiscvVfnegVv:
     case kRiscvVmaxuVv:
-    case kRiscvVmaxsVv:
+    case kRiscvVmax:
     case kRiscvVminsVv:
     case kRiscvVminuVv:
     case kRiscvVmulVv:
-    case kRiscvVwaddu:
+    case kRiscvVdivu:
+    case kRiscvVsmulVv:
     case kRiscvVgtsVv:
     case kRiscvVgesVv:
     case kRiscvVgeuVv:
@@ -296,8 +292,9 @@ int InstructionScheduler::GetTargetInstructionFlags(
     case kRiscvVsubSatSVv:
     case kRiscvVrgather:
     case kRiscvVslidedown:
-    case kRiscvVsllVi:
-    case kRiscvVsllVx:
+    case kRiscvVnclipu:
+    case kRiscvVnclip:
+    case kRiscvVsll:
     case kRiscvVfaddVv:
     case kRiscvVfsubVv:
     case kRiscvVfmulVv:
diff --git a/src/compiler/backend/riscv/instruction-selector-riscv.h b/src/compiler/backend/riscv/instruction-selector-riscv.h
index d4d6866ed91..9dd0c14b46b 100644
--- a/src/compiler/backend/riscv/instruction-selector-riscv.h
+++ b/src/compiler/backend/riscv/instruction-selector-riscv.h
@@ -1013,7 +1013,7 @@ void InstructionSelectorT<Adapter>::VisitI32x4ExtAddPairwiseI16x8S(Node* node) {
        g.UseImmediate(int8_t(E16)), g.UseImmediate(int8_t(m1)));
   Emit(kRiscvVrgather, src2, src, g.UseImmediate64(0x0007000500030001),
        g.UseImmediate(int8_t(E16)), g.UseImmediate(int8_t(m1)));
-  Emit(kRiscvVwadd, g.DefineAsRegister(node), src1, src2,
+  Emit(kRiscvVwaddVv, g.DefineAsRegister(node), src1, src2,
        g.UseImmediate(int8_t(E16)), g.UseImmediate(int8_t(mf2)));
 }
 
@@ -1027,7 +1027,7 @@ void InstructionSelectorT<Adapter>::VisitI32x4ExtAddPairwiseI16x8U(Node* node) {
        g.UseImmediate(int8_t(E16)), g.UseImmediate(int8_t(m1)));
   Emit(kRiscvVrgather, src2, src, g.UseImmediate64(0x0007000500030001),
        g.UseImmediate(int8_t(E16)), g.UseImmediate(int8_t(m1)));
-  Emit(kRiscvVwaddu, g.DefineAsRegister(node), src1, src2,
+  Emit(kRiscvVwadduVv, g.DefineAsRegister(node), src1, src2,
        g.UseImmediate(int8_t(E16)), g.UseImmediate(int8_t(mf2)));
 }
 
@@ -1041,7 +1041,7 @@ void InstructionSelectorT<Adapter>::VisitI16x8ExtAddPairwiseI8x16S(Node* node) {
        g.UseImmediate(int8_t(E8)), g.UseImmediate(int8_t(m1)));
   Emit(kRiscvVrgather, src2, src, g.UseImmediate64(0x0F0D0B0907050301),
        g.UseImmediate(int8_t(E8)), g.UseImmediate(int8_t(m1)));
-  Emit(kRiscvVwadd, g.DefineAsRegister(node), src1, src2,
+  Emit(kRiscvVwaddVv, g.DefineAsRegister(node), src1, src2,
        g.UseImmediate(int8_t(E8)), g.UseImmediate(int8_t(mf2)));
 }
 
@@ -1055,7 +1055,7 @@ void InstructionSelectorT<Adapter>::VisitI16x8ExtAddPairwiseI8x16U(Node* node) {
        g.UseImmediate(int8_t(E8)), g.UseImmediate(int8_t(m1)));
   Emit(kRiscvVrgather, src2, src, g.UseImmediate64(0x0F0D0B0907050301),
        g.UseImmediate(int8_t(E8)), g.UseImmediate(int8_t(m1)));
-  Emit(kRiscvVwaddu, g.DefineAsRegister(node), src1, src2,
+  Emit(kRiscvVwadduVv, g.DefineAsRegister(node), src1, src2,
        g.UseImmediate(int8_t(E8)), g.UseImmediate(int8_t(mf2)));
 }
 
@@ -1066,6 +1066,20 @@ void InstructionSelectorT<Adapter>::VisitI16x8ExtAddPairwiseI8x16U(Node* node) {
   V(I16x8)                \
   V(I8x16)
 
+#define SIMD_UNOP_LIST2(V)             \
+  V(F32x4Splat, kRiscvVfmvVf, E32, m1) \
+  V(I8x16Neg, kRiscvVnegVv, E8, m1)    \
+  V(I16x8Neg, kRiscvVnegVv, E16, m1)   \
+  V(I32x4Neg, kRiscvVnegVv, E32, m1)   \
+  V(I64x2Neg, kRiscvVnegVv, E64, m1)   \
+  V(I8x16Splat, kRiscvVmv, E8, m1)     \
+  V(I16x8Splat, kRiscvVmv, E16, m1)    \
+  V(I32x4Splat, kRiscvVmv, E32, m1)    \
+  V(I64x2Splat, kRiscvVmv, E64, m1)    \
+  V(F32x4Neg, kRiscvVfnegVv, E32, m1)  \
+  V(F64x2Neg, kRiscvVfnegVv, E64, m1)  \
+  V(F64x2Splat, kRiscvVfmvVf, E64, m1)
+
 #define SIMD_UNOP_LIST(V)                                       \
   V(F64x2Abs, kRiscvF64x2Abs)                                   \
   V(F64x2Sqrt, kRiscvF64x2Sqrt)                                 \
@@ -1135,89 +1149,73 @@ void InstructionSelectorT<Adapter>::VisitI16x8ExtAddPairwiseI8x16U(Node* node) {
   V(I8x16ShrS)                \
   V(I8x16ShrU)
 
-#define SIMD_BINOP_LIST2(V)                  \
-  V(I64x2Add, kRiscvVaddVv, E64, m1)         \
-  V(I32x4Add, kRiscvVaddVv, E32, m1)         \
-  V(I16x8Add, kRiscvVaddVv, E16, m1)         \
-  V(I8x16Add, kRiscvVaddVv, E8, m1)          \
-  V(I64x2Sub, kRiscvVsubVv, E64, m1)         \
-  V(I32x4Sub, kRiscvVsubVv, E32, m1)         \
-  V(I16x8Sub, kRiscvVsubVv, E16, m1)         \
-  V(I8x16Sub, kRiscvVsubVv, E8, m1)          \
-  V(I32x4MaxU, kRiscvVmaxuVv, E32, m1)       \
-  V(I16x8MaxU, kRiscvVmaxuVv, E16, m1)       \
-  V(I8x16MaxU, kRiscvVmaxuVv, E8, m1)        \
-  V(I32x4MaxS, kRiscvVmaxsVv, E32, m1)       \
-  V(I16x8MaxS, kRiscvVmaxsVv, E16, m1)       \
-  V(I8x16MaxS, kRiscvVmaxsVv, E8, m1)        \
-  V(I32x4MinS, kRiscvVminsVv, E32, m1)       \
-  V(I16x8MinS, kRiscvVminsVv, E16, m1)       \
-  V(I8x16MinS, kRiscvVminsVv, E8, m1)        \
-  V(I32x4MinU, kRiscvVminuVv, E32, m1)       \
-  V(I16x8MinU, kRiscvVminuVv, E16, m1)       \
-  V(I8x16MinU, kRiscvVminuVv, E8, m1)        \
-  V(I64x2Mul, kRiscvVmulVv, E64, m1)         \
-  V(I32x4Mul, kRiscvVmulVv, E32, m1)         \
-  V(I16x8Mul, kRiscvVmulVv, E16, m1)         \
-  V(I64x2GtS, kRiscvVgtsVv, E64, m1)         \
-  V(I32x4GtS, kRiscvVgtsVv, E32, m1)         \
-  V(I16x8GtS, kRiscvVgtsVv, E16, m1)         \
-  V(I8x16GtS, kRiscvVgtsVv, E8, m1)          \
-  V(I64x2GeS, kRiscvVgesVv, E64, m1)         \
-  V(I32x4GeS, kRiscvVgesVv, E32, m1)         \
-  V(I16x8GeS, kRiscvVgesVv, E16, m1)         \
-  V(I8x16GeS, kRiscvVgesVv, E8, m1)          \
-  V(I32x4GeU, kRiscvVgeuVv, E32, m1)         \
-  V(I16x8GeU, kRiscvVgeuVv, E16, m1)         \
-  V(I8x16GeU, kRiscvVgeuVv, E8, m1)          \
-  V(I32x4GtU, kRiscvVgtuVv, E32, m1)         \
-  V(I16x8GtU, kRiscvVgtuVv, E16, m1)         \
-  V(I8x16GtU, kRiscvVgtuVv, E8, m1)          \
-  V(I64x2Eq, kRiscvVeqVv, E64, m1)           \
-  V(I32x4Eq, kRiscvVeqVv, E32, m1)           \
-  V(I16x8Eq, kRiscvVeqVv, E16, m1)           \
-  V(I8x16Eq, kRiscvVeqVv, E8, m1)            \
-  V(I64x2Ne, kRiscvVneVv, E64, m1)           \
-  V(I32x4Ne, kRiscvVneVv, E32, m1)           \
-  V(I16x8Ne, kRiscvVneVv, E16, m1)           \
-  V(I8x16Ne, kRiscvVneVv, E8, m1)            \
-  V(I16x8AddSatS, kRiscvVaddSatSVv, E16, m1) \
-  V(I8x16AddSatS, kRiscvVaddSatSVv, E8, m1)  \
-  V(I16x8AddSatU, kRiscvVaddSatUVv, E16, m1) \
-  V(I8x16AddSatU, kRiscvVaddSatUVv, E8, m1)  \
-  V(I16x8SubSatS, kRiscvVsubSatSVv, E16, m1) \
-  V(I8x16SubSatS, kRiscvVsubSatSVv, E8, m1)  \
-  V(I16x8SubSatU, kRiscvVsubSatUVv, E16, m1) \
-  V(I8x16SubSatU, kRiscvVsubSatUVv, E8, m1)  \
-  V(F64x2Add, kRiscvVfaddVv, E64, m1)        \
-  V(F32x4Add, kRiscvVfaddVv, E32, m1)        \
-  V(F64x2Sub, kRiscvVfsubVv, E64, m1)        \
-  V(F32x4Sub, kRiscvVfsubVv, E32, m1)        \
-  V(F64x2Mul, kRiscvVfmulVv, E64, m1)        \
-  V(F32x4Mul, kRiscvVfmulVv, E32, m1)        \
-  V(F64x2Div, kRiscvVfdivVv, E64, m1)        \
-  V(F32x4Div, kRiscvVfdivVv, E32, m1)        \
-  V(S128And, kRiscvVandVv, E8, m1)           \
-  V(S128Or, kRiscvVorVv, E8, m1)             \
-  V(S128Xor, kRiscvVxorVv, E8, m1)
-
-#define SIMD_UNOP_INT_LIST(V) \
-  V(Neg, kRiscvVnegVv)        \
-  V(Splat, kRiscvVmvVx)
-
-#define SIMD_UNOP_FLOAT_LIST(V) \
-  V(Neg, kRiscvVfnegVv)         \
-  V(Splat, kRiscvVfmvVf)
-
-#define SIMD_BINOP_LIST(V)                              \
-  V(I16x8RoundingAverageU, kRiscvI16x8RoundingAverageU) \
-  V(I16x8Q15MulRSatS, kRiscvI16x8Q15MulRSatS)           \
-  V(I16x8RelaxedQ15MulRS, kRiscvI16x8Q15MulRSatS)       \
-  V(I16x8SConvertI32x4, kRiscvI16x8SConvertI32x4)       \
-  V(I16x8UConvertI32x4, kRiscvI16x8UConvertI32x4)       \
-  V(I8x16RoundingAverageU, kRiscvI8x16RoundingAverageU) \
-  V(I8x16SConvertI16x8, kRiscvI8x16SConvertI16x8)       \
-  V(I8x16UConvertI16x8, kRiscvI8x16UConvertI16x8)
+#define SIMD_BINOP_LIST(V)                    \
+  V(I64x2Add, kRiscvVaddVv, E64, m1)          \
+  V(I32x4Add, kRiscvVaddVv, E32, m1)          \
+  V(I16x8Add, kRiscvVaddVv, E16, m1)          \
+  V(I8x16Add, kRiscvVaddVv, E8, m1)           \
+  V(I64x2Sub, kRiscvVsubVv, E64, m1)          \
+  V(I32x4Sub, kRiscvVsubVv, E32, m1)          \
+  V(I16x8Sub, kRiscvVsubVv, E16, m1)          \
+  V(I8x16Sub, kRiscvVsubVv, E8, m1)           \
+  V(I32x4MaxU, kRiscvVmaxuVv, E32, m1)        \
+  V(I16x8MaxU, kRiscvVmaxuVv, E16, m1)        \
+  V(I8x16MaxU, kRiscvVmaxuVv, E8, m1)         \
+  V(I32x4MaxS, kRiscvVmax, E32, m1)           \
+  V(I16x8MaxS, kRiscvVmax, E16, m1)           \
+  V(I8x16MaxS, kRiscvVmax, E8, m1)            \
+  V(I32x4MinS, kRiscvVminsVv, E32, m1)        \
+  V(I16x8MinS, kRiscvVminsVv, E16, m1)        \
+  V(I8x16MinS, kRiscvVminsVv, E8, m1)         \
+  V(I32x4MinU, kRiscvVminuVv, E32, m1)        \
+  V(I16x8MinU, kRiscvVminuVv, E16, m1)        \
+  V(I8x16MinU, kRiscvVminuVv, E8, m1)         \
+  V(I64x2Mul, kRiscvVmulVv, E64, m1)          \
+  V(I32x4Mul, kRiscvVmulVv, E32, m1)          \
+  V(I16x8Mul, kRiscvVmulVv, E16, m1)          \
+  V(I64x2GtS, kRiscvVgtsVv, E64, m1)          \
+  V(I32x4GtS, kRiscvVgtsVv, E32, m1)          \
+  V(I16x8GtS, kRiscvVgtsVv, E16, m1)          \
+  V(I8x16GtS, kRiscvVgtsVv, E8, m1)           \
+  V(I64x2GeS, kRiscvVgesVv, E64, m1)          \
+  V(I32x4GeS, kRiscvVgesVv, E32, m1)          \
+  V(I16x8GeS, kRiscvVgesVv, E16, m1)          \
+  V(I8x16GeS, kRiscvVgesVv, E8, m1)           \
+  V(I32x4GeU, kRiscvVgeuVv, E32, m1)          \
+  V(I16x8GeU, kRiscvVgeuVv, E16, m1)          \
+  V(I8x16GeU, kRiscvVgeuVv, E8, m1)           \
+  V(I32x4GtU, kRiscvVgtuVv, E32, m1)          \
+  V(I16x8GtU, kRiscvVgtuVv, E16, m1)          \
+  V(I8x16GtU, kRiscvVgtuVv, E8, m1)           \
+  V(I64x2Eq, kRiscvVeqVv, E64, m1)            \
+  V(I32x4Eq, kRiscvVeqVv, E32, m1)            \
+  V(I16x8Eq, kRiscvVeqVv, E16, m1)            \
+  V(I8x16Eq, kRiscvVeqVv, E8, m1)             \
+  V(I64x2Ne, kRiscvVneVv, E64, m1)            \
+  V(I32x4Ne, kRiscvVneVv, E32, m1)            \
+  V(I16x8Ne, kRiscvVneVv, E16, m1)            \
+  V(I8x16Ne, kRiscvVneVv, E8, m1)             \
+  V(I16x8AddSatS, kRiscvVaddSatSVv, E16, m1)  \
+  V(I8x16AddSatS, kRiscvVaddSatSVv, E8, m1)   \
+  V(I16x8AddSatU, kRiscvVaddSatUVv, E16, m1)  \
+  V(I8x16AddSatU, kRiscvVaddSatUVv, E8, m1)   \
+  V(I16x8SubSatS, kRiscvVsubSatSVv, E16, m1)  \
+  V(I8x16SubSatS, kRiscvVsubSatSVv, E8, m1)   \
+  V(I16x8SubSatU, kRiscvVsubSatUVv, E16, m1)  \
+  V(I8x16SubSatU, kRiscvVsubSatUVv, E8, m1)   \
+  V(F64x2Add, kRiscvVfaddVv, E64, m1)         \
+  V(F32x4Add, kRiscvVfaddVv, E32, m1)         \
+  V(F64x2Sub, kRiscvVfsubVv, E64, m1)         \
+  V(F32x4Sub, kRiscvVfsubVv, E32, m1)         \
+  V(F64x2Mul, kRiscvVfmulVv, E64, m1)         \
+  V(F32x4Mul, kRiscvVfmulVv, E32, m1)         \
+  V(F64x2Div, kRiscvVfdivVv, E64, m1)         \
+  V(F32x4Div, kRiscvVfdivVv, E32, m1)         \
+  V(S128And, kRiscvVandVv, E8, m1)            \
+  V(S128Or, kRiscvVorVv, E8, m1)              \
+  V(S128Xor, kRiscvVxorVv, E8, m1)            \
+  V(I16x8Q15MulRSatS, kRiscvVsmulVv, E16, m1) \
+  V(I16x8RelaxedQ15MulRS, kRiscvVsmulVv, E16, m1)
 
 template <typename Adapter>
 void InstructionSelectorT<Adapter>::VisitS128AndNot(Node* node) {
@@ -1298,67 +1296,13 @@ SIMD_UNOP_LIST(SIMD_VISIT_UNOP)
 SIMD_SHIFT_OP_LIST(SIMD_VISIT_SHIFT_OP)
 #undef SIMD_VISIT_SHIFT_OP
 
-#define SIMD_VISIT_BINOP(Name, instruction)                     \
-  template <typename Adapter>                                   \
-  void InstructionSelectorT<Adapter>::Visit##Name(Node* node) { \
-    VisitRRR(this, instruction, node);                          \
-  }
-SIMD_BINOP_LIST(SIMD_VISIT_BINOP)
-#undef SIMD_VISIT_BINOP
-
-#define SIMD_VISIT_UNOP_INT(Name, instruction)                       \
-  template <typename Adapter>                                        \
-  void InstructionSelectorT<Adapter>::VisitI64x2##Name(Node* node) { \
-    RiscvOperandGeneratorT<Adapter> g(this);                         \
-    this->Emit(instruction, g.DefineAsRegister(node),                \
-               g.UseRegister(node->InputAt(0)), g.UseImmediate(E64), \
-               g.UseImmediate(m1));                                  \
-  }                                                                  \
-                                                                     \
-  template <typename Adapter>                                        \
-  void InstructionSelectorT<Adapter>::VisitI32x4##Name(Node* node) { \
-    RiscvOperandGeneratorT<Adapter> g(this);                         \
-    this->Emit(instruction, g.DefineAsRegister(node),                \
-               g.UseRegister(node->InputAt(0)), g.UseImmediate(E32), \
-               g.UseImmediate(m1));                                  \
-  }                                                                  \
-                                                                     \
-  template <typename Adapter>                                        \
-  void InstructionSelectorT<Adapter>::VisitI16x8##Name(Node* node) { \
-    RiscvOperandGeneratorT<Adapter> g(this);                         \
-    this->Emit(instruction, g.DefineAsRegister(node),                \
-               g.UseRegister(node->InputAt(0)), g.UseImmediate(E16), \
-               g.UseImmediate(m1));                                  \
-  }                                                                  \
-                                                                     \
-  template <typename Adapter>                                        \
-  void InstructionSelectorT<Adapter>::VisitI8x16##Name(Node* node) { \
-    RiscvOperandGeneratorT<Adapter> g(this);                         \
-    this->Emit(instruction, g.DefineAsRegister(node),                \
-               g.UseRegister(node->InputAt(0)), g.UseImmediate(E8),  \
-               g.UseImmediate(m1));                                  \
-  }
-
-SIMD_UNOP_INT_LIST(SIMD_VISIT_UNOP_INT)
-#undef SIMD_VISIT_UNOP_INT
-
-#define SIMD_VISIT_UNOP_FLOAT(Name, instruction)                     \
-  template <typename Adapter>                                        \
-  void InstructionSelectorT<Adapter>::VisitF64x2##Name(Node* node) { \
-    RiscvOperandGeneratorT<Adapter> g(this);                         \
-    this->Emit(instruction, g.DefineAsRegister(node),                \
-               g.UseRegister(node->InputAt(0)), g.UseImmediate(E64), \
-               g.UseImmediate(m1));                                  \
-  }                                                                  \
-  template <typename Adapter>                                        \
-  void InstructionSelectorT<Adapter>::VisitF32x4##Name(Node* node) { \
-    RiscvOperandGeneratorT<Adapter> g(this);                         \
-    this->Emit(instruction, g.DefineAsRegister(node),                \
-               g.UseRegister(node->InputAt(0)), g.UseImmediate(E32), \
-               g.UseImmediate(m1));                                  \
-  }
-SIMD_UNOP_FLOAT_LIST(SIMD_VISIT_UNOP_FLOAT)
-#undef SIMD_VISIT_UNOP_FLOAT
+// #define SIMD_VISIT_BINOP(Name, instruction)                     \
+//   template <typename Adapter>                                   \
+//   void InstructionSelectorT<Adapter>::Visit##Name(Node* node) { \
+//     VisitRRR(this, instruction, node);                          \
+//   }
+// SIMD_BINOP_LIST2(SIMD_VISIT_BINOP)
+// #undef SIMD_VISIT_BINOP
 
 #define SIMD_VISIT_BINOP_RVV(Name, instruction, VSEW, LMUL)           \
   template <typename Adapter>                                         \
@@ -1369,9 +1313,20 @@ SIMD_UNOP_FLOAT_LIST(SIMD_VISIT_UNOP_FLOAT)
                g.UseRegister(node->InputAt(1)), g.UseImmediate(VSEW), \
                g.UseImmediate(LMUL));                                 \
   }
-SIMD_BINOP_LIST2(SIMD_VISIT_BINOP_RVV)
+SIMD_BINOP_LIST(SIMD_VISIT_BINOP_RVV)
 #undef SIMD_VISIT_BINOP_RVV
 
+#define SIMD_VISIT_UNOP2(Name, instruction, VSEW, LMUL)               \
+  template <typename Adapter>                                         \
+  void InstructionSelectorT<Adapter>::Visit##Name(Node* node) {       \
+    RiscvOperandGeneratorT<Adapter> g(this);                          \
+    this->Emit(instruction, g.DefineAsRegister(node),                 \
+               g.UseRegister(node->InputAt(0)), g.UseImmediate(VSEW), \
+               g.UseImmediate(LMUL));                                 \
+  }
+SIMD_UNOP_LIST2(SIMD_VISIT_UNOP2)
+#undef SIMD_VISIT_UNOP2
+
 template <typename Adapter>
 void InstructionSelectorT<Adapter>::VisitS128Select(Node* node) {
   VisitRRRR(this, kRiscvS128Select, node);
@@ -1417,12 +1372,12 @@ void InstructionSelectorT<Adapter>::VisitF32x4Min(Node* node) {
 
   InstructionOperand NaN = g.TempFpRegister(kSimd128ScratchReg);
   InstructionOperand result = g.TempFpRegister(kSimd128ScratchReg);
-  this->Emit(kRiscvVmvVi, NaN, g.UseImmediate(0x7FC00000), g.UseImmediate(E32),
+  this->Emit(kRiscvVmv, NaN, g.UseImmediate(0x7FC00000), g.UseImmediate(E32),
              g.UseImmediate(m1));
   this->Emit(kRiscvVfminVv, result, g.UseRegister(node->InputAt(1)),
              g.UseRegister(node->InputAt(0)), g.UseImmediate(E32),
              g.UseImmediate(m1), g.UseImmediate(MaskType::Mask));
-  this->Emit(kRiscvVmvVv, g.DefineAsRegister(node), result, g.UseImmediate(E32),
+  this->Emit(kRiscvVmv, g.DefineAsRegister(node), result, g.UseImmediate(E32),
              g.UseImmediate(m1));
 }
 
@@ -1444,12 +1399,12 @@ void InstructionSelectorT<Adapter>::VisitF32x4Max(Node* node) {
 
   InstructionOperand NaN = g.TempFpRegister(kSimd128ScratchReg);
   InstructionOperand result = g.TempFpRegister(kSimd128ScratchReg);
-  this->Emit(kRiscvVmvVi, NaN, g.UseImmediate(0x7FC00000), g.UseImmediate(E32),
+  this->Emit(kRiscvVmv, NaN, g.UseImmediate(0x7FC00000), g.UseImmediate(E32),
              g.UseImmediate(m1));
   this->Emit(kRiscvVfmaxVv, result, g.UseRegister(node->InputAt(1)),
              g.UseRegister(node->InputAt(0)), g.UseImmediate(E32),
              g.UseImmediate(m1), g.UseImmediate(MaskType::Mask));
-  this->Emit(kRiscvVmvVv, g.DefineAsRegister(node), result, g.UseImmediate(E32),
+  this->Emit(kRiscvVmv, g.DefineAsRegister(node), result, g.UseImmediate(E32),
              g.UseImmediate(m1));
 }
 
@@ -1481,7 +1436,7 @@ void InstructionSelectorT<Adapter>::VisitF64x2Eq(Node* node) {
              g.UseRegister(node->InputAt(0)), g.UseImmediate(E64),
              g.UseImmediate(m1));
   InstructionOperand temp2 = g.TempFpRegister(kSimd128ScratchReg);
-  this->Emit(kRiscvVmvVx, temp2, g.UseImmediate(0), g.UseImmediate(E64),
+  this->Emit(kRiscvVmv, temp2, g.UseImmediate(0), g.UseImmediate(E64),
              g.UseImmediate(m1));
   this->Emit(kRiscvVmergeVx, g.DefineAsRegister(node), g.UseImmediate(-1),
              temp2, g.UseImmediate(E64), g.UseImmediate(m1));
@@ -1495,7 +1450,7 @@ void InstructionSelectorT<Adapter>::VisitF64x2Ne(Node* node) {
              g.UseRegister(node->InputAt(0)), g.UseImmediate(E64),
              g.UseImmediate(m1));
   InstructionOperand temp2 = g.TempFpRegister(kSimd128ScratchReg);
-  this->Emit(kRiscvVmvVx, temp2, g.UseImmediate(0), g.UseImmediate(E64),
+  this->Emit(kRiscvVmv, temp2, g.UseImmediate(0), g.UseImmediate(E64),
              g.UseImmediate(m1));
   this->Emit(kRiscvVmergeVx, g.DefineAsRegister(node), g.UseImmediate(-1),
              temp2, g.UseImmediate(E64), g.UseImmediate(m1));
@@ -1509,7 +1464,7 @@ void InstructionSelectorT<Adapter>::VisitF64x2Lt(Node* node) {
              g.UseRegister(node->InputAt(1)), g.UseImmediate(E64),
              g.UseImmediate(m1));
   InstructionOperand temp2 = g.TempFpRegister(kSimd128ScratchReg);
-  this->Emit(kRiscvVmvVx, temp2, g.UseImmediate(0), g.UseImmediate(E64),
+  this->Emit(kRiscvVmv, temp2, g.UseImmediate(0), g.UseImmediate(E64),
              g.UseImmediate(m1));
   this->Emit(kRiscvVmergeVx, g.DefineAsRegister(node), g.UseImmediate(-1),
              temp2, g.UseImmediate(E64), g.UseImmediate(m1));
@@ -1523,7 +1478,7 @@ void InstructionSelectorT<Adapter>::VisitF64x2Le(Node* node) {
              g.UseRegister(node->InputAt(1)), g.UseImmediate(E64),
              g.UseImmediate(m1));
   InstructionOperand temp2 = g.TempFpRegister(kSimd128ScratchReg);
-  this->Emit(kRiscvVmvVx, temp2, g.UseImmediate(0), g.UseImmediate(E64),
+  this->Emit(kRiscvVmv, temp2, g.UseImmediate(0), g.UseImmediate(E64),
              g.UseImmediate(m1));
   this->Emit(kRiscvVmergeVx, g.DefineAsRegister(node), g.UseImmediate(-1),
              temp2, g.UseImmediate(E64), g.UseImmediate(m1));
@@ -1537,7 +1492,7 @@ void InstructionSelectorT<Adapter>::VisitF32x4Eq(Node* node) {
              g.UseRegister(node->InputAt(0)), g.UseImmediate(E32),
              g.UseImmediate(m1));
   InstructionOperand temp2 = g.TempFpRegister(kSimd128ScratchReg);
-  this->Emit(kRiscvVmvVx, temp2, g.UseImmediate(0), g.UseImmediate(E32),
+  this->Emit(kRiscvVmv, temp2, g.UseImmediate(0), g.UseImmediate(E32),
              g.UseImmediate(m1));
   this->Emit(kRiscvVmergeVx, g.DefineAsRegister(node), g.UseImmediate(-1),
              temp2, g.UseImmediate(E32), g.UseImmediate(m1));
@@ -1551,7 +1506,7 @@ void InstructionSelectorT<Adapter>::VisitF32x4Ne(Node* node) {
              g.UseRegister(node->InputAt(0)), g.UseImmediate(E32),
              g.UseImmediate(m1));
   InstructionOperand temp2 = g.TempFpRegister(kSimd128ScratchReg);
-  this->Emit(kRiscvVmvVx, temp2, g.UseImmediate(0), g.UseImmediate(E32),
+  this->Emit(kRiscvVmv, temp2, g.UseImmediate(0), g.UseImmediate(E32),
              g.UseImmediate(m1));
   this->Emit(kRiscvVmergeVx, g.DefineAsRegister(node), g.UseImmediate(-1),
              temp2, g.UseImmediate(E32), g.UseImmediate(m1));
@@ -1565,7 +1520,7 @@ void InstructionSelectorT<Adapter>::VisitF32x4Lt(Node* node) {
              g.UseRegister(node->InputAt(1)), g.UseImmediate(E32),
              g.UseImmediate(m1));
   InstructionOperand temp2 = g.TempFpRegister(kSimd128ScratchReg);
-  this->Emit(kRiscvVmvVx, temp2, g.UseImmediate(0), g.UseImmediate(E32),
+  this->Emit(kRiscvVmv, temp2, g.UseImmediate(0), g.UseImmediate(E32),
              g.UseImmediate(m1));
   this->Emit(kRiscvVmergeVx, g.DefineAsRegister(node), g.UseImmediate(-1),
              temp2, g.UseImmediate(E32), g.UseImmediate(m1));
@@ -1579,12 +1534,118 @@ void InstructionSelectorT<Adapter>::VisitF32x4Le(Node* node) {
              g.UseRegister(node->InputAt(1)), g.UseImmediate(E32),
              g.UseImmediate(m1));
   InstructionOperand temp2 = g.TempFpRegister(kSimd128ScratchReg);
-  this->Emit(kRiscvVmvVx, temp2, g.UseImmediate(0), g.UseImmediate(E32),
+  this->Emit(kRiscvVmv, temp2, g.UseImmediate(0), g.UseImmediate(E32),
              g.UseImmediate(m1));
   this->Emit(kRiscvVmergeVx, g.DefineAsRegister(node), g.UseImmediate(-1),
              temp2, g.UseImmediate(E32), g.UseImmediate(m1));
 }
 
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitI16x8SConvertI32x4(Node* node) {
+  RiscvOperandGeneratorT<Adapter> g(this);
+  InstructionOperand temp = g.TempFpRegister(v26);
+  InstructionOperand temp2 = g.TempFpRegister(v27);
+  this->Emit(kRiscvVmv, temp, g.UseRegister(node->InputAt(0)),
+             g.UseImmediate(E32), g.UseImmediate(m1));
+  this->Emit(kRiscvVmv, temp2, g.UseRegister(node->InputAt(1)),
+             g.UseImmediate(E32), g.UseImmediate(m1));
+  this->Emit(kRiscvVnclip, g.DefineAsRegister(node), temp, g.UseImmediate(0),
+             g.UseImmediate(E16), g.UseImmediate(m1),
+             g.UseImmediate(FPURoundingMode::RNE));
+}
+
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitI16x8UConvertI32x4(Node* node) {
+  RiscvOperandGeneratorT<Adapter> g(this);
+  InstructionOperand temp = g.TempFpRegister(v26);
+  InstructionOperand temp2 = g.TempFpRegister(v27);
+  this->Emit(kRiscvVmv, temp, g.UseRegister(node->InputAt(0)),
+             g.UseImmediate(E32), g.UseImmediate(m1));
+  this->Emit(kRiscvVmv, temp2, g.UseRegister(node->InputAt(1)),
+             g.UseImmediate(E32), g.UseImmediate(m1));
+  this->Emit(kRiscvVmax, temp, temp, g.UseImmediate(0), g.UseImmediate(E32),
+             g.UseImmediate(m2));
+  this->Emit(kRiscvVnclipu, g.DefineAsRegister(node), temp, g.UseImmediate(0),
+             g.UseImmediate(E16), g.UseImmediate(m1),
+             g.UseImmediate(FPURoundingMode::RNE));
+}
+
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitI8x16RoundingAverageU(Node* node) {
+  RiscvOperandGeneratorT<Adapter> g(this);
+  InstructionOperand temp = g.TempFpRegister(kSimd128ScratchReg);
+  this->Emit(kRiscvVwadduVv, temp, g.UseRegister(node->InputAt(0)),
+             g.UseRegister(node->InputAt(1)), g.UseImmediate(E8),
+             g.UseImmediate(m1));
+  InstructionOperand temp2 = g.TempFpRegister(kSimd128ScratchReg3);
+  this->Emit(kRiscvVwadduWx, temp2, temp, g.UseImmediate(1), g.UseImmediate(E8),
+             g.UseImmediate(m1));
+  InstructionOperand temp3 = g.TempFpRegister(kSimd128ScratchReg3);
+  this->Emit(kRiscvVdivu, temp3, temp2, g.UseImmediate(2), g.UseImmediate(E16),
+             g.UseImmediate(m2));
+  this->Emit(kRiscvVnclipu, g.DefineAsRegister(node), temp3, g.UseImmediate(0),
+             g.UseImmediate(E8), g.UseImmediate(m1));
+}
+
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitI8x16SConvertI16x8(Node* node) {
+  RiscvOperandGeneratorT<Adapter> g(this);
+  InstructionOperand temp = g.TempFpRegister(v26);
+  InstructionOperand temp2 = g.TempFpRegister(v27);
+  this->Emit(kRiscvVmv, temp, g.UseRegister(node->InputAt(0)),
+             g.UseImmediate(E16), g.UseImmediate(m1));
+  this->Emit(kRiscvVmv, temp2, g.UseRegister(node->InputAt(1)),
+             g.UseImmediate(E16), g.UseImmediate(m1));
+  this->Emit(kRiscvVnclip, g.DefineAsRegister(node), temp, g.UseImmediate(0),
+             g.UseImmediate(E8), g.UseImmediate(m1),
+             g.UseImmediate(FPURoundingMode::RNE));
+}
+
+// case kRiscvI8x16UConvertI16x8: {
+//   __ VU.set(kScratchReg, E16, m1);
+//   __ vmv_vv(v26, i.InputSimd128Register(0));
+//   __ vmv_vv(v27, i.InputSimd128Register(1));
+//   __ VU.set(kScratchReg, E16, m2);
+//   __ vmax_vx(v26, v26, zero_reg);
+//   __ VU.set(kScratchReg, E8, m1);
+//   __ VU.set(FPURoundingMode::RNE);
+//   __ vnclipu_vi(i.OutputSimd128Register(), v26, 0);
+//   break;
+// }
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitI8x16UConvertI16x8(Node* node) {
+  RiscvOperandGeneratorT<Adapter> g(this);
+  InstructionOperand temp = g.TempFpRegister(v26);
+  InstructionOperand temp2 = g.TempFpRegister(v27);
+  this->Emit(kRiscvVmv, temp, g.UseRegister(node->InputAt(0)),
+             g.UseImmediate(E16), g.UseImmediate(m1));
+  this->Emit(kRiscvVmv, temp2, g.UseRegister(node->InputAt(1)),
+             g.UseImmediate(E16), g.UseImmediate(m1));
+  this->Emit(kRiscvVmax, temp, temp, g.UseImmediate(0), g.UseImmediate(E16),
+             g.UseImmediate(m2));
+  this->Emit(kRiscvVnclipu, g.DefineAsRegister(node), temp, g.UseImmediate(0),
+             g.UseImmediate(E8), g.UseImmediate(m1),
+             g.UseImmediate(FPURoundingMode::RNE));
+}
+
+template <typename Adapter>
+void InstructionSelectorT<Adapter>::VisitI16x8RoundingAverageU(Node* node) {
+  RiscvOperandGeneratorT<Adapter> g(this);
+  InstructionOperand temp = g.TempFpRegister(v16);
+  InstructionOperand temp2 = g.TempFpRegister(v16);
+  InstructionOperand temp3 = g.TempFpRegister(v16);
+  this->Emit(kRiscvVwadduVv, temp, g.UseRegister(node->InputAt(0)),
+             g.UseRegister(node->InputAt(1)), g.UseImmediate(E16),
+             g.UseImmediate(m1));
+  this->Emit(kRiscvVwadduWx, temp2, temp, g.UseImmediate(1),
+             g.UseImmediate(E16), g.UseImmediate(m1));
+  this->Emit(kRiscvVdivu, temp3, temp2, g.UseImmediate(2), g.UseImmediate(E32),
+             g.UseImmediate(m2));
+  this->Emit(kRiscvVnclipu, g.DefineAsRegister(node), temp3, g.UseImmediate(0),
+             g.UseImmediate(E16), g.UseImmediate(m1),
+             g.UseImmediate(FPURoundingMode::RNE));
+}
+
 template <typename Adapter>
 void InstructionSelectorT<Adapter>::VisitI32x4DotI16x8S(Node* node) {
   constexpr int32_t FIRST_INDEX = 0b01010101;
@@ -1657,9 +1718,9 @@ void InstructionSelectorT<Adapter>::VisitI32x4DotI8x16I7x16AddS(Node* node) {
 
   InstructionOperand temp2 = g.TempFpRegister(v18);
   InstructionOperand temp = g.TempFpRegister(kSimd128ScratchReg);
-  this->Emit(kRiscvVwadd, temp2, compressedPart1, compressedPart2,
+  this->Emit(kRiscvVwaddVv, temp2, compressedPart1, compressedPart2,
              g.UseImmediate(E16), g.UseImmediate(m1));
-  this->Emit(kRiscvVwadd, temp, compressedPart3, compressedPart4,
+  this->Emit(kRiscvVwaddVv, temp, compressedPart3, compressedPart4,
              g.UseImmediate(E16), g.UseImmediate(m1));
 
   InstructionOperand mul_result = g.TempFpRegister(v16);
diff --git a/src/compiler/backend/riscv/instruction-selector-riscv32.cc b/src/compiler/backend/riscv/instruction-selector-riscv32.cc
index 299892138a0..be55fd65977 100644
--- a/src/compiler/backend/riscv/instruction-selector-riscv32.cc
+++ b/src/compiler/backend/riscv/instruction-selector-riscv32.cc
@@ -1684,14 +1684,14 @@ void InstructionSelectorT<Adapter>::VisitF64x2Min(Node* node) {
   InstructionOperand temp3 = g.TempFpRegister(kSimd128ScratchReg);
   InstructionOperand temp4 = g.TempFpRegister(kSimd128ScratchReg);
   InstructionOperand temp5 = g.TempFpRegister(kSimd128ScratchReg);
-  this->Emit(kRiscvVmvVi, temp3, g.UseImmediate(kNaN), g.UseImmediate(E64),
+  this->Emit(kRiscvVmv, temp3, g.UseImmediate(kNaN), g.UseImmediate(E64),
              g.UseImmediate(m1));
-  this->Emit(kRiscvVsllVx, temp4, temp3, g.UseImmediate(kNaNShift),
+  this->Emit(kRiscvVsll, temp4, temp3, g.UseImmediate(kNaNShift),
              g.UseImmediate(E64), g.UseImmediate(m1));
   this->Emit(kRiscvVfminVv, temp5, g.UseRegister(node->InputAt(1)),
              g.UseRegister(node->InputAt(0)), g.UseImmediate(E64),
              g.UseImmediate(m1), g.UseImmediate(Mask));
-  this->Emit(kRiscvVmvVv, g.DefineAsRegister(node), temp5, g.UseImmediate(E64),
+  this->Emit(kRiscvVmv, g.DefineAsRegister(node), temp5, g.UseImmediate(E64),
              g.UseImmediate(m1));
 }
 
@@ -1714,14 +1714,14 @@ void InstructionSelectorT<Adapter>::VisitF64x2Max(Node* node) {
   InstructionOperand temp3 = g.TempFpRegister(kSimd128ScratchReg);
   InstructionOperand temp4 = g.TempFpRegister(kSimd128ScratchReg);
   InstructionOperand temp5 = g.TempFpRegister(kSimd128ScratchReg);
-  this->Emit(kRiscvVmvVi, temp3, g.UseImmediate(kNaN), g.UseImmediate(E64),
+  this->Emit(kRiscvVmv, temp3, g.UseImmediate(kNaN), g.UseImmediate(E64),
              g.UseImmediate(m1));
-  this->Emit(kRiscvVsllVx, temp4, temp3, g.UseImmediate(kNaNShift),
+  this->Emit(kRiscvVsll, temp4, temp3, g.UseImmediate(kNaNShift),
              g.UseImmediate(E64), g.UseImmediate(m1));
   this->Emit(kRiscvVfmaxVv, temp5, g.UseRegister(node->InputAt(1)),
              g.UseRegister(node->InputAt(0)), g.UseImmediate(E64),
              g.UseImmediate(m1), g.UseImmediate(Mask));
-  this->Emit(kRiscvVmvVv, g.DefineAsRegister(node), temp5, g.UseImmediate(E64),
+  this->Emit(kRiscvVmv, g.DefineAsRegister(node), temp5, g.UseImmediate(E64),
              g.UseImmediate(m1));
 }
 // static
diff --git a/src/compiler/backend/riscv/instruction-selector-riscv64.cc b/src/compiler/backend/riscv/instruction-selector-riscv64.cc
index 8e67d2d983f..5457c4e2dd7 100644
--- a/src/compiler/backend/riscv/instruction-selector-riscv64.cc
+++ b/src/compiler/backend/riscv/instruction-selector-riscv64.cc
@@ -2854,12 +2854,12 @@ void InstructionSelectorT<Adapter>::VisitF64x2Min(Node* node) {
 
   InstructionOperand NaN = g.TempFpRegister(kSimd128ScratchReg);
   InstructionOperand result = g.TempFpRegister(kSimd128ScratchReg);
-  this->Emit(kRiscvVmvVi, NaN, g.UseImmediate64(0x7ff8000000000000L),
+  this->Emit(kRiscvVmv, NaN, g.UseImmediate64(0x7ff8000000000000L),
              g.UseImmediate(E64), g.UseImmediate(m1));
   this->Emit(kRiscvVfminVv, result, g.UseRegister(node->InputAt(1)),
              g.UseRegister(node->InputAt(0)), g.UseImmediate(E64),
              g.UseImmediate(m1), g.UseImmediate(MaskType::Mask));
-  this->Emit(kRiscvVmvVv, g.DefineAsRegister(node), result, g.UseImmediate(E64),
+  this->Emit(kRiscvVmv, g.DefineAsRegister(node), result, g.UseImmediate(E64),
              g.UseImmediate(m1));
 }
 
@@ -2880,12 +2880,12 @@ void InstructionSelectorT<Adapter>::VisitF64x2Max(Node* node) {
 
   InstructionOperand NaN = g.TempFpRegister(kSimd128ScratchReg);
   InstructionOperand result = g.TempFpRegister(kSimd128ScratchReg);
-  this->Emit(kRiscvVmvVi, NaN, g.UseImmediate64(0x7ff8000000000000L),
+  this->Emit(kRiscvVmv, NaN, g.UseImmediate64(0x7ff8000000000000L),
              g.UseImmediate(E64), g.UseImmediate(m1));
   this->Emit(kRiscvVfmaxVv, result, g.UseRegister(node->InputAt(1)),
              g.UseRegister(node->InputAt(0)), g.UseImmediate(E64),
              g.UseImmediate(m1), g.UseImmediate(MaskType::Mask));
-  this->Emit(kRiscvVmvVv, g.DefineAsRegister(node), result, g.UseImmediate(E64),
+  this->Emit(kRiscvVmv, g.DefineAsRegister(node), result, g.UseImmediate(E64),
              g.UseImmediate(m1));
 }
 // static
-- 
2.35.1

