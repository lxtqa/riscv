From 0a6c1a778a1d3a1ccc66627d6fa6a5a95f258ff5 Mon Sep 17 00:00:00 2001
From: Jakob Gruber <jgruber@chromium.org>
Date: Thu, 20 Jan 2022 07:33:10 +0100
Subject: [PATCH] Remove the turboprop implementation

Bug: v8:12552
Change-Id: I99e4d8e8aeba5460f11e54cc1b2bcaea98a5276d
Reviewed-on: https://chromium-review.googlesource.com/c/v8/v8/+/3400964
Reviewed-by: Toon Verwaest <verwaest@chromium.org>
Reviewed-by: Tobias Tebbi <tebbi@chromium.org>
Commit-Queue: Jakob Gruber <jgruber@chromium.org>
Cr-Commit-Position: refs/heads/main@{#78698}
---
 src/codegen/compiler.cc                       |  22 +-
 src/codegen/optimized-compilation-info.cc     |   6 -
 src/codegen/optimized-compilation-info.h      |   1 -
 src/codegen/reloc-info.cc                     |   2 +-
 src/compiler/effect-control-linearizer.cc     |  23 +-
 src/compiler/effect-control-linearizer.h      |  11 +-
 src/compiler/graph-assembler.cc               | 433 +-----------------
 src/compiler/graph-assembler.h                |  52 +--
 src/compiler/heap-refs.cc                     |   6 +-
 src/compiler/js-call-reducer.cc               |   2 +-
 src/compiler/js-heap-broker.cc                |  65 +--
 src/compiler/js-heap-broker.h                 |   1 -
 src/compiler/js-inlining-heuristic.cc         |   7 -
 src/compiler/js-inlining-heuristic.h          |  13 +-
 src/compiler/pipeline.cc                      | 130 +-----
 src/compiler/select-lowering.cc               |   2 +-
 src/deoptimizer/deoptimizer.cc                |  20 +-
 src/deoptimizer/deoptimizer.h                 |   4 +-
 src/diagnostics/disassembler.cc               |   2 +-
 src/diagnostics/perf-jit.cc                   |   1 -
 src/execution/frames.cc                       |   1 -
 src/execution/runtime-profiler.cc             |   3 -
 src/flags/flag-definitions.h                  |  25 -
 src/logging/code-events.h                     |   7 +-
 src/logging/log.cc                            |   7 +-
 src/logging/log.h                             |   6 +-
 src/objects/code-inl.h                        |  20 -
 src/objects/code-kind.cc                      |   2 -
 src/objects/code-kind.h                       |  71 +--
 src/objects/code.h                            |  12 +-
 src/objects/feedback-vector.cc                |  33 +-
 src/objects/js-function-inl.h                 |   3 +-
 src/objects/js-function.cc                    |  23 +-
 src/objects/js-function.h                     |   2 -
 src/objects/shared-function-info-inl.h        |   8 +-
 src/objects/shared-function-info.h            |   2 +-
 src/profiler/profiler-listener.cc             |   5 +-
 src/profiler/profiler-listener.h              |   2 +-
 src/runtime/runtime-compiler.cc               |   6 -
 src/runtime/runtime-test.cc                   |  27 +-
 src/runtime/runtime.h                         |   4 -
 test/cctest/cctest.status                     |  13 -
 test/cctest/heap/test-heap.cc                 |  59 ---
 test/cctest/test-cpu-profiler.cc              |   1 -
 test/cctest/test-feedback-vector.cc           |   1 -
 test/debugger/debugger.status                 |   7 -
 test/inspector/inspector.status               |   5 +-
 .../compiler/bound-functions-serialize.js     |   2 +-
 test/mjsunit/compiler/regress-1226988.js      |  21 -
 ...c-map-check-deprecated-maps-polymorphic.js |  35 --
 .../test-dynamic-map-check-deprecated-maps.js |  36 --
 ...test-dynamic-map-check-deprecated-maps2.js |  46 --
 ...test-dynamic-map-check-deprecated-maps3.js |  41 --
 .../test-dynamic-map-checks-poly-mono.js      |  36 --
 .../test-dynamic-map-checks-wrong-handler.js  |  33 --
 .../test-dynamic-map-checks-wrong-handler1.js |  32 --
 .../compiler/test-dynamic-map-checks.js       |  45 --
 .../concurrent-initial-prototype-change-1.js  |   2 +-
 test/mjsunit/const-field-tracking-2.js        | 227 ---------
 .../es6/super-ic-opt-dynamic-map-checks.js    |  42 --
 test/mjsunit/mjsunit.status                   |   7 -
 test/mjsunit/regress/regress-1076569.js       |  16 -
 test/mjsunit/regress/regress-1079446.js       |  17 -
 test/mjsunit/regress/regress-1083272.js       |  19 -
 test/mjsunit/regress/regress-1083763.js       |  19 -
 test/mjsunit/regress/regress-1084953.js       |  16 -
 test/mjsunit/regress/regress-1137979.js       |  21 -
 test/mjsunit/regress/regress-1138075.js       |  27 --
 test/mjsunit/regress/regress-1138611.js       |  34 --
 test/mjsunit/regress/regress-1154961.js       |  42 --
 test/mjsunit/regress/regress-1163715.js       |  27 --
 test/mjsunit/regress/regress-1172797.js       |  48 --
 test/mjsunit/regress/regress-1201114.js       |  19 -
 test/mjsunit/regress/regress-1223733.js       |  16 -
 test/mjsunit/regress/regress-1225561.js       |  27 --
 test/mjsunit/regress/regress-1285007.js       |  40 --
 test/mjsunit/regress/regress-385565.js        |  11 +-
 .../regress-unlink-closures-on-deopt.js       |   4 -
 .../effect-control-linearizer-unittest.cc     | 212 ---------
 tools/profile.mjs                             |   5 -
 tools/testrunner/local/variants.py            |   6 +-
 tools/testrunner/standard_runner.py           |   2 +-
 82 files changed, 99 insertions(+), 2292 deletions(-)
 delete mode 100644 test/mjsunit/compiler/regress-1226988.js
 delete mode 100644 test/mjsunit/compiler/test-dynamic-map-check-deprecated-maps-polymorphic.js
 delete mode 100644 test/mjsunit/compiler/test-dynamic-map-check-deprecated-maps.js
 delete mode 100644 test/mjsunit/compiler/test-dynamic-map-check-deprecated-maps2.js
 delete mode 100644 test/mjsunit/compiler/test-dynamic-map-check-deprecated-maps3.js
 delete mode 100644 test/mjsunit/compiler/test-dynamic-map-checks-poly-mono.js
 delete mode 100644 test/mjsunit/compiler/test-dynamic-map-checks-wrong-handler.js
 delete mode 100644 test/mjsunit/compiler/test-dynamic-map-checks-wrong-handler1.js
 delete mode 100644 test/mjsunit/compiler/test-dynamic-map-checks.js
 delete mode 100644 test/mjsunit/const-field-tracking-2.js
 delete mode 100644 test/mjsunit/es6/super-ic-opt-dynamic-map-checks.js
 delete mode 100644 test/mjsunit/regress/regress-1076569.js
 delete mode 100644 test/mjsunit/regress/regress-1079446.js
 delete mode 100644 test/mjsunit/regress/regress-1083272.js
 delete mode 100644 test/mjsunit/regress/regress-1083763.js
 delete mode 100644 test/mjsunit/regress/regress-1084953.js
 delete mode 100644 test/mjsunit/regress/regress-1137979.js
 delete mode 100644 test/mjsunit/regress/regress-1138075.js
 delete mode 100644 test/mjsunit/regress/regress-1138611.js
 delete mode 100644 test/mjsunit/regress/regress-1154961.js
 delete mode 100644 test/mjsunit/regress/regress-1163715.js
 delete mode 100644 test/mjsunit/regress/regress-1172797.js
 delete mode 100644 test/mjsunit/regress/regress-1201114.js
 delete mode 100644 test/mjsunit/regress/regress-1223733.js
 delete mode 100644 test/mjsunit/regress/regress-1225561.js
 delete mode 100644 test/mjsunit/regress/regress-1285007.js

diff --git a/src/codegen/compiler.cc b/src/codegen/compiler.cc
index 796ec104dba..7f41d9a7336 100644
--- a/src/codegen/compiler.cc
+++ b/src/codegen/compiler.cc
@@ -255,9 +255,6 @@ void Compiler::LogFunctionCompilation(Isolate* isolate,
     case CodeKind::BASELINE:
       name = "baseline";
       break;
-    case CodeKind::TURBOPROP:
-      name = "turboprop";
-      break;
     case CodeKind::TURBOFAN:
       name = "optimize";
       break;
@@ -1011,24 +1008,7 @@ bool GetOptimizedCodeLater(std::unique_ptr<OptimizedCompilationJob> job,
 // optimization job has been started (but not finished).
 Handle<CodeT> ContinuationForConcurrentOptimization(
     Isolate* isolate, Handle<JSFunction> function) {
-  Handle<Code> cached_code;
-  if (FLAG_turboprop && function->HasAvailableOptimizedCode()) {
-    DCHECK(!FLAG_turboprop_as_toptier);
-    DCHECK(function->NextTier() == CodeKind::TURBOFAN);
-    // It is possible that we have marked a closure for TurboFan optimization
-    // but the marker is processed by another closure that doesn't have
-    // optimized code yet. So heal the closure here and return the optimized
-    // code.
-    if (!function->HasAttachedOptimizedCode()) {
-      DCHECK(function->feedback_vector().has_optimized_code());
-      // Release store isn't required here because it was done on store
-      // into the feedback vector.
-      STATIC_ASSERT(
-          FeedbackVector::kFeedbackVectorMaybeOptimizedCodeIsStoreRelease);
-      function->set_code(function->feedback_vector().optimized_code());
-    }
-    return handle(function->code(), isolate);
-  } else if (function->shared().HasBaselineCode()) {
+  if (function->shared().HasBaselineCode()) {
     CodeT baseline_code = function->shared().baseline_code(kAcquireLoad);
     function->set_code(baseline_code);
     return handle(baseline_code, isolate);
diff --git a/src/codegen/optimized-compilation-info.cc b/src/codegen/optimized-compilation-info.cc
index 1ad45c12abd..7476b770c1c 100644
--- a/src/codegen/optimized-compilation-info.cc
+++ b/src/codegen/optimized-compilation-info.cc
@@ -73,12 +73,6 @@ void OptimizedCompilationInfo::ConfigureFlags() {
       }
       if (FLAG_turbo_splitting) set_splitting();
       V8_FALLTHROUGH;
-    case CodeKind::TURBOPROP:
-      set_called_with_code_start_register();
-      set_switch_jump_table();
-      // TODO(yangguo): Disable this in case of debugging for crbug.com/826613
-      if (FLAG_analyze_environment_liveness) set_analyze_environment_liveness();
-      break;
     case CodeKind::BYTECODE_HANDLER:
       set_called_with_code_start_register();
       if (FLAG_turbo_splitting) set_splitting();
diff --git a/src/codegen/optimized-compilation-info.h b/src/codegen/optimized-compilation-info.h
index 169cf5f73c9..5f1308fc4e5 100644
--- a/src/codegen/optimized-compilation-info.h
+++ b/src/codegen/optimized-compilation-info.h
@@ -153,7 +153,6 @@ class V8_EXPORT_PRIVATE OptimizedCompilationInfo final {
   bool IsOptimizing() const {
     return CodeKindIsOptimizedJSFunction(code_kind());
   }
-  bool IsTurboprop() const { return code_kind() == CodeKind::TURBOPROP; }
 #if V8_ENABLE_WEBASSEMBLY
   bool IsWasm() const { return code_kind() == CodeKind::WASM_FUNCTION; }
 #endif  // V8_ENABLE_WEBASSEMBLY
diff --git a/src/codegen/reloc-info.cc b/src/codegen/reloc-info.cc
index 6057eca4a14..d1b4ed2b92e 100644
--- a/src/codegen/reloc-info.cc
+++ b/src/codegen/reloc-info.cc
@@ -476,7 +476,7 @@ void RelocInfo::Print(Isolate* isolate, std::ostream& os) {
     // Deoptimization bailouts are stored as runtime entries.
     DeoptimizeKind type;
     if (Deoptimizer::IsDeoptimizationEntry(isolate, target_address(), &type)) {
-      os << "  (" << Deoptimizer::MessageFor(type, false)
+      os << "  (" << Deoptimizer::MessageFor(type)
          << " deoptimization bailout)";
     }
   } else if (IsConstPool(rmode_)) {
diff --git a/src/compiler/effect-control-linearizer.cc b/src/compiler/effect-control-linearizer.cc
index bb932732c96..54766b8053b 100644
--- a/src/compiler/effect-control-linearizer.cc
+++ b/src/compiler/effect-control-linearizer.cc
@@ -626,7 +626,7 @@ void EffectControlLinearizer::Run() {
       continue;
     }
 
-    gasm()->Reset(block);
+    gasm()->Reset();
 
     BasicBlock::iterator instr = block->begin();
     BasicBlock::iterator end_instr = block->end();
@@ -765,8 +765,6 @@ void EffectControlLinearizer::Run() {
       ProcessNode(node, &frame_state);
     }
 
-    block = gasm()->FinalizeCurrentBlock(block);
-
     switch (block->control()) {
       case BasicBlock::kGoto:
       case BasicBlock::kNone:
@@ -6853,30 +6851,13 @@ void LinearizeEffectControl(JSGraph* graph, Schedule* schedule, Zone* temp_zone,
                             SourcePositionTable* source_positions,
                             NodeOriginTable* node_origins,
                             JSHeapBroker* broker) {
-  JSGraphAssembler graph_assembler_(graph, temp_zone, base::nullopt, nullptr);
+  JSGraphAssembler graph_assembler_(graph, temp_zone);
   EffectControlLinearizer linearizer(graph, schedule, &graph_assembler_,
                                      temp_zone, source_positions, node_origins,
                                      MaintainSchedule::kDiscard, broker);
   linearizer.Run();
 }
 
-void LowerToMachineSchedule(JSGraph* js_graph, Schedule* schedule,
-                            Zone* temp_zone,
-                            SourcePositionTable* source_positions,
-                            NodeOriginTable* node_origins,
-                            JSHeapBroker* broker) {
-  JSGraphAssembler graph_assembler(js_graph, temp_zone, base::nullopt,
-                                   schedule);
-  EffectControlLinearizer linearizer(js_graph, schedule, &graph_assembler,
-                                     temp_zone, source_positions, node_origins,
-                                     MaintainSchedule::kMaintain, broker);
-  MemoryLowering memory_lowering(js_graph, temp_zone, &graph_assembler);
-  SelectLowering select_lowering(&graph_assembler, js_graph->graph());
-  graph_assembler.AddInlineReducer(&memory_lowering);
-  graph_assembler.AddInlineReducer(&select_lowering);
-  linearizer.Run();
-}
-
 }  // namespace compiler
 }  // namespace internal
 }  // namespace v8
diff --git a/src/compiler/effect-control-linearizer.h b/src/compiler/effect-control-linearizer.h
index 33af60cd5b1..909a8cd6828 100644
--- a/src/compiler/effect-control-linearizer.h
+++ b/src/compiler/effect-control-linearizer.h
@@ -5,12 +5,11 @@
 #ifndef V8_COMPILER_EFFECT_CONTROL_LINEARIZER_H_
 #define V8_COMPILER_EFFECT_CONTROL_LINEARIZER_H_
 
-#include "src/handles/handles.h"
+#include "src/base/macros.h"
 
 namespace v8 {
 namespace internal {
 
-class Map;
 class Zone;
 
 namespace compiler {
@@ -26,14 +25,6 @@ V8_EXPORT_PRIVATE void LinearizeEffectControl(
     SourcePositionTable* source_positions, NodeOriginTable* node_origins,
     JSHeapBroker* broker);
 
-// Performs effect control linearization lowering in addition to machine
-// lowering, producing a scheduled graph that is ready for instruction
-// selection.
-V8_EXPORT_PRIVATE void LowerToMachineSchedule(
-    JSGraph* graph, Schedule* schedule, Zone* temp_zone,
-    SourcePositionTable* source_positions, NodeOriginTable* node_origins,
-    JSHeapBroker* broker);
-
 }  // namespace compiler
 }  // namespace internal
 }  // namespace v8
diff --git a/src/compiler/graph-assembler.cc b/src/compiler/graph-assembler.cc
index 93a6ee4a6b8..b2ece7e3b68 100644
--- a/src/compiler/graph-assembler.cc
+++ b/src/compiler/graph-assembler.cc
@@ -19,318 +19,6 @@ namespace v8 {
 namespace internal {
 namespace compiler {
 
-class GraphAssembler::BasicBlockUpdater {
- public:
-  BasicBlockUpdater(Schedule* schedule, Graph* graph,
-                    CommonOperatorBuilder* common, Zone* temp_zone);
-
-  Node* AddNode(Node* node);
-  Node* AddNode(Node* node, BasicBlock* to);
-  Node* AddClonedNode(Node* node);
-
-  BasicBlock* NewBasicBlock(bool deferred);
-  BasicBlock* SplitBasicBlock();
-  void AddBind(BasicBlock* block);
-  void AddBranch(Node* branch, BasicBlock* tblock, BasicBlock* fblock);
-  void AddGoto(BasicBlock* to);
-  void AddGoto(BasicBlock* from, BasicBlock* to);
-  void AddTailCall(Node* node);
-
-  void StartBlock(BasicBlock* block);
-  BasicBlock* Finalize(BasicBlock* original);
-
-  BasicBlock* original_block() { return original_block_; }
-  BasicBlock::Control original_control() { return original_control_; }
-  Node* original_control_input() { return original_control_input_; }
-
- private:
-  enum State { kUnchanged, kChanged };
-
-  Zone* temp_zone() { return temp_zone_; }
-
-  bool IsOriginalNode(Node* node);
-  void UpdateSuccessors(BasicBlock* block);
-  void SetBlockDeferredFromPredecessors();
-  void RemoveSuccessorsFromSchedule();
-  void CopyForChange();
-
-  Zone* temp_zone_;
-
-  // Current basic block we are scheduling.
-  BasicBlock* current_block_;
-
-  // The original block that we are lowering.
-  BasicBlock* original_block_;
-
-  // Position in the current block, only applicable in the 'unchanged' state.
-  BasicBlock::iterator node_it_;
-  BasicBlock::iterator end_it_;
-
-  Schedule* schedule_;
-  Graph* graph_;
-  CommonOperatorBuilder* common_;
-
-  // The nodes in the original block if we are in 'changed' state. Retained to
-  // avoid invalidating iterators that are iterating over the original nodes of
-  // the block.
-  NodeVector saved_nodes_;
-
-  // The original control, control input and successors, to enable recovery of
-  // them when we finalize the block.
-  struct SuccessorInfo {
-    BasicBlock* block;
-    size_t index;
-  };
-  ZoneVector<SuccessorInfo> saved_successors_;
-  BasicBlock::Control original_control_;
-  Node* original_control_input_;
-  bool original_deferred_;
-  size_t original_node_count_;
-
-  State state_;
-};
-
-GraphAssembler::BasicBlockUpdater::BasicBlockUpdater(
-    Schedule* schedule, Graph* graph, CommonOperatorBuilder* common,
-    Zone* temp_zone)
-    : temp_zone_(temp_zone),
-      current_block_(nullptr),
-      original_block_(nullptr),
-      schedule_(schedule),
-      graph_(graph),
-      common_(common),
-      saved_nodes_(schedule->zone()),
-      saved_successors_(schedule->zone()),
-      original_control_(BasicBlock::kNone),
-      original_control_input_(nullptr),
-      original_deferred_(false),
-      original_node_count_(graph->NodeCount()),
-      state_(kUnchanged) {}
-
-Node* GraphAssembler::BasicBlockUpdater::AddNode(Node* node) {
-  return AddNode(node, current_block_);
-}
-
-Node* GraphAssembler::BasicBlockUpdater::AddNode(Node* node, BasicBlock* to) {
-  if (state_ == kUnchanged) {
-    DCHECK_EQ(to, original_block());
-
-    if (node_it_ != end_it_ && *node_it_ == node) {
-      node_it_++;
-      return node;
-    }
-
-    CopyForChange();
-  }
-
-  // Add the node to the basic block.
-  DCHECK(!schedule_->IsScheduled(node));
-  schedule_->AddNode(to, node);
-  return node;
-}
-
-Node* GraphAssembler::BasicBlockUpdater::AddClonedNode(Node* node) {
-  DCHECK(node->op()->HasProperty(Operator::kPure));
-  if (state_ == kUnchanged) {
-    CopyForChange();
-  }
-
-  if (schedule_->IsScheduled(node) &&
-      schedule_->block(node) == current_block_) {
-    // Node is already scheduled for the current block, don't add it again.
-    return node;
-  } else if (!schedule_->IsScheduled(node) && !IsOriginalNode(node)) {
-    // Node is not scheduled yet, so we can add it directly.
-    return AddNode(node);
-  } else {
-    // TODO(9684): Potentially add some per-block caching so we can avoid
-    // cloning if we've already cloned for this block.
-    return AddNode(graph_->CloneNode(node));
-  }
-}
-
-bool GraphAssembler::BasicBlockUpdater::IsOriginalNode(Node* node) {
-  // Return true if node was part of the original schedule and might currently
-  // be re-added to the schedule after a CopyForChange.
-  return node->id() < original_node_count_;
-}
-
-void GraphAssembler::BasicBlockUpdater::CopyForChange() {
-  DCHECK_EQ(kUnchanged, state_);
-
-  // Save successor.
-  DCHECK(saved_successors_.empty());
-  for (BasicBlock* successor : original_block()->successors()) {
-    for (size_t i = 0; i < successor->PredecessorCount(); i++) {
-      if (successor->PredecessorAt(i) == original_block()) {
-        saved_successors_.push_back({successor, i});
-        break;
-      }
-    }
-  }
-  DCHECK_EQ(saved_successors_.size(), original_block()->SuccessorCount());
-
-  // Save control.
-  original_control_ = original_block()->control();
-  original_control_input_ = original_block()->control_input();
-
-  // Save original nodes (to allow them to continue to be iterated by the user
-  // of graph assembler).
-  original_block()->nodes()->swap(saved_nodes_);
-  DCHECK(original_block()->nodes()->empty());
-
-  // Re-insert the nodes from the front of the block.
-  original_block()->InsertNodes(original_block()->begin(), saved_nodes_.begin(),
-                                node_it_);
-
-  // Remove the tail from the schedule.
-  for (; node_it_ != end_it_; node_it_++) {
-    schedule_->SetBlockForNode(nullptr, *node_it_);
-  }
-
-  // Reset the control.
-  if (original_block()->control() != BasicBlock::kGoto) {
-    schedule_->SetBlockForNode(nullptr, original_block()->control_input());
-  }
-  original_block()->set_control_input(nullptr);
-  original_block()->set_control(BasicBlock::kNone);
-  original_block()->ClearSuccessors();
-
-  state_ = kChanged;
-  end_it_ = {};
-  node_it_ = {};
-}
-
-BasicBlock* GraphAssembler::BasicBlockUpdater::NewBasicBlock(bool deferred) {
-  BasicBlock* block = schedule_->NewBasicBlock();
-  block->set_deferred(deferred || original_deferred_);
-  return block;
-}
-
-BasicBlock* GraphAssembler::BasicBlockUpdater::SplitBasicBlock() {
-  return NewBasicBlock(current_block_->deferred());
-}
-
-void GraphAssembler::BasicBlockUpdater::AddBind(BasicBlock* to) {
-  DCHECK_NOT_NULL(to);
-  current_block_ = to;
-  // Basic block should only have the control node, if any.
-  DCHECK_LE(current_block_->NodeCount(), 1);
-  SetBlockDeferredFromPredecessors();
-}
-
-void GraphAssembler::BasicBlockUpdater::SetBlockDeferredFromPredecessors() {
-  if (!current_block_->deferred()) {
-    bool deferred = true;
-    for (BasicBlock* pred : current_block_->predecessors()) {
-      if (!pred->deferred()) {
-        deferred = false;
-        break;
-      }
-    }
-    current_block_->set_deferred(deferred);
-  }
-}
-
-void GraphAssembler::BasicBlockUpdater::AddBranch(Node* node,
-                                                  BasicBlock* tblock,
-                                                  BasicBlock* fblock) {
-  if (state_ == kUnchanged) {
-    DCHECK_EQ(current_block_, original_block());
-    CopyForChange();
-  }
-
-  DCHECK_EQ(state_, kChanged);
-  schedule_->AddBranch(current_block_, node, tblock, fblock);
-  current_block_ = nullptr;
-}
-
-void GraphAssembler::BasicBlockUpdater::AddGoto(BasicBlock* to) {
-  DCHECK_NOT_NULL(current_block_);
-  AddGoto(current_block_, to);
-}
-
-void GraphAssembler::BasicBlockUpdater::AddGoto(BasicBlock* from,
-                                                BasicBlock* to) {
-  if (state_ == kUnchanged) {
-    CopyForChange();
-  }
-
-  if (to->deferred() && !from->deferred()) {
-    // Add a new block with the correct deferred hint to avoid merges into the
-    // target block with different deferred hints.
-    // TODO(9684): Only split the current basic block if the label's target
-    // block has multiple merges.
-    BasicBlock* new_block = NewBasicBlock(to->deferred());
-    schedule_->AddGoto(from, new_block);
-    from = new_block;
-  }
-
-  schedule_->AddGoto(from, to);
-  current_block_ = nullptr;
-}
-
-void GraphAssembler::BasicBlockUpdater::AddTailCall(Node* node) {
-  DCHECK_EQ(node->opcode(), IrOpcode::kTailCall);
-  DCHECK_NOT_NULL(current_block_);
-
-  if (state_ == kUnchanged) {
-    CopyForChange();
-  }
-
-  schedule_->AddTailCall(current_block_, node);
-  current_block_ = nullptr;
-}
-
-void GraphAssembler::BasicBlockUpdater::UpdateSuccessors(BasicBlock* block) {
-  for (SuccessorInfo succ : saved_successors_) {
-    (succ.block->predecessors())[succ.index] = block;
-    block->AddSuccessor(succ.block);
-  }
-  saved_successors_.clear();
-  block->set_control(original_control_);
-  block->set_control_input(original_control_input_);
-  if (original_control_input_ != nullptr) {
-    schedule_->SetBlockForNode(block, original_control_input_);
-  } else {
-    DCHECK_EQ(BasicBlock::kGoto, original_control_);
-  }
-}
-
-void GraphAssembler::BasicBlockUpdater::StartBlock(BasicBlock* block) {
-  DCHECK_NULL(current_block_);
-  DCHECK_NULL(original_block_);
-  DCHECK(saved_nodes_.empty());
-  block->ResetRPOInfo();
-  current_block_ = block;
-  original_block_ = block;
-  original_deferred_ = block->deferred();
-  node_it_ = block->begin();
-  end_it_ = block->end();
-  state_ = kUnchanged;
-}
-
-BasicBlock* GraphAssembler::BasicBlockUpdater::Finalize(BasicBlock* original) {
-  DCHECK_EQ(original, original_block());
-  BasicBlock* block = current_block_;
-  if (state_ == kChanged) {
-    UpdateSuccessors(block);
-  } else {
-    DCHECK_EQ(block, original_block());
-    if (node_it_ != end_it_) {
-      // We have not got to the end of the node list, we need to trim.
-      block->TrimNodes(node_it_);
-    }
-  }
-  original_control_ = BasicBlock::kNone;
-  saved_nodes_.clear();
-  original_deferred_ = false;
-  original_control_input_ = nullptr;
-  original_block_ = nullptr;
-  current_block_ = nullptr;
-  return block;
-}
-
 class V8_NODISCARD GraphAssembler::BlockInlineReduction {
  public:
   explicit BlockInlineReduction(GraphAssembler* gasm) : gasm_(gasm) {
@@ -349,16 +37,12 @@ class V8_NODISCARD GraphAssembler::BlockInlineReduction {
 GraphAssembler::GraphAssembler(
     MachineGraph* mcgraph, Zone* zone,
     base::Optional<NodeChangedCallback> node_changed_callback,
-    Schedule* schedule, bool mark_loop_exits)
+    bool mark_loop_exits)
     : temp_zone_(zone),
       mcgraph_(mcgraph),
       effect_(nullptr),
       control_(nullptr),
       node_changed_callback_(node_changed_callback),
-      block_updater_(schedule != nullptr
-                         ? new BasicBlockUpdater(schedule, mcgraph->graph(),
-                                                 mcgraph->common(), zone)
-                         : nullptr),
       inline_reducers_(zone),
       inline_reductions_blocked_(false),
       loop_headers_(zone),
@@ -711,13 +395,8 @@ Node* GraphAssembler::DebugBreak() {
 Node* GraphAssembler::Unreachable(
     GraphAssemblerLabel<0u>* block_updater_successor) {
   Node* result = UnreachableWithoutConnectToEnd();
-  if (block_updater_ == nullptr) {
-    ConnectUnreachableToEnd();
-    InitializeEffectControl(nullptr, nullptr);
-  } else {
-    DCHECK_NOT_NULL(block_updater_successor);
-    Goto(block_updater_successor);
-  }
+  ConnectUnreachableToEnd();
+  InitializeEffectControl(nullptr, nullptr);
   return result;
 }
 
@@ -890,8 +569,6 @@ void GraphAssembler::TailCall(const CallDescriptor* call_descriptor,
   Node* node = AddNode(graph()->NewNode(common()->TailCall(call_descriptor),
                                         inputs_size, inputs));
 
-  if (block_updater_) block_updater_->AddTailCall(node);
-
   // Unlike ConnectUnreachableToEnd, the TailCall node terminates a block; to
   // keep it live, it *must* be connected to End (also in Turboprop schedules).
   NodeProperties::MergeControlToEnd(graph(), common(), node);
@@ -912,103 +589,18 @@ void GraphAssembler::BranchWithCriticalSafetyCheck(
   BranchImpl(condition, if_true, if_false, hint);
 }
 
-void GraphAssembler::RecordBranchInBlockUpdater(Node* branch,
-                                                Node* if_true_control,
-                                                Node* if_false_control,
-                                                BasicBlock* if_true_block,
-                                                BasicBlock* if_false_block) {
-  DCHECK_NOT_NULL(block_updater_);
-  // TODO(9684): Only split the current basic block if the label's target
-  // block has multiple merges.
-  BasicBlock* if_true_target = block_updater_->SplitBasicBlock();
-  BasicBlock* if_false_target = block_updater_->SplitBasicBlock();
-
-  block_updater_->AddBranch(branch, if_true_target, if_false_target);
-
-  block_updater_->AddNode(if_true_control, if_true_target);
-  block_updater_->AddGoto(if_true_target, if_true_block);
-
-  block_updater_->AddNode(if_false_control, if_false_target);
-  block_updater_->AddGoto(if_false_target, if_false_block);
-}
-
-void GraphAssembler::BindBasicBlock(BasicBlock* block) {
-  if (block_updater_) {
-    block_updater_->AddBind(block);
-  }
-}
-
-BasicBlock* GraphAssembler::NewBasicBlock(bool deferred) {
-  if (!block_updater_) return nullptr;
-  return block_updater_->NewBasicBlock(deferred);
-}
-
-void GraphAssembler::GotoBasicBlock(BasicBlock* block) {
-  if (block_updater_) {
-    block_updater_->AddGoto(block);
-  }
-}
-
-void GraphAssembler::GotoIfBasicBlock(BasicBlock* block, Node* branch,
-                                      IrOpcode::Value goto_if) {
-  if (block_updater_) {
-    // TODO(9684): Only split the current basic block for the goto_target
-    // if block has multiple merges.
-    BasicBlock* goto_target = block_updater_->SplitBasicBlock();
-    BasicBlock* fallthrough_target = block_updater_->SplitBasicBlock();
-
-    if (goto_if == IrOpcode::kIfTrue) {
-      block_updater_->AddBranch(branch, goto_target, fallthrough_target);
-    } else {
-      DCHECK_EQ(goto_if, IrOpcode::kIfFalse);
-      block_updater_->AddBranch(branch, fallthrough_target, goto_target);
-    }
-
-    block_updater_->AddNode(control(), goto_target);
-    block_updater_->AddGoto(goto_target, block);
-
-    block_updater_->AddBind(fallthrough_target);
-  }
-}
-
-BasicBlock* GraphAssembler::FinalizeCurrentBlock(BasicBlock* block) {
-  if (block_updater_) {
-    block = block_updater_->Finalize(block);
-    if (control() == mcgraph()->Dead()) {
-      // If the block's end is unreachable, then reset current effect and
-      // control to that of the block's throw control node.
-      DCHECK(block->control() == BasicBlock::kThrow);
-      Node* throw_node = block->control_input();
-      control_ = NodeProperties::GetControlInput(throw_node);
-      effect_ = NodeProperties::GetEffectInput(throw_node);
-    }
-  }
-  return block;
-}
-
 void GraphAssembler::ConnectUnreachableToEnd() {
   DCHECK_EQ(effect()->opcode(), IrOpcode::kUnreachable);
-  // When maintaining the schedule we can't easily rewire the successor blocks
-  // to disconnect them from the graph, so we just leave the unreachable nodes
-  // in the schedule.
-  // TODO(9684): Add a scheduled dead-code elimination phase to remove all the
-  // subsequent unreachable code from the schedule.
-  if (!block_updater_) {
-    Node* throw_node = graph()->NewNode(common()->Throw(), effect(), control());
-    NodeProperties::MergeControlToEnd(graph(), common(), throw_node);
-    if (node_changed_callback_.has_value()) {
-      (*node_changed_callback_)(graph()->end());
-    }
-    effect_ = control_ = mcgraph()->Dead();
+  Node* throw_node = graph()->NewNode(common()->Throw(), effect(), control());
+  NodeProperties::MergeControlToEnd(graph(), common(), throw_node);
+  if (node_changed_callback_.has_value()) {
+    (*node_changed_callback_)(graph()->end());
   }
+  effect_ = control_ = mcgraph()->Dead();
 }
 
 Node* GraphAssembler::AddClonedNode(Node* node) {
   DCHECK(node->op()->HasProperty(Operator::kPure));
-  if (block_updater_) {
-    node = block_updater_->AddClonedNode(node);
-  }
-
   UpdateEffectControlWith(node);
   return node;
 }
@@ -1036,10 +628,6 @@ Node* GraphAssembler::AddNode(Node* node) {
     }
   }
 
-  if (block_updater_) {
-    block_updater_->AddNode(node);
-  }
-
   if (node->opcode() == IrOpcode::kTerminate) {
     return node;
   }
@@ -1048,12 +636,9 @@ Node* GraphAssembler::AddNode(Node* node) {
   return node;
 }
 
-void GraphAssembler::Reset(BasicBlock* block) {
+void GraphAssembler::Reset() {
   effect_ = nullptr;
   control_ = nullptr;
-  if (block_updater_) {
-    block_updater_->StartBlock(block);
-  }
 }
 
 void GraphAssembler::InitializeEffectControl(Node* effect, Node* control) {
diff --git a/src/compiler/graph-assembler.h b/src/compiler/graph-assembler.h
index c7da66acfc0..cabae8699dc 100644
--- a/src/compiler/graph-assembler.h
+++ b/src/compiler/graph-assembler.h
@@ -25,8 +25,6 @@ using Boolean = Oddball;
 
 namespace compiler {
 
-class Schedule;
-class BasicBlock;
 class Reducer;
 
 #define PURE_ASSEMBLER_MACH_UNOP_LIST(V) \
@@ -161,11 +159,9 @@ class GraphAssemblerLabel {
     return TNode<T>::UncheckedCast(PhiAt(index));
   }
 
-  GraphAssemblerLabel(GraphAssemblerLabelType type, BasicBlock* basic_block,
-                      int loop_nesting_level,
+  GraphAssemblerLabel(GraphAssemblerLabelType type, int loop_nesting_level,
                       const std::array<MachineRepresentation, VarCount>& reps)
       : type_(type),
-        basic_block_(basic_block),
         loop_nesting_level_(loop_nesting_level),
         representations_(reps) {}
 
@@ -183,11 +179,9 @@ class GraphAssemblerLabel {
     return type_ == GraphAssemblerLabelType::kDeferred;
   }
   bool IsLoop() const { return type_ == GraphAssemblerLabelType::kLoop; }
-  BasicBlock* basic_block() { return basic_block_; }
 
   bool is_bound_ = false;
   const GraphAssemblerLabelType type_;
-  BasicBlock* const basic_block_;
   const int loop_nesting_level_;
   size_t merged_count_ = 0;
   Node* effect_;
@@ -204,10 +198,10 @@ class V8_EXPORT_PRIVATE GraphAssembler {
   GraphAssembler(
       MachineGraph* jsgraph, Zone* zone,
       base::Optional<NodeChangedCallback> node_changed_callback = base::nullopt,
-      Schedule* schedule = nullptr, bool mark_loop_exits = false);
+      bool mark_loop_exits = false);
   virtual ~GraphAssembler();
 
-  void Reset(BasicBlock* block);
+  void Reset();
   void InitializeEffectControl(Node* effect, Node* control);
 
   // Create label.
@@ -223,9 +217,7 @@ class V8_EXPORT_PRIVATE GraphAssembler {
   GraphAssemblerLabel<VarCount> MakeLabel(
       std::array<MachineRepresentation, VarCount> reps_array,
       GraphAssemblerLabelType type) {
-    return GraphAssemblerLabel<VarCount>(
-        type, NewBasicBlock(type == GraphAssemblerLabelType::kDeferred),
-        loop_nesting_level_, reps_array);
+    return GraphAssemblerLabel<VarCount>(type, loop_nesting_level_, reps_array);
   }
 
   // Convenience wrapper for creating non-deferred labels.
@@ -432,10 +424,6 @@ class V8_EXPORT_PRIVATE GraphAssembler {
     return TNode<T>::UncheckedCast(AddNode(node));
   }
 
-  // Finalizes the {block} being processed by the assembler, returning the
-  // finalized block (which may be different from the original block).
-  BasicBlock* FinalizeCurrentBlock(BasicBlock* block);
-
   void ConnectUnreachableToEnd();
 
   // Add an inline reducers such that nodes added to the graph will be run
@@ -452,15 +440,8 @@ class V8_EXPORT_PRIVATE GraphAssembler {
   Effect effect() const { return Effect(effect_); }
 
  protected:
-  class BasicBlockUpdater;
-
   template <typename... Vars>
   void MergeState(GraphAssemblerLabel<sizeof...(Vars)>* label, Vars... vars);
-  BasicBlock* NewBasicBlock(bool deferred);
-  void BindBasicBlock(BasicBlock* block);
-  void GotoBasicBlock(BasicBlock* block);
-  void GotoIfBasicBlock(BasicBlock* block, Node* branch,
-                        IrOpcode::Value goto_if);
 
   V8_INLINE Node* AddClonedNode(Node* node);
 
@@ -551,10 +532,6 @@ class V8_EXPORT_PRIVATE GraphAssembler {
                   GraphAssemblerLabel<sizeof...(Vars)>* if_true,
                   GraphAssemblerLabel<sizeof...(Vars)>* if_false,
                   BranchHint hint, Vars...);
-  void RecordBranchInBlockUpdater(Node* branch, Node* if_true_control,
-                                  Node* if_false_control,
-                                  BasicBlock* if_true_block,
-                                  BasicBlock* if_false_block);
 
   Zone* temp_zone_;
   MachineGraph* mcgraph_;
@@ -563,7 +540,6 @@ class V8_EXPORT_PRIVATE GraphAssembler {
   // {node_changed_callback_} should be called when a node outside the
   // subgraph created by the graph assembler changes.
   base::Optional<NodeChangedCallback> node_changed_callback_;
-  std::unique_ptr<BasicBlockUpdater> block_updater_;
 
   // Inline reducers enable reductions to be performed to nodes as they are
   // added to the graph with the graph assembler.
@@ -708,7 +684,6 @@ void GraphAssembler::Bind(GraphAssemblerLabel<VarCount>* label) {
 
   control_ = label->control_;
   effect_ = label->effect_;
-  BindBasicBlock(label->basic_block());
 
   label->SetBound();
 
@@ -755,19 +730,12 @@ void GraphAssembler::BranchImpl(Node* condition,
 
   Node* branch = graph()->NewNode(common()->Branch(hint), condition, control());
 
-  Node* if_true_control = control_ =
-      graph()->NewNode(common()->IfTrue(), branch);
+  control_ = graph()->NewNode(common()->IfTrue(), branch);
   MergeState(if_true, vars...);
 
-  Node* if_false_control = control_ =
-      graph()->NewNode(common()->IfFalse(), branch);
+  control_ = graph()->NewNode(common()->IfFalse(), branch);
   MergeState(if_false, vars...);
 
-  if (block_updater_) {
-    RecordBranchInBlockUpdater(branch, if_true_control, if_false_control,
-                               if_true->basic_block(), if_false->basic_block());
-  }
-
   control_ = nullptr;
   effect_ = nullptr;
 }
@@ -778,7 +746,6 @@ void GraphAssembler::Goto(GraphAssemblerLabel<sizeof...(Vars)>* label,
   DCHECK_NOT_NULL(control());
   DCHECK_NOT_NULL(effect());
   MergeState(label, vars...);
-  GotoBasicBlock(label->basic_block());
 
   control_ = nullptr;
   effect_ = nullptr;
@@ -793,7 +760,6 @@ void GraphAssembler::GotoIf(Node* condition,
   control_ = graph()->NewNode(common()->IfTrue(), branch);
   MergeState(label, vars...);
 
-  GotoIfBasicBlock(label->basic_block(), branch, IrOpcode::kIfTrue);
   control_ = AddNode(graph()->NewNode(common()->IfFalse(), branch));
 }
 
@@ -806,7 +772,6 @@ void GraphAssembler::GotoIfNot(Node* condition,
   control_ = graph()->NewNode(common()->IfFalse(), branch);
   MergeState(label, vars...);
 
-  GotoIfBasicBlock(label->basic_block(), branch, IrOpcode::kIfFalse);
   control_ = AddNode(graph()->NewNode(common()->IfTrue(), branch));
 }
 
@@ -850,9 +815,8 @@ class V8_EXPORT_PRIVATE JSGraphAssembler : public GraphAssembler {
   JSGraphAssembler(
       JSGraph* jsgraph, Zone* zone,
       base::Optional<NodeChangedCallback> node_changed_callback = base::nullopt,
-      Schedule* schedule = nullptr, bool mark_loop_exits = false)
-      : GraphAssembler(jsgraph, zone, node_changed_callback, schedule,
-                       mark_loop_exits),
+      bool mark_loop_exits = false)
+      : GraphAssembler(jsgraph, zone, node_changed_callback, mark_loop_exits),
         jsgraph_(jsgraph) {}
 
   Node* SmiConstant(int32_t value);
diff --git a/src/compiler/heap-refs.cc b/src/compiler/heap-refs.cc
index de62203e83b..86c36a6ac3a 100644
--- a/src/compiler/heap-refs.cc
+++ b/src/compiler/heap-refs.cc
@@ -1572,10 +1572,8 @@ BROKER_SFI_FIELDS(DEF_SFI_ACCESSOR)
 SharedFunctionInfo::Inlineability SharedFunctionInfoRef::GetInlineability()
     const {
   return broker()->IsMainThread()
-             ? object()->GetInlineability(broker()->isolate(),
-                                          broker()->is_turboprop())
-             : object()->GetInlineability(broker()->local_isolate(),
-                                          broker()->is_turboprop());
+             ? object()->GetInlineability(broker()->isolate())
+             : object()->GetInlineability(broker()->local_isolate());
 }
 
 ObjectRef FeedbackCellRef::value() const {
diff --git a/src/compiler/js-call-reducer.cc b/src/compiler/js-call-reducer.cc
index f9c47a642c2..6635cf814fa 100644
--- a/src/compiler/js-call-reducer.cc
+++ b/src/compiler/js-call-reducer.cc
@@ -65,7 +65,7 @@ class JSCallReducerAssembler : public JSGraphAssembler {
             reducer->JSGraphForGraphAssembler(),
             reducer->ZoneForGraphAssembler(),
             [reducer](Node* n) { reducer->RevisitForGraphAssembler(n); },
-            nullptr, kMarkLoopExits),
+            kMarkLoopExits),
         dependencies_(reducer->dependencies()),
         node_(node),
         outermost_catch_scope_(
diff --git a/src/compiler/js-heap-broker.cc b/src/compiler/js-heap-broker.cc
index 555b49f5bfd..adbab19f8e3 100644
--- a/src/compiler/js-heap-broker.cc
+++ b/src/compiler/js-heap-broker.cc
@@ -426,6 +426,7 @@ bool ElementAccessFeedback::HasOnlyStringMaps(JSHeapBroker* broker) const {
   return true;
 }
 
+// TODO(v8:12552): Remove.
 MinimorphicLoadPropertyAccessFeedback::MinimorphicLoadPropertyAccessFeedback(
     NameRef const& name, FeedbackSlotKind slot_kind, Handle<Object> handler,
     ZoneVector<MapRef> const& maps, bool has_migration_target_maps)
@@ -482,59 +483,6 @@ bool JSHeapBroker::FeedbackIsInsufficient(FeedbackSource const& source) const {
       .IsUninitialized();
 }
 
-namespace {
-
-using MapRefAndHandler = std::pair<MapRef, MaybeObjectHandle>;
-MaybeObjectHandle TryGetMinimorphicHandler(
-    ZoneVector<MapRefAndHandler> const& maps_and_handlers,
-    FeedbackSlotKind kind, NativeContextRef const& native_context,
-    bool is_turboprop) {
-  if (!is_turboprop || !FLAG_turbo_dynamic_map_checks || !IsLoadICKind(kind)) {
-    return MaybeObjectHandle();
-  }
-
-  // Don't use dynamic map checks when loading properties from Array.prototype.
-  // Using dynamic map checks prevents constant folding and hence does not
-  // inline the array builtins. We only care about monomorphic cases here. For
-  // polymorphic loads currently we don't inline the builtins even without
-  // dynamic map checks.
-  if (maps_and_handlers.size() == 1 &&
-      maps_and_handlers[0].first.equals(
-          native_context.initial_array_prototype().map())) {
-    return MaybeObjectHandle();
-  }
-
-  MaybeObjectHandle initial_handler;
-  for (const MapRefAndHandler& map_and_handler : maps_and_handlers) {
-    MapRef map = map_and_handler.first;
-    MaybeObjectHandle handler = map_and_handler.second;
-    if (handler.is_null()) return MaybeObjectHandle();
-    DCHECK(!handler->IsCleared());
-    // TODO(mythria): extend this to DataHandlers too
-    if (!handler.object()->IsSmi()) return MaybeObjectHandle();
-    if (LoadHandler::GetHandlerKind(handler.object()->ToSmi()) !=
-        LoadHandler::Kind::kField) {
-      return MaybeObjectHandle();
-    }
-    CHECK(!map.object()->IsJSGlobalProxyMap());
-    if (initial_handler.is_null()) {
-      initial_handler = handler;
-    } else if (!handler.is_identical_to(initial_handler)) {
-      return MaybeObjectHandle();
-    }
-  }
-  return initial_handler;
-}
-
-bool HasMigrationTargets(const ZoneVector<MapRef>& maps) {
-  for (const MapRef& map : maps) {
-    if (map.is_migration_target()) return true;
-  }
-  return false;
-}
-
-}  // namespace
-
 const ProcessedFeedback& JSHeapBroker::NewInsufficientFeedback(
     FeedbackSlotKind kind) const {
   return *zone()->New<InsufficientFeedback>(kind);
@@ -547,7 +495,6 @@ ProcessedFeedback const& JSHeapBroker::ReadFeedbackForPropertyAccess(
   FeedbackSlotKind kind = nexus.kind();
   if (nexus.IsUninitialized()) return NewInsufficientFeedback(kind);
 
-  ZoneVector<MapRefAndHandler> maps_and_handlers(zone());
   ZoneVector<MapRef> maps(zone());
   {
     std::vector<MapAndHandler> maps_and_handlers_unfiltered;
@@ -569,20 +516,12 @@ ProcessedFeedback const& JSHeapBroker::ReadFeedbackForPropertyAccess(
         }
       }
       if (map.is_abandoned_prototype_map()) continue;
-      maps_and_handlers.push_back({map, map_and_handler.second});
       maps.push_back(map);
     }
   }
 
   base::Optional<NameRef> name =
       static_name.has_value() ? static_name : GetNameFeedback(nexus);
-  MaybeObjectHandle handler = TryGetMinimorphicHandler(
-      maps_and_handlers, kind, target_native_context(), is_turboprop());
-  if (!handler.is_null()) {
-    return *zone()->New<MinimorphicLoadPropertyAccessFeedback>(
-        *name, kind, CanonicalPersistentHandle(handler.object()), maps,
-        HasMigrationTargets(maps));
-  }
 
   // If no maps were found for a non-megamorphic access, then our maps died
   // and we should soft-deopt.
@@ -970,6 +909,7 @@ PropertyAccessInfo JSHeapBroker::GetPropertyAccessInfo(
   return access_info;
 }
 
+// TODO(v8:12552): Remove.
 MinimorphicLoadPropertyAccessInfo JSHeapBroker::GetPropertyAccessInfo(
     MinimorphicLoadPropertyAccessFeedback const& feedback,
     FeedbackSource const& source) {
@@ -1032,6 +972,7 @@ NamedAccessFeedback const& ProcessedFeedback::AsNamedAccess() const {
   return *static_cast<NamedAccessFeedback const*>(this);
 }
 
+// TODO(v8:12552): Remove.
 MinimorphicLoadPropertyAccessFeedback const&
 ProcessedFeedback::AsMinimorphicPropertyAccess() const {
   CHECK_EQ(kMinimorphicPropertyAccess, kind());
diff --git a/src/compiler/js-heap-broker.h b/src/compiler/js-heap-broker.h
index 8d9265a637f..f9a94bb202a 100644
--- a/src/compiler/js-heap-broker.h
+++ b/src/compiler/js-heap-broker.h
@@ -127,7 +127,6 @@ class V8_EXPORT_PRIVATE JSHeapBroker {
 
   Zone* zone() const { return zone_; }
   bool tracing_enabled() const { return tracing_enabled_; }
-  bool is_turboprop() const { return code_kind_ == CodeKind::TURBOPROP; }
 
   NexusConfig feedback_nexus_config() const {
     return IsMainThread() ? NexusConfig::FromMainThread(isolate())
diff --git a/src/compiler/js-inlining-heuristic.cc b/src/compiler/js-inlining-heuristic.cc
index 07f3e0ec0e1..14e5080c301 100644
--- a/src/compiler/js-inlining-heuristic.cc
+++ b/src/compiler/js-inlining-heuristic.cc
@@ -852,13 +852,6 @@ SimplifiedOperatorBuilder* JSInliningHeuristic::simplified() const {
   return jsgraph()->simplified();
 }
 
-int JSInliningHeuristic::ScaleInliningSize(int value, JSHeapBroker* broker) {
-  if (broker->is_turboprop()) {
-    value = value / FLAG_turboprop_inline_scaling_factor;
-  }
-  return value;
-}
-
 #undef TRACE
 
 }  // namespace compiler
diff --git a/src/compiler/js-inlining-heuristic.h b/src/compiler/js-inlining-heuristic.h
index af8e913a476..ee4d63e8cd6 100644
--- a/src/compiler/js-inlining-heuristic.h
+++ b/src/compiler/js-inlining-heuristic.h
@@ -27,12 +27,10 @@ class JSInliningHeuristic final : public AdvancedReducer {
         jsgraph_(jsgraph),
         broker_(broker),
         mode_(mode),
-        max_inlined_bytecode_size_(
-            ScaleInliningSize(FLAG_max_inlined_bytecode_size, broker)),
-        max_inlined_bytecode_size_cumulative_(ScaleInliningSize(
-            FLAG_max_inlined_bytecode_size_cumulative, broker)),
-        max_inlined_bytecode_size_absolute_(ScaleInliningSize(
-            FLAG_max_inlined_bytecode_size_absolute, broker)) {}
+        max_inlined_bytecode_size_cumulative_(
+            FLAG_max_inlined_bytecode_size_cumulative),
+        max_inlined_bytecode_size_absolute_(
+            FLAG_max_inlined_bytecode_size_absolute) {}
 
   const char* reducer_name() const override { return "JSInliningHeuristic"; }
 
@@ -78,8 +76,6 @@ class JSInliningHeuristic final : public AdvancedReducer {
   // Candidates are kept in a sorted set of unique candidates.
   using Candidates = ZoneSet<Candidate, CandidateCompare>;
 
-  static int ScaleInliningSize(int value, JSHeapBroker* broker);
-
   // Dumps candidates to console.
   void PrintCandidates();
   Reduction InlineCandidate(Candidate const& candidate, bool small_function);
@@ -113,7 +109,6 @@ class JSInliningHeuristic final : public AdvancedReducer {
   JSHeapBroker* const broker_;
   int total_inlined_bytecode_size_ = 0;
   const Mode mode_;
-  const int max_inlined_bytecode_size_;
   const int max_inlined_bytecode_size_cumulative_;
   const int max_inlined_bytecode_size_absolute_;
 };
diff --git a/src/compiler/pipeline.cc b/src/compiler/pipeline.cc
index e77c464e830..65652a8d1c6 100644
--- a/src/compiler/pipeline.cc
+++ b/src/compiler/pipeline.cc
@@ -119,6 +119,7 @@ static constexpr char kRegisterAllocationZoneName[] =
     "register-allocation-zone";
 static constexpr char kRegisterAllocatorVerifierZoneName[] =
     "register-allocator-verifier-zone";
+
 namespace {
 
 Maybe<OuterContext> GetModuleContext(Handle<JSFunction> closure) {
@@ -686,10 +687,6 @@ class PipelineImpl final {
   // Step B. Run the concurrent optimization passes.
   bool OptimizeGraph(Linkage* linkage);
 
-  // Alternative step B. Run minimal concurrent optimization passes for
-  // mid-tier.
-  bool OptimizeGraphForMidTier(Linkage* linkage);
-
   // Substep B.1. Produce a scheduled graph.
   void ComputeScheduledGraph();
 
@@ -1174,8 +1171,7 @@ PipelineCompilationJob::Status PipelineCompilationJob::PrepareJobImpl(
   // allow context specialization for OSR code.
   if (compilation_info()->closure()->raw_feedback_cell().map() ==
           ReadOnlyRoots(isolate).one_closure_cell_map() &&
-      !compilation_info()->is_osr() &&
-      !compilation_info()->IsTurboprop()) {
+      !compilation_info()->is_osr()) {
     compilation_info()->set_function_context_specializing();
     data_.ChooseSpecializationContext();
   }
@@ -1217,14 +1213,8 @@ PipelineCompilationJob::Status PipelineCompilationJob::ExecuteJobImpl(
     return AbortOptimization(BailoutReason::kGraphBuildingFailed);
   }
 
-  // We selectively Unpark inside OptimizeGraph*.
-  bool success;
-  if (compilation_info_.code_kind() == CodeKind::TURBOPROP) {
-    success = pipeline_.OptimizeGraphForMidTier(linkage_);
-  } else {
-    success = pipeline_.OptimizeGraph(linkage_);
-  }
-  if (!success) return FAILED;
+  // We selectively Unpark inside OptimizeGraph.
+  if (!pipeline_.OptimizeGraph(linkage_)) return FAILED;
 
   pipeline_.AssembleCode(linkage_);
 
@@ -1383,10 +1373,8 @@ struct InliningPhase {
     JSIntrinsicLowering intrinsic_lowering(&graph_reducer, data->jsgraph(),
                                            data->broker());
     AddReducer(data, &graph_reducer, &dead_code_elimination);
-    if (!data->info()->IsTurboprop()) {
-      AddReducer(data, &graph_reducer, &checkpoint_elimination);
-      AddReducer(data, &graph_reducer, &common_reducer);
-    }
+    AddReducer(data, &graph_reducer, &checkpoint_elimination);
+    AddReducer(data, &graph_reducer, &common_reducer);
     AddReducer(data, &graph_reducer, &native_context_specialization);
     AddReducer(data, &graph_reducer, &context_specialization);
     AddReducer(data, &graph_reducer, &intrinsic_lowering);
@@ -1529,9 +1517,7 @@ struct TypedLoweringPhase {
     AddReducer(data, &graph_reducer, &dead_code_elimination);
 
     AddReducer(data, &graph_reducer, &create_lowering);
-    if (!data->info()->IsTurboprop()) {
-      AddReducer(data, &graph_reducer, &constant_folding_reducer);
-    }
+    AddReducer(data, &graph_reducer, &constant_folding_reducer);
     AddReducer(data, &graph_reducer, &typed_lowering);
     AddReducer(data, &graph_reducer, &typed_optimization);
     AddReducer(data, &graph_reducer, &simple_reducer);
@@ -1990,28 +1976,6 @@ struct DecompressionOptimizationPhase {
   }
 };
 
-struct ScheduledEffectControlLinearizationPhase {
-  DECL_PIPELINE_PHASE_CONSTANTS(ScheduledEffectControlLinearization)
-
-  void Run(PipelineData* data, Zone* temp_zone) {
-    // Post-pass for wiring the control/effects
-    // - connect allocating representation changes into the control&effect
-    //   chains and lower them,
-    // - get rid of the region markers,
-    // - introduce effect phis and rewire effects to get SSA again,
-    // - lower simplified memory and select nodes to machine level nodes.
-    LowerToMachineSchedule(data->jsgraph(), data->schedule(), temp_zone,
-                           data->source_positions(), data->node_origins(),
-                           data->broker());
-
-    // TODO(rmcilroy) Avoid having to rebuild rpo_order on schedule each time.
-    Scheduler::ComputeSpecialRPO(temp_zone, data->schedule());
-    Scheduler::GenerateDominatorTree(data->schedule());
-    TraceScheduleAndVerify(data->info(), data, data->schedule(),
-                           "effect linearization schedule");
-  }
-};
-
 #if V8_ENABLE_WEBASSEMBLY
 struct WasmOptimizationPhase {
   DECL_PIPELINE_PHASE_CONSTANTS(WasmOptimization)
@@ -2826,85 +2790,6 @@ bool PipelineImpl::OptimizeGraph(Linkage* linkage) {
   return SelectInstructions(linkage);
 }
 
-bool PipelineImpl::OptimizeGraphForMidTier(Linkage* linkage) {
-  PipelineData* data = this->data_;
-
-  data->BeginPhaseKind("V8.TFLowering");
-
-  // Type the graph and keep the Typer running such that new nodes get
-  // automatically typed when they are created.
-  Run<TyperPhase>(data->CreateTyper());
-  RunPrintAndVerify(TyperPhase::phase_name());
-
-  Run<TypedLoweringPhase>();
-  RunPrintAndVerify(TypedLoweringPhase::phase_name());
-
-  // TODO(9684): Consider rolling this into the preceeding phase or not creating
-  // LoopExit nodes at all.
-  Run<LoopExitEliminationPhase>();
-  RunPrintAndVerify(LoopExitEliminationPhase::phase_name(), true);
-
-  data->DeleteTyper();
-
-  if (FLAG_assert_types) {
-    Run<TypeAssertionsPhase>();
-    RunPrintAndVerify(TypeAssertionsPhase::phase_name());
-  }
-
-  // Perform simplified lowering. This has to run w/o the Typer decorator,
-  // because we cannot compute meaningful types anyways, and the computed types
-  // might even conflict with the representation/truncation logic.
-  Run<SimplifiedLoweringPhase>(linkage);
-  RunPrintAndVerify(SimplifiedLoweringPhase::phase_name(), true);
-
-#if V8_ENABLE_WEBASSEMBLY
-  if (data->has_js_wasm_calls()) {
-    DCHECK(data->info()->inline_js_wasm_calls());
-    Run<JSWasmInliningPhase>();
-    RunPrintAndVerify(JSWasmInliningPhase::phase_name(), true);
-  }
-#endif  // V8_ENABLE_WEBASSEMBLY
-
-  // From now on it is invalid to look at types on the nodes, because the types
-  // on the nodes might not make sense after representation selection due to the
-  // way we handle truncations; if we'd want to look at types afterwards we'd
-  // essentially need to re-type (large portions of) the graph.
-
-  // In order to catch bugs related to type access after this point, we now
-  // remove the types from the nodes (currently only in Debug builds).
-#ifdef DEBUG
-  Run<UntyperPhase>();
-  RunPrintAndVerify(UntyperPhase::phase_name(), true);
-#endif
-
-  // Run generic lowering pass.
-  Run<GenericLoweringPhase>();
-  RunPrintAndVerify(GenericLoweringPhase::phase_name(), true);
-
-  data->BeginPhaseKind("V8.TFBlockBuilding");
-
-  data->InitializeFrameData(linkage->GetIncomingDescriptor());
-
-  Run<EffectControlLinearizationPhase>();
-  RunPrintAndVerify(EffectControlLinearizationPhase::phase_name(), true);
-
-  Run<LateOptimizationPhase>();
-  RunPrintAndVerify(LateOptimizationPhase::phase_name(), true);
-
-  // Optimize memory access and allocation operations.
-  Run<MemoryOptimizationPhase>();
-  RunPrintAndVerify(MemoryOptimizationPhase::phase_name(), true);
-
-  data->source_positions()->RemoveDecorator();
-  if (data->info()->trace_turbo_json()) {
-    data->node_origins()->RemoveDecorator();
-  }
-
-  ComputeScheduledGraph();
-
-  return SelectInstructions(linkage);
-}
-
 namespace {
 
 // Compute a hash of the given graph, in a way that should provide the same
@@ -3573,7 +3458,6 @@ bool PipelineImpl::SelectInstructions(Linkage* linkage) {
   std::unique_ptr<const RegisterConfiguration> restricted_config;
   bool use_mid_tier_register_allocator =
       FLAG_turbo_force_mid_tier_regalloc ||
-      (FLAG_turboprop_mid_tier_reg_alloc && data->info()->IsTurboprop()) ||
       (FLAG_turbo_use_mid_tier_regalloc_for_huge_functions &&
        data->sequence()->VirtualRegisterCount() >
            kTopTierVirtualRegistersLimit);
diff --git a/src/compiler/select-lowering.cc b/src/compiler/select-lowering.cc
index e346e9171d7..6e96e4cef60 100644
--- a/src/compiler/select-lowering.cc
+++ b/src/compiler/select-lowering.cc
@@ -47,7 +47,7 @@ Reduction SelectLowering::LowerSelect(Node* node) {
   __ Bind(&done);
 
   if (reset_gasm) {
-    gasm()->Reset(nullptr);
+    gasm()->Reset();
   }
 
   return Changed(done.PhiAt(0));
diff --git a/src/deoptimizer/deoptimizer.cc b/src/deoptimizer/deoptimizer.cc
index 0b0122e1c1a..68b7e99f3a0 100644
--- a/src/deoptimizer/deoptimizer.cc
+++ b/src/deoptimizer/deoptimizer.cc
@@ -461,13 +461,12 @@ void Deoptimizer::ComputeOutputFrames(Deoptimizer* deoptimizer) {
   deoptimizer->DoComputeOutputFrames();
 }
 
-const char* Deoptimizer::MessageFor(DeoptimizeKind kind, bool reuse_code) {
-  DCHECK_IMPLIES(reuse_code, kind == DeoptimizeKind::kSoft);
+const char* Deoptimizer::MessageFor(DeoptimizeKind kind) {
   switch (kind) {
     case DeoptimizeKind::kEager:
       return "deopt-eager";
     case DeoptimizeKind::kSoft:
-      return reuse_code ? "bailout-soft" : "deopt-soft";
+      return "deopt-soft";
     case DeoptimizeKind::kLazy:
       return "deopt-lazy";
     case DeoptimizeKind::kBailout:
@@ -526,9 +525,8 @@ Deoptimizer::Deoptimizer(Isolate* isolate, JSFunction function,
   compiled_code_.set_deopt_already_counted(true);
   {
     HandleScope scope(isolate_);
-    PROFILE(isolate_,
-            CodeDeoptEvent(handle(compiled_code_, isolate_), kind, from_,
-                           fp_to_sp_delta_, should_reuse_code()));
+    PROFILE(isolate_, CodeDeoptEvent(handle(compiled_code_, isolate_), kind,
+                                     from_, fp_to_sp_delta_));
   }
   unsigned size = ComputeInputFrameSize();
   const int parameter_count =
@@ -594,16 +592,11 @@ Code Deoptimizer::FindOptimizedCode() {
 Handle<JSFunction> Deoptimizer::function() const {
   return Handle<JSFunction>(function_, isolate());
 }
+
 Handle<Code> Deoptimizer::compiled_code() const {
   return Handle<Code>(compiled_code_, isolate());
 }
 
-bool Deoptimizer::should_reuse_code() const {
-  int count = compiled_code_.deoptimization_count();
-  return deopt_kind_ == DeoptimizeKind::kSoft &&
-         count < FLAG_reuse_opt_code_count;
-}
-
 Deoptimizer::~Deoptimizer() {
   DCHECK(input_ == nullptr && output_ == nullptr);
   DCHECK_NULL(disallow_garbage_collection_);
@@ -728,8 +721,7 @@ void Deoptimizer::TraceDeoptBegin(int optimization_id,
   Deoptimizer::DeoptInfo info =
       Deoptimizer::GetDeoptInfo(compiled_code_, from_);
   PrintF(file, "[bailout (kind: %s, reason: %s): begin. deoptimizing ",
-         MessageFor(deopt_kind_, should_reuse_code()),
-         DeoptimizeReasonToString(info.deopt_reason));
+         MessageFor(deopt_kind_), DeoptimizeReasonToString(info.deopt_reason));
   if (function_.IsJSFunction()) {
     function_.ShortPrint(file);
   } else {
diff --git a/src/deoptimizer/deoptimizer.h b/src/deoptimizer/deoptimizer.h
index 173a8a4e024..abfd668dd92 100644
--- a/src/deoptimizer/deoptimizer.h
+++ b/src/deoptimizer/deoptimizer.h
@@ -49,14 +49,12 @@ class Deoptimizer : public Malloced {
       Isolate* isolate, SharedFunctionInfo shared,
       BytecodeOffset bytecode_offset);
 
-  static const char* MessageFor(DeoptimizeKind kind, bool reuse_code);
+  static const char* MessageFor(DeoptimizeKind kind);
 
   Handle<JSFunction> function() const;
   Handle<Code> compiled_code() const;
   DeoptimizeKind deopt_kind() const { return deopt_kind_; }
 
-  bool should_reuse_code() const;
-
   static Deoptimizer* New(Address raw_function, DeoptimizeKind kind,
                           unsigned deopt_exit_index, Address from,
                           int fp_to_sp_delta, Isolate* isolate);
diff --git a/src/diagnostics/disassembler.cc b/src/diagnostics/disassembler.cc
index 81b58932267..55640459d71 100644
--- a/src/diagnostics/disassembler.cc
+++ b/src/diagnostics/disassembler.cc
@@ -278,7 +278,7 @@ static void PrintRelocInfo(std::ostringstream& out, Isolate* isolate,
     Address addr = relocinfo->target_address();
     DeoptimizeKind type;
     if (Deoptimizer::IsDeoptimizationEntry(isolate, addr, &type)) {
-      out << "    ;; " << Deoptimizer::MessageFor(type, false)
+      out << "    ;; " << Deoptimizer::MessageFor(type)
           << " deoptimization bailout";
     } else {
       out << "    ;; " << RelocInfo::RelocModeName(rmode);
diff --git a/src/diagnostics/perf-jit.cc b/src/diagnostics/perf-jit.cc
index 35b47e2b1cb..75fc8a1293d 100644
--- a/src/diagnostics/perf-jit.cc
+++ b/src/diagnostics/perf-jit.cc
@@ -215,7 +215,6 @@ void PerfJitLogger::LogRecordedBuffer(
   if (FLAG_perf_basic_prof_only_functions &&
       (abstract_code->kind() != CodeKind::INTERPRETED_FUNCTION &&
        abstract_code->kind() != CodeKind::TURBOFAN &&
-       abstract_code->kind() != CodeKind::TURBOPROP &&
        abstract_code->kind() != CodeKind::BASELINE)) {
     return;
   }
diff --git a/src/execution/frames.cc b/src/execution/frames.cc
index 04a9c613d6c..4452bd571dd 100644
--- a/src/execution/frames.cc
+++ b/src/execution/frames.cc
@@ -672,7 +672,6 @@ StackFrame::Type StackFrame::ComputeType(const StackFrameIteratorBase* iterator,
           }
           return BUILTIN;
         case CodeKind::TURBOFAN:
-        case CodeKind::TURBOPROP:
           return OPTIMIZED;
         case CodeKind::BASELINE:
           return Type::BASELINE;
diff --git a/src/execution/runtime-profiler.cc b/src/execution/runtime-profiler.cc
index a586d2d3b6c..4a3f62bba00 100644
--- a/src/execution/runtime-profiler.cc
+++ b/src/execution/runtime-profiler.cc
@@ -187,9 +187,6 @@ OptimizationReason RuntimeProfiler::ShouldOptimize(JSFunction function,
   if (function.ActiveTierIsTurbofan()) {
     return OptimizationReason::kDoNotOptimize;
   }
-  if (V8_UNLIKELY(FLAG_turboprop) && function.ActiveTierIsToptierTurboprop()) {
-    return OptimizationReason::kDoNotOptimize;
-  }
   const int ticks = function.feedback_vector().profiler_ticks();
   const int ticks_for_optimization =
       FLAG_ticks_before_optimization +
diff --git a/src/flags/flag-definitions.h b/src/flags/flag-definitions.h
index 323af0d3f9d..0eb54a669bc 100644
--- a/src/flags/flag-definitions.h
+++ b/src/flags/flag-definitions.h
@@ -519,7 +519,6 @@ DEFINE_WEAK_VALUE_IMPLICATION(future, write_protect_code_memory, false)
 DEFINE_BOOL_READONLY(dict_property_const_tracking,
                      V8_DICT_PROPERTY_CONST_TRACKING_BOOL,
                      "Use const tracking on dictionary properties")
-DEFINE_NEG_IMPLICATION(dict_property_const_tracking, turboprop)
 
 // Flags for jitless
 DEFINE_BOOL(jitless, V8_LITE_BOOL,
@@ -663,25 +662,6 @@ DEFINE_BOOL(trace_track_allocation_sites, false,
 DEFINE_BOOL(trace_migration, false, "trace object migration")
 DEFINE_BOOL(trace_generalization, false, "trace map generalization")
 
-// Flags for TurboProp.
-DEFINE_BOOL(turboprop, false, "enable experimental turboprop mid-tier compiler")
-DEFINE_BOOL(turboprop_mid_tier_reg_alloc, true,
-            "enable mid-tier register allocator for turboprop")
-DEFINE_BOOL(
-    turboprop_as_toptier, false,
-    "enable experimental turboprop compiler without further tierup to turbofan")
-DEFINE_IMPLICATION(turboprop_as_toptier, turboprop)
-DEFINE_WEAK_VALUE_IMPLICATION(turboprop, interrupt_budget, 115 * KB)
-DEFINE_UINT_READONLY(max_minimorphic_map_checks, 4,
-                     "max number of map checks to perform in minimorphic state")
-DEFINE_INT(turboprop_inline_scaling_factor, 4,
-           "scale factor for reduction in bytecode that can be inline for "
-           "TurboProp compared to TurboFan")
-// The scale factor determines the interrupt budget when tiering up from
-// Turboprop to TurboFan.
-DEFINE_INT(interrupt_budget_scale_factor_for_top_tier, 20,
-           "scale factor for profiler ticks when tiering up from midtier")
-
 // Flags for Sparkplug
 #undef FLAG
 #if ENABLE_SPARKPLUG
@@ -913,11 +893,6 @@ DEFINE_BOOL(
     stress_gc_during_compilation, false,
     "simulate GC/compiler thread race related to https://crbug.com/v8/8520")
 DEFINE_BOOL(turbo_fast_api_calls, false, "enable fast API calls from TurboFan")
-DEFINE_INT(reuse_opt_code_count, 0,
-           "don't discard optimized code for the specified number of deopts.")
-DEFINE_BOOL(turbo_dynamic_map_checks, false,
-            "use dynamic map checks when generating code for property accesses "
-            "if all handlers in an IC are the same for turboprop")
 DEFINE_BOOL(turbo_compress_translation_arrays, false,
             "compress translation arrays (experimental)")
 DEFINE_WEAK_IMPLICATION(future, turbo_inline_js_wasm_calls)
diff --git a/src/logging/code-events.h b/src/logging/code-events.h
index 59c7952bd63..2f252d62bcc 100644
--- a/src/logging/code-events.h
+++ b/src/logging/code-events.h
@@ -103,8 +103,7 @@ class CodeEventListener {
   virtual void CodeDisableOptEvent(Handle<AbstractCode> code,
                                    Handle<SharedFunctionInfo> shared) = 0;
   virtual void CodeDeoptEvent(Handle<Code> code, DeoptimizeKind kind,
-                              Address pc, int fp_to_sp_delta,
-                              bool reuse_code) = 0;
+                              Address pc, int fp_to_sp_delta) = 0;
   // These events can happen when 1. an assumption made by optimized code fails
   // or 2. a weakly embedded object dies.
   virtual void CodeDependencyChangeEvent(Handle<Code> code,
@@ -234,9 +233,9 @@ class CodeEventDispatcher : public CodeEventListener {
     });
   }
   void CodeDeoptEvent(Handle<Code> code, DeoptimizeKind kind, Address pc,
-                      int fp_to_sp_delta, bool reuse_code) override {
+                      int fp_to_sp_delta) override {
     DispatchEventToListeners([=](CodeEventListener* listener) {
-      listener->CodeDeoptEvent(code, kind, pc, fp_to_sp_delta, reuse_code);
+      listener->CodeDeoptEvent(code, kind, pc, fp_to_sp_delta);
     });
   }
   void CodeDependencyChangeEvent(Handle<Code> code,
diff --git a/src/logging/log.cc b/src/logging/log.cc
index 49eaffe1934..05ecbed7ae4 100644
--- a/src/logging/log.cc
+++ b/src/logging/log.cc
@@ -1540,11 +1540,10 @@ void Logger::ProcessDeoptEvent(Handle<Code> code, SourcePosition position,
 }
 
 void Logger::CodeDeoptEvent(Handle<Code> code, DeoptimizeKind kind, Address pc,
-                            int fp_to_sp_delta, bool reuse_code) {
+                            int fp_to_sp_delta) {
   if (!is_logging() || !FLAG_log_deopt) return;
   Deoptimizer::DeoptInfo info = Deoptimizer::GetDeoptInfo(*code, pc);
-  ProcessDeoptEvent(code, info.position,
-                    Deoptimizer::MessageFor(kind, reuse_code),
+  ProcessDeoptEvent(code, info.position, Deoptimizer::MessageFor(kind),
                     DeoptimizeReasonToString(info.deopt_reason));
 }
 
@@ -2154,8 +2153,6 @@ void ExistingCodeLogger::LogCodeObject(Object object) {
     case CodeKind::INTERPRETED_FUNCTION:
     case CodeKind::TURBOFAN:
     case CodeKind::BASELINE:
-    case CodeKind::TURBOPROP:
-      return;  // We log this later using LogCompiledFunctions.
     case CodeKind::BYTECODE_HANDLER:
       return;  // We log it later by walking the dispatch table.
     case CodeKind::FOR_TESTING:
diff --git a/src/logging/log.h b/src/logging/log.h
index b4bd644f36a..8bb0c5f931c 100644
--- a/src/logging/log.h
+++ b/src/logging/log.h
@@ -223,7 +223,7 @@ class Logger : public CodeEventListener {
   void CodeDisableOptEvent(Handle<AbstractCode> code,
                            Handle<SharedFunctionInfo> shared) override;
   void CodeDeoptEvent(Handle<Code> code, DeoptimizeKind kind, Address pc,
-                      int fp_to_sp_delta, bool reuse_code) override;
+                      int fp_to_sp_delta) override;
   void CodeDependencyChangeEvent(Handle<Code> code,
                                  Handle<SharedFunctionInfo> sfi,
                                  const char* reason) override;
@@ -452,7 +452,7 @@ class V8_EXPORT_PRIVATE CodeEventLogger : public CodeEventListener {
   void NativeContextMoveEvent(Address from, Address to) override {}
   void CodeMovingGCEvent() override {}
   void CodeDeoptEvent(Handle<Code> code, DeoptimizeKind kind, Address pc,
-                      int fp_to_sp_delta, bool reuse_code) override {}
+                      int fp_to_sp_delta) override {}
   void CodeDependencyChangeEvent(Handle<Code> code,
                                  Handle<SharedFunctionInfo> sfi,
                                  const char* reason) override {}
@@ -521,7 +521,7 @@ class ExternalCodeEventListener : public CodeEventListener {
                            Handle<SharedFunctionInfo> shared) override {}
   void CodeMovingGCEvent() override {}
   void CodeDeoptEvent(Handle<Code> code, DeoptimizeKind kind, Address pc,
-                      int fp_to_sp_delta, bool reuse_code) override {}
+                      int fp_to_sp_delta) override {}
   void CodeDependencyChangeEvent(Handle<Code> code,
                                  Handle<SharedFunctionInfo> sfi,
                                  const char* reason) override {}
diff --git a/src/objects/code-inl.h b/src/objects/code-inl.h
index fc5dfad84fc..3d5dfa80d6a 100644
--- a/src/objects/code-inl.h
+++ b/src/objects/code-inl.h
@@ -727,26 +727,6 @@ void Code::set_marked_for_deoptimization(bool flag) {
   code_data_container(kAcquireLoad).set_marked_for_deoptimization(flag);
 }
 
-int Code::deoptimization_count() const {
-  DCHECK(CodeKindCanDeoptimize(kind()));
-  int32_t flags =
-      code_data_container(kAcquireLoad).kind_specific_flags(kRelaxedLoad);
-  int count = DeoptCountField::decode(flags);
-  DCHECK_GE(count, 0);
-  return count;
-}
-
-void Code::increment_deoptimization_count() {
-  DCHECK(CodeKindCanDeoptimize(kind()));
-  CodeDataContainer container = code_data_container(kAcquireLoad);
-  int32_t flags = container.kind_specific_flags(kRelaxedLoad);
-  int32_t count = DeoptCountField::decode(flags);
-  DCHECK_GE(count, 0);
-  CHECK_LE(count + 1, DeoptCountField::kMax);
-  int32_t updated = DeoptCountField::update(flags, count + 1);
-  container.set_kind_specific_flags(updated, kRelaxedStore);
-}
-
 bool Code::embedded_objects_cleared() const {
   DCHECK(CodeKindIsOptimizedJSFunction(kind()));
   int32_t flags =
diff --git a/src/objects/code-kind.cc b/src/objects/code-kind.cc
index 5c4ab5d2991..84b7436ef1c 100644
--- a/src/objects/code-kind.cc
+++ b/src/objects/code-kind.cc
@@ -24,8 +24,6 @@ const char* CodeKindToMarker(CodeKind kind) {
       return "~";
     case CodeKind::BASELINE:
       return "^";
-    case CodeKind::TURBOPROP:
-      return "+";
     case CodeKind::TURBOFAN:
       return "*";
     default:
diff --git a/src/objects/code-kind.h b/src/objects/code-kind.h
index 888e04c42b5..f6884f992ab 100644
--- a/src/objects/code-kind.h
+++ b/src/objects/code-kind.h
@@ -15,20 +15,19 @@ namespace internal {
 // The order of INTERPRETED_FUNCTION to TURBOFAN is important. We use it to
 // check the relative ordering of the tiers when fetching / installing optimized
 // code.
-#define CODE_KIND_LIST(V)       \
-  V(BYTECODE_HANDLER)           \
-  V(FOR_TESTING)                \
-  V(BUILTIN)                    \
-  V(REGEXP)                     \
-  V(WASM_FUNCTION)              \
-  V(WASM_TO_CAPI_FUNCTION)      \
-  V(WASM_TO_JS_FUNCTION)        \
-  V(JS_TO_WASM_FUNCTION)        \
-  V(JS_TO_JS_FUNCTION)          \
-  V(C_WASM_ENTRY)               \
-  V(INTERPRETED_FUNCTION)       \
-  V(BASELINE)                   \
-  V(TURBOPROP)                  \
+#define CODE_KIND_LIST(V)  \
+  V(BYTECODE_HANDLER)      \
+  V(FOR_TESTING)           \
+  V(BUILTIN)               \
+  V(REGEXP)                \
+  V(WASM_FUNCTION)         \
+  V(WASM_TO_CAPI_FUNCTION) \
+  V(WASM_TO_JS_FUNCTION)   \
+  V(JS_TO_WASM_FUNCTION)   \
+  V(JS_TO_JS_FUNCTION)     \
+  V(C_WASM_ENTRY)          \
+  V(INTERPRETED_FUNCTION)  \
+  V(BASELINE)              \
   V(TURBOFAN)
 
 enum class CodeKind {
@@ -36,11 +35,8 @@ enum class CodeKind {
   CODE_KIND_LIST(DEFINE_CODE_KIND_ENUM)
 #undef DEFINE_CODE_KIND_ENUM
 };
-STATIC_ASSERT(CodeKind::INTERPRETED_FUNCTION < CodeKind::TURBOPROP &&
-              CodeKind::INTERPRETED_FUNCTION < CodeKind::BASELINE);
-STATIC_ASSERT(CodeKind::BASELINE < CodeKind::TURBOPROP);
-STATIC_ASSERT(CodeKind::BASELINE < CodeKind::TURBOFAN &&
-              CodeKind::TURBOPROP < CodeKind::TURBOFAN);
+STATIC_ASSERT(CodeKind::INTERPRETED_FUNCTION < CodeKind::BASELINE);
+STATIC_ASSERT(CodeKind::BASELINE < CodeKind::TURBOFAN);
 
 #define V(...) +1
 static constexpr int kCodeKindCount = CODE_KIND_LIST(V);
@@ -66,9 +62,7 @@ inline constexpr bool CodeKindIsUnoptimizedJSFunction(CodeKind kind) {
 }
 
 inline constexpr bool CodeKindIsOptimizedJSFunction(CodeKind kind) {
-  STATIC_ASSERT(static_cast<int>(CodeKind::TURBOPROP) + 1 ==
-                static_cast<int>(CodeKind::TURBOFAN));
-  return base::IsInRange(kind, CodeKind::TURBOPROP, CodeKind::TURBOFAN);
+  return kind == CodeKind::TURBOFAN;
 }
 
 inline constexpr bool CodeKindIsJSFunction(CodeKind kind) {
@@ -85,47 +79,28 @@ inline constexpr bool CodeKindCanDeoptimize(CodeKind kind) {
 }
 
 inline constexpr bool CodeKindCanOSR(CodeKind kind) {
-  return kind == CodeKind::TURBOFAN || kind == CodeKind::TURBOPROP;
-}
-
-inline bool CodeKindIsOptimizedAndCanTierUp(CodeKind kind) {
-  return !FLAG_turboprop_as_toptier && kind == CodeKind::TURBOPROP;
+  return kind == CodeKind::TURBOFAN;
 }
 
 inline constexpr bool CodeKindCanTierUp(CodeKind kind) {
-  return CodeKindIsUnoptimizedJSFunction(kind) ||
-         CodeKindIsOptimizedAndCanTierUp(kind);
+  return CodeKindIsUnoptimizedJSFunction(kind);
 }
 
 // The optimization marker field on the feedback vector has a dual purpose of
 // controlling the tier-up workflow, and caching the produced code object for
 // access from multiple closures.
 inline constexpr bool CodeKindIsStoredInOptimizedCodeCache(CodeKind kind) {
-  return kind == CodeKind::TURBOFAN || kind == CodeKind::TURBOPROP;
+  return kind == CodeKind::TURBOFAN;
 }
 
 inline OptimizationTier GetTierForCodeKind(CodeKind kind) {
   if (kind == CodeKind::TURBOFAN) return OptimizationTier::kTopTier;
-  if (kind == CodeKind::TURBOPROP) {
-    return FLAG_turboprop_as_toptier ? OptimizationTier::kTopTier
-                                     : OptimizationTier::kMidTier;
-  }
   return OptimizationTier::kNone;
 }
 
-inline CodeKind CodeKindForTopTier() {
-  if (V8_UNLIKELY(FLAG_turboprop_as_toptier)) {
-    return CodeKind::TURBOPROP;
-  }
-  return CodeKind::TURBOFAN;
-}
+inline CodeKind CodeKindForTopTier() { return CodeKind::TURBOFAN; }
 
-inline CodeKind CodeKindForOSR() {
-  if (V8_UNLIKELY(FLAG_turboprop)) {
-    return CodeKind::TURBOPROP;
-  }
-  return CodeKind::TURBOFAN;
-}
+inline CodeKind CodeKindForOSR() { return CodeKind::TURBOFAN; }
 
 // The dedicated CodeKindFlag enum represents all code kinds in a format
 // suitable for bit sets.
@@ -148,9 +123,9 @@ DEFINE_OPERATORS_FOR_FLAGS(CodeKinds)
 
 static constexpr CodeKinds kJSFunctionCodeKindsMask{
     CodeKindFlag::INTERPRETED_FUNCTION | CodeKindFlag::TURBOFAN |
-    CodeKindFlag::TURBOPROP | CodeKindFlag::BASELINE};
+    CodeKindFlag::BASELINE};
 static constexpr CodeKinds kOptimizedJSFunctionCodeKindsMask{
-    CodeKindFlag::TURBOFAN | CodeKindFlag::TURBOPROP};
+    CodeKindFlag::TURBOFAN};
 
 }  // namespace internal
 }  // namespace v8
diff --git a/src/objects/code.h b/src/objects/code.h
index 545667b1305..53577318b44 100644
--- a/src/objects/code.h
+++ b/src/objects/code.h
@@ -460,13 +460,6 @@ class Code : public HeapObject {
   inline bool marked_for_deoptimization() const;
   inline void set_marked_for_deoptimization(bool flag);
 
-  // [deoptimization_count]: If CodeKindCanDeoptimize(kind). In turboprop we
-  // retain the deoptimized code on soft deopts for a certain number of soft
-  // deopts. This field keeps track of the number of deoptimizations we have
-  // seen so far.
-  inline int deoptimization_count() const;
-  inline void increment_deoptimization_count();
-
   // [embedded_objects_cleared]: If CodeKindIsOptimizedJSFunction(kind), tells
   // whether the embedded objects in the code marked for deoptimization were
   // cleared. Note that embedded_objects_cleared() implies
@@ -705,11 +698,10 @@ class Code : public HeapObject {
   V(DeoptAlreadyCountedField, bool, 1, _)         \
   V(CanHaveWeakObjectsField, bool, 1, _)          \
   V(IsPromiseRejectionField, bool, 1, _)          \
-  V(IsExceptionCaughtField, bool, 1, _)           \
-  V(DeoptCountField, int, 4, _)
+  V(IsExceptionCaughtField, bool, 1, _)
   DEFINE_BIT_FIELDS(CODE_KIND_SPECIFIC_FLAGS_BIT_FIELDS)
 #undef CODE_KIND_SPECIFIC_FLAGS_BIT_FIELDS
-  STATIC_ASSERT(CODE_KIND_SPECIFIC_FLAGS_BIT_FIELDS_Ranges::kBitsCount == 10);
+  STATIC_ASSERT(CODE_KIND_SPECIFIC_FLAGS_BIT_FIELDS_Ranges::kBitsCount == 6);
   STATIC_ASSERT(CODE_KIND_SPECIFIC_FLAGS_BIT_FIELDS_Ranges::kBitsCount <=
                 FIELD_SIZE(CodeDataContainer::kKindSpecificFlagsOffset) *
                     kBitsPerByte);
diff --git a/src/objects/feedback-vector.cc b/src/objects/feedback-vector.cc
index 925c583ce13..29ff7f0cbc0 100644
--- a/src/objects/feedback-vector.cc
+++ b/src/objects/feedback-vector.cc
@@ -393,12 +393,9 @@ void FeedbackVector::SetOptimizedCode(Handle<FeedbackVector> vector,
                                       Handle<CodeT> code,
                                       FeedbackCell feedback_cell) {
   DCHECK(CodeKindIsOptimizedJSFunction(code->kind()));
-  // We should set optimized code only when there is no valid optimized code or
-  // we are tiering up.
+  // We should set optimized code only when there is no valid optimized code.
   DCHECK(!vector->has_optimized_code() ||
          vector->optimized_code().marked_for_deoptimization() ||
-         (vector->optimized_code().kind() == CodeKind::TURBOPROP &&
-          code->kind() == CodeKind::TURBOFAN) ||
          FLAG_stress_concurrent_inlining_attach_code);
   // TODO(mythria): We could see a CompileOptimized marker here either from
   // tests that use %OptimizeFunctionOnNextCall, --always-opt or because we
@@ -411,32 +408,13 @@ void FeedbackVector::SetOptimizedCode(Handle<FeedbackVector> vector,
   state = OptimizationTierBits::update(state, GetTierForCodeKind(code->kind()));
   state = OptimizationMarkerBits::update(state, OptimizationMarker::kNone);
   vector->set_flags(state);
-  // With FLAG_turboprop, we would have an interrupt budget necessary for
-  // tiering up to Turboprop code. Once we install turboprop code, set it to a
-  // higher value as required for tiering up from Turboprop to TurboFan.
-  if (FLAG_turboprop) {
-    FeedbackVector::SetInterruptBudget(feedback_cell);
-  }
 }
 
 // static
 void FeedbackVector::SetInterruptBudget(FeedbackCell feedback_cell) {
   DCHECK(feedback_cell.value().IsFeedbackVector());
-  FeedbackVector vector = FeedbackVector::cast(feedback_cell.value());
-  // Set the interrupt budget as required for tiering up to next level. Without
-  // Turboprop, this is used only to tier up to TurboFan and hence always set to
-  // FLAG_interrupt_budget. With Turboprop, we use this budget to both tier up
-  // to Turboprop and TurboFan. When there is no optimized code, set it to
-  // FLAG_interrupt_budget required for tiering up to Turboprop. When there is
-  // optimized code, set it to a higher value required for tiering up from
-  // Turboprop to TurboFan.
-  if (FLAG_turboprop && vector.has_optimized_code()) {
-    feedback_cell.set_interrupt_budget(
-        FLAG_interrupt_budget *
-        FLAG_interrupt_budget_scale_factor_for_top_tier);
-  } else {
-    feedback_cell.set_interrupt_budget(FLAG_interrupt_budget);
-  }
+  // Set the interrupt budget as required for tiering up to next level.
+  feedback_cell.set_interrupt_budget(FLAG_interrupt_budget);
 }
 
 void FeedbackVector::ClearOptimizedCode(FeedbackCell feedback_cell) {
@@ -461,11 +439,6 @@ void FeedbackVector::ClearOptimizationTier(FeedbackCell feedback_cell) {
   int32_t state = flags();
   state = OptimizationTierBits::update(state, OptimizationTier::kNone);
   set_flags(state);
-  // We are discarding the optimized code, adjust the interrupt budget
-  // so we have the correct budget required for the tier up.
-  if (FLAG_turboprop) {
-    FeedbackVector::SetInterruptBudget(feedback_cell);
-  }
 }
 
 void FeedbackVector::InitializeOptimizationState() {
diff --git a/src/objects/js-function-inl.h b/src/objects/js-function-inl.h
index 74f3dbd0dc7..2154cef8835 100644
--- a/src/objects/js-function-inl.h
+++ b/src/objects/js-function-inl.h
@@ -88,8 +88,7 @@ void JSFunction::MarkForOptimization(ConcurrencyMode mode) {
     mode = ConcurrencyMode::kNotConcurrent;
   }
 
-  DCHECK(!is_compiled() || ActiveTierIsIgnition() ||
-         ActiveTierIsMidtierTurboprop() || ActiveTierIsBaseline());
+  DCHECK(!is_compiled() || ActiveTierIsIgnition() || ActiveTierIsBaseline());
   DCHECK(!ActiveTierIsTurbofan());
   DCHECK(shared().IsInterpreted());
   DCHECK(shared().allows_lazy_compilation() ||
diff --git a/src/objects/js-function.cc b/src/objects/js-function.cc
index 757b32e82da..5175eac85ed 100644
--- a/src/objects/js-function.cc
+++ b/src/objects/js-function.cc
@@ -87,9 +87,6 @@ V8_WARN_UNUSED_RESULT bool HighestTierOf(CodeKinds kinds,
   if ((kinds & CodeKindFlag::TURBOFAN) != 0) {
     *highest_tier = CodeKind::TURBOFAN;
     return true;
-  } else if ((kinds & CodeKindFlag::TURBOPROP) != 0) {
-    *highest_tier = CodeKind::TURBOPROP;
-    return true;
   } else if ((kinds & CodeKindFlag::BASELINE) != 0) {
     *highest_tier = CodeKind::BASELINE;
     return true;
@@ -120,7 +117,6 @@ base::Optional<CodeKind> JSFunction::GetActiveTier() const {
 #ifdef DEBUG
   CHECK(highest_tier == CodeKind::TURBOFAN ||
         highest_tier == CodeKind::BASELINE ||
-        highest_tier == CodeKind::TURBOPROP ||
         highest_tier == CodeKind::INTERPRETED_FUNCTION);
 
   if (highest_tier == CodeKind::INTERPRETED_FUNCTION) {
@@ -147,24 +143,7 @@ bool JSFunction::ActiveTierIsBaseline() const {
   return GetActiveTier() == CodeKind::BASELINE;
 }
 
-bool JSFunction::ActiveTierIsToptierTurboprop() const {
-  return FLAG_turboprop_as_toptier && GetActiveTier() == CodeKind::TURBOPROP;
-}
-
-bool JSFunction::ActiveTierIsMidtierTurboprop() const {
-  return FLAG_turboprop && !FLAG_turboprop_as_toptier &&
-         GetActiveTier() == CodeKind::TURBOPROP;
-}
-
-CodeKind JSFunction::NextTier() const {
-  if (V8_UNLIKELY(FLAG_turboprop) && ActiveTierIsMidtierTurboprop()) {
-    return CodeKind::TURBOFAN;
-  } else if (V8_UNLIKELY(FLAG_turboprop)) {
-    DCHECK(ActiveTierIsIgnition() || ActiveTierIsBaseline());
-    return CodeKind::TURBOPROP;
-  }
-  return CodeKind::TURBOFAN;
-}
+CodeKind JSFunction::NextTier() const { return CodeKind::TURBOFAN; }
 
 bool JSFunction::CanDiscardCompiled() const {
   // Essentially, what we are asking here is, has this function been compiled
diff --git a/src/objects/js-function.h b/src/objects/js-function.h
index 467bb03b85f..9e7299a761f 100644
--- a/src/objects/js-function.h
+++ b/src/objects/js-function.h
@@ -129,8 +129,6 @@ class JSFunction
   V8_EXPORT_PRIVATE bool ActiveTierIsIgnition() const;
   bool ActiveTierIsTurbofan() const;
   bool ActiveTierIsBaseline() const;
-  bool ActiveTierIsMidtierTurboprop() const;
-  bool ActiveTierIsToptierTurboprop() const;
 
   CodeKind NextTier() const;
 
diff --git a/src/objects/shared-function-info-inl.h b/src/objects/shared-function-info-inl.h
index f37cc6904ea..723fd9e133e 100644
--- a/src/objects/shared-function-info-inl.h
+++ b/src/objects/shared-function-info-inl.h
@@ -224,7 +224,7 @@ bool SharedFunctionInfo::AreSourcePositionsAvailable(IsolateT* isolate) const {
 
 template <typename IsolateT>
 SharedFunctionInfo::Inlineability SharedFunctionInfo::GetInlineability(
-    IsolateT* isolate, bool is_turboprop) const {
+    IsolateT* isolate) const {
   if (!script().IsScript()) return kHasNoScript;
 
   if (GetIsolate()->is_precise_binary_code_coverage() &&
@@ -243,11 +243,7 @@ SharedFunctionInfo::Inlineability SharedFunctionInfo::GetInlineability(
   // inline.
   if (!HasBytecodeArray()) return kHasNoBytecode;
 
-  int max_inlined_size = FLAG_max_inlined_bytecode_size;
-  if (is_turboprop) {
-    max_inlined_size = max_inlined_size / FLAG_turboprop_inline_scaling_factor;
-  }
-  if (GetBytecodeArray(isolate).length() > max_inlined_size) {
+  if (GetBytecodeArray(isolate).length() > FLAG_max_inlined_bytecode_size) {
     return kExceedsBytecodeLimit;
   }
 
diff --git a/src/objects/shared-function-info.h b/src/objects/shared-function-info.h
index f7c27455e12..230ce244e54 100644
--- a/src/objects/shared-function-info.h
+++ b/src/objects/shared-function-info.h
@@ -577,7 +577,7 @@ class SharedFunctionInfo
   };
   // Returns the first value that applies (see enum definition for the order).
   template <typename IsolateT>
-  Inlineability GetInlineability(IsolateT* isolate, bool is_turboprop) const;
+  Inlineability GetInlineability(IsolateT* isolate) const;
 
   // Source size of this function.
   int SourceSize();
diff --git a/src/profiler/profiler-listener.cc b/src/profiler/profiler-listener.cc
index af8581a8acc..90c6963afe4 100644
--- a/src/profiler/profiler-listener.cc
+++ b/src/profiler/profiler-listener.cc
@@ -321,10 +321,7 @@ void ProfilerListener::CodeDisableOptEvent(Handle<AbstractCode> code,
 }
 
 void ProfilerListener::CodeDeoptEvent(Handle<Code> code, DeoptimizeKind kind,
-                                      Address pc, int fp_to_sp_delta,
-                                      bool reuse_code) {
-  // When reuse_code is true it is just a bailout and not an actual deopt.
-  if (reuse_code) return;
+                                      Address pc, int fp_to_sp_delta) {
   CodeEventsContainer evt_rec(CodeEventRecord::Type::kCodeDeopt);
   CodeDeoptEventRecord* rec = &evt_rec.CodeDeoptEventRecord_;
   Deoptimizer::DeoptInfo info = Deoptimizer::GetDeoptInfo(*code, pc);
diff --git a/src/profiler/profiler-listener.h b/src/profiler/profiler-listener.h
index a06654820f8..5ac86eb4931 100644
--- a/src/profiler/profiler-listener.h
+++ b/src/profiler/profiler-listener.h
@@ -63,7 +63,7 @@ class V8_EXPORT_PRIVATE ProfilerListener : public CodeEventListener,
   void CodeDisableOptEvent(Handle<AbstractCode> code,
                            Handle<SharedFunctionInfo> shared) override;
   void CodeDeoptEvent(Handle<Code> code, DeoptimizeKind kind, Address pc,
-                      int fp_to_sp_delta, bool reuse_code) override;
+                      int fp_to_sp_delta) override;
   void CodeDependencyChangeEvent(Handle<Code> code,
                                  Handle<SharedFunctionInfo> sfi,
                                  const char* reason) override {}
diff --git a/src/runtime/runtime-compiler.cc b/src/runtime/runtime-compiler.cc
index 664c5310717..efb993c2acc 100644
--- a/src/runtime/runtime-compiler.cc
+++ b/src/runtime/runtime-compiler.cc
@@ -193,7 +193,6 @@ RUNTIME_FUNCTION(Runtime_NotifyDeoptimized) {
   // code object from deoptimizer.
   Handle<Code> optimized_code = deoptimizer->compiled_code();
   DeoptimizeKind type = deoptimizer->deopt_kind();
-  bool should_reuse_code = deoptimizer->should_reuse_code();
 
   // TODO(turbofan): We currently need the native context to materialize
   // the arguments object, but only to get to its map.
@@ -208,11 +207,6 @@ RUNTIME_FUNCTION(Runtime_NotifyDeoptimized) {
   JavaScriptFrame* top_frame = top_it.frame();
   isolate->set_context(Context::cast(top_frame->context()));
 
-  if (should_reuse_code) {
-    optimized_code->increment_deoptimization_count();
-    return ReadOnlyRoots(isolate).undefined_value();
-  }
-
   // Invalidate the underlying optimized code on eager and soft deopts.
   if (type == DeoptimizeKind::kEager || type == DeoptimizeKind::kSoft) {
     Deoptimizer::DeoptimizeFunction(*function, *optimized_code);
diff --git a/src/runtime/runtime-test.cc b/src/runtime/runtime-test.cc
index 469a7d1bb4a..4e372b95f24 100644
--- a/src/runtime/runtime-test.cc
+++ b/src/runtime/runtime-test.cc
@@ -206,25 +206,6 @@ RUNTIME_FUNCTION(Runtime_IsConcurrentRecompilationSupported) {
       isolate->concurrent_recompilation_enabled());
 }
 
-RUNTIME_FUNCTION(Runtime_DynamicCheckMapsEnabled) {
-  SealHandleScope shs(isolate);
-  DCHECK_EQ(0, args.length());
-  return isolate->heap()->ToBoolean(FLAG_turbo_dynamic_map_checks);
-}
-
-RUNTIME_FUNCTION(Runtime_IsTopTierTurboprop) {
-  SealHandleScope shs(isolate);
-  DCHECK_EQ(0, args.length());
-  return isolate->heap()->ToBoolean(FLAG_turboprop_as_toptier);
-}
-
-RUNTIME_FUNCTION(Runtime_IsMidTierTurboprop) {
-  SealHandleScope shs(isolate);
-  DCHECK_EQ(0, args.length());
-  return isolate->heap()->ToBoolean(FLAG_turboprop &&
-                                    !FLAG_turboprop_as_toptier);
-}
-
 RUNTIME_FUNCTION(Runtime_IsAtomicsWaitAllowed) {
   SealHandleScope shs(isolate);
   DCHECK_EQ(0, args.length());
@@ -396,12 +377,6 @@ RUNTIME_FUNCTION(Runtime_OptimizeFunctionOnNextCall) {
   return OptimizeFunctionOnNextCall(args, isolate, TierupKind::kTierupBytecode);
 }
 
-RUNTIME_FUNCTION(Runtime_TierupFunctionOnNextCall) {
-  HandleScope scope(isolate);
-  return OptimizeFunctionOnNextCall(args, isolate,
-                                    TierupKind::kTierupBytecodeOrMidTier);
-}
-
 RUNTIME_FUNCTION(Runtime_EnsureFeedbackVectorForFunction) {
   HandleScope scope(isolate);
   DCHECK_EQ(1, args.length());
@@ -1442,7 +1417,7 @@ RUNTIME_FUNCTION(Runtime_EnableCodeLoggingForTesting) {
     void CodeDisableOptEvent(Handle<AbstractCode> code,
                              Handle<SharedFunctionInfo> shared) final {}
     void CodeDeoptEvent(Handle<Code> code, DeoptimizeKind kind, Address pc,
-                        int fp_to_sp_delta, bool reuse_code) final {}
+                        int fp_to_sp_delta) final {}
     void CodeDependencyChangeEvent(Handle<Code> code,
                                    Handle<SharedFunctionInfo> shared,
                                    const char* reason) final {}
diff --git a/src/runtime/runtime.h b/src/runtime/runtime.h
index b1b7603957e..90f02a9f03e 100644
--- a/src/runtime/runtime.h
+++ b/src/runtime/runtime.h
@@ -478,7 +478,6 @@ namespace internal {
   F(DeoptimizeFunction, 1, 1)                 \
   F(DisallowCodegenFromStrings, 1, 1)         \
   F(DisassembleFunction, 1, 1)                \
-  F(DynamicCheckMapsEnabled, 0, 1)            \
   F(EnableCodeLoggingForTesting, 0, 1)        \
   F(EnsureFeedbackVectorForFunction, 1, 1)    \
   F(DisableOptimizationFinalization, 0, 1)    \
@@ -522,8 +521,6 @@ namespace internal {
   F(IsConcatSpreadableProtector, 0, 1)        \
   F(IsConcurrentRecompilationSupported, 0, 1) \
   F(IsDictPropertyConstTrackingEnabled, 0, 1) \
-  F(IsMidTierTurboprop, 0, 1)                 \
-  F(IsTopTierTurboprop, 0, 1)                 \
   F(MapIteratorProtector, 0, 1)               \
   F(NeverOptimizeFunction, 1, 1)              \
   F(NewRegExpWithBacktrackLimit, 3, 1)        \
@@ -551,7 +548,6 @@ namespace internal {
   F(StringIteratorProtector, 0, 1)            \
   F(SystemBreak, 0, 1)                        \
   F(TakeHeapSnapshot, -1, 1)                  \
-  F(TierupFunctionOnNextCall, -1, 1)          \
   F(TraceEnter, 0, 1)                         \
   F(TraceExit, 1, 1)                          \
   F(TurbofanStaticAssert, 1, 1)               \
diff --git a/test/cctest/cctest.status b/test/cctest/cctest.status
index 6e90b823348..561463a98a2 100644
--- a/test/cctest/cctest.status
+++ b/test/cctest/cctest.status
@@ -717,19 +717,6 @@
   'test-cpu-profiler/MultipleIsolates': [PASS, ['arch == arm64 and system == macos and simulator_run', SKIP]],
 }], # variant == jitless
 
-##############################################################################
-['variant == turboprop or variant == turboprop_as_toptier', {
-  # Require inlining.
-  'test-cpu-profiler/DeoptAtFirstLevelInlinedSource': [SKIP],
-  'test-cpu-profiler/DeoptAtSecondLevelInlinedSource': [SKIP],
-  'test-cpu-profiler/DeoptUntrackedFunction': [SKIP],
-  # Turboprop doesn't use call feedback and hence doesn't inline even if
-  # the inlining flag is explicitly set.
-  'test-cpu-profiler/DetailedSourcePositionAPI_Inlining': [SKIP],
-  'test-calls-with-arraylike-or-spread/*': [SKIP],
-  'test-js-to-wasm/*': [SKIP],
-}],  # variant == turboprop or variant == turboprop_as_toptier
-
 ##############################################################################
 ['no_i18n == True', {
   'test-regexp/UnicodePropertyEscapeCodeSize': [SKIP],
diff --git a/test/cctest/heap/test-heap.cc b/test/cctest/heap/test-heap.cc
index 651e0c5e49e..503052e9f05 100644
--- a/test/cctest/heap/test-heap.cc
+++ b/test/cctest/heap/test-heap.cc
@@ -1270,65 +1270,6 @@ UNINITIALIZED_TEST(Regress10843) {
   isolate->Dispose();
 }
 
-// Tests that spill slots from optimized code don't have weak pointers.
-TEST(Regress10774) {
-  if (FLAG_single_generation) return;
-  i::FLAG_allow_natives_syntax = true;
-  i::FLAG_turboprop = true;
-  i::FLAG_turbo_dynamic_map_checks = true;
-#ifdef VERIFY_HEAP
-  i::FLAG_verify_heap = true;
-#endif
-
-  ManualGCScope manual_gc_scope;
-  CcTest::InitializeVM();
-  v8::Isolate* isolate = CcTest::isolate();
-  Isolate* i_isolate = CcTest::i_isolate();
-  Factory* factory = i_isolate->factory();
-  Heap* heap = i_isolate->heap();
-
-  {
-    v8::HandleScope scope(isolate);
-    // We want to generate optimized code with dynamic map check operator that
-    // migrates deprecated maps. To force this, we want the IC state to be
-    // monomorphic and the map in the feedback should be a migration target.
-    const char* source =
-        "function f(o) {"
-        "  return o.b;"
-        "}"
-        "var o = {a:10, b:20};"
-        "var o1 = {a:10, b:20};"
-        "var o2 = {a:10, b:20};"
-        "%PrepareFunctionForOptimization(f);"
-        "f(o);"
-        "o1.b = 10.23;"  // Deprecate O's map.
-        "f(o1);"         // Install new map in IC
-        "f(o);"          // Mark o's map as migration target
-        "%OptimizeFunctionOnNextCall(f);"
-        "f(o);";
-    CompileRun(source);
-
-    Handle<String> foo_name = factory->InternalizeUtf8String("f");
-    Handle<Object> func_value =
-        Object::GetProperty(i_isolate, i_isolate->global_object(), foo_name)
-            .ToHandleChecked();
-    CHECK(func_value->IsJSFunction());
-    Handle<JSFunction> fun = Handle<JSFunction>::cast(func_value);
-
-    Handle<String> obj_name = factory->InternalizeUtf8String("o2");
-    Handle<Object> obj_value =
-        Object::GetProperty(i_isolate, i_isolate->global_object(), obj_name)
-            .ToHandleChecked();
-
-    heap::SimulateFullSpace(heap->new_space());
-
-    Handle<JSObject> global(i_isolate->context().global_object(), i_isolate);
-    // O2 still has the deprecated map and the optimized code should migrate O2
-    // successfully. This shouldn't crash.
-    Execution::Call(i_isolate, fun, global, 1, &obj_value).ToHandleChecked();
-  }
-}
-
 #ifndef V8_LITE_MODE
 
 TEST(TestOptimizeAfterBytecodeFlushingCandidate) {
diff --git a/test/cctest/test-cpu-profiler.cc b/test/cctest/test-cpu-profiler.cc
index 64a13aa9721..ed8dc97e234 100644
--- a/test/cctest/test-cpu-profiler.cc
+++ b/test/cctest/test-cpu-profiler.cc
@@ -4383,7 +4383,6 @@ TEST(FastApiCPUProfiler) {
 #if !defined(V8_LITE_MODE) && !defined(USE_SIMULATOR)
   // None of the following configurations include JSCallReducer.
   if (i::FLAG_jitless) return;
-  if (i::FLAG_turboprop) return;
 
   FLAG_SCOPE(opt);
   FLAG_SCOPE(turbo_fast_api_calls);
diff --git a/test/cctest/test-feedback-vector.cc b/test/cctest/test-feedback-vector.cc
index 717901a47d4..f010d948bc9 100644
--- a/test/cctest/test-feedback-vector.cc
+++ b/test/cctest/test-feedback-vector.cc
@@ -432,7 +432,6 @@ TEST(VectorCallSpeculationModeAndFeedbackContent) {
   if (!i::FLAG_opt) return;
   if (i::FLAG_always_opt) return;
   if (i::FLAG_jitless) return;
-  if (i::FLAG_turboprop) return;
   FLAG_allow_natives_syntax = true;
 
   CcTest::InitializeVM();
diff --git a/test/debugger/debugger.status b/test/debugger/debugger.status
index 3140b5365f1..d4803e0f087 100644
--- a/test/debugger/debugger.status
+++ b/test/debugger/debugger.status
@@ -135,13 +135,6 @@
   'regress/regress-crbug-1032042': [SKIP],
 }],  # not has_webassembly or variant == jitless
 
-##############################################################################
-['variant == turboprop or variant == turboprop_as_toptier', {
-  # Deopts differently than TurboFan.
-  'debug/debug-optimize': [SKIP],
-  'debug/debug-compile-optimized': [SKIP],
-}],  # variant == turboprop or variant == turboprop_as_toptier
-
 ##############################################################################
 # Tests requiring Sparkplug.
 ['arch not in (x64, arm64, ia32, arm, mips64el, mipsel, loong64)', {
diff --git a/test/inspector/inspector.status b/test/inspector/inspector.status
index c74a09a3dee..792d49f084e 100644
--- a/test/inspector/inspector.status
+++ b/test/inspector/inspector.status
@@ -515,10 +515,9 @@
 }], # third_party_heap
 
 ##############################################################################
-['variant == turboprop or variant == turboprop_as_toptier or variant == future or (tsan and not concurrent_marking)', {
-
+['tsan and not concurrent_marking', {
   'cpu-profiler/coverage-block': [SKIP],
-}],  # variant == turboprop or variant = turboprop_as_toptier
+}],  # tsan and not concurrent_marking
 
 ##############################################################################
 ['no_i18n == True', {
diff --git a/test/mjsunit/compiler/bound-functions-serialize.js b/test/mjsunit/compiler/bound-functions-serialize.js
index 2f9555d0a2d..0f55cc920cd 100644
--- a/test/mjsunit/compiler/bound-functions-serialize.js
+++ b/test/mjsunit/compiler/bound-functions-serialize.js
@@ -2,7 +2,7 @@
 // Use of this source code is governed by a BSD-style license that can be
 // found in the LICENSE file.
 //
-// Flags: --allow-natives-syntax --opt --noalways-opt --noturboprop
+// Flags: --allow-natives-syntax --opt --noalways-opt
 
 class C {};
 const c = new C;
diff --git a/test/mjsunit/compiler/regress-1226988.js b/test/mjsunit/compiler/regress-1226988.js
deleted file mode 100644
index 1bd073e76fb..00000000000
--- a/test/mjsunit/compiler/regress-1226988.js
+++ /dev/null
@@ -1,21 +0,0 @@
-// Copyright 2021 the V8 project authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-// Flags: --turboprop
-var __v_0 = {
-  x: 2,
-  y: 1
-};
-function __f_0() {}
-function __f_1() {
-  for (var __v_1 = 0; __v_1 < 100000; __v_1++) {
-    var __v_2 = __v_0.x + __f_0();
-  }
-  var __v_3 = [{
-    x: 2.5,
-    y: 1
-  }];
-}
-__f_1();
-__f_1();
diff --git a/test/mjsunit/compiler/test-dynamic-map-check-deprecated-maps-polymorphic.js b/test/mjsunit/compiler/test-dynamic-map-check-deprecated-maps-polymorphic.js
deleted file mode 100644
index 552d2564cb8..00000000000
--- a/test/mjsunit/compiler/test-dynamic-map-check-deprecated-maps-polymorphic.js
+++ /dev/null
@@ -1,35 +0,0 @@
-// Copyright 2020 the V8 project authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-// Flags: --allow-natives-syntax --turboprop --turbo-dynamic-map-checks --opt
-// Flags: --no-always-opt
-
-function f(o) {
-  return o.b;
-}
-
-var o = {a:10, b:20};
-var o1 = {a:10, b:20};
-var o2 = {a:10, b:20};
-var o3 = {a:10, b:20, c:30};
-%PrepareFunctionForOptimization(f);
-// Transition IC state to polymorphic.
-f(o);
-f(o3);
-%OptimizeFunctionOnNextCall(f);
-f(o);
-assertOptimized(f);
-f(o);
-
-// Deprecates O's map.
-o1.b = 10.23;
-// Deoptimizes but retains code.
-f(o1);
-assertOptimized(f);
-
-// Continues to use optimized code since deprecated map is still in the
-// feedback. ICs don't drop deprecated maps in the polymoprhic case.
-f(o);
-f(o);
-assertOptimized(f);
diff --git a/test/mjsunit/compiler/test-dynamic-map-check-deprecated-maps.js b/test/mjsunit/compiler/test-dynamic-map-check-deprecated-maps.js
deleted file mode 100644
index ee5abffe990..00000000000
--- a/test/mjsunit/compiler/test-dynamic-map-check-deprecated-maps.js
+++ /dev/null
@@ -1,36 +0,0 @@
-// Copyright 2020 the V8 project authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-// Flags: --allow-natives-syntax --turboprop --turbo-dynamic-map-checks --opt
-// Flags: --no-always-opt
-
-function f(o) {
-  return o.b;
-}
-
-var o = {a:10, b:20};
-var o1 = {a:10, b:20};
-var o2 = {a:10, b:20};
-%PrepareFunctionForOptimization(f);
-f(o);
-%OptimizeFunctionOnNextCall(f);
-f(o);
-assertOptimized(f);
-
-// Deprecates o's map.
-o1.b = 10.23;
-
-// Bails out but retains code.
-f(o1);
-assertOptimized(f);
-
-// Passing in original object should not cause any deopts.
-f(o);
-f(o);
-assertOptimized(f);
-
-// o and o2 have the same Map, so there should be no deopts.
-f(o2);
-f(o2);
-assertOptimized(f);
diff --git a/test/mjsunit/compiler/test-dynamic-map-check-deprecated-maps2.js b/test/mjsunit/compiler/test-dynamic-map-check-deprecated-maps2.js
deleted file mode 100644
index d3c201bc9d1..00000000000
--- a/test/mjsunit/compiler/test-dynamic-map-check-deprecated-maps2.js
+++ /dev/null
@@ -1,46 +0,0 @@
-// Copyright 2020 the V8 project authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-// Flags: --allow-natives-syntax --turboprop --turbo-dynamic-map-checks
-// Flags: --opt --no-always-opt --deopt-every-n-times=0
-
-function b(a) { return a; }
-
-function f(o, should_bailout) {
-  b(o.a);
-  let did_bailout = (%GetOptimizationStatus(f) &
-                    V8OptimizationStatus.kTopmostFrameIsTurboFanned) == 0;
-  assertEquals(should_bailout, did_bailout);
-}
-
-var o = {a:10, b:20, c:30};
-var o1 = {a:10, b:20, c:30};
-var o2 = {a:10, b:20, c:30};
-%PrepareFunctionForOptimization(f);
-f(o, true);
-%OptimizeFunctionOnNextCall(f);
-f(o, false);
-assertOptimized(f);
-
-// Transition o to a new map and deprecate the old one (which is embedded in the
-// optimized code for the dynamic map check).
-o.b = 10.23;
-f(o, true);
-f(o1, false);
-f(o2, false);
-assertOptimized(f);
-
-// Deprecate o's new map again and update the feedback vector but don't migrate
-// o.
-o1.c = 20.23;
-f(o1, true);
-assertOptimized(f);
-
-// We should migrates o's map with a bailout, but then should not bailout after
-// migrating.
-f(o, true);
-f(o, false);
-f(o1, false);
-f(o2, false);
-assertOptimized(f);
diff --git a/test/mjsunit/compiler/test-dynamic-map-check-deprecated-maps3.js b/test/mjsunit/compiler/test-dynamic-map-check-deprecated-maps3.js
deleted file mode 100644
index fa6dc826f00..00000000000
--- a/test/mjsunit/compiler/test-dynamic-map-check-deprecated-maps3.js
+++ /dev/null
@@ -1,41 +0,0 @@
-// Copyright 2020 the V8 project authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-// Flags: --allow-natives-syntax --turboprop --turbo-dynamic-map-checks
-// Flags: --opt --no-always-opt --deopt-every-n-times=0
-
-function b(a) { return a; }
-
-function f(o, should_bailout) {
-  b(o.a);
-  let did_bailout = (%GetOptimizationStatus(f) &
-                    V8OptimizationStatus.kTopmostFrameIsTurboFanned) == 0;
-  assertEquals(should_bailout, did_bailout);
-}
-
-var o = {a:10, b:20, c:30};
-var o1 = {a:10, b:20, c:30};
-var o2 = {a:10, b:20, c:30};
-
-// Make o's map a migration target.
-o1.b = 10.23;
-o.a;
-
-%PrepareFunctionForOptimization(f);
-f(o, true);
-%OptimizeFunctionOnNextCall(f);
-f(o, false);
-assertOptimized(f);
-
-// Deprecate o's new map again and update the feedback vector but don't migrate
-// o.
-o1.c = 20.23;
-f(o1, true);
-assertOptimized(f);
-
-// We migrates o's map without deopting or bailing out.
-f(o, false);
-f(o1, false);
-f(o2, false);
-assertOptimized(f);
diff --git a/test/mjsunit/compiler/test-dynamic-map-checks-poly-mono.js b/test/mjsunit/compiler/test-dynamic-map-checks-poly-mono.js
deleted file mode 100644
index 9058fc00b26..00000000000
--- a/test/mjsunit/compiler/test-dynamic-map-checks-poly-mono.js
+++ /dev/null
@@ -1,36 +0,0 @@
-// Copyright 2020 the V8 project authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-// Flags: --allow-natives-syntax --turboprop --turbo-dynamic-map-checks --opt
-// Flags: --no-always-opt
-
-function load(obj){
-  return obj.x;
-}
-
-var o = {x:20, y:30};
-var o1 = {x:20, y:30, z:40};
-
-%PrepareFunctionForOptimization(load);
-load(o);
-load(o1);
-
-%OptimizeFunctionOnNextCall(load);
-load(o);
-load(o1);
-assertOptimized(load);
-
-// deprecate maps in IC
-o.x = 21.32;
-o1.x = 21.32;
-
-// transition poly -> mono
-var o2 = {y:20, x:20};
-// This bails out to interpreter and updates the IC state
-load(o2);
-// Optimized code sees monomorphic and should deopt.
-load(o2);
-// should deptimize since we wouldn't generate checks for monomorphic when
-// starting off with polymorphic
-assertUnoptimized(load);
diff --git a/test/mjsunit/compiler/test-dynamic-map-checks-wrong-handler.js b/test/mjsunit/compiler/test-dynamic-map-checks-wrong-handler.js
deleted file mode 100644
index 0de7ae0c86a..00000000000
--- a/test/mjsunit/compiler/test-dynamic-map-checks-wrong-handler.js
+++ /dev/null
@@ -1,33 +0,0 @@
-// Copyright 2020 the V8 project authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-// Flags: --allow-natives-syntax --turboprop --turbo-dynamic-map-checks --opt
-// Flags: --no-always-opt
-
-function load(obj){
-  return obj.x;
-}
-
-%PrepareFunctionForOptimization(load);
-obj = {};
-obj.x = 1;
-
-//get mono feedback
-load(obj);
-
-// optimize as mono
-%OptimizeFunctionOnNextCall(load);
-load(obj);
-assertOptimized(load);
-load(obj);
-
-// change the object's representation.
-obj.x = 2.3;
-load(obj);
-// deoptimizes on a wrong map but retains the code
-assertOptimized(load);
-
-// deoptimizes on the wrong handler.
-load(obj);
-assertUnoptimized(load);
diff --git a/test/mjsunit/compiler/test-dynamic-map-checks-wrong-handler1.js b/test/mjsunit/compiler/test-dynamic-map-checks-wrong-handler1.js
deleted file mode 100644
index 4f938f67444..00000000000
--- a/test/mjsunit/compiler/test-dynamic-map-checks-wrong-handler1.js
+++ /dev/null
@@ -1,32 +0,0 @@
-// Copyright 2020 the V8 project authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-// Flags: --allow-natives-syntax --turboprop --turbo-dynamic-map-checks --opt
-// Flags: --no-always-opt
-
-function load(obj){
-  return obj.x;
-}
-
-var o = {x: 10, y:20};
-var o1 = {x:10, y:20, z:30};
-
-%PrepareFunctionForOptimization(load);
-// polymorphic with same handler
-load(o);
-load(o1);
-
-%OptimizeFunctionOnNextCall(load);
-load(o);
-load(o1);
-assertOptimized(load);
-
-var o2 = {y: 10, x:20};
-// deopts but stays optimized
-load(o2);
-assertOptimized(load);
-
-// deopts and discard code on wrong handler
-load(o2);
-assertUnoptimized(load);
diff --git a/test/mjsunit/compiler/test-dynamic-map-checks.js b/test/mjsunit/compiler/test-dynamic-map-checks.js
deleted file mode 100644
index f3c5289dbeb..00000000000
--- a/test/mjsunit/compiler/test-dynamic-map-checks.js
+++ /dev/null
@@ -1,45 +0,0 @@
-// Copyright 2020 the V8 project authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-// Flags: --allow-natives-syntax --turboprop --turbo-dynamic-map-checks --opt
-// Flags: --no-always-opt
-
-function load(obj){
-  return obj.x;
-}
-
-%PrepareFunctionForOptimization(load);
-obj = {};
-obj.x = 1;
-
-//get mono feedback
-load(obj);
-load(obj);
-
-// optimize as mono
-%OptimizeFunctionOnNextCall(load);
-load(obj);
-assertOptimized(load);
-load(obj);
-
-// transition to poly - should retain optimized code
-obj.y = 2;
-load(obj);
-assertOptimized(load);
-load(obj);
-
-// transition to more polymorphic
-obj.z = 3;
-load(obj);
-obj.q =4;
-load(obj);
-
-// transition to megamorphic
-assertOptimized(load);
-obj.r = 5;
-load(obj);
-obj.s = 6;
-load(obj);
-assertUnoptimized(load);
-load(obj);
diff --git a/test/mjsunit/concurrent-initial-prototype-change-1.js b/test/mjsunit/concurrent-initial-prototype-change-1.js
index 2ca1f8a7d97..bb12ed3702a 100644
--- a/test/mjsunit/concurrent-initial-prototype-change-1.js
+++ b/test/mjsunit/concurrent-initial-prototype-change-1.js
@@ -26,7 +26,7 @@
 // OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 
 // Flags: --allow-natives-syntax --concurrent-recompilation
-// Flags: --no-stress-opt --no-always-opt --no-turboprop
+// Flags: --no-stress-opt --no-always-opt
 //
 // --nostress-opt is in place because this particular optimization
 // (guaranteeing that the Array prototype chain has no elements) is
diff --git a/test/mjsunit/const-field-tracking-2.js b/test/mjsunit/const-field-tracking-2.js
deleted file mode 100644
index 34511cc8362..00000000000
--- a/test/mjsunit/const-field-tracking-2.js
+++ /dev/null
@@ -1,227 +0,0 @@
-// Copyright 2020 the V8 project authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-// TODO(gsathya): This test will probably break when v8 tiers up to turbofan
-// from turboprop.
-//
-// Flags: --allow-natives-syntax --opt --no-always-opt --turboprop
-// Flags: --turbo-dynamic-map-checks
-
-var global = this;
-var unique_id = 0;
-// Creates a function with unique SharedFunctionInfo to ensure the feedback
-// vector is unique for each test case.
-function MakeFunctionWithUniqueSFI(...args) {
-  assertTrue(args.length > 0);
-  var body = `/* Unique comment: ${unique_id++} */ ` + args.pop();
-  return new Function(...args, body);
-}
-
-
-//
-// Load constant field from constant object directly.
-//
-function TestLoadFromConstantFieldOfAConstantObject(the_value, other_value) {
-  function A(v) { this.v = v; }
-  function O() { this.a = new A(the_value); }
-  var the_object = new O();
-
-  // Ensure that {the_object.a}'s map is not stable to complicate compiler's
-  // life.
-  new A(the_value).blah = 0;
-
-  // Ensure that constant tracking is enabled for {contant_object}.
-  delete global.constant_object;
-  global.constant_object = the_object;
-  assertEquals(the_object, constant_object);
-
-  assertTrue(%HasFastProperties(the_object));
-
-  // {constant_object} is known to the compiler via global property cell
-  // tracking.
-  var load = MakeFunctionWithUniqueSFI("return constant_object.a.v;");
-  %PrepareFunctionForOptimization(load);
-  load();
-  load();
-  %OptimizeFunctionOnNextCall(load);
-  assertEquals(the_value, load());
-  assertOptimized(load);
-  var a = new A(other_value);
-  assertTrue(%HaveSameMap(a, the_object.a));
-  // Make constant field mutable by assigning another value
-  // to some other instance of A.
-  new A(the_value).v = other_value;
-  assertTrue(%HaveSameMap(a, new A(the_value)));
-  assertTrue(%HaveSameMap(a, the_object.a));
-  assertOptimized(load);
-  assertEquals(the_value, load());
-  assertOptimized(load);
-  assertEquals(the_value, load());
-}
-
-//Test constant tracking with Smi value.
-(function() {
-  var the_value = 42;
-  var other_value = 153;
-  TestLoadFromConstantFieldOfAConstantObject(the_value, other_value);
-})();
-
-// Test constant tracking with double value.
-(function() {
-  var the_value = 0.9;
-  var other_value = 0.42;
-  TestLoadFromConstantFieldOfAConstantObject(the_value, other_value);
-})();
-
-// Test constant tracking with function value.
-(function() {
-  var the_value = function V() {};
-  var other_value = function W() {};
-  TestLoadFromConstantFieldOfAConstantObject(the_value, other_value);
-})();
-
-// Test constant tracking with heap object value.
-(function() {
-  function V() {}
-  var the_value = new V();
-  var other_value = new V();
-  TestLoadFromConstantFieldOfAConstantObject(the_value, other_value);
-})();
-
-
-//
-// Load constant field from a prototype.
-//
-function TestLoadFromConstantFieldOfAPrototype(the_value, other_value) {
-  function Proto() { this.v = the_value; }
-  var the_prototype = new Proto();
-
-  function O() {}
-  O.prototype = the_prototype;
-  var the_object = new O();
-
-  // Ensure O.prototype is in fast mode by loading from its field.
-  function warmup() { return new O().v; }
-  %EnsureFeedbackVectorForFunction(warmup);
-  warmup(); warmup(); warmup();
-  if (!%IsDictPropertyConstTrackingEnabled())
-    assertTrue(%HasFastProperties(O.prototype));
-
-  // The parameter object is not constant but all the values have the same
-  // map and therefore the compiler knows the prototype object and can
-  // optimize load of "v".
-  var load = MakeFunctionWithUniqueSFI("o", "return o.v;");
-  %PrepareFunctionForOptimization(load);
-  load(new O());
-  load(new O());
-  %OptimizeFunctionOnNextCall(load);
-  assertEquals(the_value, load(new O()));
-  assertOptimized(load);
-  // Invalidation of mutability should trigger deoptimization with a
-  // "field-owner" reason.
-  the_prototype.v = other_value;
-  assertUnoptimized(load);
-}
-
-// Test constant tracking with Smi value.
-(function() {
-  var the_value = 42;
-  var other_value = 153;
-  TestLoadFromConstantFieldOfAPrototype(the_value, other_value);
-})();
-
-// Test constant tracking with double value.
-(function() {
-  var the_value = 0.9;
-  var other_value = 0.42;
-  TestLoadFromConstantFieldOfAPrototype(the_value, other_value);
-})();
-
-// Test constant tracking with function value.
-(function() {
-  var the_value = function V() {};
-  var other_value = function W() {};
-  TestLoadFromConstantFieldOfAPrototype(the_value, other_value);
-})();
-
-// Test constant tracking with heap object value.
-(function() {
-  function V() {}
-  var the_value = new V();
-  var other_value = new V();
-  TestLoadFromConstantFieldOfAPrototype(the_value, other_value);
-})();
-
-
-//
-// Store to constant field of a constant object.
-//
-function TestStoreToConstantFieldOfConstantObject(the_value, other_value) {
-  function A(v) { this.v = v; }
-  function O() { this.a = new A(the_value); }
-  var the_object = new O();
-
-  // Ensure that {the_object.a}'s map is not stable to complicate compiler's
-  // life.
-  new A(the_value).blah = 0;
-
-  // Ensure that constant tracking is enabled for {contant_object}.
-  delete global.constant_object;
-  global.constant_object = the_object;
-  assertEquals(the_object, constant_object);
-
-  assertTrue(%HasFastProperties(the_object));
-
-  // {constant_object} is known to the compiler via global property cell
-  // tracking.
-  var store = MakeFunctionWithUniqueSFI("v", "constant_object.a.v = v;");
-  %PrepareFunctionForOptimization(store);
-  store(the_value);
-  store(the_value);
-  %OptimizeFunctionOnNextCall(store);
-  store(the_value);
-  assertEquals(the_value, constant_object.a.v);
-  assertOptimized(store);
-  // Storing of the same value does not deoptimize.
-  store(the_value);
-  assertEquals(the_value, constant_object.a.v);
-  assertOptimized(store);
-
-  var a = new A(other_value);
-
-  assertOptimized(store);
-  // Storing other value deoptimizes because of failed value check.
-  store(other_value);
-  assertUnoptimized(store);
-  assertEquals(other_value, constant_object.a.v);
-}
-
-// Test constant tracking with Smi values.
-(function() {
-  var the_value = 42;
-  var other_value = 153;
-  TestStoreToConstantFieldOfConstantObject(the_value, other_value);
-})();
-
-// Test constant tracking with double values.
-(function() {
-  var the_value = 0.9;
-  var other_value = 0.42
-  TestStoreToConstantFieldOfConstantObject(the_value, other_value);
-})();
-
-// Test constant tracking with function values.
-(function() {
-  var the_value = function V() {};
-  var other_value = function W() {};
-  TestStoreToConstantFieldOfConstantObject(the_value, other_value);
-})();
-
-// Test constant tracking with heap object values.
-(function() {
-  function V() {}
-  var the_value = new V();
-  var other_value = new V();
-  TestStoreToConstantFieldOfConstantObject(the_value, other_value);
-})();
diff --git a/test/mjsunit/es6/super-ic-opt-dynamic-map-checks.js b/test/mjsunit/es6/super-ic-opt-dynamic-map-checks.js
deleted file mode 100644
index 4e3d02e5e34..00000000000
--- a/test/mjsunit/es6/super-ic-opt-dynamic-map-checks.js
+++ /dev/null
@@ -1,42 +0,0 @@
-// Copyright 2020 the V8 project authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-// Flags: --allow-natives-syntax --super-ic --opt
-// Flags: --no-always-opt --no-stress-opt --turboprop
-// Flags: --turbo-dynamic-map-checks --deopt-every-n-times=0
-
-// This file contains tests which require --dynamic-map-chekcs.
-
-(function TestMinimorphicPropertyAccess() {
-  class A {}
-  A.prototype.bar = "wrong value: A.prototype.bar";
-
-  class B extends A {};
-  B.prototype.bar = "correct value";
-
-  class C extends B {
-    foo(should_bailout) {
-      const r = super.bar;
-      const did_bailout = (
-          %GetOptimizationStatus(C.prototype.foo) &
-          V8OptimizationStatus.kTopmostFrameIsTurboFanned) == 0;
-      assertEquals(should_bailout, did_bailout);
-      return r;
-    }
-  }
-  C.prototype.bar = "wrong value: C.prototype.bar";
-  %PrepareFunctionForOptimization(C.prototype.foo);
-
-  let o = new C();
-  o.bar = "wrong value: o.bar";
-
-  // Fill in the feedback.
-  let r = o.foo(true);
-  assertEquals("correct value", r);
-  %OptimizeFunctionOnNextCall(C.prototype.foo);
-
-  // Test the optimized function.
-  r = o.foo(false);
-  assertEquals("correct value", r);
-})();
diff --git a/test/mjsunit/mjsunit.status b/test/mjsunit/mjsunit.status
index 6fe5de0753a..6b3d9a34b27 100644
--- a/test/mjsunit/mjsunit.status
+++ b/test/mjsunit/mjsunit.status
@@ -404,8 +404,6 @@
   'regress/regress-1122': [SKIP],
   'regress/regress-331444': [SKIP],
   'regress/regress-353551': [SKIP],
-  'regress/regress-1138075': [SKIP],
-  'regress/regress-1138611': [SKIP],
   'regress/regress-crbug-119926': [SKIP],
   'regress/short-circuit': [SKIP],
   'stack-traces-overflow': [SKIP],
@@ -974,10 +972,6 @@
   # This often fails in debug mode because it is too slow
   'd8/d8-performance-now': [PASS, ['mode == debug', SKIP]],
 
-  # https://github.com/v8-riscv/v8/issues/418
-  'regress/regress-1138075': [SKIP],
-  'regress/regress-1138611': [SKIP],
-
   # SIMD not be implemented
   'regress/wasm/regress-1054466': [SKIP],
   'regress/wasm/regress-1065599': [SKIP],
@@ -997,7 +991,6 @@
   'regress/wasm/regress-1199662': [SKIP],
   'regress/wasm/regress-1231950': [SKIP],
   'regress/wasm/regress-1264462': [SKIP],
-  'regress/regress-1172797': [SKIP],
   'regress/wasm/regress-1179025': [SKIP],
   'wasm/multi-value-simd': [SKIP],
   'wasm/liftoff-simd-params': [SKIP],
diff --git a/test/mjsunit/regress/regress-1076569.js b/test/mjsunit/regress/regress-1076569.js
deleted file mode 100644
index a223b600a63..00000000000
--- a/test/mjsunit/regress/regress-1076569.js
+++ /dev/null
@@ -1,16 +0,0 @@
-// Copyright 2020 the V8 project authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-// Flags: --allow-natives-syntax --turboprop
-
-var array = new Int16Array();
-
-function foo() {
-  array[0] = "123.12";
-}
-
-%PrepareFunctionForOptimization(foo);
-foo();
-foo();
-%OptimizeFunctionOnNextCall(foo);
-foo();
diff --git a/test/mjsunit/regress/regress-1079446.js b/test/mjsunit/regress/regress-1079446.js
deleted file mode 100644
index 2322843751a..00000000000
--- a/test/mjsunit/regress/regress-1079446.js
+++ /dev/null
@@ -1,17 +0,0 @@
-// Copyright 2020 the V8 project authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-// Flags: --allow-natives-syntax --turboprop
-
-arr = new Int16Array();
-function foo() {
-  arr.__defineGetter__('a', function() { });
-  arr[0] = "123.12";
-}
-
-%PrepareFunctionForOptimization(foo);
-foo();
-foo();
-%OptimizeFunctionOnNextCall(foo);
-foo();
diff --git a/test/mjsunit/regress/regress-1083272.js b/test/mjsunit/regress/regress-1083272.js
deleted file mode 100644
index 0f16db70400..00000000000
--- a/test/mjsunit/regress/regress-1083272.js
+++ /dev/null
@@ -1,19 +0,0 @@
-// Copyright 2020 the V8 project authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-// Flags: --allow-natives-syntax --turboprop
-
-function foo(e, t) {
-    for (var n = [e], s = e.length; s > 0; --s) {}
-    for (var s = 0; s < n.length; s++) { t() }
-}
-
-var e = 'abc';
-function t() {};
-
-%PrepareFunctionForOptimization(foo);
-foo(e, t);
-foo(e, t);
-%OptimizeFunctionOnNextCall(foo);
-foo(e, t);
diff --git a/test/mjsunit/regress/regress-1083763.js b/test/mjsunit/regress/regress-1083763.js
deleted file mode 100644
index e0504c90e28..00000000000
--- a/test/mjsunit/regress/regress-1083763.js
+++ /dev/null
@@ -1,19 +0,0 @@
-// Copyright 2020 the V8 project authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-// Flags: --allow-natives-syntax --turboprop
-
-function bar() {}
-
-function foo() {
-  try {
-    bar( "abc".charAt(4));
-  } catch (e) {}
-}
-
-%PrepareFunctionForOptimization(foo);
-foo();
-foo();
-%OptimizeFunctionOnNextCall(foo);
-foo();
diff --git a/test/mjsunit/regress/regress-1084953.js b/test/mjsunit/regress/regress-1084953.js
deleted file mode 100644
index 57a27d741d9..00000000000
--- a/test/mjsunit/regress/regress-1084953.js
+++ /dev/null
@@ -1,16 +0,0 @@
-// Copyright 2020 the V8 project authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-//
-// Flags: --allow-natives-syntax --turboprop
-
-function foo() {
-  try {
-    +Symbol();
-  } catch {
-  }
-}
-%PrepareFunctionForOptimization(foo);
-foo();
-%OptimizeFunctionOnNextCall(foo);
-foo();
diff --git a/test/mjsunit/regress/regress-1137979.js b/test/mjsunit/regress/regress-1137979.js
deleted file mode 100644
index 2e06a9c3c3d..00000000000
--- a/test/mjsunit/regress/regress-1137979.js
+++ /dev/null
@@ -1,21 +0,0 @@
-// Copyright 2020 the V8 project authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-// Flags: --allow-natives-syntax --turboprop --no-lazy-feedback-allocation
-// Flags: --noanalyze-environment-liveness
-
-function foo() {
-  try {
-    bar();
-  } catch (e) {}
-  for (var i = 0; i < 3; i++) {
-    try {
-      %PrepareFunctionForOptimization(foo);
-      %OptimizeOsr();
-    } catch (e) {}
-  }
-}
-
-foo();
-foo();
diff --git a/test/mjsunit/regress/regress-1138075.js b/test/mjsunit/regress/regress-1138075.js
deleted file mode 100644
index e68e1b54713..00000000000
--- a/test/mjsunit/regress/regress-1138075.js
+++ /dev/null
@@ -1,27 +0,0 @@
-// Copyright 2020 the V8 project authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-// Flags: --allow-natives-syntax --turboprop --max-semi-space-size=1
-
-function runNearStackLimit(f) {
-  function t() {
-    try {
-      return t();
-    } catch (e) {
-      return f();
-    }
-  }
-  %PrepareFunctionForOptimization(t);
-  %OptimizeFunctionOnNextCall(t);
-  return t();
-}
-
-function foo(a) {}
-function bar(a, b) {}
-
-for (let i = 0; i < 150; i++) {
-  runNearStackLimit(() => {
-    return foo(bar(3, 4) === false);
-  });
-}
diff --git a/test/mjsunit/regress/regress-1138611.js b/test/mjsunit/regress/regress-1138611.js
deleted file mode 100644
index bca6a4bd09d..00000000000
--- a/test/mjsunit/regress/regress-1138611.js
+++ /dev/null
@@ -1,34 +0,0 @@
-// Copyright 2020 the V8 project authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-// Flags: --allow-natives-syntax --turboprop --gc-interval=1000
-
-function runNearStackLimit(f) {
-  function t() {
-    try {
-      return t();
-    } catch (e) {
-      return f();
-    }
-  }
-  %PrepareFunctionForOptimization(t);
-  %OptimizeFunctionOnNextCall(t);
-  return t();
-}
-
-function foo() {
-  runNearStackLimit(() => {});
-}
-
-(function () {
-  var a = 42;
-  var b = 153;
-  try {
-    Object.defineProperty({});
-  } catch (e) {}
-    foo();
-    foo();
-})();
-
-runNearStackLimit(() => {});
diff --git a/test/mjsunit/regress/regress-1154961.js b/test/mjsunit/regress/regress-1154961.js
deleted file mode 100644
index 5bc1a8e8b85..00000000000
--- a/test/mjsunit/regress/regress-1154961.js
+++ /dev/null
@@ -1,42 +0,0 @@
-// Copyright 2020 the V8 project authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-// Flags: --allow-natives-syntax --turboprop --stack-size=100
-
-function runNearStackLimit(f) {
-  function t() {
-    try {
-      return t();
-    } catch (e) {
-      return f();
-    }
-  }
-  return t();
-}
-
-function baz(f) {
-  return [[f(1)], 1, 2, 3, 4, 5, 6, 7, 8];
-}
-
-function foo(__v_3) {
-  try {
-    var arr = baz(__v_3);
-  } catch (e) {}
-  try {
-    for (var i = 0; i < arr.length; i++) {
-      function bar() {
-        return arr[i];
-      }
-      try {
-        throw e;
-      } catch (e) {}
-    }
-  } catch (e) {}
-}
-
-%PrepareFunctionForOptimization(foo);
-foo(a => a);
-foo(a => a);
-%OptimizeFunctionOnNextCall(foo);
-runNearStackLimit(() => { foo(a => a); });
diff --git a/test/mjsunit/regress/regress-1163715.js b/test/mjsunit/regress/regress-1163715.js
deleted file mode 100644
index c0838c213a2..00000000000
--- a/test/mjsunit/regress/regress-1163715.js
+++ /dev/null
@@ -1,27 +0,0 @@
-// Copyright 2021 the V8 project authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-// Flags: --turboprop --allow-natives-syntax
-
-let last_value;
-let throwFunc;
-
-function foo(count) {
-  let val = 1;
-  for (let i = 16; i < count; ++i) {
-    try {
-      throwFunc();
-    } catch (e) {
-    }
-    val *= 2;
-    last_value = val;
-  }
-}
-
-%PrepareFunctionForOptimization(foo);
-foo(20);
-foo(21);
-%OptimizeFunctionOnNextCall(foo);
-foo(47);
-assertEquals(2147483648, last_value);
diff --git a/test/mjsunit/regress/regress-1172797.js b/test/mjsunit/regress/regress-1172797.js
deleted file mode 100644
index 05d39a1b868..00000000000
--- a/test/mjsunit/regress/regress-1172797.js
+++ /dev/null
@@ -1,48 +0,0 @@
-// Copyright 2020 the V8 project authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-// Flags: --allow-natives-syntax --turboprop --opt --no-always-opt
-
-
-var v_0 = {};
-function f_0(o, v) {
-  o.f = v;
-}
-
-function f_1() {
-  return v_0.f;
-}
-
-%PrepareFunctionForOptimization(f_0);
-f_0(v_0, 42);
-f_0(v_0, 42);
-%OptimizeFunctionOnNextCall(f_0);
-f_0(v_0, 42);
-
-// TP tier up
-%PrepareFunctionForOptimization(f_1);
-f_1();
-f_1();
-%OptimizeFunctionOnNextCall(f_1);
-f_1();
-// Now TF tier up
-%PrepareFunctionForOptimization(f_1);
-f_1();
-%TierupFunctionOnNextCall(f_1);
-f_1();
-
-assertOptimized(f_0);
-// TODO(mythria): Add an option to assert on the optimization tier and assert
-// f_1 is optimized with TurboFan.
-assertOptimized(f_1);
-// Store in f_0 should trigger a change to the constness of the field.
-f_0(v_0, 53);
-// f_0 does a eager deopt and lets the interpreter update the field constness.
-assertUnoptimized(f_0);
-if (!%IsTopTierTurboprop()) {
-  // f_1 has TurboFan code and should deopt because of dependency change.
-  assertUnoptimized(f_1);
-}
-assertEquals(v_0.f, 53);
-assertEquals(f_1(), 53);
diff --git a/test/mjsunit/regress/regress-1201114.js b/test/mjsunit/regress/regress-1201114.js
deleted file mode 100644
index 7f81d63c958..00000000000
--- a/test/mjsunit/regress/regress-1201114.js
+++ /dev/null
@@ -1,19 +0,0 @@
-// Copyright 2021 the V8 project authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-// Flags: --turboprop --allow-natives-syntax --print-code
-
-var a = {b: 1};
-function nop() { return false; }
-function __f_4(a) { return a; }
-function __f_5(__v_2) {
-  __f_4(__v_2.a);
-  nop(__f_5)&a.b;
-}
-%PrepareFunctionForOptimization(__f_5);
-__f_5(true);
-%OptimizeFunctionOnNextCall(__f_5);
-try {
-  __f_5();
-} catch {}
diff --git a/test/mjsunit/regress/regress-1223733.js b/test/mjsunit/regress/regress-1223733.js
deleted file mode 100644
index be5fd915f45..00000000000
--- a/test/mjsunit/regress/regress-1223733.js
+++ /dev/null
@@ -1,16 +0,0 @@
-// Copyright 2021 the V8 project authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-// Flags: --allow-natives-syntax --turboprop --turbo-dynamic-map-checks
-
-function main() {
-  // Store something onto a function prototype so we will bailout of the
-  // function.prototype load optimization in NativeContextSpecialization.
-  isNaN.prototype = 14;
-  const v14 = isNaN.prototype;
-}
-%PrepareFunctionForOptimization(main);
-main();
-%OptimizeFunctionOnNextCall(main);
-main();
diff --git a/test/mjsunit/regress/regress-1225561.js b/test/mjsunit/regress/regress-1225561.js
deleted file mode 100644
index 5ec2d665adb..00000000000
--- a/test/mjsunit/regress/regress-1225561.js
+++ /dev/null
@@ -1,27 +0,0 @@
-// Copyright 2021 the V8 project authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-// Flags: --allow-natives-syntax --turboprop --turbo-dynamic-map-checks
-
-function bar(obj) {
-  return Object.getPrototypeOf(obj);
-}
-
-function foo(a, b) {
-  try {
-    a.a;
-  } catch (e) {}
-  try {
-    b[bar()] = 1;
-  } catch (e) {}
-}
-
-var arg = {
-  a: 10,
-};
-
-%PrepareFunctionForOptimization(foo);
-foo(arg);
-%OptimizeFunctionOnNextCall(foo);
-foo();
diff --git a/test/mjsunit/regress/regress-1285007.js b/test/mjsunit/regress/regress-1285007.js
deleted file mode 100644
index d12098aeccd..00000000000
--- a/test/mjsunit/regress/regress-1285007.js
+++ /dev/null
@@ -1,40 +0,0 @@
-// Copyright 2022 the V8 project authors. All rights reserved.
-// Use of this source code is governed by a BSD-style license that can be
-// found in the LICENSE file.
-
-// Flags: --allow-natives-syntax --assert-types --interrupt-budget=1000
-// Flags: --no-lazy-feedback-allocation --turboprop
-
-var __v_12 = [];
-var __v_30 = {};
-function __f_0(x, len) {
-  var __v_1 = new Array();
-  var __v_2 = x + 0.5;
-  var __v_3 = x + 1.5;
-  var __v_4 = x + 2.5;
-  var __v_5 = x + 3.5;
-  var __v_7 = x + 5.5;
-  var __v_15 = x + 13.5;
-  var __v_16 = x + 14.5;
-  var __v_22 = x + 20.5;
-  var __v_25 = x + 23.5;
-  var __v_8 = x + 24.5;
-  __v_12[len] = 0;
-  __v_1[0] = __v_2;
-  __v_1[1] = __v_3;
-  __v_1[2] = __v_4;
-  __v_1[3] = __v_5;
-  __v_1 = __v_30;
-  __v_1[5] = __v_7;
-  __v_1[6] = __v_8;
-  __v_1[13] = __v_15;
-  __v_1[14] = __v_16;
-  __v_1[23] = __v_25;
-  for (var __v_27 = 0; __v_27 < __v_1.length; __v_27++) {
-    x + __v_22 + [__v_37];
-  }
-}
-%PrepareFunctionForOptimization(__f_0);
-__f_0();
-%OptimizeFunctionOnNextCall(__f_0);
-__f_0();
diff --git a/test/mjsunit/regress/regress-385565.js b/test/mjsunit/regress/regress-385565.js
index 96dded2a00f..1403119681b 100644
--- a/test/mjsunit/regress/regress-385565.js
+++ b/test/mjsunit/regress/regress-385565.js
@@ -50,10 +50,6 @@ callsFReceiver(o1);
 var r2 = callsFReceiver(o1);
 assertOptimized(callsFReceiver);
 callsFReceiver(o2);
-if (%DynamicCheckMapsEnabled()) {
-  // Call it again to ensure a deopt when dynamic map checks is enabled.
-  callsFReceiver(o2);
-}
 assertUnoptimized(callsFReceiver);
 
 %PrepareFunctionForOptimization(callsFReceiver);
@@ -76,9 +72,4 @@ assertEquals(1, r1);
 assertTrue(r1 === r2);
 assertTrue(r2 === r3);
 
-
-if (%DynamicCheckMapsEnabled()) {
-  assertEquals(11, calls);
-} else {
-  assertEquals(10, calls);
-}
+assertEquals(10, calls);
diff --git a/test/mjsunit/regress/regress-unlink-closures-on-deopt.js b/test/mjsunit/regress/regress-unlink-closures-on-deopt.js
index fceac248e9c..c2e6212eb16 100644
--- a/test/mjsunit/regress/regress-unlink-closures-on-deopt.js
+++ b/test/mjsunit/regress/regress-unlink-closures-on-deopt.js
@@ -27,10 +27,6 @@ g1({ f : 1});
 %OptimizeFunctionOnNextCall(g2);
 g2({ f : 2});
 g1({});
-if (%DynamicCheckMapsEnabled()) {
-  // One more call to ensure a deopt even if dynamic map checks is enabled.
-  g1({});
-}
 
 assertUnoptimized(g1);
 
diff --git a/test/unittests/compiler/effect-control-linearizer-unittest.cc b/test/unittests/compiler/effect-control-linearizer-unittest.cc
index 03960705e1a..6f0a4b7d843 100644
--- a/test/unittests/compiler/effect-control-linearizer-unittest.cc
+++ b/test/unittests/compiler/effect-control-linearizer-unittest.cc
@@ -288,218 +288,6 @@ TEST_F(EffectControlLinearizerTest, CloneBranch) {
                                             IsBranch(cond2, control2)))))));
 }
 
-TEST_F(EffectControlLinearizerTest, UnreachableThenBranch) {
-  Schedule schedule(zone());
-
-  // Create the graph.
-  Node* unreachable = graph()->NewNode(common()->Unreachable(),
-                                       graph()->start(), graph()->start());
-  Node* branch =
-      graph()->NewNode(common()->Branch(), Int32Constant(0), graph()->start());
-
-  Node* if_true = graph()->NewNode(common()->IfTrue(), branch);
-  Node* true_throw = graph()->NewNode(common()->Throw(), unreachable, if_true);
-
-  Node* if_false = graph()->NewNode(common()->IfFalse(), branch);
-  Node* false_throw =
-      graph()->NewNode(common()->Throw(), unreachable, if_false);
-
-  graph()->SetEnd(graph()->NewNode(common()->End(0)));
-
-  // Build the basic block structure.
-  BasicBlock* start = schedule.start();
-  schedule.rpo_order()->push_back(start);
-  start->set_rpo_number(0);
-
-  BasicBlock* tblock = AddBlockToSchedule(&schedule);
-  BasicBlock* fblock = AddBlockToSchedule(&schedule);
-
-  // Populate the basic blocks with nodes.
-  schedule.AddNode(start, graph()->start());
-  schedule.AddNode(start, unreachable);
-  schedule.AddBranch(start, branch, tblock, fblock);
-
-  schedule.AddNode(tblock, if_true);
-  schedule.AddThrow(tblock, true_throw);
-  NodeProperties::MergeControlToEnd(graph(), common(), true_throw);
-
-  schedule.AddNode(fblock, if_false);
-  schedule.AddThrow(fblock, false_throw);
-  NodeProperties::MergeControlToEnd(graph(), common(), false_throw);
-
-  ASSERT_THAT(end(), IsEnd(IsThrow(), IsThrow()));
-  ASSERT_THAT(end()->op()->ControlInputCount(), 2);
-
-  // Run the state effect linearizer and machine lowering, maintaining the
-  // schedule.
-  LowerToMachineSchedule(jsgraph(), &schedule, zone(), source_positions(),
-                         node_origins(), broker());
-
-  ASSERT_THAT(end(), IsEnd(IsThrow()));
-}
-
-TEST_F(EffectControlLinearizerTest, UnreachableThenDiamond) {
-  Schedule schedule(zone());
-
-  // Create the graph.
-  Node* unreachable = graph()->NewNode(common()->Unreachable(),
-                                       graph()->start(), graph()->start());
-  Node* branch =
-      graph()->NewNode(common()->Branch(), Int32Constant(0), graph()->start());
-
-  Node* if_true = graph()->NewNode(common()->IfTrue(), branch);
-
-  Node* if_false = graph()->NewNode(common()->IfFalse(), branch);
-
-  Node* merge = graph()->NewNode(common()->Merge(2), if_true, if_false);
-  Node* throw_node = graph()->NewNode(common()->Throw(), unreachable, if_false);
-  graph()->SetEnd(graph()->NewNode(common()->End(0)));
-
-  // Build the basic block structure.
-  BasicBlock* start = schedule.start();
-  schedule.rpo_order()->push_back(start);
-  start->set_rpo_number(0);
-
-  BasicBlock* tblock = AddBlockToSchedule(&schedule);
-  BasicBlock* fblock = AddBlockToSchedule(&schedule);
-  BasicBlock* mblock = AddBlockToSchedule(&schedule);
-
-  // Populate the basic blocks with nodes.
-  schedule.AddNode(start, graph()->start());
-  schedule.AddNode(start, unreachable);
-  schedule.AddBranch(start, branch, tblock, fblock);
-
-  schedule.AddNode(tblock, if_true);
-  schedule.AddGoto(tblock, mblock);
-
-  schedule.AddNode(fblock, if_false);
-  schedule.AddGoto(fblock, mblock);
-
-  schedule.AddNode(mblock, merge);
-  schedule.AddThrow(mblock, throw_node);
-  NodeProperties::MergeControlToEnd(graph(), common(), throw_node);
-
-  ASSERT_THAT(end(), IsEnd(IsThrow()));
-  ASSERT_THAT(end()->op()->ControlInputCount(), 1);
-
-  // Run the state effect linearizer and machine lowering, maintaining the
-  // schedule.
-  LowerToMachineSchedule(jsgraph(), &schedule, zone(), source_positions(),
-                         node_origins(), broker());
-
-  ASSERT_THAT(end(), IsEnd(IsThrow()));
-}
-
-TEST_F(EffectControlLinearizerTest, UnreachableThenLoop) {
-  Schedule schedule(zone());
-
-  // Create the graph.
-  Node* unreachable = graph()->NewNode(common()->Unreachable(),
-                                       graph()->start(), graph()->start());
-  Node* loop = graph()->NewNode(common()->Loop(1), graph()->start());
-
-  Node* cond = Int32Constant(0);
-  Node* branch = graph()->NewNode(common()->Branch(), cond, loop);
-
-  Node* if_true = graph()->NewNode(common()->IfTrue(), branch);
-
-  Node* if_false = graph()->NewNode(common()->IfFalse(), branch);
-
-  loop->AppendInput(zone(), if_false);
-  NodeProperties::ChangeOp(loop, common()->Loop(2));
-
-  Node* throw_node = graph()->NewNode(common()->Throw(), unreachable, if_false);
-  graph()->SetEnd(graph()->NewNode(common()->End(0)));
-
-  // Build the basic block structure.
-  BasicBlock* start = schedule.start();
-  schedule.rpo_order()->push_back(start);
-  start->set_rpo_number(0);
-
-  BasicBlock* lblock = AddBlockToSchedule(&schedule);
-  BasicBlock* fblock = AddBlockToSchedule(&schedule);
-  BasicBlock* tblock = AddBlockToSchedule(&schedule);
-
-  // Populate the basic blocks with nodes.
-  schedule.AddNode(start, graph()->start());
-  schedule.AddNode(start, unreachable);
-  schedule.AddGoto(start, lblock);
-
-  schedule.AddNode(lblock, loop);
-  schedule.AddNode(lblock, cond);
-  schedule.AddBranch(lblock, branch, tblock, fblock);
-
-  schedule.AddNode(fblock, if_false);
-  schedule.AddGoto(fblock, lblock);
-
-  schedule.AddNode(tblock, if_true);
-  schedule.AddThrow(tblock, throw_node);
-  NodeProperties::MergeControlToEnd(graph(), common(), throw_node);
-
-  ASSERT_THAT(end(), IsEnd(IsThrow()));
-  ASSERT_THAT(end()->op()->ControlInputCount(), 1);
-
-  // Run the state effect linearizer and machine lowering, maintaining the
-  // schedule.
-  LowerToMachineSchedule(jsgraph(), &schedule, zone(), source_positions(),
-                         node_origins(), broker());
-
-  ASSERT_THAT(end(), IsEnd(IsThrow()));
-}
-
-TEST_F(EffectControlLinearizerTest, UnreachableInChangedBlockThenBranch) {
-  Schedule schedule(zone());
-
-  // Create the graph.
-  Node* truncate = graph()->NewNode(simplified()->TruncateTaggedToWord32(),
-                                    NumberConstant(1.1));
-  Node* unreachable = graph()->NewNode(common()->Unreachable(),
-                                       graph()->start(), graph()->start());
-  Node* branch =
-      graph()->NewNode(common()->Branch(), Int32Constant(0), graph()->start());
-
-  Node* if_true = graph()->NewNode(common()->IfTrue(), branch);
-  Node* true_throw = graph()->NewNode(common()->Throw(), unreachable, if_true);
-
-  Node* if_false = graph()->NewNode(common()->IfFalse(), branch);
-  Node* false_throw =
-      graph()->NewNode(common()->Throw(), unreachable, if_false);
-
-  graph()->SetEnd(graph()->NewNode(common()->End(0)));
-
-  // Build the basic block structure.
-  BasicBlock* start = schedule.start();
-  schedule.rpo_order()->push_back(start);
-  start->set_rpo_number(0);
-
-  BasicBlock* tblock = AddBlockToSchedule(&schedule);
-  BasicBlock* fblock = AddBlockToSchedule(&schedule);
-
-  // Populate the basic blocks with nodes.
-  schedule.AddNode(start, graph()->start());
-  schedule.AddNode(start, truncate);
-  schedule.AddNode(start, unreachable);
-  schedule.AddBranch(start, branch, tblock, fblock);
-
-  schedule.AddNode(tblock, if_true);
-  schedule.AddThrow(tblock, true_throw);
-  NodeProperties::MergeControlToEnd(graph(), common(), true_throw);
-
-  schedule.AddNode(fblock, if_false);
-  schedule.AddThrow(fblock, false_throw);
-  NodeProperties::MergeControlToEnd(graph(), common(), false_throw);
-
-  ASSERT_THAT(end(), IsEnd(IsThrow(), IsThrow()));
-  ASSERT_THAT(end()->op()->ControlInputCount(), 2);
-
-  // Run the state effect linearizer and machine lowering, maintaining the
-  // schedule.
-  LowerToMachineSchedule(jsgraph(), &schedule, zone(), source_positions(),
-                         node_origins(), broker());
-
-  ASSERT_THAT(end(), IsEnd(IsThrow()));
-}
-
 }  // namespace compiler
 }  // namespace internal
 }  // namespace v8
diff --git a/tools/profile.mjs b/tools/profile.mjs
index 5f0b1667ec0..3f11bff1394 100644
--- a/tools/profile.mjs
+++ b/tools/profile.mjs
@@ -314,7 +314,6 @@ export class Profile {
     COMPILED: 0,
     IGNITION: 1,
     BASELINE: 2,
-    TURBOPROP: 4,
     TURBOFAN: 5,
   }
 
@@ -346,8 +345,6 @@ export class Profile {
         return this.CodeState.IGNITION;
       case '^':
         return this.CodeState.BASELINE;
-      case '+':
-        return this.CodeState.TURBOPROP;
       case '*':
         return this.CodeState.TURBOFAN;
     }
@@ -361,8 +358,6 @@ export class Profile {
       return "Unopt";
     } else if (state === this.CodeState.BASELINE) {
       return "Baseline";
-    } else if (state === this.CodeState.TURBOPROP) {
-      return "Turboprop";
     } else if (state === this.CodeState.TURBOFAN) {
       return "Opt";
     }
diff --git a/tools/testrunner/local/variants.py b/tools/testrunner/local/variants.py
index e064f5e3fca..f973b9d4d8e 100644
--- a/tools/testrunner/local/variants.py
+++ b/tools/testrunner/local/variants.py
@@ -37,8 +37,6 @@ ALL_VARIANT_FLAGS = {
   # Trigger stress sampling allocation profiler with sample interval = 2^14
   "stress_sampling": [["--stress-sampling-allocation-profiler=16384"]],
   "no_wasm_traps": [["--no-wasm-trap-handler"]],
-  "turboprop": [["--turboprop"]],
-  "turboprop_as_toptier": [["--turboprop-as-toptier", "--turboprop"]],
   "instruction_scheduling": [["--turbo-instruction-scheduling"]],
   "stress_instruction_scheduling": [["--turbo-stress-instruction-scheduling"]],
   "wasm_write_protect_code": [["--wasm-write-protect-code-memory"]],
@@ -58,10 +56,9 @@ INCOMPATIBLE_FLAGS_PER_VARIANT = {
   "slow_path": ["--no-force-slow-path"],
   "stress_concurrent_allocation": ["--single-threaded-gc", "--predictable"],
   "stress_concurrent_inlining": ["--single-threaded", "--predictable",
-                                 "--turboprop", "--lazy-feedback-allocation",
+                                 "--lazy-feedback-allocation",
                                  "--assert-types",
                                  "--no-concurrent-recompilation"],
-  "turboprop": ["--stress_concurrent_inlining"],
   # The fast API tests initialize an embedder object that never needs to be
   # serialized to the snapshot, so we don't have a
   # SerializeInternalFieldsCallback for it, so they are incompatible with
@@ -98,7 +95,6 @@ INCOMPATIBLE_FLAGS_PER_BUILD_VARIABLE = {
                   "--stress-concurrent-allocation",
                   "--stress-concurrent-inlining"],
   "dict_property_const_tracking": [
-                  "--turboprop",
                   "--stress-concurrent-inlining"],
 }
 
diff --git a/tools/testrunner/standard_runner.py b/tools/testrunner/standard_runner.py
index 08f17e77216..eed75274539 100755
--- a/tools/testrunner/standard_runner.py
+++ b/tools/testrunner/standard_runner.py
@@ -46,7 +46,7 @@ VARIANT_ALIASES = {
   # Shortcut for the two above ('more' first - it has the longer running tests)
   'exhaustive': MORE_VARIANTS + VARIANTS,
   # Additional variants, run on a subset of bots.
-  'extra': ['nooptimization', 'future', 'no_wasm_traps', 'turboprop',
+  'extra': ['nooptimization', 'future', 'no_wasm_traps',
             'instruction_scheduling', 'always_sparkplug'],
 }
 
-- 
2.35.1

