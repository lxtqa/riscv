From d91e7905a3a5022f37f1a1f2a96c9d5db9e08519 Mon Sep 17 00:00:00 2001
From: Nico Hartmann <nicohartmann@chromium.org>
Date: Mon, 11 Sep 2023 13:48:09 +0200
Subject: [PATCH] [compiler] Generalize InstructionSelectorT for Turboshaft
 (part 16)

Introduce --turboshaft-wasm-instruction-selection as a temporary flag
to enable the new instruction selection for wasm in isolation.
Support a number of wasm instructions in the new selector.

Drive-by: Fix a few missing cases of Load and Store (in particular
protected loads).

Bug: v8:12783
Change-Id: I4c0ddfc5f6b07f19b7b4a78958d5042de94460db
Reviewed-on: https://chromium-review.googlesource.com/c/v8/v8/+/4853563
Reviewed-by: Darius Mercadier <dmercadier@chromium.org>
Commit-Queue: Nico Hartmann <nicohartmann@chromium.org>
Reviewed-by: Andreas Haas <ahaas@chromium.org>
Cr-Commit-Position: refs/heads/main@{#89897}
---
 .../backend/arm/instruction-selector-arm.cc   |  41 ++-
 .../arm64/instruction-selector-arm64.cc       |  74 ++++--
 .../backend/ia32/instruction-selector-ia32.cc |  41 ++-
 .../backend/instruction-selector-adapter.h    | 112 +++++++-
 src/compiler/backend/instruction-selector.cc  | 139 +++++++---
 src/compiler/backend/instruction-selector.h   |  28 +-
 .../backend/x64/instruction-selector-x64.cc   | 245 +++++++++++++-----
 src/compiler/pipeline.cc                      |  58 +++--
 src/compiler/turboshaft/operations.h          |   1 +
 src/flags/flag-definitions.h                  |   3 +
 10 files changed, 541 insertions(+), 201 deletions(-)

diff --git a/src/compiler/backend/arm/instruction-selector-arm.cc b/src/compiler/backend/arm/instruction-selector-arm.cc
index f9a7e144f1d..486ae29b67c 100644
--- a/src/compiler/backend/arm/instruction-selector-arm.cc
+++ b/src/compiler/backend/arm/instruction-selector-arm.cc
@@ -2726,9 +2726,16 @@ void InstructionSelectorT<Adapter>::VisitWord32AtomicStore(node_t node) {
   }
 }
 
-template <typename Adapter>
-void InstructionSelectorT<Adapter>::VisitWord32AtomicExchange(Node* node) {
-  ArmOperandGeneratorT<Adapter> g(this);
+template <>
+void InstructionSelectorT<TurboshaftAdapter>::VisitWord32AtomicExchange(
+    node_t node) {
+  UNIMPLEMENTED();
+}
+
+template <>
+void InstructionSelectorT<TurbofanAdapter>::VisitWord32AtomicExchange(
+    Node* node) {
+  ArmOperandGeneratorT<TurbofanAdapter> g(this);
   Node* base = node->InputAt(0);
   Node* index = node->InputAt(1);
   Node* value = node->InputAt(2);
@@ -2761,10 +2768,16 @@ void InstructionSelectorT<Adapter>::VisitWord32AtomicExchange(Node* node) {
   Emit(code, 1, outputs, input_count, inputs, arraysize(temps), temps);
 }
 
-template <typename Adapter>
-void InstructionSelectorT<Adapter>::VisitWord32AtomicCompareExchange(
+template <>
+void InstructionSelectorT<TurboshaftAdapter>::VisitWord32AtomicCompareExchange(
+    node_t node) {
+  UNIMPLEMENTED();
+}
+
+template <>
+void InstructionSelectorT<TurbofanAdapter>::VisitWord32AtomicCompareExchange(
     Node* node) {
-  ArmOperandGeneratorT<Adapter> g(this);
+  ArmOperandGeneratorT<TurbofanAdapter> g(this);
   Node* base = node->InputAt(0);
   Node* index = node->InputAt(1);
   Node* old_value = node->InputAt(2);
@@ -2844,12 +2857,16 @@ void InstructionSelectorT<TurbofanAdapter>::VisitWord32AtomicBinaryOperation(
   Emit(code, 1, outputs, input_count, inputs, arraysize(temps), temps);
 }
 
-#define VISIT_ATOMIC_BINOP(op)                                            \
-  template <typename Adapter>                                             \
-  void InstructionSelectorT<Adapter>::VisitWord32Atomic##op(Node* node) { \
-    VisitWord32AtomicBinaryOperation(                                     \
-        node, kAtomic##op##Int8, kAtomic##op##Uint8, kAtomic##op##Int16,  \
-        kAtomic##op##Uint16, kAtomic##op##Word32);                        \
+#define VISIT_ATOMIC_BINOP(op)                                             \
+  template <typename Adapter>                                              \
+  void InstructionSelectorT<Adapter>::VisitWord32Atomic##op(node_t node) { \
+    if constexpr (Adapter::IsTurboshaft) {                                 \
+      UNIMPLEMENTED();                                                     \
+    } else {                                                               \
+      VisitWord32AtomicBinaryOperation(                                    \
+          node, kAtomic##op##Int8, kAtomic##op##Uint8, kAtomic##op##Int16, \
+          kAtomic##op##Uint16, kAtomic##op##Word32);                       \
+    }                                                                      \
   }
 VISIT_ATOMIC_BINOP(Add)
 VISIT_ATOMIC_BINOP(Sub)
diff --git a/src/compiler/backend/arm64/instruction-selector-arm64.cc b/src/compiler/backend/arm64/instruction-selector-arm64.cc
index 2225f726707..6c23bb1e49d 100644
--- a/src/compiler/backend/arm64/instruction-selector-arm64.cc
+++ b/src/compiler/backend/arm64/instruction-selector-arm64.cc
@@ -4219,8 +4219,15 @@ void InstructionSelectorT<Adapter>::VisitWord64AtomicStore(node_t node) {
   VisitAtomicStore(this, node, AtomicWidth::kWord64);
 }
 
-template <typename Adapter>
-void InstructionSelectorT<Adapter>::VisitWord32AtomicExchange(Node* node) {
+template <>
+void InstructionSelectorT<TurboshaftAdapter>::VisitWord32AtomicExchange(
+    node_t node) {
+  UNIMPLEMENTED();
+}
+
+template <>
+void InstructionSelectorT<TurbofanAdapter>::VisitWord32AtomicExchange(
+    Node* node) {
   ArchOpcode opcode;
   AtomicOpParameters params = AtomicOpParametersOf(node->op());
   if (params.type() == MachineType::Int8()) {
@@ -4240,8 +4247,15 @@ void InstructionSelectorT<Adapter>::VisitWord32AtomicExchange(Node* node) {
   VisitAtomicExchange(this, node, opcode, AtomicWidth::kWord32, params.kind());
 }
 
-template <typename Adapter>
-void InstructionSelectorT<Adapter>::VisitWord64AtomicExchange(Node* node) {
+template <>
+void InstructionSelectorT<TurboshaftAdapter>::VisitWord64AtomicExchange(
+    node_t node) {
+  UNIMPLEMENTED();
+}
+
+template <>
+void InstructionSelectorT<TurbofanAdapter>::VisitWord64AtomicExchange(
+    Node* node) {
   ArchOpcode opcode;
   AtomicOpParameters params = AtomicOpParametersOf(node->op());
   if (params.type() == MachineType::Uint8()) {
@@ -4258,8 +4272,14 @@ void InstructionSelectorT<Adapter>::VisitWord64AtomicExchange(Node* node) {
   VisitAtomicExchange(this, node, opcode, AtomicWidth::kWord64, params.kind());
 }
 
-template <typename Adapter>
-void InstructionSelectorT<Adapter>::VisitWord32AtomicCompareExchange(
+template <>
+void InstructionSelectorT<TurboshaftAdapter>::VisitWord32AtomicCompareExchange(
+    node_t node) {
+  UNIMPLEMENTED();
+}
+
+template <>
+void InstructionSelectorT<TurbofanAdapter>::VisitWord32AtomicCompareExchange(
     Node* node) {
   ArchOpcode opcode;
   AtomicOpParameters params = AtomicOpParametersOf(node->op());
@@ -4281,8 +4301,14 @@ void InstructionSelectorT<Adapter>::VisitWord32AtomicCompareExchange(
                              params.kind());
 }
 
-template <typename Adapter>
-void InstructionSelectorT<Adapter>::VisitWord64AtomicCompareExchange(
+template <>
+void InstructionSelectorT<TurboshaftAdapter>::VisitWord64AtomicCompareExchange(
+    node_t node) {
+  UNIMPLEMENTED();
+}
+
+template <>
+void InstructionSelectorT<TurbofanAdapter>::VisitWord64AtomicCompareExchange(
     Node* node) {
   ArchOpcode opcode;
   AtomicOpParameters params = AtomicOpParametersOf(node->op());
@@ -4328,12 +4354,16 @@ void InstructionSelectorT<Adapter>::VisitWord32AtomicBinaryOperation(
   }
 }
 
-#define VISIT_ATOMIC_BINOP(op)                                            \
-  template <typename Adapter>                                             \
-  void InstructionSelectorT<Adapter>::VisitWord32Atomic##op(Node* node) { \
-    VisitWord32AtomicBinaryOperation(                                     \
-        node, kAtomic##op##Int8, kAtomic##op##Uint8, kAtomic##op##Int16,  \
-        kAtomic##op##Uint16, kAtomic##op##Word32);                        \
+#define VISIT_ATOMIC_BINOP(op)                                             \
+  template <typename Adapter>                                              \
+  void InstructionSelectorT<Adapter>::VisitWord32Atomic##op(node_t node) { \
+    if constexpr (Adapter::IsTurboshaft) {                                 \
+      UNIMPLEMENTED();                                                     \
+    } else {                                                               \
+      VisitWord32AtomicBinaryOperation(                                    \
+          node, kAtomic##op##Int8, kAtomic##op##Uint8, kAtomic##op##Int16, \
+          kAtomic##op##Uint16, kAtomic##op##Word32);                       \
+    }                                                                      \
   }
 VISIT_ATOMIC_BINOP(Add)
 VISIT_ATOMIC_BINOP(Sub)
@@ -4366,12 +4396,16 @@ void InstructionSelectorT<Adapter>::VisitWord64AtomicBinaryOperation(
   }
 }
 
-#define VISIT_ATOMIC_BINOP(op)                                                 \
-  template <typename Adapter>                                                  \
-  void InstructionSelectorT<Adapter>::VisitWord64Atomic##op(Node* node) {      \
-    VisitWord64AtomicBinaryOperation(node, kAtomic##op##Uint8,                 \
-                                     kAtomic##op##Uint16, kAtomic##op##Word32, \
-                                     kArm64Word64Atomic##op##Uint64);          \
+#define VISIT_ATOMIC_BINOP(op)                                                \
+  template <typename Adapter>                                                 \
+  void InstructionSelectorT<Adapter>::VisitWord64Atomic##op(node_t node) {    \
+    if constexpr (Adapter::IsTurboshaft) {                                    \
+      UNIMPLEMENTED();                                                        \
+    } else {                                                                  \
+      VisitWord64AtomicBinaryOperation(                                       \
+          node, kAtomic##op##Uint8, kAtomic##op##Uint16, kAtomic##op##Word32, \
+          kArm64Word64Atomic##op##Uint64);                                    \
+    }                                                                         \
   }
 VISIT_ATOMIC_BINOP(Add)
 VISIT_ATOMIC_BINOP(Sub)
diff --git a/src/compiler/backend/ia32/instruction-selector-ia32.cc b/src/compiler/backend/ia32/instruction-selector-ia32.cc
index 630a9fd5d9f..533909fc909 100644
--- a/src/compiler/backend/ia32/instruction-selector-ia32.cc
+++ b/src/compiler/backend/ia32/instruction-selector-ia32.cc
@@ -2482,9 +2482,16 @@ void InstructionSelectorT<Adapter>::VisitWord32AtomicStore(node_t node) {
   }
 }
 
-template <typename Adapter>
-void InstructionSelectorT<Adapter>::VisitWord32AtomicExchange(Node* node) {
-  IA32OperandGeneratorT<Adapter> g(this);
+template <>
+void InstructionSelectorT<TurboshaftAdapter>::VisitWord32AtomicExchange(
+    node_t node) {
+  UNIMPLEMENTED();
+}
+
+template <>
+void InstructionSelectorT<TurbofanAdapter>::VisitWord32AtomicExchange(
+    node_t node) {
+  IA32OperandGeneratorT<TurbofanAdapter> g(this);
   MachineType type = AtomicOpType(node->op());
   ArchOpcode opcode;
   if (type == MachineType::Int8()) {
@@ -2503,10 +2510,16 @@ void InstructionSelectorT<Adapter>::VisitWord32AtomicExchange(Node* node) {
   VisitAtomicExchange(this, node, opcode, type.representation());
 }
 
-template <typename Adapter>
-void InstructionSelectorT<Adapter>::VisitWord32AtomicCompareExchange(
+template <>
+void InstructionSelectorT<TurboshaftAdapter>::VisitWord32AtomicCompareExchange(
+    node_t node) {
+  UNIMPLEMENTED();
+}
+
+template <>
+void InstructionSelectorT<TurbofanAdapter>::VisitWord32AtomicCompareExchange(
     Node* node) {
-  IA32OperandGeneratorT<Adapter> g(this);
+  IA32OperandGeneratorT<TurbofanAdapter> g(this);
   Node* base = node->InputAt(0);
   Node* index = node->InputAt(1);
   Node* old_value = node->InputAt(2);
@@ -2566,12 +2579,16 @@ void InstructionSelectorT<Adapter>::VisitWord32AtomicBinaryOperation(
   }
 }
 
-#define VISIT_ATOMIC_BINOP(op)                                            \
-  template <typename Adapter>                                             \
-  void InstructionSelectorT<Adapter>::VisitWord32Atomic##op(Node* node) { \
-    VisitWord32AtomicBinaryOperation(                                     \
-        node, kAtomic##op##Int8, kAtomic##op##Uint8, kAtomic##op##Int16,  \
-        kAtomic##op##Uint16, kAtomic##op##Word32);                        \
+#define VISIT_ATOMIC_BINOP(op)                                             \
+  template <typename Adapter>                                              \
+  void InstructionSelectorT<Adapter>::VisitWord32Atomic##op(node_t node) { \
+    if constexpr (Adapter::IsTurboshaft) {                                 \
+      UNIMPLEMENTED();                                                     \
+    } else {                                                               \
+      VisitWord32AtomicBinaryOperation(                                    \
+          node, kAtomic##op##Int8, kAtomic##op##Uint8, kAtomic##op##Int16, \
+          kAtomic##op##Uint16, kAtomic##op##Word32);                       \
+    }                                                                      \
   }
 VISIT_ATOMIC_BINOP(Add)
 VISIT_ATOMIC_BINOP(Sub)
diff --git a/src/compiler/backend/instruction-selector-adapter.h b/src/compiler/backend/instruction-selector-adapter.h
index 04228a57969..d36bacbf158 100644
--- a/src/compiler/backend/instruction-selector-adapter.h
+++ b/src/compiler/backend/instruction-selector-adapter.h
@@ -182,16 +182,25 @@ struct TurbofanAdapter {
 
   class LoadView {
    public:
-    explicit LoadView(node_t node) : node_(node) {
-      DCHECK(node_->opcode() == IrOpcode::kLoad ||
-             node_->opcode() == IrOpcode::kLoadImmutable ||
-             node_->opcode() == IrOpcode::kProtectedLoad ||
-             node_->opcode() == IrOpcode::kLoadTrapOnNull);
-    }
+    explicit LoadView(node_t node) : node_(node) {}
 
     LoadRepresentation loaded_rep() const {
       return LoadRepresentationOf(node_->op());
     }
+    bool is_protected(bool* traps_on_null) const {
+      if (node_->opcode() == IrOpcode::kLoadTrapOnNull) {
+        *traps_on_null = true;
+        return true;
+      }
+      *traps_on_null = false;
+      return node_->opcode() == IrOpcode::kProtectedLoad ||
+             (is_atomic() && AtomicLoadParametersOf(node_->op()).kind() ==
+                                 MemoryAccessKind::kProtected);
+    }
+    bool is_atomic() const {
+      return node_->opcode() == IrOpcode::kWord32AtomicLoad ||
+             node_->opcode() == IrOpcode::kWord64AtomicLoad;
+    }
 
     node_t base() const { return node_->InputAt(0); }
     node_t index() const { return node_->InputAt(1); }
@@ -316,6 +325,46 @@ struct TurbofanAdapter {
     node_t node_;
   };
 
+  class AtomicRMWView {
+   public:
+    explicit AtomicRMWView(node_t node) : node_(node) {
+      DCHECK(node_->opcode() == IrOpcode::kWord32AtomicAdd ||
+             node_->opcode() == IrOpcode::kWord32AtomicSub ||
+             node_->opcode() == IrOpcode::kWord32AtomicAnd ||
+             node_->opcode() == IrOpcode::kWord32AtomicOr ||
+             node_->opcode() == IrOpcode::kWord32AtomicXor ||
+             node_->opcode() == IrOpcode::kWord32AtomicExchange ||
+             node_->opcode() == IrOpcode::kWord32AtomicCompareExchange ||
+             node_->opcode() == IrOpcode::kWord64AtomicAdd ||
+             node_->opcode() == IrOpcode::kWord64AtomicSub ||
+             node_->opcode() == IrOpcode::kWord64AtomicAnd ||
+             node_->opcode() == IrOpcode::kWord64AtomicOr ||
+             node_->opcode() == IrOpcode::kWord64AtomicXor ||
+             node_->opcode() == IrOpcode::kWord64AtomicExchange ||
+             node_->opcode() == IrOpcode::kWord64AtomicCompareExchange);
+    }
+
+    node_t base() const { return node_->InputAt(0); }
+    node_t index() const { return node_->InputAt(1); }
+    node_t value() const {
+      if (node_->opcode() == IrOpcode::kWord32AtomicCompareExchange ||
+          node_->opcode() == IrOpcode::kWord64AtomicCompareExchange) {
+        return node_->InputAt(3);
+      }
+      return node_->InputAt(2);
+    }
+    node_t expected() const {
+      DCHECK(node_->opcode() == IrOpcode::kWord32AtomicCompareExchange ||
+             node_->opcode() == IrOpcode::kWord64AtomicCompareExchange);
+      return node_->InputAt(2);
+    }
+
+    operator node_t() const { return node_; }
+
+   private:
+    node_t node_;
+  };
+
   bool is_constant(node_t node) const {
     switch (node->opcode()) {
       case IrOpcode::kInt32Constant:
@@ -336,7 +385,11 @@ struct TurbofanAdapter {
     return node->opcode() == IrOpcode::kLoad ||
            node->opcode() == IrOpcode::kLoadImmutable ||
            node->opcode() == IrOpcode::kProtectedLoad ||
-           node->opcode() == IrOpcode::kLoadTrapOnNull;
+           node->opcode() == IrOpcode::kLoadTrapOnNull ||
+           node->opcode() == IrOpcode::kWord32AtomicLoad ||
+           node->opcode() == IrOpcode::kWord64AtomicLoad ||
+           node->opcode() == IrOpcode::kLoadTransform ||
+           node->opcode() == IrOpcode::kF64x2PromoteLowF32x4;
   }
   ConstantView constant_view(node_t node) const { return ConstantView{node}; }
   CallView call_view(node_t node) { return CallView{node}; }
@@ -348,6 +401,7 @@ struct TurbofanAdapter {
   }
   StoreView store_view(node_t node) { return StoreView(node); }
   DeoptimizeView deoptimize_view(node_t node) { return DeoptimizeView(node); }
+  AtomicRMWView atomic_rmw_view(node_t node) { return AtomicRMWView(node); }
 
   block_t block(schedule_t schedule, node_t node) const {
     return schedule->block(node);
@@ -642,6 +696,14 @@ struct TurboshaftAdapter : public turboshaft::OperationMatcher {
     LoadRepresentation loaded_rep() const {
       return op_->loaded_rep.ToMachineType();
     }
+    bool is_protected(bool* traps_on_null) const {
+      if (op_->kind.with_trap_handler) {
+        *traps_on_null = op_->kind.tagged_base;
+        return true;
+      }
+      return false;
+    }
+    bool is_atomic() const { return op_->kind.is_atomic; }
 
     node_t base() const { return op_->base(); }
     node_t index() const { return op_->index(); }
@@ -681,11 +743,12 @@ struct TurboshaftAdapter : public turboshaft::OperationMatcher {
     }
     base::Optional<AtomicMemoryOrder> memory_order() const {
       // TODO(nicohartmann@): Currently we only have non-atomic stores.
+      DCHECK(!op_->kind.is_atomic);
       return base::nullopt;
     }
     MemoryAccessKind access_kind() const {
-      // TODO(nicohartmann@): Currently we only have non-atomic stores.
-      return MemoryAccessKind::kNormal;
+      return op_->kind.with_trap_handler ? MemoryAccessKind::kProtected
+                                         : MemoryAccessKind::kNormal;
     }
 
     node_t base() const { return op_->base(); }
@@ -708,7 +771,9 @@ struct TurboshaftAdapter : public turboshaft::OperationMatcher {
       return op_->element_size_log2;
     }
 
-    bool is_store_trap_on_null() const { return false; }
+    bool is_store_trap_on_null() const {
+      return op_->kind.with_trap_handler && op_->kind.tagged_base;
+    }
 
     operator node_t() const { return node_; }
 
@@ -719,8 +784,7 @@ struct TurboshaftAdapter : public turboshaft::OperationMatcher {
 
   class DeoptimizeView {
    public:
-    explicit DeoptimizeView(const turboshaft::Graph* graph, node_t node)
-        : node_(node) {
+    DeoptimizeView(const turboshaft::Graph* graph, node_t node) : node_(node) {
       const auto& op = graph->Get(node);
       if (op.Is<turboshaft::DeoptimizeOp>()) {
         deoptimize_op_ = &op.Cast<turboshaft::DeoptimizeOp>();
@@ -761,6 +825,27 @@ struct TurboshaftAdapter : public turboshaft::OperationMatcher {
     const DeoptimizeParameters* parameters_;
   };
 
+  class AtomicRMWView {
+   public:
+    AtomicRMWView(const turboshaft::Graph* graph, node_t node) : node_(node) {
+      op_ = &graph->Get(node).Cast<turboshaft::AtomicRMWOp>();
+    }
+
+    node_t base() const { return op_->base(); }
+    node_t index() const { return op_->index(); }
+    node_t value() const { return op_->value(); }
+    node_t expected() const {
+      DCHECK_EQ(op_->bin_op, turboshaft::AtomicRMWOp::BinOp::kCompareExchange);
+      return op_->expected();
+    }
+
+    operator node_t() const { return node_; }
+
+   private:
+    node_t node_;
+    const turboshaft::AtomicRMWOp* op_;
+  };
+
   bool is_constant(node_t node) const {
     return graph_->Get(node).Is<turboshaft::ConstantOp>();
   }
@@ -781,6 +866,9 @@ struct TurboshaftAdapter : public turboshaft::OperationMatcher {
   DeoptimizeView deoptimize_view(node_t node) {
     return DeoptimizeView(graph_, node);
   }
+  AtomicRMWView atomic_rmw_view(node_t node) {
+    return AtomicRMWView(graph_, node);
+  }
 
   turboshaft::Graph* turboshaft_graph() const { return graph_; }
 
diff --git a/src/compiler/backend/instruction-selector.cc b/src/compiler/backend/instruction-selector.cc
index d3bafbace72..0bfa966b3e7 100644
--- a/src/compiler/backend/instruction-selector.cc
+++ b/src/compiler/backend/instruction-selector.cc
@@ -1546,13 +1546,15 @@ bool InstructionSelectorT<Adapter>::IsSourcePositionUsed(node_t node) {
   if constexpr (Adapter::IsTurboshaft) {
     using namespace turboshaft;  // NOLINT(build/namespaces)
     const Operation& operation = this->Get(node);
-    if (operation.Is<TrapIfOp>()) return true;
+    // DidntThrow is where the actual call is generated.
+    if (operation.Is<DidntThrowOp>()) return true;
     if (const LoadOp* load = operation.TryCast<LoadOp>()) {
       return load->kind.with_trap_handler;
     }
     if (const StoreOp* store = operation.TryCast<StoreOp>()) {
       return store->kind.with_trap_handler;
     }
+    if (operation.Is<TrapIfOp>()) return true;
     return false;
   } else {
     switch (node->opcode()) {
@@ -2009,42 +2011,14 @@ void InstructionSelectorT<Adapter>::VisitWord64AtomicLoad(Node* node) {
 }
 
 VISIT_UNSUPPORTED_OP(Word64AtomicStore)
+VISIT_UNSUPPORTED_OP(Word64AtomicAdd)
+VISIT_UNSUPPORTED_OP(Word64AtomicSub)
+VISIT_UNSUPPORTED_OP(Word64AtomicAnd)
+VISIT_UNSUPPORTED_OP(Word64AtomicOr)
+VISIT_UNSUPPORTED_OP(Word64AtomicXor)
+VISIT_UNSUPPORTED_OP(Word64AtomicExchange)
+VISIT_UNSUPPORTED_OP(Word64AtomicCompareExchange)
 
-template <typename Adapter>
-void InstructionSelectorT<Adapter>::VisitWord64AtomicAdd(Node* node) {
-  UNIMPLEMENTED();
-}
-
-template <typename Adapter>
-void InstructionSelectorT<Adapter>::VisitWord64AtomicSub(Node* node) {
-  UNIMPLEMENTED();
-}
-
-template <typename Adapter>
-void InstructionSelectorT<Adapter>::VisitWord64AtomicAnd(Node* node) {
-  UNIMPLEMENTED();
-}
-
-template <typename Adapter>
-void InstructionSelectorT<Adapter>::VisitWord64AtomicOr(Node* node) {
-  UNIMPLEMENTED();
-}
-
-template <typename Adapter>
-void InstructionSelectorT<Adapter>::VisitWord64AtomicXor(Node* node) {
-  UNIMPLEMENTED();
-}
-
-template <typename Adapter>
-void InstructionSelectorT<Adapter>::VisitWord64AtomicExchange(Node* node) {
-  UNIMPLEMENTED();
-}
-
-template <typename Adapter>
-void InstructionSelectorT<Adapter>::VisitWord64AtomicCompareExchange(
-    Node* node) {
-  UNIMPLEMENTED();
-}
 #endif  // !V8_TARGET_ARCH_X64 && !V8_TARGET_ARCH_ARM64 && !V8_TARGET_ARCH_PPC64
         // !V8_TARGET_ARCH_MIPS64 && !V8_TARGET_ARCH_S390 &&
         // !V8_TARGET_ARCH_RISCV64 && !V8_TARGET_ARCH_LOONG64
@@ -4829,13 +4803,53 @@ void InstructionSelectorT<TurboshaftAdapter>::VisitNode(
       UNREACHABLE();
     }
     case Opcode::kLoad: {
+      const LoadOp& load = op.Cast<LoadOp>();
       MachineRepresentation rep =
-          op.Cast<LoadOp>().loaded_rep.ToMachineType().representation();
+          load.loaded_rep.ToMachineType().representation();
       MarkAsRepresentation(rep, node);
-      return VisitLoad(node);
+      if (load.kind.maybe_unaligned) {
+        DCHECK(!load.kind.with_trap_handler);
+        if (rep == MachineRepresentation::kWord8 ||
+            InstructionSelector::AlignmentRequirements()
+                .IsUnalignedLoadSupported(rep)) {
+          return VisitLoad(node);
+        } else {
+          return VisitUnalignedLoad(node);
+        }
+      } else if (load.kind.is_atomic) {
+        UNIMPLEMENTED();
+      } else if (load.kind.with_trap_handler) {
+        DCHECK(!load.kind.maybe_unaligned);
+        return VisitProtectedLoad(node);
+      } else {
+        return VisitLoad(node);
+      }
+      UNREACHABLE();
+    }
+    case Opcode::kStore: {
+      const StoreOp& store = op.Cast<StoreOp>();
+      MachineRepresentation rep =
+          store.stored_rep.ToMachineType().representation();
+      if (store.kind.maybe_unaligned) {
+        DCHECK(!store.kind.with_trap_handler);
+        DCHECK_EQ(store.write_barrier, WriteBarrierKind::kNoWriteBarrier);
+        if (rep == MachineRepresentation::kWord8 ||
+            InstructionSelector::AlignmentRequirements()
+                .IsUnalignedStoreSupported(rep)) {
+          return VisitStore(node);
+        } else {
+          return VisitUnalignedStore(node);
+        }
+      } else if (store.kind.is_atomic) {
+        UNIMPLEMENTED();
+      } else if (store.kind.with_trap_handler) {
+        DCHECK(!store.kind.maybe_unaligned);
+        return VisitProtectedStore(node);
+      } else {
+        return VisitStore(node);
+      }
+      UNREACHABLE();
     }
-    case Opcode::kStore:
-      return VisitStore(node);
     case Opcode::kTaggedBitcast: {
       const TaggedBitcastOp& cast = op.Cast<TaggedBitcastOp>();
       if (cast.from == RegisterRepresentation::Tagged() &&
@@ -4922,14 +4936,55 @@ void InstructionSelectorT<TurboshaftAdapter>::VisitNode(
     }
     case Opcode::kBitcastWord32PairToFloat64:
       return VisitBitcastWord32PairToFloat64(node);
+    case Opcode::kAtomicRMW: {
+      const AtomicRMWOp& atomic_op = op.Cast<AtomicRMWOp>();
+      MarkAsRepresentation(atomic_op.input_rep.ToRegisterRepresentation(),
+                           node);
+      if (atomic_op.result_rep == Rep::Word32()) {
+        switch (atomic_op.bin_op) {
+          case AtomicRMWOp::BinOp::kAdd:
+            return VisitWord32AtomicAdd(node);
+          case AtomicRMWOp::BinOp::kSub:
+            return VisitWord32AtomicSub(node);
+          case AtomicRMWOp::BinOp::kAnd:
+            return VisitWord32AtomicAnd(node);
+          case AtomicRMWOp::BinOp::kOr:
+            return VisitWord32AtomicOr(node);
+          case AtomicRMWOp::BinOp::kXor:
+            return VisitWord32AtomicXor(node);
+          case AtomicRMWOp::BinOp::kExchange:
+            return VisitWord32AtomicExchange(node);
+          case AtomicRMWOp::BinOp::kCompareExchange:
+            return VisitWord32AtomicCompareExchange(node);
+        }
+      } else {
+        DCHECK_EQ(atomic_op.result_rep, Rep::Word64());
+        switch (atomic_op.bin_op) {
+          case AtomicRMWOp::BinOp::kAdd:
+            return VisitWord64AtomicAdd(node);
+          case AtomicRMWOp::BinOp::kSub:
+            return VisitWord64AtomicSub(node);
+          case AtomicRMWOp::BinOp::kAnd:
+            return VisitWord64AtomicAnd(node);
+          case AtomicRMWOp::BinOp::kOr:
+            return VisitWord64AtomicOr(node);
+          case AtomicRMWOp::BinOp::kXor:
+            return VisitWord64AtomicXor(node);
+          case AtomicRMWOp::BinOp::kExchange:
+            return VisitWord64AtomicExchange(node);
+          case AtomicRMWOp::BinOp::kCompareExchange:
+            return VisitWord64AtomicCompareExchange(node);
+        }
+      }
+      UNREACHABLE();
+    }
 
 #define UNIMPLEMENTED_CASE(op) case Opcode::k##op:
       TURBOSHAFT_WASM_OPERATION_LIST(UNIMPLEMENTED_CASE)
       TURBOSHAFT_SIMD_OPERATION_LIST(UNIMPLEMENTED_CASE)
 #undef UNIMPLEMENTED_CASE
     case Opcode::kAtomicWord32Pair:
-    case Opcode::kMemoryBarrier:
-    case Opcode::kAtomicRMW: {
+    case Opcode::kMemoryBarrier: {
       const std::string op_string = op.ToString();
       PrintF("\033[31mNo ISEL support for: %s\033[m\n", op_string.c_str());
       FATAL("Unexpected operation #%d:%s", node.id(), op_string.c_str());
diff --git a/src/compiler/backend/instruction-selector.h b/src/compiler/backend/instruction-selector.h
index 3e94f1ad063..a6b9451129c 100644
--- a/src/compiler/backend/instruction-selector.h
+++ b/src/compiler/backend/instruction-selector.h
@@ -911,17 +911,24 @@ class InstructionSelectorT final : public Adapter {
   DECLARE_GENERATOR_T(LoadFramePointer)
   DECLARE_GENERATOR_T(LoadParentFramePointer)
   DECLARE_GENERATOR_T(ProtectedLoad)
+  DECLARE_GENERATOR_T(Word32AtomicAdd)
+  DECLARE_GENERATOR_T(Word32AtomicSub)
+  DECLARE_GENERATOR_T(Word32AtomicAnd)
+  DECLARE_GENERATOR_T(Word32AtomicOr)
+  DECLARE_GENERATOR_T(Word32AtomicXor)
+  DECLARE_GENERATOR_T(Word32AtomicExchange)
+  DECLARE_GENERATOR_T(Word32AtomicCompareExchange)
+  DECLARE_GENERATOR_T(Word64AtomicAdd)
+  DECLARE_GENERATOR_T(Word64AtomicSub)
+  DECLARE_GENERATOR_T(Word64AtomicAnd)
+  DECLARE_GENERATOR_T(Word64AtomicOr)
+  DECLARE_GENERATOR_T(Word64AtomicXor)
+  DECLARE_GENERATOR_T(Word64AtomicExchange)
+  DECLARE_GENERATOR_T(Word64AtomicCompareExchange)
 #undef DECLARE_GENERATOR_T
 
 #define DECLARE_GENERATOR(x) void Visit##x(Node* node);
   DECLARE_GENERATOR(Word32AtomicLoad)
-  DECLARE_GENERATOR(Word32AtomicExchange)
-  DECLARE_GENERATOR(Word32AtomicCompareExchange)
-  DECLARE_GENERATOR(Word32AtomicAdd)
-  DECLARE_GENERATOR(Word32AtomicSub)
-  DECLARE_GENERATOR(Word32AtomicAnd)
-  DECLARE_GENERATOR(Word32AtomicOr)
-  DECLARE_GENERATOR(Word32AtomicXor)
   DECLARE_GENERATOR(Word32AtomicPairLoad)
   DECLARE_GENERATOR(Word32AtomicPairStore)
   DECLARE_GENERATOR(Word32AtomicPairAdd)
@@ -932,13 +939,6 @@ class InstructionSelectorT final : public Adapter {
   DECLARE_GENERATOR(Word32AtomicPairExchange)
   DECLARE_GENERATOR(Word32AtomicPairCompareExchange)
   DECLARE_GENERATOR(Word64AtomicLoad)
-  DECLARE_GENERATOR(Word64AtomicAdd)
-  DECLARE_GENERATOR(Word64AtomicSub)
-  DECLARE_GENERATOR(Word64AtomicAnd)
-  DECLARE_GENERATOR(Word64AtomicOr)
-  DECLARE_GENERATOR(Word64AtomicXor)
-  DECLARE_GENERATOR(Word64AtomicExchange)
-  DECLARE_GENERATOR(Word64AtomicCompareExchange)
   DECLARE_GENERATOR(Simd128ReverseBytes)
   MACHINE_SIMD128_OP_LIST(DECLARE_GENERATOR)
   MACHINE_SIMD256_OP_LIST(DECLARE_GENERATOR)
diff --git a/src/compiler/backend/x64/instruction-selector-x64.cc b/src/compiler/backend/x64/instruction-selector-x64.cc
index c846b523f02..dec91ece15c 100644
--- a/src/compiler/backend/x64/instruction-selector-x64.cc
+++ b/src/compiler/backend/x64/instruction-selector-x64.cc
@@ -1122,17 +1122,13 @@ void InstructionSelectorT<Adapter>::VisitLoad(node_t node, node_t value,
   AddressingMode mode =
       g.GetEffectiveAddressMemoryOperand(value, inputs, &input_count, reg_kind);
   InstructionCode code = opcode | AddressingModeField::encode(mode);
-  if constexpr (Adapter::IsTurboshaft) {
-    // TODO(nicohartmann@): Implement for Turboshaft.
-  } else {
-    if (node->opcode() == IrOpcode::kProtectedLoad ||
-        ((node->opcode() == IrOpcode::kWord32AtomicLoad ||
-          node->opcode() == IrOpcode::kWord64AtomicLoad) &&
-         (AtomicLoadParametersOf(node->op()).kind() ==
-          MemoryAccessKind::kProtected))) {
-      code |= AccessModeField::encode(kMemoryAccessProtectedMemOutOfBounds);
-    } else if (node->opcode() == IrOpcode::kLoadTrapOnNull) {
+  auto load = this->load_view(node);
+  bool traps_on_null;
+  if (load.is_protected(&traps_on_null)) {
+    if (traps_on_null) {
       code |= AccessModeField::encode(kMemoryAccessProtectedNullDereference);
+    } else {
+      code |= AccessModeField::encode(kMemoryAccessProtectedMemOutOfBounds);
     }
   }
   Emit(code, 1, outputs, input_count, inputs, temp_count, temps);
@@ -1154,30 +1150,23 @@ namespace {
 
 // Shared routine for Word32/Word64 Atomic Exchange
 template <typename Adapter>
-void VisitAtomicExchange(InstructionSelectorT<Adapter>* selector, Node* node,
-                         ArchOpcode opcode, AtomicWidth width,
-                         MemoryAccessKind access_kind) {
-  if constexpr (Adapter::IsTurboshaft) {
-    UNIMPLEMENTED();
-  } else {
-    X64OperandGeneratorT<Adapter> g(selector);
-    Node* base = node->InputAt(0);
-    Node* index = node->InputAt(1);
-    Node* value = node->InputAt(2);
-    AddressingMode addressing_mode;
-    InstructionOperand inputs[] = {
-        g.UseUniqueRegister(value), g.UseUniqueRegister(base),
-        g.GetEffectiveIndexOperand(index, &addressing_mode)};
-    InstructionOperand outputs[] = {g.DefineSameAsFirst(node)};
-    InstructionCode code = opcode |
-                           AddressingModeField::encode(addressing_mode) |
-                           AtomicWidthField::encode(width);
-    if (access_kind == MemoryAccessKind::kProtected) {
-      code |= AccessModeField::encode(kMemoryAccessProtectedMemOutOfBounds);
-    }
-    selector->Emit(code, arraysize(outputs), outputs, arraysize(inputs),
-                   inputs);
+void VisitAtomicExchange(InstructionSelectorT<Adapter>* selector,
+                         typename Adapter::node_t node, ArchOpcode opcode,
+                         AtomicWidth width, MemoryAccessKind access_kind) {
+  auto atomic_op = selector->atomic_rmw_view(node);
+  X64OperandGeneratorT<Adapter> g(selector);
+  AddressingMode addressing_mode;
+  InstructionOperand inputs[] = {
+      g.UseUniqueRegister(atomic_op.value()),
+      g.UseUniqueRegister(atomic_op.base()),
+      g.GetEffectiveIndexOperand(atomic_op.index(), &addressing_mode)};
+  InstructionOperand outputs[] = {g.DefineSameAsFirst(node)};
+  InstructionCode code = opcode | AddressingModeField::encode(addressing_mode) |
+                         AtomicWidthField::encode(width);
+  if (access_kind == MemoryAccessKind::kProtected) {
+    code |= AccessModeField::encode(kMemoryAccessProtectedMemOutOfBounds);
   }
+  selector->Emit(code, arraysize(outputs), outputs, arraysize(inputs), inputs);
 }
 
 template <typename Adapter>
@@ -3891,17 +3880,17 @@ void VisitFloat64Compare(InstructionSelectorT<Adapter>* selector,
 }
 
 // Shared routine for Word32/Word64 Atomic Binops
-void VisitAtomicBinop(InstructionSelectorT<TurbofanAdapter>* selector,
-                      Node* node, ArchOpcode opcode, AtomicWidth width,
-                      MemoryAccessKind access_kind) {
-  X64OperandGeneratorT<TurbofanAdapter> g(selector);
-  Node* base = node->InputAt(0);
-  Node* index = node->InputAt(1);
-  Node* value = node->InputAt(2);
+template <typename Adapter>
+void VisitAtomicBinop(InstructionSelectorT<Adapter>* selector,
+                      typename Adapter::node_t node, ArchOpcode opcode,
+                      AtomicWidth width, MemoryAccessKind access_kind) {
+  auto atomic_op = selector->atomic_rmw_view(node);
+  X64OperandGeneratorT<Adapter> g(selector);
   AddressingMode addressing_mode;
   InstructionOperand inputs[] = {
-      g.UseUniqueRegister(value), g.UseUniqueRegister(base),
-      g.GetEffectiveIndexOperand(index, &addressing_mode)};
+      g.UseUniqueRegister(atomic_op.value()),
+      g.UseUniqueRegister(atomic_op.base()),
+      g.GetEffectiveIndexOperand(atomic_op.index(), &addressing_mode)};
   InstructionOperand outputs[] = {g.DefineAsFixed(node, rax)};
   InstructionOperand temps[] = {g.TempRegister()};
   InstructionCode code = opcode | AddressingModeField::encode(addressing_mode) |
@@ -3914,20 +3903,19 @@ void VisitAtomicBinop(InstructionSelectorT<TurbofanAdapter>* selector,
 }
 
 // Shared routine for Word32/Word64 Atomic CmpExchg
-void VisitAtomicCompareExchange(InstructionSelectorT<TurbofanAdapter>* selector,
-                                Node* node, ArchOpcode opcode,
-                                AtomicWidth width,
+template <typename Adapter>
+void VisitAtomicCompareExchange(InstructionSelectorT<Adapter>* selector,
+                                typename Adapter::node_t node,
+                                ArchOpcode opcode, AtomicWidth width,
                                 MemoryAccessKind access_kind) {
-  X64OperandGeneratorT<TurbofanAdapter> g(selector);
-  Node* base = node->InputAt(0);
-  Node* index = node->InputAt(1);
-  Node* old_value = node->InputAt(2);
-  Node* new_value = node->InputAt(3);
+  auto atomic_op = selector->atomic_rmw_view(node);
+  X64OperandGeneratorT<Adapter> g(selector);
   AddressingMode addressing_mode;
   InstructionOperand inputs[] = {
-      g.UseFixed(old_value, rax), g.UseUniqueRegister(new_value),
-      g.UseUniqueRegister(base),
-      g.GetEffectiveIndexOperand(index, &addressing_mode)};
+      g.UseFixed(atomic_op.expected(), rax),
+      g.UseUniqueRegister(atomic_op.value()),
+      g.UseUniqueRegister(atomic_op.base()),
+      g.GetEffectiveIndexOperand(atomic_op.index(), &addressing_mode)};
   InstructionOperand outputs[] = {g.DefineAsFixed(node, rax)};
   InstructionCode code = opcode | AddressingModeField::encode(addressing_mode) |
                          AtomicWidthField::encode(width);
@@ -4627,8 +4615,9 @@ void InstructionSelectorT<Adapter>::VisitWord64AtomicStore(node_t node) {
   VisitStoreCommon(this, store);
 }
 
-template <typename Adapter>
-void InstructionSelectorT<Adapter>::VisitWord32AtomicExchange(Node* node) {
+template <>
+void InstructionSelectorT<TurbofanAdapter>::VisitWord32AtomicExchange(
+    Node* node) {
   AtomicOpParameters params = AtomicOpParametersOf(node->op());
   ArchOpcode opcode;
   if (params.type() == MachineType::Int8()) {
@@ -4648,8 +4637,33 @@ void InstructionSelectorT<Adapter>::VisitWord32AtomicExchange(Node* node) {
   VisitAtomicExchange(this, node, opcode, AtomicWidth::kWord32, params.kind());
 }
 
-template <typename Adapter>
-void InstructionSelectorT<Adapter>::VisitWord64AtomicExchange(Node* node) {
+template <>
+void InstructionSelectorT<TurboshaftAdapter>::VisitWord32AtomicExchange(
+    node_t node) {
+  using namespace turboshaft;  // NOLINT(build/namespaces)
+  const AtomicRMWOp& atomic_op = this->Get(node).template Cast<AtomicRMWOp>();
+  ArchOpcode opcode;
+  if (atomic_op.input_rep == MemoryRepresentation::Int8()) {
+    opcode = kAtomicExchangeInt8;
+  } else if (atomic_op.input_rep == MemoryRepresentation::Uint8()) {
+    opcode = kAtomicExchangeUint8;
+  } else if (atomic_op.input_rep == MemoryRepresentation::Int16()) {
+    opcode = kAtomicExchangeInt16;
+  } else if (atomic_op.input_rep == MemoryRepresentation::Uint16()) {
+    opcode = kAtomicExchangeUint16;
+  } else if (atomic_op.input_rep == MemoryRepresentation::Int32() ||
+             atomic_op.input_rep == MemoryRepresentation::Uint32()) {
+    opcode = kAtomicExchangeWord32;
+  } else {
+    UNREACHABLE();
+  }
+  VisitAtomicExchange(this, node, opcode, AtomicWidth::kWord32,
+                      atomic_op.memory_access_kind);
+}
+
+template <>
+void InstructionSelectorT<TurbofanAdapter>::VisitWord64AtomicExchange(
+    Node* node) {
   AtomicOpParameters params = AtomicOpParametersOf(node->op());
   ArchOpcode opcode;
   if (params.type() == MachineType::Uint8()) {
@@ -4666,6 +4680,27 @@ void InstructionSelectorT<Adapter>::VisitWord64AtomicExchange(Node* node) {
   VisitAtomicExchange(this, node, opcode, AtomicWidth::kWord64, params.kind());
 }
 
+template <>
+void InstructionSelectorT<TurboshaftAdapter>::VisitWord64AtomicExchange(
+    node_t node) {
+  using namespace turboshaft;  // NOLINT(build/namespaces)
+  const AtomicRMWOp& atomic_op = this->Get(node).template Cast<AtomicRMWOp>();
+  ArchOpcode opcode;
+  if (atomic_op.input_rep == MemoryRepresentation::Uint8()) {
+    opcode = kAtomicExchangeUint8;
+  } else if (atomic_op.input_rep == MemoryRepresentation::Uint16()) {
+    opcode = kAtomicExchangeUint16;
+  } else if (atomic_op.input_rep == MemoryRepresentation::Uint32()) {
+    opcode = kAtomicExchangeWord32;
+  } else if (atomic_op.input_rep == MemoryRepresentation::Uint64()) {
+    opcode = kX64Word64AtomicExchangeUint64;
+  } else {
+    UNREACHABLE();
+  }
+  VisitAtomicExchange(this, node, opcode, AtomicWidth::kWord64,
+                      atomic_op.memory_access_kind);
+}
+
 template <>
 void InstructionSelectorT<TurbofanAdapter>::VisitWord32AtomicCompareExchange(
     Node* node) {
@@ -4689,6 +4724,30 @@ void InstructionSelectorT<TurbofanAdapter>::VisitWord32AtomicCompareExchange(
                              params.kind());
 }
 
+template <>
+void InstructionSelectorT<TurboshaftAdapter>::VisitWord32AtomicCompareExchange(
+    node_t node) {
+  using namespace turboshaft;  // NOLINT(build/namespaces)
+  const AtomicRMWOp& atomic_op = this->Get(node).template Cast<AtomicRMWOp>();
+  ArchOpcode opcode;
+  if (atomic_op.input_rep == MemoryRepresentation::Int8()) {
+    opcode = kAtomicCompareExchangeInt8;
+  } else if (atomic_op.input_rep == MemoryRepresentation::Uint8()) {
+    opcode = kAtomicCompareExchangeUint8;
+  } else if (atomic_op.input_rep == MemoryRepresentation::Int16()) {
+    opcode = kAtomicCompareExchangeInt16;
+  } else if (atomic_op.input_rep == MemoryRepresentation::Uint16()) {
+    opcode = kAtomicCompareExchangeUint16;
+  } else if (atomic_op.input_rep == MemoryRepresentation::Int32() ||
+             atomic_op.input_rep == MemoryRepresentation::Uint32()) {
+    opcode = kAtomicCompareExchangeWord32;
+  } else {
+    UNREACHABLE();
+  }
+  VisitAtomicCompareExchange(this, node, opcode, AtomicWidth::kWord32,
+                             atomic_op.memory_access_kind);
+}
+
 template <>
 void InstructionSelectorT<TurbofanAdapter>::VisitWord64AtomicCompareExchange(
     Node* node) {
@@ -4709,11 +4768,50 @@ void InstructionSelectorT<TurbofanAdapter>::VisitWord64AtomicCompareExchange(
                              params.kind());
 }
 
+template <>
+void InstructionSelectorT<TurboshaftAdapter>::VisitWord64AtomicCompareExchange(
+    node_t node) {
+  using namespace turboshaft;  // NOLINT(build/namespaces)
+  const AtomicRMWOp& atomic_op = this->Get(node).template Cast<AtomicRMWOp>();
+  ArchOpcode opcode;
+  if (atomic_op.input_rep == MemoryRepresentation::Uint8()) {
+    opcode = kAtomicCompareExchangeUint8;
+  } else if (atomic_op.input_rep == MemoryRepresentation::Uint16()) {
+    opcode = kAtomicCompareExchangeUint16;
+  } else if (atomic_op.input_rep == MemoryRepresentation::Uint32()) {
+    opcode = kAtomicCompareExchangeWord32;
+  } else if (atomic_op.input_rep == MemoryRepresentation::Uint64()) {
+    opcode = kX64Word64AtomicCompareExchangeUint64;
+  } else {
+    UNREACHABLE();
+  }
+  VisitAtomicCompareExchange(this, node, opcode, AtomicWidth::kWord64,
+                             atomic_op.memory_access_kind);
+}
+
 template <>
 void InstructionSelectorT<TurboshaftAdapter>::VisitWord32AtomicBinaryOperation(
     turboshaft::OpIndex node, ArchOpcode int8_op, ArchOpcode uint8_op,
     ArchOpcode int16_op, ArchOpcode uint16_op, ArchOpcode word32_op) {
-  UNIMPLEMENTED();
+  using namespace turboshaft;  // NOLINT(build/namespaces)
+  const AtomicRMWOp& atomic_op = this->Get(node).template Cast<AtomicRMWOp>();
+  ArchOpcode opcode;
+  if (atomic_op.input_rep == MemoryRepresentation::Int8()) {
+    opcode = int8_op;
+  } else if (atomic_op.input_rep == MemoryRepresentation::Uint8()) {
+    opcode = uint8_op;
+  } else if (atomic_op.input_rep == MemoryRepresentation::Int16()) {
+    opcode = int16_op;
+  } else if (atomic_op.input_rep == MemoryRepresentation::Uint16()) {
+    opcode = uint16_op;
+  } else if (atomic_op.input_rep == MemoryRepresentation::Int32() ||
+             atomic_op.input_rep == MemoryRepresentation::Uint32()) {
+    opcode = word32_op;
+  } else {
+    UNREACHABLE();
+  }
+  VisitAtomicBinop(this, node, opcode, AtomicWidth::kWord32,
+                   atomic_op.memory_access_kind);
 }
 
 template <>
@@ -4739,12 +4837,12 @@ void InstructionSelectorT<TurbofanAdapter>::VisitWord32AtomicBinaryOperation(
   VisitAtomicBinop(this, node, opcode, AtomicWidth::kWord32, params.kind());
 }
 
-#define VISIT_ATOMIC_BINOP(op)                                            \
-  template <typename Adapter>                                             \
-  void InstructionSelectorT<Adapter>::VisitWord32Atomic##op(Node* node) { \
-    VisitWord32AtomicBinaryOperation(                                     \
-        node, kAtomic##op##Int8, kAtomic##op##Uint8, kAtomic##op##Int16,  \
-        kAtomic##op##Uint16, kAtomic##op##Word32);                        \
+#define VISIT_ATOMIC_BINOP(op)                                             \
+  template <typename Adapter>                                              \
+  void InstructionSelectorT<Adapter>::VisitWord32Atomic##op(node_t node) { \
+    VisitWord32AtomicBinaryOperation(                                      \
+        node, kAtomic##op##Int8, kAtomic##op##Uint8, kAtomic##op##Int16,   \
+        kAtomic##op##Uint16, kAtomic##op##Word32);                         \
   }
 VISIT_ATOMIC_BINOP(Add)
 VISIT_ATOMIC_BINOP(Sub)
@@ -4757,7 +4855,22 @@ template <>
 void InstructionSelectorT<TurboshaftAdapter>::VisitWord64AtomicBinaryOperation(
     node_t node, ArchOpcode uint8_op, ArchOpcode uint16_op,
     ArchOpcode uint32_op, ArchOpcode word64_op) {
-  UNIMPLEMENTED();
+  using namespace turboshaft;  // NOLINT(build/namespaces)
+  const AtomicRMWOp& atomic_op = this->Get(node).template Cast<AtomicRMWOp>();
+  ArchOpcode opcode;
+  if (atomic_op.input_rep == MemoryRepresentation::Uint8()) {
+    opcode = uint8_op;
+  } else if (atomic_op.input_rep == MemoryRepresentation::Uint16()) {
+    opcode = uint16_op;
+  } else if (atomic_op.input_rep == MemoryRepresentation::Uint32()) {
+    opcode = uint32_op;
+  } else if (atomic_op.input_rep == MemoryRepresentation::Uint64()) {
+    opcode = word64_op;
+  } else {
+    UNREACHABLE();
+  }
+  VisitAtomicBinop(this, node, opcode, AtomicWidth::kWord64,
+                   atomic_op.memory_access_kind);
 }
 
 template <>
@@ -4782,7 +4895,7 @@ void InstructionSelectorT<TurbofanAdapter>::VisitWord64AtomicBinaryOperation(
 
 #define VISIT_ATOMIC_BINOP(op)                                                 \
   template <typename Adapter>                                                  \
-  void InstructionSelectorT<Adapter>::VisitWord64Atomic##op(Node* node) {      \
+  void InstructionSelectorT<Adapter>::VisitWord64Atomic##op(node_t node) {     \
     VisitWord64AtomicBinaryOperation(node, kAtomic##op##Uint8,                 \
                                      kAtomic##op##Uint16, kAtomic##op##Word32, \
                                      kX64Word64Atomic##op##Uint64);            \
diff --git a/src/compiler/pipeline.cc b/src/compiler/pipeline.cc
index 588b0a834d2..71a3c3b678a 100644
--- a/src/compiler/pipeline.cc
+++ b/src/compiler/pipeline.cc
@@ -769,9 +769,7 @@ class PipelineImpl final {
   bool SelectInstructions(Linkage* linkage);
 
   // Substep B.2.turboshaft Select instructions from a turboshaft graph.
-  bool SelectInstructionsTurboshaft(
-      Linkage* linkage,
-      base::Optional<turboshaft::PipelineData::Scope>& turboshaft_scope);
+  bool SelectInstructionsTurboshaft(Linkage* linkage);
 
   // Substep B.3. Run register allocation on the instruction sequence.
   bool AllocateRegisters(CallDescriptor* call_descriptor,
@@ -3126,7 +3124,13 @@ bool PipelineImpl::OptimizeGraph(Linkage* linkage) {
 
     if (v8_flags.turboshaft_instruction_selection) {
       // Run Turboshaft instruction selection.
-      return SelectInstructionsTurboshaft(linkage, turboshaft_pipeline);
+      if (!SelectInstructionsTurboshaft(linkage)) {
+        return false;
+      }
+
+      turboshaft_pipeline.reset();
+      data->DeleteGraphZone();
+      return AllocateRegisters(linkage->GetIncomingDescriptor(), false);
     }
 
     // Otherwise, translate back to Turbofan and run instruction selection on
@@ -3757,11 +3761,11 @@ bool Pipeline::GenerateWasmCodeFromTurboshaftGraph(
   Linkage linkage(call_descriptor);
 
   {
-    turboshaft::PipelineData::Scope turboshaft_pipeline(
+    base::Optional<turboshaft::PipelineData::Scope> turboshaft_scope(
         pipeline.CreateTurboshaftPipeline());
-    turboshaft::PipelineData::Get().SetIsWasm(env->module,
-                                              compilation_data.func_body.sig);
-
+    auto& turboshaft_pipeline = turboshaft_scope.value();
+    turboshaft_pipeline.Value().SetIsWasm(env->module,
+                                          compilation_data.func_body.sig);
     DCHECK_NOT_NULL(turboshaft::PipelineData::Get().wasm_module());
 
     AccountingAllocator allocator;
@@ -3789,15 +3793,28 @@ bool Pipeline::GenerateWasmCodeFromTurboshaftGraph(
       pipeline.Run<turboshaft::Int64LoweringPhase>();
     }
 
-    auto [new_graph, new_schedule] =
-        pipeline.Run<turboshaft::RecreateSchedulePhase>(&linkage);
-    data.set_graph(new_graph);
-    data.set_schedule(new_schedule);
-    TraceSchedule(data.info(), &data, data.schedule(),
-                  turboshaft::RecreateSchedulePhase::phase_name());
+    if (v8_flags.turboshaft_wasm_instruction_selection) {
+      // Run Turboshaft instruction selection.
+      if (!pipeline.SelectInstructionsTurboshaft(&linkage)) {
+        return false;
+      }
+
+      turboshaft_scope.reset();
+      data.DeleteGraphZone();
+      pipeline.AllocateRegisters(linkage.GetIncomingDescriptor(), false);
+    } else {
+      auto [new_graph, new_schedule] =
+          pipeline.Run<turboshaft::RecreateSchedulePhase>(&linkage);
+      data.set_graph(new_graph);
+      data.set_schedule(new_schedule);
+      TraceSchedule(data.info(), &data, data.schedule(),
+                    turboshaft::RecreateSchedulePhase::phase_name());
+
+      turboshaft_scope.reset();
+      CHECK(pipeline.SelectInstructions(&linkage));
+    }
   }
 
-  CHECK(pipeline.SelectInstructions(&linkage));
   pipeline.AssembleCode(&linkage);
 
   auto result = std::make_unique<wasm::WasmCompilationResult>();
@@ -4096,9 +4113,7 @@ bool PipelineImpl::SelectInstructions(Linkage* linkage) {
   return AllocateRegisters(call_descriptor, true);
 }
 
-bool PipelineImpl::SelectInstructionsTurboshaft(
-    Linkage* linkage,
-    base::Optional<turboshaft::PipelineData::Scope>& turboshaft_scope) {
+bool PipelineImpl::SelectInstructionsTurboshaft(Linkage* linkage) {
   auto call_descriptor = linkage->GetIncomingDescriptor();
   PipelineData* turbofan_data = this->data_;
 
@@ -4124,6 +4139,8 @@ bool PipelineImpl::SelectInstructionsTurboshaft(
     return false;
   }
 
+  return true;
+
   // TODO(nicohartmann@): We might need to provide this.
   // if (info()->trace_turbo_json()) {
   //   UnparkedScopeIfNeeded scope(turbofan_data->broker());
@@ -4144,11 +4161,6 @@ bool PipelineImpl::SelectInstructionsTurboshaft(
   //   data_->node_origins()->PrintJson(source_position_output);
   //   data_->set_source_position_output(source_position_output.str());
   // }
-
-  turboshaft_scope.reset();
-  turbofan_data->DeleteGraphZone();
-
-  return AllocateRegisters(call_descriptor, false);
 }
 
 bool PipelineImpl::AllocateRegisters(CallDescriptor* call_descriptor,
diff --git a/src/compiler/turboshaft/operations.h b/src/compiler/turboshaft/operations.h
index 506f546c384..6ce50222e53 100644
--- a/src/compiler/turboshaft/operations.h
+++ b/src/compiler/turboshaft/operations.h
@@ -2672,6 +2672,7 @@ struct AtomicRMWOp : OperationT<AtomicRMWOp> {
     return std::tuple{bin_op, result_rep, input_rep, memory_access_kind};
   }
 };
+DEFINE_MULTI_SWITCH_INTEGRAL(AtomicRMWOp::BinOp, 8)
 
 std::ostream& operator<<(std::ostream& os, AtomicRMWOp::BinOp kind);
 
diff --git a/src/flags/flag-definitions.h b/src/flags/flag-definitions.h
index d5c4d18029d..6e667d1d227 100644
--- a/src/flags/flag-definitions.h
+++ b/src/flags/flag-definitions.h
@@ -1234,6 +1234,9 @@ DEFINE_EXPERIMENTAL_FEATURE(turboshaft_typed_optimizations,
 DEFINE_EXPERIMENTAL_FEATURE(
     turboshaft_instruction_selection,
     "run instruction selection on Turboshaft IR directly")
+DEFINE_EXPERIMENTAL_FEATURE(
+    turboshaft_wasm_instruction_selection,
+    "run instruction selection on Turboshaft IR directly for wasm")
 DEFINE_EXPERIMENTAL_FEATURE(turboshaft_load_elimination,
                             "enable Turboshaft's low-level load elimination")
 DEFINE_EXPERIMENTAL_FEATURE(turboshaft_machine_lowering_opt,
-- 
2.35.1

