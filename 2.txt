From eee76b8bd6b891ec9ecba6f69a4ca25357b9ef7b Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Dominik=20Inf=C3=BChr?= <dinfuehr@chromium.org>
Date: Wed, 22 May 2024 14:40:04 +0200
Subject: [PATCH] [heap] Speed up indirect pointer write barrier
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

This CL replaces the page flag checks in the indirect pointer write
barrier with directly checking the is_marking flag on the isolate.
The deferred code path is now only entered if marking is enabled,
while previously it was always entered when writing into old objects.
This should help in making the barrier faster and more cache-friendly.

We do not need page flag checks because we know that the value has
to be an ExposedTrustedObject and cannot be e.g. a read only object
like undefined.

This check is always precise except when the shared heap is enabled.
In this case is_marking may be true on client isolates for enabling
the shared marking barrier while incremental marking is not enabled
for this client isolate itself but only for the shared space/main
isolate. Should this ever become a problem, we can simply introduce a
"is_marking_local" flag that we could check instead.

Bug: 338342768
Change-Id: Ibe37352b1dc7f0bffa03b1cbfcbbd0597864c419
Reviewed-on: https://chromium-review.googlesource.com/c/v8/v8/+/5543923
Reviewed-by: Samuel Groß <saelo@chromium.org>
Reviewed-by: Michael Lippautz <mlippautz@chromium.org>
Commit-Queue: Dominik Inführ <dinfuehr@chromium.org>
Cr-Commit-Position: refs/heads/main@{#94030}
---
 src/builtins/builtins-internal-gen.cc         | 12 +---
 src/codegen/arm64/macro-assembler-arm64.cc    | 32 +++++++--
 src/codegen/arm64/macro-assembler-arm64.h     |  5 ++
 src/codegen/x64/macro-assembler-x64.cc        | 67 ++++++++++++-------
 src/codegen/x64/macro-assembler-x64.h         |  4 ++
 .../backend/arm64/code-generator-arm64.cc     | 11 +--
 .../backend/x64/code-generator-x64.cc         | 46 ++++++-------
 src/execution/isolate-data.h                  |  1 +
 src/heap/heap-write-barrier.cc                | 15 ++---
 9 files changed, 114 insertions(+), 79 deletions(-)

diff --git a/src/builtins/builtins-internal-gen.cc b/src/builtins/builtins-internal-gen.cc
index 361980114ec..1857c11b91e 100644
--- a/src/builtins/builtins-internal-gen.cc
+++ b/src/builtins/builtins-internal-gen.cc
@@ -243,14 +243,7 @@ class WriteBarrierCodeStubAssembler : public CodeStubAssembler {
   }
 
   void IndirectPointerWriteBarrier(SaveFPRegsMode fp_mode) {
-    // Currently, only objects living in (local) old space are referenced
-    // through a pointer table indirection and we have DCHECKs in the CPP write
-    // barrier code to check that. This simplifies the write barrier code for
-    // these cases.
-    Label marking_is_on(this), next(this);
-    Branch(IsMarking(), &marking_is_on, &next);
-
-    BIND(&marking_is_on);
+    CSA_DCHECK(this, IsMarking());
 
     // For this barrier, the slot contains an index into a pointer table and not
     // directly a pointer to a HeapObject. Further, the slot address is tagged
@@ -271,9 +264,6 @@ class WriteBarrierCodeStubAssembler : public CodeStubAssembler {
         std::make_pair(MachineTypeOf<IntPtrT>::value, object),
         std::make_pair(MachineTypeOf<IntPtrT>::value, slot),
         std::make_pair(MachineTypeOf<IntPtrT>::value, tag));
-    Goto(&next);
-
-    BIND(&next);
   }
 
   void GenerationalOrSharedBarrierSlow(TNode<IntPtrT> slot, Label* next,
diff --git a/src/codegen/arm64/macro-assembler-arm64.cc b/src/codegen/arm64/macro-assembler-arm64.cc
index 36b0a8782fe..4c26bc0ff64 100644
--- a/src/codegen/arm64/macro-assembler-arm64.cc
+++ b/src/codegen/arm64/macro-assembler-arm64.cc
@@ -3522,6 +3522,24 @@ void MacroAssembler::CheckPageFlag(const Register& object, int mask,
   }
 }
 
+void MacroAssembler::JumpIfMarking(Label* is_marking,
+                                   Label::Distance condition_met_distance) {
+  UseScratchRegisterScope temps(this);
+  Register scratch = temps.AcquireX();
+  Ldrb(scratch,
+       MemOperand(kRootRegister, IsolateData::is_marking_flag_offset()));
+  Cbnz(scratch, is_marking);
+}
+
+void MacroAssembler::JumpIfNotMarking(Label* not_marking,
+                                      Label::Distance condition_met_distance) {
+  UseScratchRegisterScope temps(this);
+  Register scratch = temps.AcquireX();
+  Ldrb(scratch,
+       MemOperand(kRootRegister, IsolateData::is_marking_flag_offset()));
+  Cbz(scratch, not_marking);
+}
+
 void MacroAssembler::RecordWriteField(Register object, int offset,
                                       Register value,
                                       LinkRegisterStatus lr_status,
@@ -3934,11 +3952,17 @@ void MacroAssembler::RecordWrite(Register object, Operand offset,
     DCHECK_EQ(0, kSmiTag);
     JumpIfSmi(value, &done);
   }
-  CheckPageFlag(value, MemoryChunk::kPointersToHereAreInterestingMask, eq,
-                &done);
 
-  CheckPageFlag(object, MemoryChunk::kPointersFromHereAreInterestingMask, eq,
-                &done);
+  if (slot.contains_indirect_pointer()) {
+    // The indirect pointer write barrier is only enabled during marking.
+    JumpIfNotMarking(&done);
+  } else {
+    CheckPageFlag(value, MemoryChunk::kPointersToHereAreInterestingMask, eq,
+                  &done);
+
+    CheckPageFlag(object, MemoryChunk::kPointersFromHereAreInterestingMask, eq,
+                  &done);
+  }
 
   // Record the actual write.
   if (lr_status == kLRHasNotBeenSaved) {
diff --git a/src/codegen/arm64/macro-assembler-arm64.h b/src/codegen/arm64/macro-assembler-arm64.h
index 39121d4ffc8..2cf8c14ae99 100644
--- a/src/codegen/arm64/macro-assembler-arm64.h
+++ b/src/codegen/arm64/macro-assembler-arm64.h
@@ -1001,6 +1001,11 @@ class V8_EXPORT_PRIVATE MacroAssembler : public MacroAssemblerBase {
   inline void JumpIfEqual(Register x, int32_t y, Label* dest);
   inline void JumpIfLessThan(Register x, int32_t y, Label* dest);
 
+  void JumpIfMarking(Label* is_marking,
+                     Label::Distance condition_met_distance = Label::kFar);
+  void JumpIfNotMarking(Label* not_marking,
+                        Label::Distance condition_met_distance = Label::kFar);
+
   void LoadMap(Register dst, Register object);
   void LoadCompressedMap(Register dst, Register object);
 
diff --git a/src/codegen/x64/macro-assembler-x64.cc b/src/codegen/x64/macro-assembler-x64.cc
index eddb974de88..0df5b1f366e 100644
--- a/src/codegen/x64/macro-assembler-x64.cc
+++ b/src/codegen/x64/macro-assembler-x64.cc
@@ -876,34 +876,37 @@ void MacroAssembler::RecordWrite(Register object, Register slot_address,
     JumpIfSmi(value, &done);
   }
 
+  if (slot.contains_indirect_pointer()) {
+    // The indirect pointer write barrier is only enabled during marking.
+    JumpIfNotMarking(&done);
+  } else {
 #if V8_ENABLE_STICKY_MARK_BITS_BOOL
-  DCHECK(!AreAliased(kScratchRegister, object, slot_address, value));
-  Label stub_call;
-
-  testb(Operand(kRootRegister, IsolateData::is_marking_flag_offset()),
-        Immediate(static_cast<uint8_t>(1)));
-  j(not_zero, &stub_call, Label::kFar);
-
-  // Save the slot_address in the xmm scratch register.
-  movq(kScratchDoubleReg, slot_address);
-  Register scratch0 = slot_address;
-  CheckMarkBit(object, kScratchRegister, scratch0, carry, &done);
-  CheckPageFlag(value, kScratchRegister, MemoryChunk::kIsInReadOnlyHeapMask,
-                not_zero, &done, Label::kFar);
-  CheckMarkBit(value, kScratchRegister, scratch0, carry, &done);
-  movq(slot_address, kScratchDoubleReg);
-  bind(&stub_call);
+    DCHECK(!AreAliased(kScratchRegister, object, slot_address, value));
+    Label stub_call;
+
+    JumpIfMarking(&stub_call);
+
+    // Save the slot_address in the xmm scratch register.
+    movq(kScratchDoubleReg, slot_address);
+    Register scratch0 = slot_address;
+    CheckMarkBit(object, kScratchRegister, scratch0, carry, &done);
+    CheckPageFlag(value, kScratchRegister, MemoryChunk::kIsInReadOnlyHeapMask,
+                  not_zero, &done, Label::kFar);
+    CheckMarkBit(value, kScratchRegister, scratch0, carry, &done);
+    movq(slot_address, kScratchDoubleReg);
+    bind(&stub_call);
 #else   // !V8_ENABLE_STICKY_MARK_BITS_BOOL
-  CheckPageFlag(value,
-                value,  // Used as scratch.
-                MemoryChunk::kPointersToHereAreInterestingMask, zero, &done,
-                Label::kNear);
-
-  CheckPageFlag(object,
-                value,  // Used as scratch.
-                MemoryChunk::kPointersFromHereAreInterestingMask, zero, &done,
-                Label::kNear);
+    CheckPageFlag(value,
+                  value,  // Used as scratch.
+                  MemoryChunk::kPointersToHereAreInterestingMask, zero, &done,
+                  Label::kNear);
+
+    CheckPageFlag(object,
+                  value,  // Used as scratch.
+                  MemoryChunk::kPointersFromHereAreInterestingMask, zero, &done,
+                  Label::kNear);
 #endif  // !V8_ENABLE_STICKY_MARK_BITS_BOOL
+  }
 
   if (slot.contains_direct_pointer()) {
     CallRecordWriteStub(object, slot_address, fp_mode,
@@ -4244,6 +4247,20 @@ void MacroAssembler::CheckPageFlag(Register object, Register scratch, int mask,
   j(cc, condition_met, condition_met_distance);
 }
 
+void MacroAssembler::JumpIfMarking(Label* is_marking,
+                                   Label::Distance condition_met_distance) {
+  testb(Operand(kRootRegister, IsolateData::is_marking_flag_offset()),
+        Immediate(static_cast<uint8_t>(1)));
+  j(not_zero, is_marking, condition_met_distance);
+}
+
+void MacroAssembler::JumpIfNotMarking(Label* not_marking,
+                                      Label::Distance condition_met_distance) {
+  testb(Operand(kRootRegister, IsolateData::is_marking_flag_offset()),
+        Immediate(static_cast<uint8_t>(1)));
+  j(zero, not_marking, condition_met_distance);
+}
+
 void MacroAssembler::CheckMarkBit(Register object, Register scratch0,
                                   Register scratch1, Condition cc,
                                   Label* condition_met,
diff --git a/src/codegen/x64/macro-assembler-x64.h b/src/codegen/x64/macro-assembler-x64.h
index ae7dd84e25f..678ed76157a 100644
--- a/src/codegen/x64/macro-assembler-x64.h
+++ b/src/codegen/x64/macro-assembler-x64.h
@@ -133,6 +133,10 @@ class V8_EXPORT_PRIVATE MacroAssembler
   void CheckMarkBit(Register object, Register scratch0, Register scratch1,
                     Condition cc, Label* condition_met,
                     Label::Distance condition_met_distance = Label::kFar);
+  void JumpIfMarking(Label* is_marking,
+                     Label::Distance condition_met_distance = Label::kFar);
+  void JumpIfNotMarking(Label* not_marking,
+                        Label::Distance condition_met_distance = Label::kFar);
 
   // Define movq here instead of using AVX_OP. movq is defined using templates
   // and there is a function template `void movq(P1)`, while technically
diff --git a/src/compiler/backend/arm64/code-generator-arm64.cc b/src/compiler/backend/arm64/code-generator-arm64.cc
index ccb56b479af..5e88ed44bb0 100644
--- a/src/compiler/backend/arm64/code-generator-arm64.cc
+++ b/src/compiler/backend/arm64/code-generator-arm64.cc
@@ -330,8 +330,12 @@ class OutOfLineRecordWrite final : public OutOfLineCode {
       __ DecompressTagged(value_, value_);
     }
 
-    __ CheckPageFlag(value_, MemoryChunk::kPointersToHereAreInterestingMask, eq,
-                     exit());
+    // No need to check value page flags with the indirect pointer write barrier
+    // because the value is always an ExposedTrustedObject.
+    if (mode_ != RecordWriteMode::kValueIsIndirectPointer) {
+      __ CheckPageFlag(value_, MemoryChunk::kPointersToHereAreInterestingMask,
+                       eq, exit());
+    }
 
     SaveFPRegsMode const save_fp_mode = frame()->DidAllocateDoubleRegisters()
                                             ? SaveFPRegsMode::kSave
@@ -1133,8 +1137,7 @@ CodeGenerator::CodeGenResult CodeGenerator::AssembleArchInstruction(
           &unwinding_info_writer_, tag);
       RecordTrapInfoIfNeeded(zone(), this, opcode, instr, __ pc_offset());
       __ StoreIndirectPointerField(value, MemOperand(object, offset));
-      __ CheckPageFlag(object, MemoryChunk::kPointersFromHereAreInterestingMask,
-                       ne, ool->entry());
+      __ JumpIfMarking(ool->entry());
       __ Bind(ool->exit());
       break;
     }
diff --git a/src/compiler/backend/x64/code-generator-x64.cc b/src/compiler/backend/x64/code-generator-x64.cc
index fce1917744a..e06561dafa2 100644
--- a/src/compiler/backend/x64/code-generator-x64.cc
+++ b/src/compiler/backend/x64/code-generator-x64.cc
@@ -403,26 +403,30 @@ class OutOfLineRecordWrite final : public OutOfLineCode {
       __ DecompressTagged(value_, value_);
     }
 
+    // No need to check value page flags with the indirect pointer write barrier
+    // because the value is always an ExposedTrustedObject.
+    if (mode_ != RecordWriteMode::kValueIsIndirectPointer) {
 #if V8_ENABLE_STICKY_MARK_BITS_BOOL
-    // TODO(333906585): Optimize this path.
-    Label stub_call_with_decompressed_value;
-    __ CheckPageFlag(value_, scratch0_, MemoryChunk::kIsInReadOnlyHeapMask,
-                     not_zero, exit());
-    __ CheckMarkBit(value_, scratch0_, scratch1_, carry, exit());
-    __ jmp(&stub_call_with_decompressed_value);
-
-    __ bind(&stub_call_);
-    if (COMPRESS_POINTERS_BOOL &&
-        mode_ != RecordWriteMode::kValueIsIndirectPointer) {
-      __ DecompressTagged(value_, value_);
-    }
+      // TODO(333906585): Optimize this path.
+      Label stub_call_with_decompressed_value;
+      __ CheckPageFlag(value_, scratch0_, MemoryChunk::kIsInReadOnlyHeapMask,
+                       not_zero, exit());
+      __ CheckMarkBit(value_, scratch0_, scratch1_, carry, exit());
+      __ jmp(&stub_call_with_decompressed_value);
 
-    __ bind(&stub_call_with_decompressed_value);
+      __ bind(&stub_call_);
+      if (COMPRESS_POINTERS_BOOL &&
+          mode_ != RecordWriteMode::kValueIsIndirectPointer) {
+        __ DecompressTagged(value_, value_);
+      }
+
+      __ bind(&stub_call_with_decompressed_value);
 #else   // !V8_ENABLE_STICKY_MARK_BITS_BOOL
-    __ CheckPageFlag(value_, scratch0_,
-                     MemoryChunk::kPointersToHereAreInterestingMask, zero,
-                     exit());
+      __ CheckPageFlag(value_, scratch0_,
+                       MemoryChunk::kPointersToHereAreInterestingMask, zero,
+                       exit());
 #endif  // !V8_ENABLE_STICKY_MARK_BITS_BOOL
+    }
 
     __ leaq(scratch1_, operand_);
 
@@ -1794,15 +1798,7 @@ CodeGenerator::CodeGenResult CodeGenerator::AssembleArchInstruction(
       EmitTSANAwareStore<std::memory_order_relaxed>(
           zone(), this, masm(), operand, value, i, DetermineStubCallMode(),
           MachineRepresentation::kIndirectPointer, instr);
-#if V8_ENABLE_STICKY_MARK_BITS_BOOL
-      __ CheckPageFlag(object, scratch0, MemoryChunk::kIncrementalMarking,
-                       not_zero, ool->stub_call());
-      __ CheckMarkBit(object, scratch0, scratch1, carry, ool->entry());
-#else   // !V8_ENABLE_STICKY_MARK_BITS_BOOL
-      __ CheckPageFlag(object, scratch0,
-                       MemoryChunk::kPointersFromHereAreInterestingMask,
-                       not_zero, ool->entry());
-#endif  // !V8_ENABLE_STICKY_MARK_BITS_BOOL
+      __ JumpIfMarking(ool->entry());
       __ bind(ool->exit());
       break;
     }
diff --git a/src/execution/isolate-data.h b/src/execution/isolate-data.h
index c7c43749052..7d8f4470b8a 100644
--- a/src/execution/isolate-data.h
+++ b/src/execution/isolate-data.h
@@ -210,6 +210,7 @@ class IsolateData final {
     DCHECK(stack_is_iterable_ == 0 || stack_is_iterable_ == 1);
     return stack_is_iterable_ != 0;
   }
+  bool is_marking() const { return is_marking_flag_; }
 
   // Returns true if this address points to data stored in this instance. If
   // it's the case then the value can be accessed indirectly through the root
diff --git a/src/heap/heap-write-barrier.cc b/src/heap/heap-write-barrier.cc
index 2b779f3c718..4838cff6479 100644
--- a/src/heap/heap-write-barrier.cc
+++ b/src/heap/heap-write-barrier.cc
@@ -161,17 +161,12 @@ int WriteBarrier::IndirectPointerMarkingFromCode(Address raw_host,
   IndirectPointerSlot slot(raw_slot, tag);
 
 #if DEBUG
-  Heap* heap = MutablePageMetadata::FromHeapObject(host)->heap();
-  DCHECK(heap->incremental_marking()->IsMarking());
-
-  // We will only reach local objects here while incremental marking in the
-  // current isolate is enabled. However, we might still reach objects in the
-  // shared space but only from the shared space isolate (= the main isolate).
+  DCHECK(!InWritableSharedSpace(host));
   MarkingBarrier* barrier = CurrentMarkingBarrier(host);
-  DCHECK_IMPLIES(InWritableSharedSpace(host),
-                 barrier->heap()->isolate()->is_shared_space_isolate());
-  barrier->AssertMarkingIsActivated();
-#endif  // DEBUG
+  DCHECK(barrier->heap()->isolate()->isolate_data()->is_marking());
+
+  DCHECK(IsExposedTrustedObject(slot.load(barrier->heap()->isolate())));
+#endif
 
   WriteBarrier::Marking(host, slot);
   // Called by WriteBarrierCodeStubAssembler, which doesn't accept void type
-- 
2.35.1

